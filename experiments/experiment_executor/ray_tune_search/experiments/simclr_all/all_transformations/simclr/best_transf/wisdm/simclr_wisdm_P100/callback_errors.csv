trial_id,config,error_type,error_message,error_traceback
a1973d84,"{'min_delta': 0.394, 'temperature': 0.8, 'batch_size': 415, 'latent_dim': 212}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 770.00 MiB memory in use. Process 1539216 has 922.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 724.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 770.00 MiB memory in use. Process 1542433 has 744.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 942.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 554.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 554.00 MiB memory in use. Process 1543600 has 466.00 MiB memory in use. Process 1543606 has 508.00 MiB memory in use. Process 1543612 has 464.00 MiB memory in use. Process 1543605 has 442.00 MiB memory in use. Process 1543609 has 490.00 MiB memory in use. Of the allocated memory 83.64 MiB is allocated by PyTorch, and 44.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1cd2ad63,"{'min_delta': 0.495, 'temperature': 1.6, 'batch_size': 134, 'latent_dim': 285}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 770.00 MiB memory in use. Process 1539216 has 922.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 730.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 770.00 MiB memory in use. Process 1542433 has 744.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 942.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 554.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 442.00 MiB memory in use. Process 1543600 has 424.00 MiB memory in use. Process 1543606 has 458.00 MiB memory in use. Process 1543612 has 468.00 MiB memory in use. Process 1543605 has 548.00 MiB memory in use. Process 1543609 has 578.00 MiB memory in use. Of the allocated memory 49.21 MiB is allocated by PyTorch, and 36.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2fb32460,"{'min_delta': 0.01, 'temperature': 0.7000000000000001, 'batch_size': 491, 'latent_dim': 305}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 770.00 MiB memory in use. Process 1539216 has 922.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 730.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 744.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 942.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 524.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 442.00 MiB memory in use. Process 1543600 has 424.00 MiB memory in use. Process 1543606 has 510.00 MiB memory in use. Process 1543612 has 468.00 MiB memory in use. Process 1543605 has 548.00 MiB memory in use. Process 1543609 has 566.00 MiB memory in use. Of the allocated memory 146.70 MiB is allocated by PyTorch, and 39.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
70655493,"{'min_delta': 0.253, 'temperature': 1.5, 'batch_size': 189, 'latent_dim': 319}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 148.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 770.00 MiB memory in use. Process 1539216 has 922.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 680.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 744.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 942.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 524.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 442.00 MiB memory in use. Process 1543600 has 482.00 MiB memory in use. Process 1543606 has 510.00 MiB memory in use. Process 1543612 has 468.00 MiB memory in use. Process 1543605 has 548.00 MiB memory in use. Process 1543609 has 442.00 MiB memory in use. Of the allocated memory 278.77 MiB is allocated by PyTorch, and 63.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5740735d,"{'min_delta': 0.532, 'temperature': 1.6, 'batch_size': 310, 'latent_dim': 165}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 770.00 MiB memory in use. Process 1539216 has 922.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 466.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 910.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 942.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 472.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 442.00 MiB memory in use. Process 1543600 has 456.00 MiB memory in use. Process 1543606 has 562.00 MiB memory in use. Process 1543612 has 650.00 MiB memory in use. Process 1543605 has 548.00 MiB memory in use. Process 1543609 has 444.00 MiB memory in use. Of the allocated memory 83.27 MiB is allocated by PyTorch, and 34.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
19279797,"{'min_delta': 0.126, 'temperature': 0.8, 'batch_size': 439, 'latent_dim': 42}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 770.00 MiB memory in use. Process 1539216 has 922.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 442.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 912.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 942.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 472.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 456.00 MiB memory in use. Process 1543600 has 490.00 MiB memory in use. Process 1543606 has 466.00 MiB memory in use. Process 1543612 has 714.00 MiB memory in use. Process 1543605 has 548.00 MiB memory in use. Process 1543609 has 462.00 MiB memory in use. Of the allocated memory 82.31 MiB is allocated by PyTorch, and 21.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fc721932,"{'min_delta': 0.664, 'temperature': 1.4000000000000001, 'batch_size': 208, 'latent_dim': 301}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 770.00 MiB memory in use. Process 1539216 has 922.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 442.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 912.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 942.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 458.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 456.00 MiB memory in use. Process 1543600 has 508.00 MiB memory in use. Process 1543606 has 466.00 MiB memory in use. Process 1543612 has 714.00 MiB memory in use. Process 1543605 has 548.00 MiB memory in use. Process 1543609 has 462.00 MiB memory in use. Of the allocated memory 84.34 MiB is allocated by PyTorch, and 35.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
54d82545,"{'min_delta': 0.861, 'temperature': 1.6, 'batch_size': 347, 'latent_dim': 61}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 750.00 MiB memory in use. Process 1539216 has 922.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 424.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 942.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 504.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 446.00 MiB memory in use. Process 1543600 has 508.00 MiB memory in use. Process 1543606 has 430.00 MiB memory in use. Process 1543612 has 708.00 MiB memory in use. Process 1543605 has 604.00 MiB memory in use. Process 1543609 has 508.00 MiB memory in use. Of the allocated memory 75.04 MiB is allocated by PyTorch, and 10.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
f87a1db1,"{'min_delta': 0.185, 'temperature': 1.6, 'batch_size': 267, 'latent_dim': 268}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 460.00 MiB memory in use. Process 1539216 has 922.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 488.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 942.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 502.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 440.00 MiB memory in use. Process 1543600 has 508.00 MiB memory in use. Process 1543606 has 484.00 MiB memory in use. Process 1543612 has 760.00 MiB memory in use. Process 1543605 has 498.00 MiB memory in use. Process 1543609 has 752.00 MiB memory in use. Of the allocated memory 96.41 MiB is allocated by PyTorch, and 67.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
a45e9d90,"{'min_delta': 0.194, 'temperature': 0.30000000000000004, 'batch_size': 478, 'latent_dim': 306}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 458.00 MiB memory in use. Process 1539216 has 922.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 488.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 942.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 478.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 466.00 MiB memory in use. Process 1543600 has 508.00 MiB memory in use. Process 1543606 has 464.00 MiB memory in use. Process 1543612 has 762.00 MiB memory in use. Process 1543605 has 514.00 MiB memory in use. Process 1543609 has 752.00 MiB memory in use. Of the allocated memory 96.71 MiB is allocated by PyTorch, and 73.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
c52c5ead,"{'min_delta': 0.065, 'temperature': 1.7000000000000002, 'batch_size': 440, 'latent_dim': 105}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 512.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 488.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 942.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 452.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 460.00 MiB memory in use. Process 1543600 has 486.00 MiB memory in use. Process 1543606 has 468.00 MiB memory in use. Process 1543612 has 766.00 MiB memory in use. Process 1543605 has 468.00 MiB memory in use. Process 1543609 has 752.00 MiB memory in use. Of the allocated memory 82.80 MiB is allocated by PyTorch, and 31.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
01e020fe,"{'min_delta': 0.249, 'temperature': 0.2, 'batch_size': 344, 'latent_dim': 241}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 512.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 512.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 942.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 452.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 460.00 MiB memory in use. Process 1543600 has 486.00 MiB memory in use. Process 1543606 has 468.00 MiB memory in use. Process 1543612 has 766.00 MiB memory in use. Process 1543605 has 468.00 MiB memory in use. Process 1543609 has 752.00 MiB memory in use. Of the allocated memory 146.20 MiB is allocated by PyTorch, and 27.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d49bbe66,"{'min_delta': 0.11800000000000001, 'temperature': 1.3, 'batch_size': 412, 'latent_dim': 133}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 508.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 512.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 942.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 452.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 480.00 MiB memory in use. Process 1543600 has 458.00 MiB memory in use. Process 1543606 has 462.00 MiB memory in use. Process 1543612 has 766.00 MiB memory in use. Process 1543605 has 468.00 MiB memory in use. Process 1543609 has 752.00 MiB memory in use. Of the allocated memory 83.02 MiB is allocated by PyTorch, and 36.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a2c37a4e,"{'min_delta': 0.683, 'temperature': 1.3, 'batch_size': 398, 'latent_dim': 185}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 116.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 464.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 454.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 942.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 810.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 464.00 MiB memory in use. Process 1543600 has 462.00 MiB memory in use. Process 1543606 has 464.00 MiB memory in use. Process 1543612 has 458.00 MiB memory in use. Process 1543605 has 548.00 MiB memory in use. Process 1543609 has 752.00 MiB memory in use. Of the allocated memory 393.73 MiB is allocated by PyTorch, and 78.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
aeb06c0b,"{'min_delta': 0.317, 'temperature': 0.6000000000000001, 'batch_size': 352, 'latent_dim': 32}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 464.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 448.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 942.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 810.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 472.00 MiB memory in use. Process 1543600 has 462.00 MiB memory in use. Process 1543606 has 464.00 MiB memory in use. Process 1543612 has 458.00 MiB memory in use. Process 1543605 has 548.00 MiB memory in use. Process 1543609 has 752.00 MiB memory in use. Of the allocated memory 82.23 MiB is allocated by PyTorch, and 27.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3661d966,"{'min_delta': 0.016, 'temperature': 1.9000000000000001, 'batch_size': 136, 'latent_dim': 132}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 490.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 416.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 942.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 458.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 514.00 MiB memory in use. Process 1543600 has 812.00 MiB memory in use. Process 1543606 has 444.00 MiB memory in use. Process 1543612 has 458.00 MiB memory in use. Process 1543605 has 548.00 MiB memory in use. Process 1543609 has 752.00 MiB memory in use. Of the allocated memory 71.21 MiB is allocated by PyTorch, and 6.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
509607f5,"{'min_delta': 0.363, 'temperature': 1.1, 'batch_size': 261, 'latent_dim': 79}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 460.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 464.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 912.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 424.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 514.00 MiB memory in use. Process 1543600 has 812.00 MiB memory in use. Process 1543606 has 442.00 MiB memory in use. Process 1543612 has 468.00 MiB memory in use. Process 1543605 has 548.00 MiB memory in use. Process 1543609 has 752.00 MiB memory in use. Of the allocated memory 47.60 MiB is allocated by PyTorch, and 38.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f35e4a23,"{'min_delta': 0.444, 'temperature': 1.0, 'batch_size': 281, 'latent_dim': 122}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 456.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 438.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 912.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 456.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 458.00 MiB memory in use. Process 1543600 has 812.00 MiB memory in use. Process 1543606 has 442.00 MiB memory in use. Process 1543612 has 462.00 MiB memory in use. Process 1543605 has 614.00 MiB memory in use. Process 1543609 has 752.00 MiB memory in use. Of the allocated memory 82.93 MiB is allocated by PyTorch, and 17.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f30b54ef,"{'min_delta': 0.314, 'temperature': 2.0, 'batch_size': 238, 'latent_dim': 164}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 438.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 476.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 912.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 422.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 648.00 MiB memory in use. Process 1543600 has 812.00 MiB memory in use. Process 1543606 has 444.00 MiB memory in use. Process 1543612 has 454.00 MiB memory in use. Process 1543605 has 442.00 MiB memory in use. Process 1543609 has 752.00 MiB memory in use. Of the allocated memory 48.26 MiB is allocated by PyTorch, and 35.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9813e033,"{'min_delta': 0.001, 'temperature': 0.4, 'batch_size': 219, 'latent_dim': 106}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 442.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 476.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 454.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 912.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 436.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 696.00 MiB memory in use. Process 1543600 has 812.00 MiB memory in use. Process 1543606 has 444.00 MiB memory in use. Process 1543612 has 454.00 MiB memory in use. Process 1543605 has 728.00 MiB memory in use. Process 1543609 has 752.00 MiB memory in use. Of the allocated memory 75.73 MiB is allocated by PyTorch, and 22.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
5420b4d7,"{'min_delta': 0.067, 'temperature': 1.1, 'batch_size': 375, 'latent_dim': 67}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 442.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 512.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 468.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 912.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 436.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 696.00 MiB memory in use. Process 1543600 has 812.00 MiB memory in use. Process 1543606 has 426.00 MiB memory in use. Process 1543612 has 420.00 MiB memory in use. Process 1543605 has 728.00 MiB memory in use. Process 1543609 has 752.00 MiB memory in use. Of the allocated memory 144.84 MiB is allocated by PyTorch, and 29.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
60cf1e53,"{'min_delta': 0.549, 'temperature': 1.0, 'batch_size': 504, 'latent_dim': 5}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 442.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 512.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 432.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 912.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 452.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 706.00 MiB memory in use. Process 1543600 has 812.00 MiB memory in use. Process 1543606 has 436.00 MiB memory in use. Process 1543612 has 420.00 MiB memory in use. Process 1543605 has 728.00 MiB memory in use. Process 1543609 has 752.00 MiB memory in use. Of the allocated memory 74.57 MiB is allocated by PyTorch, and 39.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
6cf8ebaf,"{'min_delta': 0.12, 'temperature': 1.2000000000000002, 'batch_size': 468, 'latent_dim': 3}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 442.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 422.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 432.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 912.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 452.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 706.00 MiB memory in use. Process 1543600 has 812.00 MiB memory in use. Process 1543606 has 484.00 MiB memory in use. Process 1543612 has 458.00 MiB memory in use. Process 1543605 has 728.00 MiB memory in use. Process 1543609 has 752.00 MiB memory in use. Of the allocated memory 77.61 MiB is allocated by PyTorch, and 6.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 46, in calculate_loss
    logits = torch.cat([torch.cat([logits_ab, logits_aa], dim=1), torch.cat([logits_ba, logits_bb], dim=1)], dim=0)
"
7feb48c8,"{'min_delta': 0.27, 'temperature': 1.8, 'batch_size': 162, 'latent_dim': 49}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 456.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 464.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 420.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 912.00 MiB memory in use. Process 1542830 has 904.00 MiB memory in use. Process 1543212 has 418.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 680.00 MiB memory in use. Process 1543600 has 812.00 MiB memory in use. Process 1543606 has 442.00 MiB memory in use. Process 1543612 has 476.00 MiB memory in use. Process 1543605 has 728.00 MiB memory in use. Process 1543609 has 752.00 MiB memory in use. Of the allocated memory 47.36 MiB is allocated by PyTorch, and 32.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
96b42947,"{'min_delta': 0.405, 'temperature': 0.8, 'batch_size': 452, 'latent_dim': 356}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 456.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 464.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 440.00 MiB memory in use. Process 1542433 has 860.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 912.00 MiB memory in use. Process 1542830 has 888.00 MiB memory in use. Process 1543212 has 508.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 700.00 MiB memory in use. Process 1543600 has 812.00 MiB memory in use. Process 1543606 has 530.00 MiB memory in use. Process 1543612 has 526.00 MiB memory in use. Process 1543605 has 730.00 MiB memory in use. Process 1543609 has 520.00 MiB memory in use. Of the allocated memory 501.51 MiB is allocated by PyTorch, and 48.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
03da44a2,"{'min_delta': 0.34500000000000003, 'temperature': 0.9, 'batch_size': 507, 'latent_dim': 195}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 726.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 464.00 MiB memory in use. Process 1542430 has 1.04 GiB memory in use. Process 1542439 has 440.00 MiB memory in use. Process 1542433 has 470.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 912.00 MiB memory in use. Process 1542830 has 916.00 MiB memory in use. Process 1543212 has 548.00 MiB memory in use. Process 1543209 has 786.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 700.00 MiB memory in use. Process 1543600 has 812.00 MiB memory in use. Process 1543606 has 588.00 MiB memory in use. Process 1543612 has 526.00 MiB memory in use. Process 1543605 has 730.00 MiB memory in use. Process 1543609 has 520.00 MiB memory in use. Of the allocated memory 145.84 MiB is allocated by PyTorch, and 64.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4b10fd0b,"{'min_delta': 0.59, 'temperature': 0.6000000000000001, 'batch_size': 189, 'latent_dim': 220}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 726.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 886.00 MiB memory in use. Process 1542430 has 510.00 MiB memory in use. Process 1542439 has 440.00 MiB memory in use. Process 1542433 has 704.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 912.00 MiB memory in use. Process 1542830 has 888.00 MiB memory in use. Process 1543212 has 614.00 MiB memory in use. Process 1543209 has 770.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 678.00 MiB memory in use. Process 1543600 has 812.00 MiB memory in use. Process 1543606 has 634.00 MiB memory in use. Process 1543612 has 504.00 MiB memory in use. Process 1543605 has 468.00 MiB memory in use. Process 1543609 has 600.00 MiB memory in use. Of the allocated memory 415.47 MiB is allocated by PyTorch, and 134.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6dc33312,"{'min_delta': 0.9, 'temperature': 2.0, 'batch_size': 303, 'latent_dim': 59}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 726.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 886.00 MiB memory in use. Process 1542430 has 730.00 MiB memory in use. Process 1542439 has 440.00 MiB memory in use. Process 1542433 has 894.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 912.00 MiB memory in use. Process 1542830 has 422.00 MiB memory in use. Process 1543212 has 616.00 MiB memory in use. Process 1543209 has 420.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 716.00 MiB memory in use. Process 1543600 has 812.00 MiB memory in use. Process 1543606 has 1020.00 MiB memory in use. Process 1543612 has 530.00 MiB memory in use. Process 1543605 has 448.00 MiB memory in use. Process 1543609 has 600.00 MiB memory in use. Of the allocated memory 47.44 MiB is allocated by PyTorch, and 36.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
93cb4070,"{'min_delta': 0.461, 'temperature': 0.1, 'batch_size': 376, 'latent_dim': 147}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 726.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 886.00 MiB memory in use. Process 1542430 has 678.00 MiB memory in use. Process 1542439 has 440.00 MiB memory in use. Process 1542433 has 894.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 912.00 MiB memory in use. Process 1542830 has 422.00 MiB memory in use. Process 1543212 has 672.00 MiB memory in use. Process 1543209 has 464.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 758.00 MiB memory in use. Process 1543600 has 812.00 MiB memory in use. Process 1543606 has 1020.00 MiB memory in use. Process 1543612 has 530.00 MiB memory in use. Process 1543605 has 448.00 MiB memory in use. Process 1543609 has 532.00 MiB memory in use. Of the allocated memory 277.43 MiB is allocated by PyTorch, and 56.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
85147dd4,"{'min_delta': 0.226, 'temperature': 1.4000000000000001, 'batch_size': 213, 'latent_dim': 117}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 726.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 886.00 MiB memory in use. Process 1542430 has 480.00 MiB memory in use. Process 1542439 has 446.00 MiB memory in use. Process 1542433 has 894.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 912.00 MiB memory in use. Process 1542830 has 586.00 MiB memory in use. Process 1543212 has 722.00 MiB memory in use. Process 1543209 has 444.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 760.00 MiB memory in use. Process 1543600 has 872.00 MiB memory in use. Process 1543606 has 1020.00 MiB memory in use. Process 1543612 has 484.00 MiB memory in use. Process 1543605 has 448.00 MiB memory in use. Process 1543609 has 534.00 MiB memory in use. Of the allocated memory 203.88 MiB is allocated by PyTorch, and 44.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b6f79686,"{'min_delta': 0.129, 'temperature': 1.2000000000000002, 'batch_size': 335, 'latent_dim': 201}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 726.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 886.00 MiB memory in use. Process 1542430 has 462.00 MiB memory in use. Process 1542439 has 446.00 MiB memory in use. Process 1542433 has 894.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 912.00 MiB memory in use. Process 1542830 has 586.00 MiB memory in use. Process 1543212 has 722.00 MiB memory in use. Process 1543209 has 444.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 984.00 MiB memory in use. Process 1543215 has 868.00 MiB memory in use. Process 1543600 has 822.00 MiB memory in use. Process 1543606 has 1020.00 MiB memory in use. Process 1543612 has 484.00 MiB memory in use. Process 1543605 has 448.00 MiB memory in use. Process 1543609 has 426.00 MiB memory in use. Of the allocated memory 403.85 MiB is allocated by PyTorch, and 80.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
eafa8054,"{'min_delta': 0.279, 'temperature': 0.7000000000000001, 'batch_size': 158, 'latent_dim': 224}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 140.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 472.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 886.00 MiB memory in use. Process 1542430 has 518.00 MiB memory in use. Process 1542439 has 446.00 MiB memory in use. Process 1542433 has 894.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 816.00 MiB memory in use. Process 1542830 has 928.00 MiB memory in use. Process 1543212 has 668.00 MiB memory in use. Process 1543209 has 428.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 930.00 MiB memory in use. Process 1543600 has 464.00 MiB memory in use. Process 1543606 has 1020.00 MiB memory in use. Process 1543612 has 484.00 MiB memory in use. Process 1543605 has 756.00 MiB memory in use. Process 1543609 has 444.00 MiB memory in use. Of the allocated memory 278.03 MiB is allocated by PyTorch, and 51.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b65280b2,"{'min_delta': 0.767, 'temperature': 1.5, 'batch_size': 239, 'latent_dim': 248}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 472.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 886.00 MiB memory in use. Process 1542430 has 518.00 MiB memory in use. Process 1542439 has 446.00 MiB memory in use. Process 1542433 has 894.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 816.00 MiB memory in use. Process 1542830 has 928.00 MiB memory in use. Process 1543212 has 668.00 MiB memory in use. Process 1543209 has 428.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 930.00 MiB memory in use. Process 1543600 has 464.00 MiB memory in use. Process 1543606 has 1020.00 MiB memory in use. Process 1543612 has 514.00 MiB memory in use. Process 1543605 has 756.00 MiB memory in use. Process 1543609 has 444.00 MiB memory in use. Of the allocated memory 83.92 MiB is allocated by PyTorch, and 42.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a422fa42,"{'min_delta': 0.398, 'temperature': 0.9, 'batch_size': 196, 'latent_dim': 97}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 660.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 886.00 MiB memory in use. Process 1542430 has 622.00 MiB memory in use. Process 1542439 has 478.00 MiB memory in use. Process 1542433 has 894.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 816.00 MiB memory in use. Process 1542830 has 928.00 MiB memory in use. Process 1543212 has 454.00 MiB memory in use. Process 1543209 has 464.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 444.00 MiB memory in use. Process 1543600 has 488.00 MiB memory in use. Process 1543606 has 1020.00 MiB memory in use. Process 1543612 has 566.00 MiB memory in use. Process 1543605 has 756.00 MiB memory in use. Process 1543609 has 692.00 MiB memory in use. Of the allocated memory 82.74 MiB is allocated by PyTorch, and 33.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
60fba3d2,"{'min_delta': 0.021, 'temperature': 1.7000000000000002, 'batch_size': 297, 'latent_dim': 15}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 466.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 886.00 MiB memory in use. Process 1542430 has 848.00 MiB memory in use. Process 1542439 has 478.00 MiB memory in use. Process 1542433 has 894.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 816.00 MiB memory in use. Process 1542830 has 928.00 MiB memory in use. Process 1543212 has 616.00 MiB memory in use. Process 1543209 has 482.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 462.00 MiB memory in use. Process 1543600 has 488.00 MiB memory in use. Process 1543606 has 1020.00 MiB memory in use. Process 1543612 has 434.00 MiB memory in use. Process 1543605 has 756.00 MiB memory in use. Process 1543609 has 588.00 MiB memory in use. Of the allocated memory 203.08 MiB is allocated by PyTorch, and 74.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3bd8f12e,"{'min_delta': 0.083, 'temperature': 0.30000000000000004, 'batch_size': 490, 'latent_dim': 77}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 466.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 886.00 MiB memory in use. Process 1542430 has 848.00 MiB memory in use. Process 1542439 has 478.00 MiB memory in use. Process 1542433 has 894.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 816.00 MiB memory in use. Process 1542830 has 928.00 MiB memory in use. Process 1543212 has 616.00 MiB memory in use. Process 1543209 has 512.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 462.00 MiB memory in use. Process 1543600 has 584.00 MiB memory in use. Process 1543606 has 1020.00 MiB memory in use. Process 1543612 has 444.00 MiB memory in use. Process 1543605 has 756.00 MiB memory in use. Process 1543609 has 448.00 MiB memory in use. Of the allocated memory 203.57 MiB is allocated by PyTorch, and 42.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
07472820,"{'min_delta': 0.515, 'temperature': 1.5, 'batch_size': 427, 'latent_dim': 45}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 474.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 886.00 MiB memory in use. Process 1542430 has 848.00 MiB memory in use. Process 1542439 has 522.00 MiB memory in use. Process 1542433 has 894.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 816.00 MiB memory in use. Process 1542830 has 928.00 MiB memory in use. Process 1543212 has 422.00 MiB memory in use. Process 1543209 has 466.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 510.00 MiB memory in use. Process 1543600 has 644.00 MiB memory in use. Process 1543606 has 1020.00 MiB memory in use. Process 1543612 has 462.00 MiB memory in use. Process 1543605 has 756.00 MiB memory in use. Process 1543609 has 520.00 MiB memory in use. Of the allocated memory 47.33 MiB is allocated by PyTorch, and 36.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a6193def,"{'min_delta': 0.28800000000000003, 'temperature': 1.3, 'batch_size': 329, 'latent_dim': 138}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 476.00 MiB memory in use. Process 1539216 has 926.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 886.00 MiB memory in use. Process 1542430 has 848.00 MiB memory in use. Process 1542439 has 522.00 MiB memory in use. Process 1542433 has 894.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 816.00 MiB memory in use. Process 1542830 has 928.00 MiB memory in use. Process 1543212 has 422.00 MiB memory in use. Process 1543209 has 466.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 508.00 MiB memory in use. Process 1543600 has 712.00 MiB memory in use. Process 1543606 has 1020.00 MiB memory in use. Process 1543612 has 508.00 MiB memory in use. Process 1543605 has 756.00 MiB memory in use. Process 1543609 has 444.00 MiB memory in use. Of the allocated memory 277.36 MiB is allocated by PyTorch, and 96.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
fc51f6b1,"{'min_delta': 0.159, 'temperature': 1.4000000000000001, 'batch_size': 140, 'latent_dim': 80}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 464.00 MiB memory in use. Process 1539216 has 928.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 886.00 MiB memory in use. Process 1542430 has 848.00 MiB memory in use. Process 1542439 has 730.00 MiB memory in use. Process 1542433 has 894.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 816.00 MiB memory in use. Process 1542830 has 928.00 MiB memory in use. Process 1543212 has 450.00 MiB memory in use. Process 1543209 has 458.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 462.00 MiB memory in use. Process 1543600 has 446.00 MiB memory in use. Process 1543606 has 1020.00 MiB memory in use. Process 1543612 has 510.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 460.00 MiB memory in use. Of the allocated memory 82.61 MiB is allocated by PyTorch, and 29.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f818d18c,"{'min_delta': 0.229, 'temperature': 0.7000000000000001, 'batch_size': 261, 'latent_dim': 342}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 464.00 MiB memory in use. Process 1539216 has 906.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 886.00 MiB memory in use. Process 1542430 has 848.00 MiB memory in use. Process 1542439 has 730.00 MiB memory in use. Process 1542433 has 894.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 816.00 MiB memory in use. Process 1542830 has 928.00 MiB memory in use. Process 1543212 has 450.00 MiB memory in use. Process 1543209 has 458.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 462.00 MiB memory in use. Process 1543600 has 446.00 MiB memory in use. Process 1543606 has 1020.00 MiB memory in use. Process 1543612 has 510.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 460.00 MiB memory in use. Of the allocated memory 492.95 MiB is allocated by PyTorch, and 75.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ef558b22,"{'min_delta': 0.186, 'temperature': 1.2000000000000002, 'batch_size': 148, 'latent_dim': 117}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 466.00 MiB memory in use. Process 1539216 has 906.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 886.00 MiB memory in use. Process 1542430 has 848.00 MiB memory in use. Process 1542439 has 730.00 MiB memory in use. Process 1542433 has 894.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 816.00 MiB memory in use. Process 1542830 has 928.00 MiB memory in use. Process 1543212 has 450.00 MiB memory in use. Process 1543209 has 488.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 462.00 MiB memory in use. Process 1543600 has 422.00 MiB memory in use. Process 1543606 has 1020.00 MiB memory in use. Process 1543612 has 510.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 460.00 MiB memory in use. Of the allocated memory 47.89 MiB is allocated by PyTorch, and 36.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f81dde58,"{'min_delta': 0.34700000000000003, 'temperature': 0.5, 'batch_size': 222, 'latent_dim': 161}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 960.00 MiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.08 GiB memory in use. Process 1539214 has 844.00 MiB memory in use. Process 1539216 has 462.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 940.00 MiB memory in use. Process 1542430 has 848.00 MiB memory in use. Process 1542439 has 730.00 MiB memory in use. Process 1542433 has 894.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 816.00 MiB memory in use. Process 1542830 has 928.00 MiB memory in use. Process 1543212 has 456.00 MiB memory in use. Process 1543209 has 474.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 470.00 MiB memory in use. Process 1543600 has 422.00 MiB memory in use. Process 1543606 has 1020.00 MiB memory in use. Process 1543612 has 510.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 444.00 MiB memory in use. Of the allocated memory 56.96 MiB is allocated by PyTorch, and 27.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
15494f52,"{'min_delta': 0.057, 'temperature': 0.5, 'batch_size': 276, 'latent_dim': 151}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.08 GiB memory in use. Process 1539214 has 844.00 MiB memory in use. Process 1539216 has 464.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 1.04 GiB memory in use. Process 1542430 has 848.00 MiB memory in use. Process 1542439 has 730.00 MiB memory in use. Process 1542433 has 586.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 458.00 MiB memory in use. Process 1542830 has 928.00 MiB memory in use. Process 1543212 has 452.00 MiB memory in use. Process 1543209 has 638.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 470.00 MiB memory in use. Process 1543600 has 470.00 MiB memory in use. Process 1543606 has 1020.00 MiB memory in use. Process 1543612 has 510.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 580.00 MiB memory in use. Of the allocated memory 83.16 MiB is allocated by PyTorch, and 30.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
26b6f5cf,"{'min_delta': 0.109, 'temperature': 0.1, 'batch_size': 291, 'latent_dim': 181}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.08 GiB memory in use. Process 1539214 has 844.00 MiB memory in use. Process 1539216 has 432.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 1.04 GiB memory in use. Process 1542430 has 848.00 MiB memory in use. Process 1542439 has 454.00 MiB memory in use. Process 1542433 has 444.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 468.00 MiB memory in use. Process 1542830 has 928.00 MiB memory in use. Process 1543212 has 474.00 MiB memory in use. Process 1543209 has 706.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 512.00 MiB memory in use. Process 1543600 has 468.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 714.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 662.00 MiB memory in use. Of the allocated memory 48.39 MiB is allocated by PyTorch, and 45.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4aaf45d7,"{'min_delta': 0.444, 'temperature': 0.2, 'batch_size': 201, 'latent_dim': 289}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.08 GiB memory in use. Process 1539214 has 844.00 MiB memory in use. Process 1539216 has 432.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 1.04 GiB memory in use. Process 1542430 has 848.00 MiB memory in use. Process 1542439 has 456.00 MiB memory in use. Process 1542433 has 468.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 468.00 MiB memory in use. Process 1542830 has 928.00 MiB memory in use. Process 1543212 has 522.00 MiB memory in use. Process 1543209 has 706.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 512.00 MiB memory in use. Process 1543600 has 476.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 764.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 566.00 MiB memory in use. Of the allocated memory 146.57 MiB is allocated by PyTorch, and 37.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b05bcb0d,"{'min_delta': 0.662, 'temperature': 0.8, 'batch_size': 363, 'latent_dim': 193}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.08 GiB memory in use. Process 1539214 has 864.00 MiB memory in use. Process 1539216 has 506.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 1.04 GiB memory in use. Process 1542430 has 848.00 MiB memory in use. Process 1542439 has 476.00 MiB memory in use. Process 1542433 has 468.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 468.00 MiB memory in use. Process 1542830 has 928.00 MiB memory in use. Process 1543212 has 466.00 MiB memory in use. Process 1543209 has 706.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 464.00 MiB memory in use. Process 1543600 has 476.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 764.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 542.00 MiB memory in use. Of the allocated memory 95.82 MiB is allocated by PyTorch, and 72.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
7bc7b56d,"{'min_delta': 0.05, 'temperature': 1.1, 'batch_size': 406, 'latent_dim': 37}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.08 GiB memory in use. Process 1539214 has 864.00 MiB memory in use. Process 1539216 has 466.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 1.04 GiB memory in use. Process 1542430 has 848.00 MiB memory in use. Process 1542439 has 506.00 MiB memory in use. Process 1542433 has 468.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 468.00 MiB memory in use. Process 1542830 has 928.00 MiB memory in use. Process 1543212 has 500.00 MiB memory in use. Process 1543209 has 706.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 466.00 MiB memory in use. Process 1543600 has 476.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 764.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 522.00 MiB memory in use. Of the allocated memory 94.60 MiB is allocated by PyTorch, and 67.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
a4b69485,"{'min_delta': 0.20700000000000002, 'temperature': 0.7000000000000001, 'batch_size': 313, 'latent_dim': 265}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.08 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 464.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 1.04 GiB memory in use. Process 1542430 has 574.00 MiB memory in use. Process 1542439 has 464.00 MiB memory in use. Process 1542433 has 468.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 648.00 MiB memory in use. Process 1542830 has 976.00 MiB memory in use. Process 1543212 has 462.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 616.00 MiB memory in use. Process 1543600 has 476.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 652.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 522.00 MiB memory in use. Of the allocated memory 84.05 MiB is allocated by PyTorch, and 41.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
18fa7d15,"{'min_delta': 0.10400000000000001, 'temperature': 0.5, 'batch_size': 254, 'latent_dim': 208}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.08 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 518.00 MiB memory in use. Process 1542427 has 1.04 GiB memory in use. Process 1542438 has 1.04 GiB memory in use. Process 1542430 has 482.00 MiB memory in use. Process 1542439 has 700.00 MiB memory in use. Process 1542433 has 480.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 708.00 MiB memory in use. Process 1542830 has 896.00 MiB memory in use. Process 1543212 has 644.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 464.00 MiB memory in use. Process 1543600 has 476.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 442.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 500.00 MiB memory in use. Of the allocated memory 219.25 MiB is allocated by PyTorch, and 86.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
7e8455ce,"{'min_delta': 0.307, 'temperature': 0.2, 'batch_size': 225, 'latent_dim': 323}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.08 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 564.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 1.04 GiB memory in use. Process 1542430 has 484.00 MiB memory in use. Process 1542439 has 444.00 MiB memory in use. Process 1542433 has 482.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 708.00 MiB memory in use. Process 1542830 has 896.00 MiB memory in use. Process 1543212 has 466.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 464.00 MiB memory in use. Process 1543600 has 476.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 464.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 768.00 MiB memory in use. Of the allocated memory 146.84 MiB is allocated by PyTorch, and 79.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5340640a,"{'min_delta': 0.09, 'temperature': 0.8, 'batch_size': 388, 'latent_dim': 58}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.08 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 444.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 1.04 GiB memory in use. Process 1542430 has 588.00 MiB memory in use. Process 1542439 has 444.00 MiB memory in use. Process 1542433 has 482.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 708.00 MiB memory in use. Process 1542830 has 896.00 MiB memory in use. Process 1543212 has 504.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 464.00 MiB memory in use. Process 1543600 has 478.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 464.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 768.00 MiB memory in use. Of the allocated memory 94.77 MiB is allocated by PyTorch, and 71.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
0b3696f9,"{'min_delta': 0.25, 'temperature': 0.6000000000000001, 'batch_size': 175, 'latent_dim': 172}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.08 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 460.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 1.04 GiB memory in use. Process 1542430 has 590.00 MiB memory in use. Process 1542439 has 442.00 MiB memory in use. Process 1542433 has 482.00 MiB memory in use. Process 1542827 has 1.12 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 708.00 MiB memory in use. Process 1542830 has 896.00 MiB memory in use. Process 1543212 has 480.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 466.00 MiB memory in use. Process 1543600 has 478.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 456.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 758.00 MiB memory in use. Of the allocated memory 83.33 MiB is allocated by PyTorch, and 38.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fec5e1f4,"{'min_delta': 0.169, 'temperature': 1.5, 'batch_size': 151, 'latent_dim': 82}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.08 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 558.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 1.04 GiB memory in use. Process 1542430 has 538.00 MiB memory in use. Process 1542439 has 488.00 MiB memory in use. Process 1542433 has 662.00 MiB memory in use. Process 1542827 has 1020.00 MiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 762.00 MiB memory in use. Process 1542830 has 896.00 MiB memory in use. Process 1543212 has 480.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 486.00 MiB memory in use. Process 1543600 has 478.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 508.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 506.00 MiB memory in use. Of the allocated memory 144.95 MiB is allocated by PyTorch, and 75.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
39855eae,"{'min_delta': 0.146, 'temperature': 1.4000000000000001, 'batch_size': 132, 'latent_dim': 92}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 464.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 462.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 1.07 GiB memory in use. Process 1542430 has 506.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 662.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 896.00 MiB memory in use. Process 1543212 has 482.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 560.00 MiB memory in use. Process 1543600 has 478.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 466.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 560.00 MiB memory in use. Of the allocated memory 82.70 MiB is allocated by PyTorch, and 41.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
38650d3d,"{'min_delta': 0.025, 'temperature': 0.30000000000000004, 'batch_size': 323, 'latent_dim': 153}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 510.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 448.00 MiB memory in use. Process 1542430 has 512.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 662.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 896.00 MiB memory in use. Process 1543212 has 456.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 478.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 458.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 614.00 MiB memory in use. Of the allocated memory 83.18 MiB is allocated by PyTorch, and 34.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a5b6dcfa,"{'min_delta': 0.222, 'temperature': 1.3, 'batch_size': 186, 'latent_dim': 128}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 510.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 838.00 MiB memory in use. Process 1542430 has 548.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 662.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 438.00 MiB memory in use. Process 1543212 has 456.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 478.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 526.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 614.00 MiB memory in use. Of the allocated memory 462.61 MiB is allocated by PyTorch, and 37.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 33, in forward
    x = self.global_max_pooling(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/pooling.py"", line 1031, in forward
    return F.adaptive_max_pool1d(input, self.output_size, self.return_indices)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/_jit_internal.py"", line 488, in fn
    return if_false(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1096, in _adaptive_max_pool1d
    return adaptive_max_pool1d_with_indices(input, output_size)[0]

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1088, in adaptive_max_pool1d_with_indices
    return torch.adaptive_max_pool1d(input, output_size)
"
5c0edca8,"{'min_delta': 0.5750000000000001, 'temperature': 0.9, 'batch_size': 207, 'latent_dim': 260}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 510.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 838.00 MiB memory in use. Process 1542430 has 558.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 662.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 430.00 MiB memory in use. Process 1543212 has 456.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 478.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 526.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 614.00 MiB memory in use. Of the allocated memory 66.90 MiB is allocated by PyTorch, and 25.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
08466499,"{'min_delta': 0.47800000000000004, 'temperature': 1.0, 'batch_size': 271, 'latent_dim': 225}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 510.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 838.00 MiB memory in use. Process 1542430 has 512.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 662.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 440.00 MiB memory in use. Process 1543212 has 492.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 478.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 526.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 614.00 MiB memory in use. Of the allocated memory 80.89 MiB is allocated by PyTorch, and 21.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 46, in calculate_loss
    logits = torch.cat([torch.cat([logits_ab, logits_aa], dim=1), torch.cat([logits_ba, logits_bb], dim=1)], dim=0)
"
012b4bf3,"{'min_delta': 0.619, 'temperature': 0.9, 'batch_size': 178, 'latent_dim': 312}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 512.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 868.00 MiB memory in use. Process 1542430 has 512.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 662.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 440.00 MiB memory in use. Process 1543212 has 452.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 478.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 526.00 MiB memory in use. Process 1543605 has 816.00 MiB memory in use. Process 1543609 has 614.00 MiB memory in use. Of the allocated memory 96.75 MiB is allocated by PyTorch, and 77.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
d9e9f3b4,"{'min_delta': 0.628, 'temperature': 1.1, 'batch_size': 232, 'latent_dim': 336}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 562.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 488.00 MiB memory in use. Process 1542430 has 716.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 662.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 470.00 MiB memory in use. Process 1543212 has 454.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 478.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 526.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 614.00 MiB memory in use. Of the allocated memory 96.94 MiB is allocated by PyTorch, and 53.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
24ea8d8c,"{'min_delta': 0.722, 'temperature': 0.4, 'batch_size': 167, 'latent_dim': 276}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 562.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 488.00 MiB memory in use. Process 1542430 has 716.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 662.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 470.00 MiB memory in use. Process 1543212 has 418.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 478.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 526.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 614.00 MiB memory in use. Of the allocated memory 49.14 MiB is allocated by PyTorch, and 30.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b83ed06b,"{'min_delta': 0.779, 'temperature': 1.2000000000000002, 'batch_size': 248, 'latent_dim': 138}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 562.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 488.00 MiB memory in use. Process 1542430 has 716.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 662.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 462.00 MiB memory in use. Process 1543212 has 418.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 478.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 526.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 622.00 MiB memory in use. Of the allocated memory 83.06 MiB is allocated by PyTorch, and 40.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
684433f0,"{'min_delta': 0.533, 'temperature': 0.7000000000000001, 'batch_size': 197, 'latent_dim': 284}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 676.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 530.00 MiB memory in use. Process 1542430 has 570.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 662.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 462.00 MiB memory in use. Process 1543212 has 432.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 478.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 526.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 622.00 MiB memory in use. Of the allocated memory 278.50 MiB is allocated by PyTorch, and 59.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
da14b323,"{'min_delta': 0.722, 'temperature': 0.8, 'batch_size': 357, 'latent_dim': 253}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 676.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 540.00 MiB memory in use. Process 1542430 has 570.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 662.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 462.00 MiB memory in use. Process 1543212 has 442.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 478.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 526.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 622.00 MiB memory in use. Of the allocated memory 92.80 MiB is allocated by PyTorch, and 11.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 40, in calculate_loss
    logits_aa = torch.matmul(h1, h1.t()) / self.temperature
"
81a4cc89,"{'min_delta': 0.002, 'temperature': 0.4, 'batch_size': 250, 'latent_dim': 241}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 686.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 540.00 MiB memory in use. Process 1542430 has 570.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 662.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 520.00 MiB memory in use. Process 1543212 has 474.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 532.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 526.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 466.00 MiB memory in use. Of the allocated memory 146.20 MiB is allocated by PyTorch, and 47.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
76cacd36,"{'min_delta': 0.677, 'temperature': 1.0, 'batch_size': 213, 'latent_dim': 217}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 448.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 540.00 MiB memory in use. Process 1542430 has 556.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 662.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 684.00 MiB memory in use. Process 1543212 has 474.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 486.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 624.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 466.00 MiB memory in use. Of the allocated memory 277.98 MiB is allocated by PyTorch, and 68.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6458a53e,"{'min_delta': 0.585, 'temperature': 0.5, 'batch_size': 307, 'latent_dim': 70}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 448.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 540.00 MiB memory in use. Process 1542430 has 556.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 662.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 684.00 MiB memory in use. Process 1543212 has 450.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 486.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 654.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 466.00 MiB memory in use. Of the allocated memory 82.53 MiB is allocated by PyTorch, and 29.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
86942905,"{'min_delta': 0.41200000000000003, 'temperature': 0.6000000000000001, 'batch_size': 129, 'latent_dim': 296}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 448.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 542.00 MiB memory in use. Process 1542430 has 556.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 662.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 684.00 MiB memory in use. Process 1543212 has 450.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 486.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 682.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 466.00 MiB memory in use. Of the allocated memory 146.63 MiB is allocated by PyTorch, and 57.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
948984a7,"{'min_delta': 0.366, 'temperature': 0.9, 'batch_size': 184, 'latent_dim': 230}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 426.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 542.00 MiB memory in use. Process 1542430 has 556.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 698.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 684.00 MiB memory in use. Process 1543212 has 450.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 986.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 486.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 682.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 428.00 MiB memory in use. Of the allocated memory 48.78 MiB is allocated by PyTorch, and 39.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b41a25e8,"{'min_delta': 0.516, 'temperature': 0.4, 'batch_size': 345, 'latent_dim': 234}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 484.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 592.00 MiB memory in use. Process 1542430 has 648.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 444.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 482.00 MiB memory in use. Process 1543212 has 502.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 648.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 684.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 486.00 MiB memory in use. Of the allocated memory 219.46 MiB is allocated by PyTorch, and 90.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
49b54d67,"{'min_delta': 0.434, 'temperature': 1.1, 'batch_size': 232, 'latent_dim': 357}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 484.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 592.00 MiB memory in use. Process 1542430 has 558.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 444.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 560.00 MiB memory in use. Process 1543212 has 502.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 682.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 684.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 486.00 MiB memory in use. Of the allocated memory 147.10 MiB is allocated by PyTorch, and 74.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
942e9404,"{'min_delta': 0.637, 'temperature': 0.7000000000000001, 'batch_size': 296, 'latent_dim': 103}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 460.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 598.00 MiB memory in use. Process 1542430 has 558.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 444.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 560.00 MiB memory in use. Process 1543212 has 502.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 708.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 684.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 456.00 MiB memory in use. Of the allocated memory 82.79 MiB is allocated by PyTorch, and 39.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b0b5eae5,"{'min_delta': 0.87, 'temperature': 0.8, 'batch_size': 172, 'latent_dim': 191}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 460.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 598.00 MiB memory in use. Process 1542430 has 558.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 444.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.12 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 560.00 MiB memory in use. Process 1543212 has 502.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 708.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 684.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 456.00 MiB memory in use. Of the allocated memory 204.46 MiB is allocated by PyTorch, and 55.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0f4c6ef0,"{'min_delta': 0.491, 'temperature': 0.30000000000000004, 'batch_size': 154, 'latent_dim': 174}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 460.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 598.00 MiB memory in use. Process 1542430 has 642.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 426.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 464.00 MiB memory in use. Process 1543212 has 498.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 708.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 684.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 508.00 MiB memory in use. Of the allocated memory 95.67 MiB is allocated by PyTorch, and 64.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
daa92c19,"{'min_delta': 0.37, 'temperature': 1.2000000000000002, 'batch_size': 262, 'latent_dim': 208}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 792.00 MiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 460.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 602.00 MiB memory in use. Process 1542430 has 642.00 MiB memory in use. Process 1542439 has 784.00 MiB memory in use. Process 1542433 has 426.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 464.00 MiB memory in use. Process 1543212 has 498.00 MiB memory in use. Process 1543209 has 764.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 716.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 684.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 508.00 MiB memory in use. Of the allocated memory 277.91 MiB is allocated by PyTorch, and 100.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
fe13b5f7,"{'min_delta': 0.56, 'temperature': 1.3, 'batch_size': 245, 'latent_dim': 15}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 514.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 444.00 MiB memory in use. Process 1542430 has 720.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 484.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 464.00 MiB memory in use. Process 1543212 has 458.00 MiB memory in use. Process 1543209 has 766.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 446.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 684.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 508.00 MiB memory in use. Of the allocated memory 94.43 MiB is allocated by PyTorch, and 81.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
298c85c9,"{'min_delta': 0.332, 'temperature': 0.6000000000000001, 'batch_size': 286, 'latent_dim': 161}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 514.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 444.00 MiB memory in use. Process 1542430 has 722.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 484.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 428.00 MiB memory in use. Process 1543212 has 458.00 MiB memory in use. Process 1543209 has 766.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 446.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 684.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 508.00 MiB memory in use. Of the allocated memory 48.24 MiB is allocated by PyTorch, and 41.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cdb4c2ef,"{'min_delta': 0.607, 'temperature': 0.9, 'batch_size': 203, 'latent_dim': 141}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 514.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 406.00 MiB memory in use. Process 1542430 has 722.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 514.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 428.00 MiB memory in use. Process 1543212 has 458.00 MiB memory in use. Process 1543209 has 766.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 446.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 684.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 508.00 MiB memory in use. Of the allocated memory 48.08 MiB is allocated by PyTorch, and 19.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
12f7d21d,"{'min_delta': 0.807, 'temperature': 0.2, 'batch_size': 332, 'latent_dim': 53}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 514.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 406.00 MiB memory in use. Process 1542430 has 722.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 514.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 428.00 MiB memory in use. Process 1543212 has 460.00 MiB memory in use. Process 1543209 has 766.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 446.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 684.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 508.00 MiB memory in use. Of the allocated memory 82.40 MiB is allocated by PyTorch, and 39.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
24a308c0,"{'min_delta': 0.652, 'temperature': 1.6, 'batch_size': 190, 'latent_dim': 123}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 444.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 420.00 MiB memory in use. Process 1542430 has 722.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 546.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 460.00 MiB memory in use. Process 1543212 has 460.00 MiB memory in use. Process 1543209 has 708.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 458.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 684.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 560.00 MiB memory in use. Of the allocated memory 82.94 MiB is allocated by PyTorch, and 37.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3365c345,"{'min_delta': 0.421, 'temperature': 1.0, 'batch_size': 273, 'latent_dim': 29}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 460.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 446.00 MiB memory in use. Process 1542430 has 466.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 564.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 902.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 448.00 MiB memory in use. Process 1543212 has 460.00 MiB memory in use. Process 1543209 has 758.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 792.00 MiB memory in use. Process 1543600 has 512.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 684.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 674.00 MiB memory in use. Of the allocated memory 82.21 MiB is allocated by PyTorch, and 39.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2cc2f277,"{'min_delta': 0.6990000000000001, 'temperature': 1.1, 'batch_size': 215, 'latent_dim': 97}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 508.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 446.00 MiB memory in use. Process 1542430 has 466.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 638.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 584.00 MiB memory in use. Process 1543212 has 454.00 MiB memory in use. Process 1543209 has 758.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 444.00 MiB memory in use. Process 1543600 has 512.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 684.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 740.00 MiB memory in use. Of the allocated memory 82.74 MiB is allocated by PyTorch, and 33.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1088cb84,"{'min_delta': 0.039, 'temperature': 1.7000000000000002, 'batch_size': 162, 'latent_dim': 200}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 508.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 446.00 MiB memory in use. Process 1542430 has 466.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 638.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 584.00 MiB memory in use. Process 1543212 has 454.00 MiB memory in use. Process 1543209 has 758.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 444.00 MiB memory in use. Process 1543600 has 512.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 684.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 740.00 MiB memory in use. Of the allocated memory 204.53 MiB is allocated by PyTorch, and 41.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8cc7899a,"{'min_delta': 0.3, 'temperature': 1.2000000000000002, 'batch_size': 240, 'latent_dim': 70}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 558.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 446.00 MiB memory in use. Process 1542430 has 548.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 620.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 468.00 MiB memory in use. Process 1543212 has 482.00 MiB memory in use. Process 1543209 has 758.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 444.00 MiB memory in use. Process 1543600 has 512.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 740.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 676.00 MiB memory in use. Of the allocated memory 144.86 MiB is allocated by PyTorch, and 75.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
72bbaf9d,"{'min_delta': 0.26, 'temperature': 0.8, 'batch_size': 429, 'latent_dim': 156}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 558.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 446.00 MiB memory in use. Process 1542430 has 568.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 476.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 468.00 MiB memory in use. Process 1543212 has 504.00 MiB memory in use. Process 1543209 has 758.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 444.00 MiB memory in use. Process 1543600 has 512.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 800.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 714.00 MiB memory in use. Of the allocated memory 95.53 MiB is allocated by PyTorch, and 70.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
6426707b,"{'min_delta': 0.185, 'temperature': 1.3, 'batch_size': 255, 'latent_dim': 147}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 498.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 446.00 MiB memory in use. Process 1542430 has 568.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 476.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 700.00 MiB memory in use. Process 1543212 has 534.00 MiB memory in use. Process 1543209 has 758.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 508.00 MiB memory in use. Process 1543600 has 512.00 MiB memory in use. Process 1543606 has 1.02 GiB memory in use. Process 1543612 has 482.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 736.00 MiB memory in use. Of the allocated memory 277.43 MiB is allocated by PyTorch, and 84.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d2c730d6,"{'min_delta': 0.077, 'temperature': 0.5, 'batch_size': 229, 'latent_dim': 180}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 866.00 MiB memory in use. Process 1539216 has 500.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 446.00 MiB memory in use. Process 1542430 has 568.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 476.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 700.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 758.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 564.00 MiB memory in use. Process 1543600 has 508.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 486.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 736.00 MiB memory in use. Of the allocated memory 95.72 MiB is allocated by PyTorch, and 74.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
970b1a92,"{'min_delta': 0.14200000000000002, 'temperature': 1.4000000000000001, 'batch_size': 324, 'latent_dim': 273}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 562.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 446.00 MiB memory in use. Process 1542430 has 568.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 476.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 502.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 758.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 564.00 MiB memory in use. Process 1543600 has 560.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 488.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 736.00 MiB memory in use. Of the allocated memory 146.45 MiB is allocated by PyTorch, and 77.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b4e80b3b,"{'min_delta': 0.388, 'temperature': 0.7000000000000001, 'batch_size': 367, 'latent_dim': 39}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 450.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 568.00 MiB memory in use. Process 1542430 has 568.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 476.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 502.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 758.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 564.00 MiB memory in use. Process 1543600 has 562.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 488.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 736.00 MiB memory in use. Of the allocated memory 72.31 MiB is allocated by PyTorch, and 39.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
6f2dd110,"{'min_delta': 0.463, 'temperature': 0.1, 'batch_size': 146, 'latent_dim': 113}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 450.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 568.00 MiB memory in use. Process 1542430 has 568.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 476.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 502.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 758.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 564.00 MiB memory in use. Process 1543600 has 562.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 488.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 736.00 MiB memory in use. Of the allocated memory 203.85 MiB is allocated by PyTorch, and 26.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
06fe7843,"{'min_delta': 0.75, 'temperature': 1.9000000000000001, 'batch_size': 471, 'latent_dim': 243}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.19 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 450.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 568.00 MiB memory in use. Process 1542430 has 568.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 476.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 984.00 MiB memory in use. Process 1542830 has 462.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 758.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 564.00 MiB memory in use. Process 1543600 has 562.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 488.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 736.00 MiB memory in use. Of the allocated memory 83.88 MiB is allocated by PyTorch, and 40.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c37148fd,"{'min_delta': 0.23, 'temperature': 1.5, 'batch_size': 388, 'latent_dim': 304}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 450.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 682.00 MiB memory in use. Process 1542430 has 468.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 518.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 468.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 758.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 564.00 MiB memory in use. Process 1543600 has 562.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 522.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 570.00 MiB memory in use. Of the allocated memory 278.66 MiB is allocated by PyTorch, and 65.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8e2e1787,"{'min_delta': 0.28, 'temperature': 0.9, 'batch_size': 315, 'latent_dim': 90}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 450.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 682.00 MiB memory in use. Process 1542430 has 468.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 518.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 512.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 758.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 564.00 MiB memory in use. Process 1543600 has 562.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 522.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 570.00 MiB memory in use. Of the allocated memory 95.02 MiB is allocated by PyTorch, and 78.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
9633eb7f,"{'min_delta': 0.099, 'temperature': 0.6000000000000001, 'batch_size': 339, 'latent_dim': 130}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 450.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 682.00 MiB memory in use. Process 1542430 has 460.00 MiB memory in use. Process 1542439 has 812.00 MiB memory in use. Process 1542433 has 518.00 MiB memory in use. Process 1542827 has 1.11 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 512.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 758.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 564.00 MiB memory in use. Process 1543600 has 562.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 514.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 570.00 MiB memory in use. Of the allocated memory 145.33 MiB is allocated by PyTorch, and 78.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5ec97e5a,"{'min_delta': 0.54, 'temperature': 0.30000000000000004, 'batch_size': 136, 'latent_dim': 330}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 512.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 468.00 MiB memory in use. Process 1542430 has 514.00 MiB memory in use. Process 1542439 has 914.00 MiB memory in use. Process 1542433 has 518.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 574.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 758.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 464.00 MiB memory in use. Process 1543600 has 612.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 474.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 572.00 MiB memory in use. Of the allocated memory 96.89 MiB is allocated by PyTorch, and 77.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
ee2ef724,"{'min_delta': 0.505, 'temperature': 0.8, 'batch_size': 454, 'latent_dim': 199}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 462.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 468.00 MiB memory in use. Process 1542430 has 514.00 MiB memory in use. Process 1542439 has 914.00 MiB memory in use. Process 1542433 has 518.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 574.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 770.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 466.00 MiB memory in use. Process 1543600 has 564.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 514.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 572.00 MiB memory in use. Of the allocated memory 145.87 MiB is allocated by PyTorch, and 80.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0799fcdf,"{'min_delta': 0.339, 'temperature': 1.0, 'batch_size': 222, 'latent_dim': 187}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 462.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 492.00 MiB memory in use. Process 1542430 has 514.00 MiB memory in use. Process 1542439 has 914.00 MiB memory in use. Process 1542433 has 518.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 574.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 770.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 466.00 MiB memory in use. Process 1543600 has 564.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 514.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 572.00 MiB memory in use. Of the allocated memory 95.77 MiB is allocated by PyTorch, and 58.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
d106ddcb,"{'min_delta': 0.203, 'temperature': 1.1, 'batch_size': 300, 'latent_dim': 316}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 462.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 492.00 MiB memory in use. Process 1542430 has 514.00 MiB memory in use. Process 1542439 has 914.00 MiB memory in use. Process 1542433 has 518.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 566.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 770.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 466.00 MiB memory in use. Process 1543600 has 564.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 514.00 MiB memory in use. Process 1543605 has 910.00 MiB memory in use. Process 1543609 has 572.00 MiB memory in use. Of the allocated memory 146.78 MiB is allocated by PyTorch, and 81.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
505210f4,"{'min_delta': 0.459, 'temperature': 0.7000000000000001, 'batch_size': 193, 'latent_dim': 216}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 92.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 464.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 546.00 MiB memory in use. Process 1542430 has 518.00 MiB memory in use. Process 1542439 has 914.00 MiB memory in use. Process 1542433 has 518.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 446.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 772.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 476.00 MiB memory in use. Process 1543600 has 958.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 538.00 MiB memory in use. Process 1543605 has 472.00 MiB memory in use. Process 1543609 has 584.00 MiB memory in use. Of the allocated memory 446.68 MiB is allocated by PyTorch, and 173.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 32, in forward
    x = self.dropout3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
57fe736c,"{'min_delta': 0.382, 'temperature': 1.2000000000000002, 'batch_size': 169, 'latent_dim': 166}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 464.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 546.00 MiB memory in use. Process 1542430 has 486.00 MiB memory in use. Process 1542439 has 914.00 MiB memory in use. Process 1542433 has 518.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 462.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 772.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 476.00 MiB memory in use. Process 1543600 has 958.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 596.00 MiB memory in use. Process 1543605 has 472.00 MiB memory in use. Process 1543609 has 584.00 MiB memory in use. Of the allocated memory 83.28 MiB is allocated by PyTorch, and 40.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5e21eb37,"{'min_delta': 0.604, 'temperature': 0.2, 'batch_size': 208, 'latent_dim': 255}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 434.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 546.00 MiB memory in use. Process 1542430 has 486.00 MiB memory in use. Process 1542439 has 914.00 MiB memory in use. Process 1542433 has 566.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 462.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 734.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 514.00 MiB memory in use. Process 1543600 has 958.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 596.00 MiB memory in use. Process 1543605 has 472.00 MiB memory in use. Process 1543609 has 584.00 MiB memory in use. Of the allocated memory 48.97 MiB is allocated by PyTorch, and 47.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
90bac43c,"{'min_delta': 0.054, 'temperature': 0.9, 'batch_size': 264, 'latent_dim': 121}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 438.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 664.00 MiB memory in use. Process 1542430 has 486.00 MiB memory in use. Process 1542439 has 914.00 MiB memory in use. Process 1542433 has 594.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 506.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 734.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 464.00 MiB memory in use. Process 1543600 has 440.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 598.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 584.00 MiB memory in use. Of the allocated memory 277.23 MiB is allocated by PyTorch, and 48.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f6e4fabd,"{'min_delta': 0.843, 'temperature': 1.0, 'batch_size': 291, 'latent_dim': 63}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 480.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 712.00 MiB memory in use. Process 1542430 has 486.00 MiB memory in use. Process 1542439 has 914.00 MiB memory in use. Process 1542433 has 466.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 464.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 734.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 464.00 MiB memory in use. Process 1543600 has 442.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 650.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 594.00 MiB memory in use. Of the allocated memory 47.47 MiB is allocated by PyTorch, and 78.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b20e4dff,"{'min_delta': 0.562, 'temperature': 0.5, 'batch_size': 159, 'latent_dim': 5}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 480.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 712.00 MiB memory in use. Process 1542430 has 532.00 MiB memory in use. Process 1542439 has 914.00 MiB memory in use. Process 1542433 has 466.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 464.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 734.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 464.00 MiB memory in use. Process 1543600 has 460.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 650.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 534.00 MiB memory in use. Of the allocated memory 82.02 MiB is allocated by PyTorch, and 39.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6b4dc5f9,"{'min_delta': 0.896, 'temperature': 1.8, 'batch_size': 181, 'latent_dim': 282}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1.02 GiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 586.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 712.00 MiB memory in use. Process 1542430 has 582.00 MiB memory in use. Process 1542439 has 914.00 MiB memory in use. Process 1542433 has 466.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.11 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 484.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 734.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 460.00 MiB memory in use. Process 1543600 has 460.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 466.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 570.00 MiB memory in use. Of the allocated memory 205.17 MiB is allocated by PyTorch, and 42.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2b42fead,"{'min_delta': 0.6980000000000001, 'temperature': 1.3, 'batch_size': 199, 'latent_dim': 177}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 840.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 700.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 900.00 MiB memory in use. Process 1542430 has 644.00 MiB memory in use. Process 1542439 has 914.00 MiB memory in use. Process 1542433 has 518.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.16 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 462.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 734.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 586.00 MiB memory in use. Process 1543215 has 562.00 MiB memory in use. Process 1543600 has 508.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 514.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 444.00 MiB memory in use. Of the allocated memory 277.66 MiB is allocated by PyTorch, and 84.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b980f144,"{'min_delta': 0.005, 'temperature': 0.4, 'batch_size': 279, 'latent_dim': 347}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 840.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 700.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 900.00 MiB memory in use. Process 1542430 has 644.00 MiB memory in use. Process 1542439 has 914.00 MiB memory in use. Process 1542433 has 518.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.16 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 462.00 MiB memory in use. Process 1543212 has 556.00 MiB memory in use. Process 1543209 has 734.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 586.00 MiB memory in use. Process 1543215 has 594.00 MiB memory in use. Process 1543600 has 508.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 514.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 444.00 MiB memory in use. Of the allocated memory 147.03 MiB is allocated by PyTorch, and 70.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4aa9cf79,"{'min_delta': 0.134, 'temperature': 0.4, 'batch_size': 241, 'latent_dim': 88}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 840.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 462.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 900.00 MiB memory in use. Process 1542430 has 644.00 MiB memory in use. Process 1542439 has 914.00 MiB memory in use. Process 1542433 has 566.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 704.00 MiB memory in use. Process 1543212 has 508.00 MiB memory in use. Process 1543209 has 734.00 MiB memory in use. Process 1543218 has 1.87 GiB memory in use. Process 1543221 has 496.00 MiB memory in use. Process 1543215 has 626.00 MiB memory in use. Process 1543600 has 508.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 480.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 542.00 MiB memory in use. Of the allocated memory 276.97 MiB is allocated by PyTorch, and 89.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c56e2fe1,"{'min_delta': 0.323, 'temperature': 1.5, 'batch_size': 351, 'latent_dim': 234}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 122.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 840.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 462.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 900.00 MiB memory in use. Process 1542430 has 644.00 MiB memory in use. Process 1542439 has 914.00 MiB memory in use. Process 1542433 has 566.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 440.00 MiB memory in use. Process 1543212 has 670.00 MiB memory in use. Process 1543209 has 734.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 496.00 MiB memory in use. Process 1543215 has 626.00 MiB memory in use. Process 1543600 has 508.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 480.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 564.00 MiB memory in use. Of the allocated memory 278.11 MiB is allocated by PyTorch, and 53.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
599caf50,"{'min_delta': 0.784, 'temperature': 1.4000000000000001, 'batch_size': 217, 'latent_dim': 49}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 840.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 462.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 900.00 MiB memory in use. Process 1542430 has 716.00 MiB memory in use. Process 1542439 has 914.00 MiB memory in use. Process 1542433 has 566.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 432.00 MiB memory in use. Process 1543212 has 458.00 MiB memory in use. Process 1543209 has 734.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 570.00 MiB memory in use. Process 1543215 has 626.00 MiB memory in use. Process 1543600 has 508.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 638.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 564.00 MiB memory in use. Of the allocated memory 47.36 MiB is allocated by PyTorch, and 46.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5cf4b1ca,"{'min_delta': 0.24, 'temperature': 1.6, 'batch_size': 257, 'latent_dim': 108}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 840.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 462.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 900.00 MiB memory in use. Process 1542430 has 716.00 MiB memory in use. Process 1542439 has 836.00 MiB memory in use. Process 1542433 has 566.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1008.00 MiB memory in use. Process 1542830 has 478.00 MiB memory in use. Process 1543212 has 456.00 MiB memory in use. Process 1543209 has 442.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 570.00 MiB memory in use. Process 1543215 has 622.00 MiB memory in use. Process 1543600 has 838.00 MiB memory in use. Process 1543606 has 1000.00 MiB memory in use. Process 1543612 has 638.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 564.00 MiB memory in use. Of the allocated memory 82.83 MiB is allocated by PyTorch, and 35.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9c1977e0,"{'min_delta': 0.065, 'temperature': 1.1, 'batch_size': 267, 'latent_dim': 210}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 840.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 462.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 900.00 MiB memory in use. Process 1542430 has 774.00 MiB memory in use. Process 1542439 has 836.00 MiB memory in use. Process 1542433 has 466.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 506.00 MiB memory in use. Process 1543212 has 506.00 MiB memory in use. Process 1543209 has 574.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 474.00 MiB memory in use. Process 1543215 has 466.00 MiB memory in use. Process 1543600 has 838.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 486.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 732.00 MiB memory in use. Of the allocated memory 95.95 MiB is allocated by PyTorch, and 72.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
bae9a39a,"{'min_delta': 0.114, 'temperature': 0.7000000000000001, 'batch_size': 403, 'latent_dim': 295}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 840.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 462.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 900.00 MiB memory in use. Process 1542430 has 774.00 MiB memory in use. Process 1542439 has 836.00 MiB memory in use. Process 1542433 has 462.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 560.00 MiB memory in use. Process 1543212 has 450.00 MiB memory in use. Process 1543209 has 574.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 474.00 MiB memory in use. Process 1543215 has 466.00 MiB memory in use. Process 1543600 has 838.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 462.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 732.00 MiB memory in use. Of the allocated memory 146.62 MiB is allocated by PyTorch, and 75.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a9771ba8,"{'min_delta': 0.523, 'temperature': 0.8, 'batch_size': 232, 'latent_dim': 264}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 840.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 462.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 900.00 MiB memory in use. Process 1542430 has 446.00 MiB memory in use. Process 1542439 has 836.00 MiB memory in use. Process 1542433 has 714.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 610.00 MiB memory in use. Process 1543212 has 580.00 MiB memory in use. Process 1543209 has 636.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 466.00 MiB memory in use. Process 1543215 has 504.00 MiB memory in use. Process 1543600 has 838.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 488.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 496.00 MiB memory in use. Of the allocated memory 205.03 MiB is allocated by PyTorch, and 36.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a28a35a5,"{'min_delta': 0.423, 'temperature': 1.2000000000000002, 'batch_size': 151, 'latent_dim': 157}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 840.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 462.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 900.00 MiB memory in use. Process 1542430 has 458.00 MiB memory in use. Process 1542439 has 836.00 MiB memory in use. Process 1542433 has 466.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 622.00 MiB memory in use. Process 1543212 has 630.00 MiB memory in use. Process 1543209 has 806.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 466.00 MiB memory in use. Process 1543215 has 504.00 MiB memory in use. Process 1543600 has 838.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 510.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 496.00 MiB memory in use. Of the allocated memory 204.19 MiB is allocated by PyTorch, and 79.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
25c521e2,"{'min_delta': 0.645, 'temperature': 0.6000000000000001, 'batch_size': 179, 'latent_dim': 141}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 840.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 462.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 900.00 MiB memory in use. Process 1542430 has 486.00 MiB memory in use. Process 1542439 has 836.00 MiB memory in use. Process 1542433 has 466.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 448.00 MiB memory in use. Process 1543212 has 702.00 MiB memory in use. Process 1543209 has 806.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 468.00 MiB memory in use. Process 1543215 has 470.00 MiB memory in use. Process 1543600 has 838.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 468.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 648.00 MiB memory in use. Of the allocated memory 277.38 MiB is allocated by PyTorch, and 86.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5309acd3,"{'min_delta': 0.039, 'temperature': 0.1, 'batch_size': 309, 'latent_dim': 21}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 840.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 456.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 900.00 MiB memory in use. Process 1542430 has 510.00 MiB memory in use. Process 1542439 has 836.00 MiB memory in use. Process 1542433 has 648.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 448.00 MiB memory in use. Process 1543212 has 702.00 MiB memory in use. Process 1543209 has 806.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 468.00 MiB memory in use. Process 1543215 has 472.00 MiB memory in use. Process 1543600 has 838.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 468.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 446.00 MiB memory in use. Of the allocated memory 82.15 MiB is allocated by PyTorch, and 35.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bb4d21fc,"{'min_delta': 0.294, 'temperature': 1.0, 'batch_size': 163, 'latent_dim': 187}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 840.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 456.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 900.00 MiB memory in use. Process 1542430 has 536.00 MiB memory in use. Process 1542439 has 836.00 MiB memory in use. Process 1542433 has 700.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 426.00 MiB memory in use. Process 1543212 has 462.00 MiB memory in use. Process 1543209 has 806.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 468.00 MiB memory in use. Process 1543215 has 650.00 MiB memory in use. Process 1543600 has 838.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 468.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 446.00 MiB memory in use. Of the allocated memory 48.44 MiB is allocated by PyTorch, and 39.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cf71b38f,"{'min_delta': 0.266, 'temperature': 1.3, 'batch_size': 414, 'latent_dim': 167}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 840.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 448.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 900.00 MiB memory in use. Process 1542430 has 558.00 MiB memory in use. Process 1542439 has 836.00 MiB memory in use. Process 1542433 has 706.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 474.00 MiB memory in use. Process 1543212 has 462.00 MiB memory in use. Process 1543209 has 806.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 470.00 MiB memory in use. Process 1543215 has 482.00 MiB memory in use. Process 1543600 has 838.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 590.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 446.00 MiB memory in use. Of the allocated memory 76.84 MiB is allocated by PyTorch, and 33.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
4b261d54,"{'min_delta': 0.357, 'temperature': 0.5, 'batch_size': 382, 'latent_dim': 125}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 504.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 490.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 904.00 MiB memory in use. Process 1542430 has 496.00 MiB memory in use. Process 1542439 has 836.00 MiB memory in use. Process 1542433 has 772.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 464.00 MiB memory in use. Process 1543212 has 464.00 MiB memory in use. Process 1543209 has 806.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 470.00 MiB memory in use. Process 1543215 has 882.00 MiB memory in use. Process 1543600 has 838.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 462.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 452.00 MiB memory in use. Of the allocated memory 82.96 MiB is allocated by PyTorch, and 43.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
18531245,"{'min_delta': 0.084, 'temperature': 1.7000000000000002, 'batch_size': 279, 'latent_dim': 148}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 490.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 486.00 MiB memory in use. Process 1542439 has 494.00 MiB memory in use. Process 1542433 has 464.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 446.00 MiB memory in use. Process 1543212 has 464.00 MiB memory in use. Process 1543209 has 806.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 514.00 MiB memory in use. Process 1543215 has 882.00 MiB memory in use. Process 1543600 has 708.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 824.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 510.00 MiB memory in use. Of the allocated memory 277.44 MiB is allocated by PyTorch, and 92.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7552fd3c,"{'min_delta': 0.216, 'temperature': 0.30000000000000004, 'batch_size': 366, 'latent_dim': 223}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 512.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 486.00 MiB memory in use. Process 1542439 has 494.00 MiB memory in use. Process 1542433 has 464.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 446.00 MiB memory in use. Process 1543212 has 464.00 MiB memory in use. Process 1543209 has 806.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 514.00 MiB memory in use. Process 1543215 has 882.00 MiB memory in use. Process 1543600 has 708.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 826.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 510.00 MiB memory in use. Of the allocated memory 96.06 MiB is allocated by PyTorch, and 77.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
5e59bbe5,"{'min_delta': 0.186, 'temperature': 0.4, 'batch_size': 129, 'latent_dim': 78}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 404.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 486.00 MiB memory in use. Process 1542439 has 618.00 MiB memory in use. Process 1542433 has 458.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 446.00 MiB memory in use. Process 1543212 has 464.00 MiB memory in use. Process 1543209 has 806.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 514.00 MiB memory in use. Process 1543215 has 882.00 MiB memory in use. Process 1543600 has 708.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 826.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 510.00 MiB memory in use. Of the allocated memory 41.59 MiB is allocated by PyTorch, and 24.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
cb782e0d,"{'min_delta': 0.013000000000000001, 'temperature': 0.9, 'batch_size': 246, 'latent_dim': 134}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 404.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 486.00 MiB memory in use. Process 1542439 has 728.00 MiB memory in use. Process 1542433 has 458.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 448.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 806.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 514.00 MiB memory in use. Process 1543215 has 882.00 MiB memory in use. Process 1543600 has 446.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 826.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 564.00 MiB memory in use. Of the allocated memory 145.36 MiB is allocated by PyTorch, and 74.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
762d70b9,"{'min_delta': 0.668, 'temperature': 0.1, 'batch_size': 498, 'latent_dim': 271}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 404.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 486.00 MiB memory in use. Process 1542439 has 728.00 MiB memory in use. Process 1542433 has 458.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 448.00 MiB memory in use. Process 1543212 has 558.00 MiB memory in use. Process 1543209 has 806.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 514.00 MiB memory in use. Process 1543215 has 882.00 MiB memory in use. Process 1543600 has 448.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 826.00 MiB memory in use. Process 1543605 has 842.00 MiB memory in use. Process 1543609 has 564.00 MiB memory in use. Of the allocated memory 66.22 MiB is allocated by PyTorch, and 43.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
0ad64e84,"{'min_delta': 0.402, 'temperature': 0.30000000000000004, 'batch_size': 453, 'latent_dim': 33}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 466.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 616.00 MiB memory in use. Process 1542439 has 728.00 MiB memory in use. Process 1542433 has 434.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 448.00 MiB memory in use. Process 1543212 has 612.00 MiB memory in use. Process 1543209 has 812.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 448.00 MiB memory in use. Process 1543215 has 882.00 MiB memory in use. Process 1543600 has 448.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 778.00 MiB memory in use. Process 1543605 has 740.00 MiB memory in use. Process 1543609 has 530.00 MiB memory in use. Of the allocated memory 82.24 MiB is allocated by PyTorch, and 45.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f82d711a,"{'min_delta': 0.721, 'temperature': 0.2, 'batch_size': 430, 'latent_dim': 344}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 466.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 616.00 MiB memory in use. Process 1542439 has 728.00 MiB memory in use. Process 1542433 has 434.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 448.00 MiB memory in use. Process 1543212 has 618.00 MiB memory in use. Process 1543209 has 812.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 444.00 MiB memory in use. Process 1543215 has 882.00 MiB memory in use. Process 1543600 has 448.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 778.00 MiB memory in use. Process 1543605 has 740.00 MiB memory in use. Process 1543609 has 530.00 MiB memory in use. Of the allocated memory 205.65 MiB is allocated by PyTorch, and 74.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e2cf1c0c,"{'min_delta': 0.164, 'temperature': 0.2, 'batch_size': 133, 'latent_dim': 324}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 518.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 552.00 MiB memory in use. Process 1542439 has 728.00 MiB memory in use. Process 1542433 has 462.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 592.00 MiB memory in use. Process 1543212 has 666.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 472.00 MiB memory in use. Process 1543215 has 882.00 MiB memory in use. Process 1543600 has 448.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 474.00 MiB memory in use. Process 1543605 has 740.00 MiB memory in use. Process 1543609 has 582.00 MiB memory in use. Of the allocated memory 205.50 MiB is allocated by PyTorch, and 48.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a891ba6d,"{'min_delta': 0.579, 'temperature': 0.4, 'batch_size': 142, 'latent_dim': 68}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 518.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 552.00 MiB memory in use. Process 1542439 has 728.00 MiB memory in use. Process 1542433 has 462.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 592.00 MiB memory in use. Process 1543212 has 666.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 472.00 MiB memory in use. Process 1543215 has 882.00 MiB memory in use. Process 1543600 has 460.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 474.00 MiB memory in use. Process 1543605 has 740.00 MiB memory in use. Process 1543609 has 582.00 MiB memory in use. Of the allocated memory 82.51 MiB is allocated by PyTorch, and 39.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
91f57f57,"{'min_delta': 0.551, 'temperature': 0.5, 'batch_size': 320, 'latent_dim': 56}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 514.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 528.00 MiB memory in use. Process 1542439 has 728.00 MiB memory in use. Process 1542433 has 462.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 592.00 MiB memory in use. Process 1543212 has 666.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 472.00 MiB memory in use. Process 1543215 has 882.00 MiB memory in use. Process 1543600 has 460.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 476.00 MiB memory in use. Process 1543605 has 740.00 MiB memory in use. Process 1543609 has 582.00 MiB memory in use. Of the allocated memory 94.75 MiB is allocated by PyTorch, and 81.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
1846f13a,"{'min_delta': 0.117, 'temperature': 0.7000000000000001, 'batch_size': 206, 'latent_dim': 74}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 514.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 528.00 MiB memory in use. Process 1542439 has 728.00 MiB memory in use. Process 1542433 has 462.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 620.00 MiB memory in use. Process 1543212 has 666.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 512.00 MiB memory in use. Process 1543215 has 882.00 MiB memory in use. Process 1543600 has 438.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 476.00 MiB memory in use. Process 1543605 has 740.00 MiB memory in use. Process 1543609 has 582.00 MiB memory in use. Of the allocated memory 75.05 MiB is allocated by PyTorch, and 24.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
a464ba2b,"{'min_delta': 0.198, 'temperature': 0.1, 'batch_size': 222, 'latent_dim': 93}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 564.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 588.00 MiB memory in use. Process 1542439 has 728.00 MiB memory in use. Process 1542433 has 464.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 442.00 MiB memory in use. Process 1543212 has 776.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 464.00 MiB memory in use. Process 1543215 has 882.00 MiB memory in use. Process 1543600 has 442.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 476.00 MiB memory in use. Process 1543605 has 740.00 MiB memory in use. Process 1543609 has 582.00 MiB memory in use. Of the allocated memory 75.18 MiB is allocated by PyTorch, and 28.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
256179ae,"{'min_delta': 0.177, 'temperature': 1.1, 'batch_size': 187, 'latent_dim': 116}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 564.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 590.00 MiB memory in use. Process 1542439 has 728.00 MiB memory in use. Process 1542433 has 460.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 442.00 MiB memory in use. Process 1543212 has 776.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 466.00 MiB memory in use. Process 1543215 has 882.00 MiB memory in use. Process 1543600 has 510.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 466.00 MiB memory in use. Process 1543605 has 740.00 MiB memory in use. Process 1543609 has 484.00 MiB memory in use. Of the allocated memory 95.22 MiB is allocated by PyTorch, and 76.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
52e1f11a,"{'min_delta': 0.153, 'temperature': 0.30000000000000004, 'batch_size': 156, 'latent_dim': 43}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 564.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 590.00 MiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 702.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 460.00 MiB memory in use. Process 1543212 has 776.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 446.00 MiB memory in use. Process 1543215 has 474.00 MiB memory in use. Process 1543600 has 562.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 516.00 MiB memory in use. Process 1543605 has 736.00 MiB memory in use. Process 1543609 has 524.00 MiB memory in use. Of the allocated memory 82.32 MiB is allocated by PyTorch, and 39.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5b96b2e2,"{'min_delta': 0.128, 'temperature': 0.5, 'batch_size': 165, 'latent_dim': 17}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 564.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 590.00 MiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 702.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 448.00 MiB memory in use. Process 1543212 has 776.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 518.00 MiB memory in use. Process 1543215 has 474.00 MiB memory in use. Process 1543600 has 558.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 510.00 MiB memory in use. Process 1543605 has 736.00 MiB memory in use. Process 1543609 has 460.00 MiB memory in use. Of the allocated memory 144.44 MiB is allocated by PyTorch, and 75.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
58411e95,"{'min_delta': 0.8210000000000001, 'temperature': 0.8, 'batch_size': 193, 'latent_dim': 109}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 566.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 444.00 MiB memory in use. Process 1542430 has 590.00 MiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 702.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 750.00 MiB memory in use. Process 1543212 has 868.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 560.00 MiB memory in use. Process 1543215 has 474.00 MiB memory in use. Process 1543600 has 588.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 470.00 MiB memory in use. Process 1543605 has 736.00 MiB memory in use. Process 1543609 has 482.00 MiB memory in use. Of the allocated memory 203.82 MiB is allocated by PyTorch, and 46.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
befbae4b,"{'min_delta': 0.068, 'temperature': 0.9, 'batch_size': 176, 'latent_dim': 131}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 566.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 410.00 MiB memory in use. Process 1542430 has 590.00 MiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 736.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 750.00 MiB memory in use. Process 1543212 has 868.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 470.00 MiB memory in use. Process 1543215 has 474.00 MiB memory in use. Process 1543600 has 640.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 434.00 MiB memory in use. Process 1543605 has 736.00 MiB memory in use. Process 1543609 has 518.00 MiB memory in use. Of the allocated memory 48.00 MiB is allocated by PyTorch, and 24.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
196f5d9c,"{'min_delta': 0.733, 'temperature': 0.6000000000000001, 'batch_size': 235, 'latent_dim': 143}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 566.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 416.00 MiB memory in use. Process 1542430 has 590.00 MiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 758.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 750.00 MiB memory in use. Process 1543212 has 868.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 470.00 MiB memory in use. Process 1543215 has 474.00 MiB memory in use. Process 1543600 has 640.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 446.00 MiB memory in use. Process 1543605 has 740.00 MiB memory in use. Process 1543609 has 518.00 MiB memory in use. Of the allocated memory 69.98 MiB is allocated by PyTorch, and 8.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 46, in calculate_loss
    logits = torch.cat([torch.cat([logits_ab, logits_aa], dim=1), torch.cat([logits_ba, logits_bb], dim=1)], dim=0)
"
4b7cea94,"{'min_delta': 0.7000000000000001, 'temperature': 0.5, 'batch_size': 136, 'latent_dim': 63}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 566.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 420.00 MiB memory in use. Process 1542430 has 590.00 MiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 448.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 750.00 MiB memory in use. Process 1543212 has 868.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 778.00 MiB memory in use. Process 1543215 has 474.00 MiB memory in use. Process 1543600 has 640.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 448.00 MiB memory in use. Process 1543605 has 740.00 MiB memory in use. Process 1543609 has 514.00 MiB memory in use. Of the allocated memory 74.92 MiB is allocated by PyTorch, and 7.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
fd2a0135,"{'min_delta': 0.877, 'temperature': 0.4, 'batch_size': 185, 'latent_dim': 205}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 870.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 566.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 420.00 MiB memory in use. Process 1542430 has 590.00 MiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 448.00 MiB memory in use. Process 1542827 has 1.16 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 750.00 MiB memory in use. Process 1543212 has 868.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 778.00 MiB memory in use. Process 1543215 has 474.00 MiB memory in use. Process 1543600 has 592.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 448.00 MiB memory in use. Process 1543605 has 740.00 MiB memory in use. Process 1543609 has 514.00 MiB memory in use. Of the allocated memory 204.57 MiB is allocated by PyTorch, and 49.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3470729c,"{'min_delta': 0.797, 'temperature': 0.6000000000000001, 'batch_size': 289, 'latent_dim': 118}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 882.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 566.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 466.00 MiB memory in use. Process 1542430 has 758.00 MiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 448.00 MiB memory in use. Process 1542827 has 1.17 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 750.00 MiB memory in use. Process 1543212 has 868.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 466.00 MiB memory in use. Process 1543215 has 474.00 MiB memory in use. Process 1543600 has 642.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 468.00 MiB memory in use. Process 1543605 has 740.00 MiB memory in use. Process 1543609 has 570.00 MiB memory in use. Of the allocated memory 218.55 MiB is allocated by PyTorch, and 85.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
669a875c,"{'min_delta': 0.754, 'temperature': 0.8, 'batch_size': 226, 'latent_dim': 172}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 882.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 566.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 446.00 MiB memory in use. Process 1542430 has 758.00 MiB memory in use. Process 1542439 has 772.00 MiB memory in use. Process 1542433 has 448.00 MiB memory in use. Process 1542827 has 1.17 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 750.00 MiB memory in use. Process 1543212 has 868.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 466.00 MiB memory in use. Process 1543215 has 474.00 MiB memory in use. Process 1543600 has 642.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 468.00 MiB memory in use. Process 1543605 has 740.00 MiB memory in use. Process 1543609 has 570.00 MiB memory in use. Of the allocated memory 83.33 MiB is allocated by PyTorch, and 24.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
37cb027b,"{'min_delta': 0.764, 'temperature': 0.7000000000000001, 'batch_size': 156, 'latent_dim': 156}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 882.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 566.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 498.00 MiB memory in use. Process 1542430 has 750.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 448.00 MiB memory in use. Process 1542827 has 1.17 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 696.00 MiB memory in use. Process 1543212 has 868.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 590.00 MiB memory in use. Process 1543215 has 474.00 MiB memory in use. Process 1543600 has 448.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 446.00 MiB memory in use. Process 1543605 has 740.00 MiB memory in use. Process 1543609 has 572.00 MiB memory in use. Of the allocated memory 277.50 MiB is allocated by PyTorch, and 80.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
fd487241,"{'min_delta': 0.029, 'temperature': 0.2, 'batch_size': 148, 'latent_dim': 85}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 882.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 518.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 500.00 MiB memory in use. Process 1542430 has 750.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 448.00 MiB memory in use. Process 1542827 has 1.17 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 746.00 MiB memory in use. Process 1543212 has 868.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 648.00 MiB memory in use. Process 1543215 has 474.00 MiB memory in use. Process 1543600 has 448.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 446.00 MiB memory in use. Process 1543605 has 700.00 MiB memory in use. Process 1543609 has 560.00 MiB memory in use. Of the allocated memory 94.98 MiB is allocated by PyTorch, and 85.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
abe8b687,"{'min_delta': 0.323, 'temperature': 0.30000000000000004, 'batch_size': 250, 'latent_dim': 35}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 882.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 564.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 498.00 MiB memory in use. Process 1542430 has 750.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 448.00 MiB memory in use. Process 1542827 has 1.17 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 746.00 MiB memory in use. Process 1543212 has 868.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 464.00 MiB memory in use. Process 1543215 has 474.00 MiB memory in use. Process 1543600 has 448.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 446.00 MiB memory in use. Process 1543605 has 700.00 MiB memory in use. Process 1543609 has 724.00 MiB memory in use. Of the allocated memory 94.59 MiB is allocated by PyTorch, and 65.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
3e7d3bf3,"{'min_delta': 0.248, 'temperature': 0.1, 'batch_size': 212, 'latent_dim': 9}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.09 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 882.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 564.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 494.00 MiB memory in use. Process 1542430 has 750.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 446.00 MiB memory in use. Process 1542827 has 1.17 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 746.00 MiB memory in use. Process 1543212 has 868.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 1.86 GiB memory in use. Process 1543221 has 448.00 MiB memory in use. Process 1543215 has 474.00 MiB memory in use. Process 1543600 has 418.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 440.00 MiB memory in use. Process 1543605 has 700.00 MiB memory in use. Process 1543609 has 780.00 MiB memory in use. Of the allocated memory 47.05 MiB is allocated by PyTorch, and 32.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c43718a0,"{'min_delta': 0.276, 'temperature': 0.2, 'batch_size': 276, 'latent_dim': 51}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 984.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 882.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 564.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 494.00 MiB memory in use. Process 1542430 has 758.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 456.00 MiB memory in use. Process 1542827 has 1.17 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 746.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 430.00 MiB memory in use. Process 1543221 has 936.00 MiB memory in use. Process 1543215 has 604.00 MiB memory in use. Process 1543600 has 478.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 824.00 MiB memory in use. Process 1543605 has 700.00 MiB memory in use. Process 1543609 has 1.25 GiB memory in use. Of the allocated memory 144.71 MiB is allocated by PyTorch, and 81.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
913928cc,"{'min_delta': 0.233, 'temperature': 0.4, 'batch_size': 298, 'latent_dim': 309}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 984.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 882.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 564.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 636.00 MiB memory in use. Process 1542430 has 758.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 456.00 MiB memory in use. Process 1542827 has 1.17 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 746.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 430.00 MiB memory in use. Process 1543221 has 936.00 MiB memory in use. Process 1543215 has 436.00 MiB memory in use. Process 1543600 has 480.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 846.00 MiB memory in use. Process 1543605 has 700.00 MiB memory in use. Process 1543609 has 1.25 GiB memory in use. Of the allocated memory 220.04 MiB is allocated by PyTorch, and 77.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
1687186b,"{'min_delta': 0.482, 'temperature': 0.1, 'batch_size': 258, 'latent_dim': 8}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 984.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 882.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 614.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 690.00 MiB memory in use. Process 1542430 has 698.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 470.00 MiB memory in use. Process 1542827 has 1.17 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 746.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 814.00 MiB memory in use. Process 1543218 has 556.00 MiB memory in use. Process 1543221 has 936.00 MiB memory in use. Process 1543215 has 460.00 MiB memory in use. Process 1543600 has 586.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 466.00 MiB memory in use. Process 1543605 has 762.00 MiB memory in use. Process 1543609 has 1.25 GiB memory in use. Of the allocated memory 203.03 MiB is allocated by PyTorch, and 44.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0c7b2af7,"{'min_delta': 0.443, 'temperature': 0.5, 'batch_size': 203, 'latent_dim': 243}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 984.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 882.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 624.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 690.00 MiB memory in use. Process 1542430 has 564.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 470.00 MiB memory in use. Process 1542827 has 1.17 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 746.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 816.00 MiB memory in use. Process 1543218 has 748.00 MiB memory in use. Process 1543221 has 936.00 MiB memory in use. Process 1543215 has 460.00 MiB memory in use. Process 1543600 has 446.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 528.00 MiB memory in use. Process 1543605 has 762.00 MiB memory in use. Process 1543609 has 1.25 GiB memory in use. Of the allocated memory 204.86 MiB is allocated by PyTorch, and 81.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
97e54f3b,"{'min_delta': 0.21, 'temperature': 0.4, 'batch_size': 168, 'latent_dim': 231}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 984.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 882.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 674.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 690.00 MiB memory in use. Process 1542430 has 510.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 436.00 MiB memory in use. Process 1542827 has 1.17 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 746.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 818.00 MiB memory in use. Process 1543218 has 752.00 MiB memory in use. Process 1543221 has 936.00 MiB memory in use. Process 1543215 has 460.00 MiB memory in use. Process 1543600 has 464.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 518.00 MiB memory in use. Process 1543605 has 762.00 MiB memory in use. Process 1543609 has 1.25 GiB memory in use. Of the allocated memory 83.79 MiB is allocated by PyTorch, and 42.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bcb9ceac,"{'min_delta': 0.14, 'temperature': 0.30000000000000004, 'batch_size': 214, 'latent_dim': 252}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 984.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 882.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 674.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 696.00 MiB memory in use. Process 1542430 has 510.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 446.00 MiB memory in use. Process 1542827 has 1.17 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 746.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 818.00 MiB memory in use. Process 1543218 has 694.00 MiB memory in use. Process 1543221 has 936.00 MiB memory in use. Process 1543215 has 458.00 MiB memory in use. Process 1543600 has 464.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 562.00 MiB memory in use. Process 1543605 has 762.00 MiB memory in use. Process 1543609 has 1.25 GiB memory in use. Of the allocated memory 278.25 MiB is allocated by PyTorch, and 79.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
35b69f11,"{'min_delta': 0.503, 'temperature': 0.2, 'batch_size': 305, 'latent_dim': 20}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 984.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 938.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 676.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 744.00 MiB memory in use. Process 1542430 has 598.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 446.00 MiB memory in use. Process 1542827 has 1.17 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 746.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 818.00 MiB memory in use. Process 1543218 has 498.00 MiB memory in use. Process 1543221 has 936.00 MiB memory in use. Process 1543215 has 482.00 MiB memory in use. Process 1543600 has 460.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 562.00 MiB memory in use. Process 1543605 has 762.00 MiB memory in use. Process 1543609 has 1.25 GiB memory in use. Of the allocated memory 82.14 MiB is allocated by PyTorch, and 39.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cfe3b24d,"{'min_delta': 0.29, 'temperature': 0.4, 'batch_size': 359, 'latent_dim': 281}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 984.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 938.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 676.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 868.00 MiB memory in use. Process 1542430 has 422.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 474.00 MiB memory in use. Process 1542827 has 1.17 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 746.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 818.00 MiB memory in use. Process 1543218 has 500.00 MiB memory in use. Process 1543221 has 936.00 MiB memory in use. Process 1543215 has 510.00 MiB memory in use. Process 1543600 has 442.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 562.00 MiB memory in use. Process 1543605 has 762.00 MiB memory in use. Process 1543609 has 1.25 GiB memory in use. Of the allocated memory 454.48 MiB is allocated by PyTorch, and 75.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
768f29b5,"{'min_delta': 0.34800000000000003, 'temperature': 0.5, 'batch_size': 143, 'latent_dim': 296}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 984.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 938.00 MiB memory in use. Process 1539214 has 960.00 MiB memory in use. Process 1539216 has 676.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 868.00 MiB memory in use. Process 1542430 has 444.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 474.00 MiB memory in use. Process 1542827 has 1.17 GiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 746.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 818.00 MiB memory in use. Process 1543218 has 510.00 MiB memory in use. Process 1543221 has 936.00 MiB memory in use. Process 1543215 has 510.00 MiB memory in use. Process 1543600 has 442.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 562.00 MiB memory in use. Process 1543605 has 762.00 MiB memory in use. Process 1543609 has 1.25 GiB memory in use. Of the allocated memory 77.95 MiB is allocated by PyTorch, and 26.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
995fc1d8,"{'min_delta': 0.10400000000000001, 'temperature': 0.30000000000000004, 'batch_size': 241, 'latent_dim': 193}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 80.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 984.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 938.00 MiB memory in use. Process 1539214 has 888.00 MiB memory in use. Process 1539216 has 676.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 918.00 MiB memory in use. Process 1542430 has 514.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 476.00 MiB memory in use. Process 1542827 has 508.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 694.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 910.00 MiB memory in use. Process 1543218 has 616.00 MiB memory in use. Process 1543221 has 936.00 MiB memory in use. Process 1543215 has 466.00 MiB memory in use. Process 1543600 has 444.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 962.00 MiB memory in use. Process 1543605 has 822.00 MiB memory in use. Process 1543609 has 1.25 GiB memory in use. Of the allocated memory 277.79 MiB is allocated by PyTorch, and 78.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e6997574,"{'min_delta': 0.387, 'temperature': 0.2, 'batch_size': 179, 'latent_dim': 60}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 984.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 940.00 MiB memory in use. Process 1539214 has 888.00 MiB memory in use. Process 1539216 has 676.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 918.00 MiB memory in use. Process 1542430 has 712.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 476.00 MiB memory in use. Process 1542827 has 424.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 482.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 910.00 MiB memory in use. Process 1543218 has 616.00 MiB memory in use. Process 1543221 has 996.00 MiB memory in use. Process 1543215 has 516.00 MiB memory in use. Process 1543600 has 506.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 962.00 MiB memory in use. Process 1543605 has 822.00 MiB memory in use. Process 1543609 has 1.25 GiB memory in use. Of the allocated memory 94.78 MiB is allocated by PyTorch, and 71.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
f436ebd5,"{'min_delta': 0.253, 'temperature': 0.30000000000000004, 'batch_size': 230, 'latent_dim': 351}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 470.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 940.00 MiB memory in use. Process 1539214 has 888.00 MiB memory in use. Process 1539216 has 676.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 918.00 MiB memory in use. Process 1542430 has 488.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 708.00 MiB memory in use. Process 1542827 has 442.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 588.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 910.00 MiB memory in use. Process 1543218 has 924.00 MiB memory in use. Process 1543221 has 996.00 MiB memory in use. Process 1543215 has 516.00 MiB memory in use. Process 1543600 has 568.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 962.00 MiB memory in use. Process 1543605 has 822.00 MiB memory in use. Process 1543609 has 1.25 GiB memory in use. Of the allocated memory 205.71 MiB is allocated by PyTorch, and 44.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8171eadd,"{'min_delta': 0.465, 'temperature': 0.5, 'batch_size': 251, 'latent_dim': 180}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 866.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 940.00 MiB memory in use. Process 1539214 has 888.00 MiB memory in use. Process 1539216 has 676.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 918.00 MiB memory in use. Process 1542430 has 488.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 462.00 MiB memory in use. Process 1542827 has 704.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 904.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 640.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 910.00 MiB memory in use. Process 1543218 has 464.00 MiB memory in use. Process 1543221 has 996.00 MiB memory in use. Process 1543215 has 516.00 MiB memory in use. Process 1543600 has 566.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 962.00 MiB memory in use. Process 1543605 has 822.00 MiB memory in use. Process 1543609 has 1.25 GiB memory in use. Of the allocated memory 145.72 MiB is allocated by PyTorch, and 80.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d3880250,"{'min_delta': 0.59, 'temperature': 0.6000000000000001, 'batch_size': 218, 'latent_dim': 332}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 866.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 940.00 MiB memory in use. Process 1539214 has 944.00 MiB memory in use. Process 1539216 has 740.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 918.00 MiB memory in use. Process 1542430 has 442.00 MiB memory in use. Process 1542439 has 832.00 MiB memory in use. Process 1542433 has 464.00 MiB memory in use. Process 1542827 has 524.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 914.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 798.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 910.00 MiB memory in use. Process 1543218 has 464.00 MiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 564.00 MiB memory in use. Process 1543600 has 466.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 962.00 MiB memory in use. Process 1543605 has 822.00 MiB memory in use. Process 1543609 has 1.25 GiB memory in use. Of the allocated memory 84.58 MiB is allocated by PyTorch, and 41.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3ddc6981,"{'min_delta': 0.182, 'temperature': 0.9, 'batch_size': 129, 'latent_dim': 214}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 134.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 104.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 608.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 940.00 MiB memory in use. Process 1539214 has 944.00 MiB memory in use. Process 1539216 has 740.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 872.00 MiB memory in use. Process 1542430 has 510.00 MiB memory in use. Process 1542439 has 804.00 MiB memory in use. Process 1542433 has 764.00 MiB memory in use. Process 1542827 has 508.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 914.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 798.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 864.00 MiB memory in use. Process 1543218 has 540.00 MiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 462.00 MiB memory in use. Process 1543600 has 486.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 942.00 MiB memory in use. Process 1543605 has 812.00 MiB memory in use. Process 1543609 has 1.25 GiB memory in use. Of the allocated memory 411.67 MiB is allocated by PyTorch, and 122.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8be28975,"{'min_delta': 0.225, 'temperature': 0.6000000000000001, 'batch_size': 151, 'latent_dim': 318}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 148.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 448.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 940.00 MiB memory in use. Process 1539214 has 1.03 GiB memory in use. Process 1539216 has 666.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 748.00 MiB memory in use. Process 1542430 has 598.00 MiB memory in use. Process 1542439 has 804.00 MiB memory in use. Process 1542433 has 824.00 MiB memory in use. Process 1542827 has 650.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 914.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 798.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 864.00 MiB memory in use. Process 1543218 has 624.00 MiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 464.00 MiB memory in use. Process 1543600 has 486.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 942.00 MiB memory in use. Process 1543605 has 812.00 MiB memory in use. Process 1543609 has 1.08 GiB memory in use. Of the allocated memory 278.77 MiB is allocated by PyTorch, and 49.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b3c34edd,"{'min_delta': 0.074, 'temperature': 0.1, 'batch_size': 270, 'latent_dim': 260}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 448.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 940.00 MiB memory in use. Process 1539214 has 1.03 GiB memory in use. Process 1539216 has 666.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 748.00 MiB memory in use. Process 1542430 has 734.00 MiB memory in use. Process 1542439 has 804.00 MiB memory in use. Process 1542433 has 824.00 MiB memory in use. Process 1542827 has 512.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 914.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 852.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 864.00 MiB memory in use. Process 1543218 has 626.00 MiB memory in use. Process 1543221 has 954.00 MiB memory in use. Process 1543215 has 464.00 MiB memory in use. Process 1543600 has 564.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 942.00 MiB memory in use. Process 1543605 has 812.00 MiB memory in use. Process 1543609 has 1.08 GiB memory in use. Of the allocated memory 146.35 MiB is allocated by PyTorch, and 77.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
09ca7b61,"{'min_delta': 0.534, 'temperature': 0.1, 'batch_size': 344, 'latent_dim': 36}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 642.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 940.00 MiB memory in use. Process 1539214 has 1.03 GiB memory in use. Process 1539216 has 458.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 706.00 MiB memory in use. Process 1542430 has 564.00 MiB memory in use. Process 1542439 has 976.00 MiB memory in use. Process 1542433 has 824.00 MiB memory in use. Process 1542827 has 512.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 854.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 916.00 MiB memory in use. Process 1543218 has 742.00 MiB memory in use. Process 1543221 has 462.00 MiB memory in use. Process 1543215 has 488.00 MiB memory in use. Process 1543600 has 620.00 MiB memory in use. Process 1543606 has 1.03 GiB memory in use. Process 1543612 has 942.00 MiB memory in use. Process 1543605 has 864.00 MiB memory in use. Process 1543609 has 1.23 GiB memory in use. Of the allocated memory 203.25 MiB is allocated by PyTorch, and 76.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
31333a02,"{'min_delta': 0.029, 'temperature': 0.1, 'batch_size': 328, 'latent_dim': 15}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 576.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 796.00 MiB memory in use. Process 1539214 has 1.04 GiB memory in use. Process 1539216 has 526.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 458.00 MiB memory in use. Process 1542430 has 486.00 MiB memory in use. Process 1542439 has 976.00 MiB memory in use. Process 1542433 has 874.00 MiB memory in use. Process 1542827 has 1020.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 854.00 MiB memory in use. Process 1543212 has 918.00 MiB memory in use. Process 1543209 has 866.00 MiB memory in use. Process 1543218 has 442.00 MiB memory in use. Process 1543221 has 762.00 MiB memory in use. Process 1543215 has 524.00 MiB memory in use. Process 1543600 has 454.00 MiB memory in use. Process 1543606 has 1.07 GiB memory in use. Process 1543612 has 972.00 MiB memory in use. Process 1543605 has 864.00 MiB memory in use. Process 1543609 has 1.23 GiB memory in use. Of the allocated memory 144.43 MiB is allocated by PyTorch, and 43.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
66e5c48c,"{'min_delta': 0.054, 'temperature': 0.1, 'batch_size': 294, 'latent_dim': 22}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 686.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 444.00 MiB memory in use. Process 1539214 has 1.04 GiB memory in use. Process 1539216 has 584.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 744.00 MiB memory in use. Process 1542430 has 486.00 MiB memory in use. Process 1542439 has 976.00 MiB memory in use. Process 1542433 has 874.00 MiB memory in use. Process 1542827 has 1020.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 854.00 MiB memory in use. Process 1543212 has 920.00 MiB memory in use. Process 1543209 has 866.00 MiB memory in use. Process 1543218 has 646.00 MiB memory in use. Process 1543221 has 464.00 MiB memory in use. Process 1543215 has 524.00 MiB memory in use. Process 1543600 has 424.00 MiB memory in use. Process 1543606 has 1.07 GiB memory in use. Process 1543612 has 972.00 MiB memory in use. Process 1543605 has 864.00 MiB memory in use. Process 1543609 has 1.23 GiB memory in use. Of the allocated memory 47.15 MiB is allocated by PyTorch, and 36.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7aeb4711,"{'min_delta': 0.039, 'temperature': 0.1, 'batch_size': 265, 'latent_dim': 46}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 444.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 894.00 MiB memory in use. Process 1539214 has 1.04 GiB memory in use. Process 1539216 has 584.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 744.00 MiB memory in use. Process 1542430 has 518.00 MiB memory in use. Process 1542439 has 976.00 MiB memory in use. Process 1542433 has 1014.00 MiB memory in use. Process 1542827 has 1020.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 868.00 MiB memory in use. Process 1543212 has 920.00 MiB memory in use. Process 1543209 has 474.00 MiB memory in use. Process 1543218 has 500.00 MiB memory in use. Process 1543221 has 510.00 MiB memory in use. Process 1543215 has 588.00 MiB memory in use. Process 1543600 has 462.00 MiB memory in use. Process 1543606 has 1.07 GiB memory in use. Process 1543612 has 972.00 MiB memory in use. Process 1543605 has 868.00 MiB memory in use. Process 1543609 has 1.23 GiB memory in use. Of the allocated memory 82.34 MiB is allocated by PyTorch, and 39.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
29b10688,"{'min_delta': 0.14, 'temperature': 0.2, 'batch_size': 260, 'latent_dim': 22}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 464.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 894.00 MiB memory in use. Process 1539214 has 1.04 GiB memory in use. Process 1539216 has 584.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 744.00 MiB memory in use. Process 1542430 has 512.00 MiB memory in use. Process 1542439 has 976.00 MiB memory in use. Process 1542433 has 1014.00 MiB memory in use. Process 1542827 has 1020.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 868.00 MiB memory in use. Process 1543212 has 920.00 MiB memory in use. Process 1543209 has 474.00 MiB memory in use. Process 1543218 has 500.00 MiB memory in use. Process 1543221 has 510.00 MiB memory in use. Process 1543215 has 618.00 MiB memory in use. Process 1543600 has 442.00 MiB memory in use. Process 1543606 has 1.07 GiB memory in use. Process 1543612 has 972.00 MiB memory in use. Process 1543605 has 868.00 MiB memory in use. Process 1543609 has 1.23 GiB memory in use. Of the allocated memory 72.01 MiB is allocated by PyTorch, and 29.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
1b89dd6a,"{'min_delta': 0.018000000000000002, 'temperature': 0.1, 'batch_size': 310, 'latent_dim': 74}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 464.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1008.00 MiB memory in use. Process 1539214 has 1.04 GiB memory in use. Process 1539216 has 584.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 744.00 MiB memory in use. Process 1542430 has 564.00 MiB memory in use. Process 1542439 has 976.00 MiB memory in use. Process 1542433 has 1014.00 MiB memory in use. Process 1542827 has 1020.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 868.00 MiB memory in use. Process 1543212 has 920.00 MiB memory in use. Process 1543209 has 474.00 MiB memory in use. Process 1543218 has 502.00 MiB memory in use. Process 1543221 has 508.00 MiB memory in use. Process 1543215 has 446.00 MiB memory in use. Process 1543600 has 448.00 MiB memory in use. Process 1543606 has 1.07 GiB memory in use. Process 1543612 has 972.00 MiB memory in use. Process 1543605 has 868.00 MiB memory in use. Process 1543609 has 1.23 GiB memory in use. Of the allocated memory 74.95 MiB is allocated by PyTorch, and 33.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
f032ed05,"{'min_delta': 0.039, 'temperature': 2.0, 'batch_size': 353, 'latent_dim': 61}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 464.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1008.00 MiB memory in use. Process 1539214 has 1.04 GiB memory in use. Process 1539216 has 584.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 744.00 MiB memory in use. Process 1542430 has 446.00 MiB memory in use. Process 1542439 has 976.00 MiB memory in use. Process 1542433 has 1014.00 MiB memory in use. Process 1542827 has 1020.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 854.00 MiB memory in use. Process 1543212 has 920.00 MiB memory in use. Process 1543209 has 474.00 MiB memory in use. Process 1543218 has 490.00 MiB memory in use. Process 1543221 has 508.00 MiB memory in use. Process 1543215 has 446.00 MiB memory in use. Process 1543600 has 526.00 MiB memory in use. Process 1543606 has 1.13 GiB memory in use. Process 1543612 has 972.00 MiB memory in use. Process 1543605 has 868.00 MiB memory in use. Process 1543609 has 1.23 GiB memory in use. Of the allocated memory 144.79 MiB is allocated by PyTorch, and 41.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c6181ff6,"{'min_delta': 0.001, 'temperature': 0.2, 'batch_size': 304, 'latent_dim': 44}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 444.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1008.00 MiB memory in use. Process 1539214 has 1.04 GiB memory in use. Process 1539216 has 644.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 744.00 MiB memory in use. Process 1542430 has 446.00 MiB memory in use. Process 1542439 has 976.00 MiB memory in use. Process 1542433 has 1014.00 MiB memory in use. Process 1542827 has 1020.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 854.00 MiB memory in use. Process 1543212 has 922.00 MiB memory in use. Process 1543209 has 456.00 MiB memory in use. Process 1543218 has 582.00 MiB memory in use. Process 1543221 has 486.00 MiB memory in use. Process 1543215 has 448.00 MiB memory in use. Process 1543600 has 468.00 MiB memory in use. Process 1543606 has 1.13 GiB memory in use. Process 1543612 has 928.00 MiB memory in use. Process 1543605 has 868.00 MiB memory in use. Process 1543609 has 1.23 GiB memory in use. Of the allocated memory 217.97 MiB is allocated by PyTorch, and 88.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
467a5289,"{'min_delta': 0.095, 'temperature': 0.2, 'batch_size': 384, 'latent_dim': 41}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 620.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1008.00 MiB memory in use. Process 1539214 has 1.04 GiB memory in use. Process 1539216 has 466.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 916.00 MiB memory in use. Process 1542439 has 976.00 MiB memory in use. Process 1542433 has 484.00 MiB memory in use. Process 1542827 has 1020.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 854.00 MiB memory in use. Process 1543212 has 922.00 MiB memory in use. Process 1543209 has 510.00 MiB memory in use. Process 1543218 has 584.00 MiB memory in use. Process 1543221 has 996.00 MiB memory in use. Process 1543215 has 488.00 MiB memory in use. Process 1543600 has 582.00 MiB memory in use. Process 1543606 has 1.13 GiB memory in use. Process 1543612 has 928.00 MiB memory in use. Process 1543605 has 868.00 MiB memory in use. Process 1543609 has 468.00 MiB memory in use. Of the allocated memory 203.28 MiB is allocated by PyTorch, and 38.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b0668f3d,"{'min_delta': 0.156, 'temperature': 0.1, 'batch_size': 300, 'latent_dim': 54}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 526.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1008.00 MiB memory in use. Process 1539214 has 1.04 GiB memory in use. Process 1539216 has 426.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 916.00 MiB memory in use. Process 1542439 has 922.00 MiB memory in use. Process 1542433 has 486.00 MiB memory in use. Process 1542827 has 1020.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 908.00 MiB memory in use. Process 1543212 has 922.00 MiB memory in use. Process 1543209 has 442.00 MiB memory in use. Process 1543218 has 584.00 MiB memory in use. Process 1543221 has 996.00 MiB memory in use. Process 1543215 has 518.00 MiB memory in use. Process 1543600 has 468.00 MiB memory in use. Process 1543606 has 1.13 GiB memory in use. Process 1543612 has 928.00 MiB memory in use. Process 1543605 has 868.00 MiB memory in use. Process 1543609 has 738.00 MiB memory in use. Of the allocated memory 47.40 MiB is allocated by PyTorch, and 40.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
943af4ae,"{'min_delta': 0.078, 'temperature': 0.30000000000000004, 'batch_size': 441, 'latent_dim': 46}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 488.00 MiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 1008.00 MiB memory in use. Process 1539214 has 1.04 GiB memory in use. Process 1539216 has 476.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 916.00 MiB memory in use. Process 1542439 has 922.00 MiB memory in use. Process 1542433 has 486.00 MiB memory in use. Process 1542827 has 1020.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 908.00 MiB memory in use. Process 1543212 has 922.00 MiB memory in use. Process 1543209 has 442.00 MiB memory in use. Process 1543218 has 584.00 MiB memory in use. Process 1543221 has 996.00 MiB memory in use. Process 1543215 has 518.00 MiB memory in use. Process 1543600 has 470.00 MiB memory in use. Process 1543606 has 1.13 GiB memory in use. Process 1543612 has 928.00 MiB memory in use. Process 1543605 has 868.00 MiB memory in use. Process 1543609 has 738.00 MiB memory in use. Of the allocated memory 82.34 MiB is allocated by PyTorch, and 47.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6bd5fb94,"{'min_delta': 0.026000000000000002, 'temperature': 0.5, 'batch_size': 269, 'latent_dim': 88}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 478.00 MiB memory in use. Process 1539214 has 1.04 GiB memory in use. Process 1539216 has 564.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 864.00 MiB memory in use. Process 1542430 has 916.00 MiB memory in use. Process 1542439 has 922.00 MiB memory in use. Process 1542433 has 486.00 MiB memory in use. Process 1542827 has 442.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 908.00 MiB memory in use. Process 1543212 has 922.00 MiB memory in use. Process 1543209 has 780.00 MiB memory in use. Process 1543218 has 998.00 MiB memory in use. Process 1543221 has 996.00 MiB memory in use. Process 1543215 has 562.00 MiB memory in use. Process 1543600 has 452.00 MiB memory in use. Process 1543606 has 1.13 GiB memory in use. Process 1543612 has 928.00 MiB memory in use. Process 1543605 has 868.00 MiB memory in use. Process 1543609 has 448.00 MiB memory in use. Of the allocated memory 145.00 MiB is allocated by PyTorch, and 81.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9f452a12,"{'min_delta': 0.049, 'temperature': 0.5, 'batch_size': 258, 'latent_dim': 3}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 478.00 MiB memory in use. Process 1539214 has 1.04 GiB memory in use. Process 1539216 has 560.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 874.00 MiB memory in use. Process 1542430 has 924.00 MiB memory in use. Process 1542439 has 922.00 MiB memory in use. Process 1542433 has 442.00 MiB memory in use. Process 1542827 has 716.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 908.00 MiB memory in use. Process 1543212 has 922.00 MiB memory in use. Process 1543209 has 880.00 MiB memory in use. Process 1543218 has 998.00 MiB memory in use. Process 1543221 has 972.00 MiB memory in use. Process 1543215 has 564.00 MiB memory in use. Process 1543600 has 456.00 MiB memory in use. Process 1543606 has 1.13 GiB memory in use. Process 1543612 has 568.00 MiB memory in use. Process 1543605 has 868.00 MiB memory in use. Process 1543609 has 434.00 MiB memory in use. Of the allocated memory 144.34 MiB is allocated by PyTorch, and 77.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ea095d7a,"{'min_delta': 0.101, 'temperature': 0.30000000000000004, 'batch_size': 225, 'latent_dim': 60}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 902.00 MiB memory in use. Process 1539214 has 914.00 MiB memory in use. Process 1539216 has 622.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 874.00 MiB memory in use. Process 1542430 has 924.00 MiB memory in use. Process 1542439 has 460.00 MiB memory in use. Process 1542433 has 466.00 MiB memory in use. Process 1542827 has 770.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1018.00 MiB memory in use. Process 1543212 has 922.00 MiB memory in use. Process 1543209 has 886.00 MiB memory in use. Process 1543218 has 998.00 MiB memory in use. Process 1543221 has 972.00 MiB memory in use. Process 1543215 has 564.00 MiB memory in use. Process 1543600 has 460.00 MiB memory in use. Process 1543606 has 1.13 GiB memory in use. Process 1543612 has 510.00 MiB memory in use. Process 1543605 has 868.00 MiB memory in use. Process 1543609 has 446.00 MiB memory in use. Of the allocated memory 203.43 MiB is allocated by PyTorch, and 80.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5ef4f90f,"{'min_delta': 0.16, 'temperature': 0.2, 'batch_size': 397, 'latent_dim': 50}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 902.00 MiB memory in use. Process 1539214 has 914.00 MiB memory in use. Process 1539216 has 708.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 874.00 MiB memory in use. Process 1542430 has 924.00 MiB memory in use. Process 1542439 has 470.00 MiB memory in use. Process 1542433 has 466.00 MiB memory in use. Process 1542827 has 446.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1018.00 MiB memory in use. Process 1543212 has 922.00 MiB memory in use. Process 1543209 has 886.00 MiB memory in use. Process 1543218 has 998.00 MiB memory in use. Process 1543221 has 972.00 MiB memory in use. Process 1543215 has 564.00 MiB memory in use. Process 1543600 has 462.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 614.00 MiB memory in use. Process 1543605 has 868.00 MiB memory in use. Process 1543609 has 562.00 MiB memory in use. Of the allocated memory 307.91 MiB is allocated by PyTorch, and 62.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
78391c59,"{'min_delta': 0.14400000000000002, 'temperature': 0.5, 'batch_size': 362, 'latent_dim': 33}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 902.00 MiB memory in use. Process 1539214 has 914.00 MiB memory in use. Process 1539216 has 456.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 874.00 MiB memory in use. Process 1542430 has 924.00 MiB memory in use. Process 1542439 has 594.00 MiB memory in use. Process 1542433 has 408.00 MiB memory in use. Process 1542827 has 444.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1018.00 MiB memory in use. Process 1543212 has 924.00 MiB memory in use. Process 1543209 has 886.00 MiB memory in use. Process 1543218 has 998.00 MiB memory in use. Process 1543221 has 972.00 MiB memory in use. Process 1543215 has 616.00 MiB memory in use. Process 1543600 has 462.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 674.00 MiB memory in use. Process 1543605 has 870.00 MiB memory in use. Process 1543609 has 610.00 MiB memory in use. Of the allocated memory 82.24 MiB is allocated by PyTorch, and 35.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8c0330b4,"{'min_delta': 0.187, 'temperature': 0.4, 'batch_size': 279, 'latent_dim': 66}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 902.00 MiB memory in use. Process 1539214 has 914.00 MiB memory in use. Process 1539216 has 430.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 874.00 MiB memory in use. Process 1542430 has 924.00 MiB memory in use. Process 1542439 has 626.00 MiB memory in use. Process 1542433 has 438.00 MiB memory in use. Process 1542827 has 444.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1018.00 MiB memory in use. Process 1543212 has 924.00 MiB memory in use. Process 1543209 has 886.00 MiB memory in use. Process 1543218 has 998.00 MiB memory in use. Process 1543221 has 972.00 MiB memory in use. Process 1543215 has 616.00 MiB memory in use. Process 1543600 has 462.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 680.00 MiB memory in use. Process 1543605 has 870.00 MiB memory in use. Process 1543609 has 610.00 MiB memory in use. Of the allocated memory 65.25 MiB is allocated by PyTorch, and 26.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
a0ced048,"{'min_delta': 0.002, 'temperature': 0.4, 'batch_size': 244, 'latent_dim': 71}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 902.00 MiB memory in use. Process 1539214 has 914.00 MiB memory in use. Process 1539216 has 430.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 874.00 MiB memory in use. Process 1542430 has 924.00 MiB memory in use. Process 1542439 has 478.00 MiB memory in use. Process 1542433 has 438.00 MiB memory in use. Process 1542827 has 444.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1018.00 MiB memory in use. Process 1543212 has 924.00 MiB memory in use. Process 1543209 has 886.00 MiB memory in use. Process 1543218 has 998.00 MiB memory in use. Process 1543221 has 972.00 MiB memory in use. Process 1543215 has 616.00 MiB memory in use. Process 1543600 has 586.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 680.00 MiB memory in use. Process 1543605 has 870.00 MiB memory in use. Process 1543609 has 610.00 MiB memory in use. Of the allocated memory 203.52 MiB is allocated by PyTorch, and 42.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e89b253a,"{'min_delta': 0.28, 'temperature': 0.30000000000000004, 'batch_size': 247, 'latent_dim': 40}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 902.00 MiB memory in use. Process 1539214 has 442.00 MiB memory in use. Process 1539216 has 426.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 874.00 MiB memory in use. Process 1542430 has 924.00 MiB memory in use. Process 1542439 has 516.00 MiB memory in use. Process 1542433 has 490.00 MiB memory in use. Process 1542827 has 702.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 924.00 MiB memory in use. Process 1543209 has 886.00 MiB memory in use. Process 1543218 has 998.00 MiB memory in use. Process 1543221 has 1020.00 MiB memory in use. Process 1543215 has 842.00 MiB memory in use. Process 1543600 has 648.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 440.00 MiB memory in use. Process 1543605 has 870.00 MiB memory in use. Process 1543609 has 624.00 MiB memory in use. Of the allocated memory 47.29 MiB is allocated by PyTorch, and 40.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
38db5db5,"{'min_delta': 0.339, 'temperature': 0.30000000000000004, 'batch_size': 235, 'latent_dim': 21}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 958.00 MiB memory in use. Process 1539214 has 442.00 MiB memory in use. Process 1539216 has 462.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 986.00 MiB memory in use. Process 1542430 has 924.00 MiB memory in use. Process 1542439 has 448.00 MiB memory in use. Process 1542433 has 490.00 MiB memory in use. Process 1542827 has 444.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 924.00 MiB memory in use. Process 1543209 has 886.00 MiB memory in use. Process 1543218 has 998.00 MiB memory in use. Process 1543221 has 1020.00 MiB memory in use. Process 1543215 has 842.00 MiB memory in use. Process 1543600 has 648.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 510.00 MiB memory in use. Process 1543605 has 870.00 MiB memory in use. Process 1543609 has 670.00 MiB memory in use. Of the allocated memory 82.15 MiB is allocated by PyTorch, and 41.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
585c4d6a,"{'min_delta': 0.06, 'temperature': 0.2, 'batch_size': 295, 'latent_dim': 57}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 958.00 MiB memory in use. Process 1539214 has 442.00 MiB memory in use. Process 1539216 has 466.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 986.00 MiB memory in use. Process 1542430 has 924.00 MiB memory in use. Process 1542439 has 448.00 MiB memory in use. Process 1542433 has 546.00 MiB memory in use. Process 1542827 has 444.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 924.00 MiB memory in use. Process 1543209 has 886.00 MiB memory in use. Process 1543218 has 998.00 MiB memory in use. Process 1543221 has 1020.00 MiB memory in use. Process 1543215 has 842.00 MiB memory in use. Process 1543600 has 646.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 468.00 MiB memory in use. Process 1543605 has 870.00 MiB memory in use. Process 1543609 has 670.00 MiB memory in use. Of the allocated memory 218.07 MiB is allocated by PyTorch, and 87.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
b5328f5f,"{'min_delta': 0.301, 'temperature': 0.5, 'batch_size': 205, 'latent_dim': 29}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 922.00 MiB memory in use. Process 1539214 has 444.00 MiB memory in use. Process 1539216 has 468.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 986.00 MiB memory in use. Process 1542430 has 934.00 MiB memory in use. Process 1542439 has 448.00 MiB memory in use. Process 1542433 has 572.00 MiB memory in use. Process 1542827 has 444.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 924.00 MiB memory in use. Process 1543209 has 886.00 MiB memory in use. Process 1543218 has 998.00 MiB memory in use. Process 1543221 has 1020.00 MiB memory in use. Process 1543215 has 842.00 MiB memory in use. Process 1543600 has 428.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 468.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 780.00 MiB memory in use. Of the allocated memory 47.20 MiB is allocated by PyTorch, and 40.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d737db27,"{'min_delta': 0.10400000000000001, 'temperature': 0.2, 'batch_size': 370, 'latent_dim': 75}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 922.00 MiB memory in use. Process 1539214 has 424.00 MiB memory in use. Process 1539216 has 468.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 986.00 MiB memory in use. Process 1542430 has 934.00 MiB memory in use. Process 1542439 has 448.00 MiB memory in use. Process 1542433 has 562.00 MiB memory in use. Process 1542827 has 444.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 924.00 MiB memory in use. Process 1543209 has 886.00 MiB memory in use. Process 1543218 has 998.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 842.00 MiB memory in use. Process 1543600 has 426.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 488.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 780.00 MiB memory in use. Of the allocated memory 77.77 MiB is allocated by PyTorch, and 8.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 46, in calculate_loss
    logits = torch.cat([torch.cat([logits_ab, logits_aa], dim=1), torch.cat([logits_ba, logits_bb], dim=1)], dim=0)
"
c93a78dd,"{'min_delta': 0.028, 'temperature': 0.6000000000000001, 'batch_size': 263, 'latent_dim': 105}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 922.00 MiB memory in use. Process 1539214 has 474.00 MiB memory in use. Process 1539216 has 464.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 986.00 MiB memory in use. Process 1542430 has 934.00 MiB memory in use. Process 1542439 has 444.00 MiB memory in use. Process 1542433 has 486.00 MiB memory in use. Process 1542827 has 444.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 924.00 MiB memory in use. Process 1543209 has 886.00 MiB memory in use. Process 1543218 has 998.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 842.00 MiB memory in use. Process 1543600 has 466.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 466.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 780.00 MiB memory in use. Of the allocated memory 82.80 MiB is allocated by PyTorch, and 43.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c078a98e,"{'min_delta': 0.254, 'temperature': 0.1, 'batch_size': 303, 'latent_dim': 48}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 922.00 MiB memory in use. Process 1539214 has 464.00 MiB memory in use. Process 1539216 has 464.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 986.00 MiB memory in use. Process 1542430 has 934.00 MiB memory in use. Process 1542439 has 476.00 MiB memory in use. Process 1542433 has 446.00 MiB memory in use. Process 1542827 has 510.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 1018.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 924.00 MiB memory in use. Process 1543209 has 828.00 MiB memory in use. Process 1543218 has 998.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 842.00 MiB memory in use. Process 1543600 has 458.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 468.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 782.00 MiB memory in use. Of the allocated memory 82.36 MiB is allocated by PyTorch, and 35.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ee788a82,"{'min_delta': 0.148, 'temperature': 0.4, 'batch_size': 317, 'latent_dim': 64}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 922.00 MiB memory in use. Process 1539214 has 514.00 MiB memory in use. Process 1539216 has 464.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 986.00 MiB memory in use. Process 1542430 has 934.00 MiB memory in use. Process 1542439 has 476.00 MiB memory in use. Process 1542433 has 508.00 MiB memory in use. Process 1542827 has 428.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 896.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 924.00 MiB memory in use. Process 1543209 has 828.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 486.00 MiB memory in use. Process 1543600 has 590.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 814.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 782.00 MiB memory in use. Of the allocated memory 203.46 MiB is allocated by PyTorch, and 46.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8eb85dce,"{'min_delta': 0.044, 'temperature': 0.30000000000000004, 'batch_size': 271, 'latent_dim': 125}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 922.00 MiB memory in use. Process 1539214 has 514.00 MiB memory in use. Process 1539216 has 430.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 986.00 MiB memory in use. Process 1542430 has 934.00 MiB memory in use. Process 1542439 has 588.00 MiB memory in use. Process 1542433 has 508.00 MiB memory in use. Process 1542827 has 442.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 896.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 924.00 MiB memory in use. Process 1543209 has 828.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 486.00 MiB memory in use. Process 1543600 has 458.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 826.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 782.00 MiB memory in use. Of the allocated memory 47.95 MiB is allocated by PyTorch, and 44.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5232c644,"{'min_delta': 0.115, 'temperature': 0.5, 'batch_size': 347, 'latent_dim': 13}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 922.00 MiB memory in use. Process 1539214 has 444.00 MiB memory in use. Process 1539216 has 480.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 986.00 MiB memory in use. Process 1542430 has 934.00 MiB memory in use. Process 1542439 has 512.00 MiB memory in use. Process 1542433 has 564.00 MiB memory in use. Process 1542827 has 444.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 896.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 924.00 MiB memory in use. Process 1543209 has 828.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 486.00 MiB memory in use. Process 1543600 has 512.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 826.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 782.00 MiB memory in use. Of the allocated memory 94.41 MiB is allocated by PyTorch, and 77.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
e781eba4,"{'min_delta': 0.20400000000000001, 'temperature': 0.4, 'batch_size': 235, 'latent_dim': 42}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 472.00 MiB memory in use. Process 1539214 has 906.00 MiB memory in use. Process 1539216 has 480.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 986.00 MiB memory in use. Process 1542430 has 450.00 MiB memory in use. Process 1542439 has 890.00 MiB memory in use. Process 1542433 has 564.00 MiB memory in use. Process 1542827 has 444.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 896.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 928.00 MiB memory in use. Process 1543209 has 828.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 486.00 MiB memory in use. Process 1543600 has 624.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 826.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 782.00 MiB memory in use. Of the allocated memory 203.29 MiB is allocated by PyTorch, and 80.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5d479953,"{'min_delta': 0.18, 'temperature': 0.1, 'batch_size': 198, 'latent_dim': 88}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 722.00 MiB memory in use. Process 1539214 has 906.00 MiB memory in use. Process 1539216 has 750.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 986.00 MiB memory in use. Process 1542430 has 526.00 MiB memory in use. Process 1542439 has 890.00 MiB memory in use. Process 1542433 has 446.00 MiB memory in use. Process 1542827 has 720.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 442.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 928.00 MiB memory in use. Process 1543209 has 706.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 766.00 MiB memory in use. Process 1543600 has 458.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 466.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 828.00 MiB memory in use. Of the allocated memory 82.67 MiB is allocated by PyTorch, and 35.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8e0f2728,"{'min_delta': 0.23600000000000002, 'temperature': 0.6000000000000001, 'batch_size': 390, 'latent_dim': 100}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 722.00 MiB memory in use. Process 1539214 has 906.00 MiB memory in use. Process 1539216 has 758.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 986.00 MiB memory in use. Process 1542430 has 444.00 MiB memory in use. Process 1542439 has 890.00 MiB memory in use. Process 1542433 has 446.00 MiB memory in use. Process 1542827 has 720.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 478.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 928.00 MiB memory in use. Process 1543209 has 736.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 712.00 MiB memory in use. Process 1543600 has 462.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 456.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 888.00 MiB memory in use. Of the allocated memory 339.55 MiB is allocated by PyTorch, and 80.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e402099d,"{'min_delta': 0.128, 'temperature': 0.30000000000000004, 'batch_size': 324, 'latent_dim': 27}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 722.00 MiB memory in use. Process 1539214 has 906.00 MiB memory in use. Process 1539216 has 918.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 986.00 MiB memory in use. Process 1542430 has 444.00 MiB memory in use. Process 1542439 has 892.00 MiB memory in use. Process 1542433 has 446.00 MiB memory in use. Process 1542827 has 750.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 480.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 928.00 MiB memory in use. Process 1543209 has 820.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 466.00 MiB memory in use. Process 1543600 has 428.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 456.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 888.00 MiB memory in use. Of the allocated memory 47.19 MiB is allocated by PyTorch, and 40.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
409f472e,"{'min_delta': 0.405, 'temperature': 1.6, 'batch_size': 230, 'latent_dim': 17}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 722.00 MiB memory in use. Process 1539214 has 916.00 MiB memory in use. Process 1539216 has 918.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 986.00 MiB memory in use. Process 1542430 has 444.00 MiB memory in use. Process 1542439 has 892.00 MiB memory in use. Process 1542433 has 446.00 MiB memory in use. Process 1542827 has 768.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 480.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 928.00 MiB memory in use. Process 1543209 has 820.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 466.00 MiB memory in use. Process 1543600 has 422.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 446.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 888.00 MiB memory in use. Of the allocated memory 47.11 MiB is allocated by PyTorch, and 34.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
88b19e11,"{'min_delta': 0.05, 'temperature': 0.4, 'batch_size': 298, 'latent_dim': 48}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 722.00 MiB memory in use. Process 1539214 has 916.00 MiB memory in use. Process 1539216 has 918.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 986.00 MiB memory in use. Process 1542430 has 444.00 MiB memory in use. Process 1542439 has 892.00 MiB memory in use. Process 1542433 has 446.00 MiB memory in use. Process 1542827 has 768.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 480.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 928.00 MiB memory in use. Process 1543209 has 820.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 466.00 MiB memory in use. Process 1543600 has 426.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 466.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 888.00 MiB memory in use. Of the allocated memory 54.93 MiB is allocated by PyTorch, and 31.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
501a4797,"{'min_delta': 0.432, 'temperature': 0.5, 'batch_size': 267, 'latent_dim': 10}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 722.00 MiB memory in use. Process 1539214 has 916.00 MiB memory in use. Process 1539216 has 918.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 986.00 MiB memory in use. Process 1542430 has 434.00 MiB memory in use. Process 1542439 has 892.00 MiB memory in use. Process 1542433 has 446.00 MiB memory in use. Process 1542827 has 780.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 512.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 928.00 MiB memory in use. Process 1543209 has 820.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 426.00 MiB memory in use. Process 1543600 has 430.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 468.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 888.00 MiB memory in use. Of the allocated memory 62.30 MiB is allocated by PyTorch, and 27.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
67ac3785,"{'min_delta': 0.264, 'temperature': 0.1, 'batch_size': 244, 'latent_dim': 80}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 820.00 MiB memory in use. Process 1539214 has 916.00 MiB memory in use. Process 1539216 has 918.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 922.00 MiB memory in use. Process 1542430 has 474.00 MiB memory in use. Process 1542439 has 892.00 MiB memory in use. Process 1542433 has 446.00 MiB memory in use. Process 1542827 has 780.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 444.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 1020.00 MiB memory in use. Process 1543212 has 928.00 MiB memory in use. Process 1543209 has 820.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 446.00 MiB memory in use. Process 1543600 has 442.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 430.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 888.00 MiB memory in use. Of the allocated memory 69.48 MiB is allocated by PyTorch, and 32.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
2fd62a62,"{'min_delta': 0.036000000000000004, 'temperature': 0.30000000000000004, 'batch_size': 277, 'latent_dim': 35}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 502.00 MiB memory in use. Process 1539214 has 446.00 MiB memory in use. Process 1539216 has 922.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 922.00 MiB memory in use. Process 1542430 has 444.00 MiB memory in use. Process 1542439 has 896.00 MiB memory in use. Process 1542433 has 512.00 MiB memory in use. Process 1542827 has 780.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 442.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 926.00 MiB memory in use. Process 1543212 has 928.00 MiB memory in use. Process 1543209 has 820.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 760.00 MiB memory in use. Process 1543600 has 428.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 942.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 888.00 MiB memory in use. Of the allocated memory 47.25 MiB is allocated by PyTorch, and 40.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7a02076b,"{'min_delta': 0.073, 'temperature': 2.0, 'batch_size': 309, 'latent_dim': 2}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 564.00 MiB memory in use. Process 1539214 has 460.00 MiB memory in use. Process 1539216 has 922.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 922.00 MiB memory in use. Process 1542430 has 478.00 MiB memory in use. Process 1542439 has 896.00 MiB memory in use. Process 1542433 has 676.00 MiB memory in use. Process 1542827 has 448.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 442.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 926.00 MiB memory in use. Process 1543212 has 928.00 MiB memory in use. Process 1543209 has 826.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 760.00 MiB memory in use. Process 1543600 has 462.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 942.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 888.00 MiB memory in use. Of the allocated memory 82.00 MiB is allocated by PyTorch, and 40.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3cf02f51,"{'min_delta': 0.152, 'temperature': 0.4, 'batch_size': 338, 'latent_dim': 122}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 514.00 MiB memory in use. Process 1539214 has 512.00 MiB memory in use. Process 1539216 has 922.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 974.00 MiB memory in use. Process 1542430 has 478.00 MiB memory in use. Process 1542439 has 896.00 MiB memory in use. Process 1542433 has 572.00 MiB memory in use. Process 1542827 has 448.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 474.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 926.00 MiB memory in use. Process 1543212 has 928.00 MiB memory in use. Process 1543209 has 826.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 760.00 MiB memory in use. Process 1543600 has 514.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 942.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 888.00 MiB memory in use. Of the allocated memory 95.27 MiB is allocated by PyTorch, and 78.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
f8bf7c39,"{'min_delta': 0.09, 'temperature': 0.2, 'batch_size': 194, 'latent_dim': 112}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 892.00 MiB memory in use. Process 1539214 has 442.00 MiB memory in use. Process 1539216 has 884.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 974.00 MiB memory in use. Process 1542430 has 478.00 MiB memory in use. Process 1542439 has 896.00 MiB memory in use. Process 1542433 has 638.00 MiB memory in use. Process 1542827 has 442.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 874.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 462.00 MiB memory in use. Process 1543212 has 928.00 MiB memory in use. Process 1543209 has 464.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 974.00 MiB memory in use. Process 1543600 has 452.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 928.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 832.00 MiB memory in use. Of the allocated memory 82.86 MiB is allocated by PyTorch, and 41.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1ff090a2,"{'min_delta': 0.022, 'temperature': 0.2, 'batch_size': 210, 'latent_dim': 148}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 892.00 MiB memory in use. Process 1539214 has 442.00 MiB memory in use. Process 1539216 has 884.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 974.00 MiB memory in use. Process 1542430 has 478.00 MiB memory in use. Process 1542439 has 896.00 MiB memory in use. Process 1542433 has 640.00 MiB memory in use. Process 1542827 has 442.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 878.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 444.00 MiB memory in use. Process 1543212 has 928.00 MiB memory in use. Process 1543209 has 450.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 974.00 MiB memory in use. Process 1543600 has 428.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 928.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 884.00 MiB memory in use. Of the allocated memory 48.14 MiB is allocated by PyTorch, and 39.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a0cd20ee,"{'min_delta': 0.056, 'temperature': 0.30000000000000004, 'batch_size': 173, 'latent_dim': 129}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 898.00 MiB memory in use. Process 1539214 has 442.00 MiB memory in use. Process 1539216 has 448.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 974.00 MiB memory in use. Process 1542430 has 648.00 MiB memory in use. Process 1542439 has 850.00 MiB memory in use. Process 1542433 has 474.00 MiB memory in use. Process 1542827 has 446.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 878.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 428.00 MiB memory in use. Process 1543212 has 928.00 MiB memory in use. Process 1543209 has 906.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 974.00 MiB memory in use. Process 1543600 has 448.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 928.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 884.00 MiB memory in use. Of the allocated memory 47.99 MiB is allocated by PyTorch, and 42.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
63c5b26c,"{'min_delta': 0.137, 'temperature': 0.2, 'batch_size': 256, 'latent_dim': 30}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 898.00 MiB memory in use. Process 1539214 has 442.00 MiB memory in use. Process 1539216 has 448.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 974.00 MiB memory in use. Process 1542430 has 678.00 MiB memory in use. Process 1542439 has 850.00 MiB memory in use. Process 1542433 has 474.00 MiB memory in use. Process 1542827 has 446.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 878.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 430.00 MiB memory in use. Process 1543212 has 928.00 MiB memory in use. Process 1543209 has 906.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 974.00 MiB memory in use. Process 1543600 has 448.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 928.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 884.00 MiB memory in use. Of the allocated memory 62.83 MiB is allocated by PyTorch, and 29.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
23dd3fc8,"{'min_delta': 0.07200000000000001, 'temperature': 0.2, 'batch_size': 218, 'latent_dim': 76}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 898.00 MiB memory in use. Process 1539214 has 490.00 MiB memory in use. Process 1539216 has 448.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 974.00 MiB memory in use. Process 1542430 has 448.00 MiB memory in use. Process 1542439 has 850.00 MiB memory in use. Process 1542433 has 466.00 MiB memory in use. Process 1542827 has 446.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 834.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 450.00 MiB memory in use. Process 1543212 has 1.00 GiB memory in use. Process 1543209 has 906.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 964.00 MiB memory in use. Process 1543600 has 464.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 992.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 884.00 MiB memory in use. Of the allocated memory 82.58 MiB is allocated by PyTorch, and 41.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c09430ce,"{'min_delta': 0.109, 'temperature': 0.1, 'batch_size': 209, 'latent_dim': 100}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 898.00 MiB memory in use. Process 1539214 has 446.00 MiB memory in use. Process 1539216 has 448.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 974.00 MiB memory in use. Process 1542430 has 444.00 MiB memory in use. Process 1542439 has 792.00 MiB memory in use. Process 1542433 has 474.00 MiB memory in use. Process 1542827 has 444.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 834.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 508.00 MiB memory in use. Process 1543212 has 1.00 GiB memory in use. Process 1543209 has 906.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 964.00 MiB memory in use. Process 1543600 has 518.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 992.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 884.00 MiB memory in use. Of the allocated memory 95.09 MiB is allocated by PyTorch, and 74.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
c5d3b6b4,"{'min_delta': 0.007, 'temperature': 0.4, 'batch_size': 183, 'latent_dim': 86}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.38 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1539218 has 1.02 GiB memory in use. Process 1539174 has 2.21 GiB memory in use. Process 1539200 has 898.00 MiB memory in use. Process 1539214 has 442.00 MiB memory in use. Process 1539216 has 508.00 MiB memory in use. Process 1542427 has 1.15 GiB memory in use. Process 1542438 has 974.00 MiB memory in use. Process 1542430 has 466.00 MiB memory in use. Process 1542439 has 792.00 MiB memory in use. Process 1542433 has 474.00 MiB memory in use. Process 1542827 has 444.00 MiB memory in use. Process 1542824 has 1.17 GiB memory in use. Process 1542821 has 834.00 MiB memory in use. Process 1542818 has 1.04 GiB memory in use. Process 1542830 has 444.00 MiB memory in use. Process 1543212 has 1.00 GiB memory in use. Process 1543209 has 918.00 MiB memory in use. Process 1543218 has 1000.00 MiB memory in use. Process 1543221 has 1.01 GiB memory in use. Process 1543215 has 964.00 MiB memory in use. Process 1543600 has 518.00 MiB memory in use. Process 1543606 has 1.14 GiB memory in use. Process 1543612 has 992.00 MiB memory in use. Process 1543605 has 988.00 MiB memory in use. Process 1543609 has 884.00 MiB memory in use. Of the allocated memory 94.98 MiB is allocated by PyTorch, and 75.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
