trial_id,config,error_type,error_message,error_traceback
2fdb93f0,"{'temperature': 0.9, 'latent_dim': 38, 'transform_funcs': (7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 7.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.12 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 786.00 MiB memory in use. Process 1556896 has 1.56 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 850.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 454.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.40 GiB memory in use. Process 1560126 has 720.00 MiB memory in use. Process 1560129 has 1012.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.57 GiB memory in use. Process 1560440 has 614.00 MiB memory in use. Process 1560441 has 924.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 236.19 MiB is allocated by PyTorch, and 39.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5547d788,"{'temperature': 0.8, 'latent_dim': 58, 'transform_funcs': (1, 5, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.56 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 850.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 434.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.41 GiB memory in use. Process 1560126 has 432.00 MiB memory in use. Process 1560129 has 1.13 GiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.57 GiB memory in use. Process 1560440 has 530.00 MiB memory in use. Process 1560441 has 924.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 160.80 MiB is allocated by PyTorch, and 31.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3ee8c96b,"{'temperature': 1.0, 'latent_dim': 43, 'transform_funcs': (6, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.60 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 850.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 454.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.41 GiB memory in use. Process 1560126 has 652.00 MiB memory in use. Process 1560129 has 914.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.57 GiB memory in use. Process 1560440 has 468.00 MiB memory in use. Process 1560441 has 924.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 76.68 MiB is allocated by PyTorch, and 53.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
939df9da,"{'temperature': 1.1, 'latent_dim': 63, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 850.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 548.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.43 GiB memory in use. Process 1560126 has 672.00 MiB memory in use. Process 1560129 has 454.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.57 GiB memory in use. Process 1560440 has 428.00 MiB memory in use. Process 1560441 has 888.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 67.35 MiB is allocated by PyTorch, and 22.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
720f2167,"{'temperature': 1.0, 'latent_dim': 30, 'transform_funcs': (1, 2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 850.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 548.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 674.00 MiB memory in use. Process 1560129 has 454.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.57 GiB memory in use. Process 1560440 has 424.00 MiB memory in use. Process 1560441 has 870.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 67.09 MiB is allocated by PyTorch, and 18.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
01f28dd9,"{'temperature': 0.9, 'latent_dim': 45, 'transform_funcs': (5, 6, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 13.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 850.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 452.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 726.00 MiB memory in use. Process 1560129 has 454.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.59 GiB memory in use. Process 1560440 has 470.00 MiB memory in use. Process 1560441 has 870.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 76.70 MiB is allocated by PyTorch, and 55.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
dd6478bf,"{'temperature': 1.3, 'latent_dim': 53, 'transform_funcs': (8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 17.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 932.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 452.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 432.00 MiB memory in use. Process 1560129 has 662.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.59 GiB memory in use. Process 1560440 has 432.00 MiB memory in use. Process 1560441 has 908.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 67.27 MiB is allocated by PyTorch, and 26.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1814ff55,"{'temperature': 1.1, 'latent_dim': 22, 'transform_funcs': (1, 3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 932.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 452.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 446.00 MiB memory in use. Process 1560129 has 662.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.59 GiB memory in use. Process 1560440 has 402.00 MiB memory in use. Process 1560441 has 908.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 41.03 MiB is allocated by PyTorch, and 22.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2e8b9527,"{'temperature': 1.0, 'latent_dim': 40, 'transform_funcs': (5, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 932.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 452.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 452.00 MiB memory in use. Process 1560129 has 662.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.59 GiB memory in use. Process 1560440 has 426.00 MiB memory in use. Process 1560441 has 908.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 59.13 MiB is allocated by PyTorch, and 28.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
05c69560,"{'temperature': 0.5, 'latent_dim': 12, 'transform_funcs': (2, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 932.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 452.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 452.00 MiB memory in use. Process 1560129 has 662.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.59 GiB memory in use. Process 1560440 has 426.00 MiB memory in use. Process 1560441 has 908.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 58.97 MiB is allocated by PyTorch, and 29.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
5966ac0e,"{'temperature': 0.9, 'latent_dim': 37, 'transform_funcs': (0, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 932.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 452.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 452.00 MiB memory in use. Process 1560129 has 662.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.59 GiB memory in use. Process 1560440 has 426.00 MiB memory in use. Process 1560441 has 908.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 59.11 MiB is allocated by PyTorch, and 28.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
cfedb602,"{'temperature': 0.8, 'latent_dim': 18, 'transform_funcs': (0, 9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 932.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 452.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 452.00 MiB memory in use. Process 1560129 has 662.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.59 GiB memory in use. Process 1560440 has 426.00 MiB memory in use. Process 1560441 has 908.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 59.00 MiB is allocated by PyTorch, and 29.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
9d0df98c,"{'temperature': 0.9, 'latent_dim': 57, 'transform_funcs': (2, 5, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 932.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 452.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 452.00 MiB memory in use. Process 1560129 has 662.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.59 GiB memory in use. Process 1560440 has 426.00 MiB memory in use. Process 1560441 has 908.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 59.23 MiB is allocated by PyTorch, and 28.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
31b50336,"{'temperature': 1.2000000000000002, 'latent_dim': 67, 'transform_funcs': (5, 6, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 932.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 452.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 452.00 MiB memory in use. Process 1560129 has 662.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.59 GiB memory in use. Process 1560440 has 426.00 MiB memory in use. Process 1560441 has 908.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 59.29 MiB is allocated by PyTorch, and 28.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
97e8c46b,"{'temperature': 1.1, 'latent_dim': 61, 'transform_funcs': (3, 4, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 932.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 452.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 452.00 MiB memory in use. Process 1560129 has 662.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.59 GiB memory in use. Process 1560440 has 426.00 MiB memory in use. Process 1560441 has 908.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 58.90 MiB is allocated by PyTorch, and 29.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
49aebd23,"{'temperature': 0.8, 'latent_dim': 34, 'transform_funcs': (1, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 932.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 452.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 452.00 MiB memory in use. Process 1560129 has 662.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.59 GiB memory in use. Process 1560440 has 426.00 MiB memory in use. Process 1560441 has 908.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 59.10 MiB is allocated by PyTorch, and 28.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
d6f3232c,"{'temperature': 1.0, 'latent_dim': 29, 'transform_funcs': (2, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 932.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 452.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 452.00 MiB memory in use. Process 1560129 has 662.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.59 GiB memory in use. Process 1560440 has 426.00 MiB memory in use. Process 1560441 has 908.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 59.07 MiB is allocated by PyTorch, and 28.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
e69f9581,"{'temperature': 1.3, 'latent_dim': 83, 'transform_funcs': (0, 2, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 932.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 452.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 452.00 MiB memory in use. Process 1560129 has 662.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.59 GiB memory in use. Process 1560440 has 426.00 MiB memory in use. Process 1560441 has 908.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 59.38 MiB is allocated by PyTorch, and 28.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
42df31fd,"{'temperature': 0.9, 'latent_dim': 53, 'transform_funcs': (0, 4, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 932.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 452.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 452.00 MiB memory in use. Process 1560129 has 662.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.59 GiB memory in use. Process 1560440 has 426.00 MiB memory in use. Process 1560441 has 908.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 59.21 MiB is allocated by PyTorch, and 28.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
334a09c8,"{'temperature': 1.5, 'latent_dim': 47, 'transform_funcs': (2, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 932.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 452.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 452.00 MiB memory in use. Process 1560129 has 662.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 1.59 GiB memory in use. Process 1560440 has 426.00 MiB memory in use. Process 1560441 has 908.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 59.17 MiB is allocated by PyTorch, and 28.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
f35d61b7,"{'temperature': 1.1, 'latent_dim': 10, 'transform_funcs': (0, 2, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 932.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 856.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 786.00 MiB memory in use. Process 1560129 has 920.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 502.00 MiB memory in use. Process 1560440 has 526.00 MiB memory in use. Process 1560441 has 908.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 160.42 MiB is allocated by PyTorch, and 27.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
db89ae5a,"{'temperature': 0.6000000000000001, 'latent_dim': 42, 'transform_funcs': (2, 6, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 828.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 1018.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 856.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 786.00 MiB memory in use. Process 1560129 has 920.00 MiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 432.00 MiB memory in use. Process 1560440 has 530.00 MiB memory in use. Process 1560441 has 908.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 160.67 MiB is allocated by PyTorch, and 31.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8f885baa,"{'temperature': 0.9, 'latent_dim': 89, 'transform_funcs': (0, 1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.31 GiB memory in use. Process 1556924 has 950.00 MiB memory in use. Process 1556893 has 748.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.24 GiB memory in use. Process 1559500 has 1018.00 MiB memory in use. Process 1559499 has 1.28 GiB memory in use. Process 1559501 has 1.32 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 856.00 MiB memory in use. Process 1559815 has 2.03 GiB memory in use. Process 1560128 has 1.45 GiB memory in use. Process 1560126 has 786.00 MiB memory in use. Process 1560129 has 1.03 GiB memory in use. Process 1560127 has 1.05 GiB memory in use. Process 1560439 has 518.00 MiB memory in use. Process 1560440 has 426.00 MiB memory in use. Process 1560441 has 908.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 67.56 MiB is allocated by PyTorch, and 20.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
028db3d9,"{'temperature': 0.8, 'latent_dim': 66, 'transform_funcs': (6, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.03 GiB memory in use. Process 1556924 has 956.00 MiB memory in use. Process 1556893 has 862.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 1.05 GiB memory in use. Process 1559500 has 1018.00 MiB memory in use. Process 1559499 has 1.02 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 946.00 MiB memory in use. Process 1559815 has 2.04 GiB memory in use. Process 1560128 has 1.25 GiB memory in use. Process 1560126 has 874.00 MiB memory in use. Process 1560129 has 910.00 MiB memory in use. Process 1560127 has 1.26 GiB memory in use. Process 1560439 has 970.00 MiB memory in use. Process 1560440 has 430.00 MiB memory in use. Process 1560441 has 986.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 67.38 MiB is allocated by PyTorch, and 24.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
82df0f1c,"{'temperature': 1.2000000000000002, 'latent_dim': 60, 'transform_funcs': (0, 2, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.03 GiB memory in use. Process 1556924 has 956.00 MiB memory in use. Process 1556893 has 862.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 922.00 MiB memory in use. Process 1559500 has 1018.00 MiB memory in use. Process 1559499 has 1.02 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 946.00 MiB memory in use. Process 1559815 has 2.04 GiB memory in use. Process 1560128 has 1.25 GiB memory in use. Process 1560126 has 874.00 MiB memory in use. Process 1560129 has 910.00 MiB memory in use. Process 1560127 has 1.26 GiB memory in use. Process 1560439 has 970.00 MiB memory in use. Process 1560440 has 574.00 MiB memory in use. Process 1560441 has 986.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 172.09 MiB is allocated by PyTorch, and 63.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
0497294c,"{'temperature': 1.1, 'latent_dim': 13, 'transform_funcs': (3, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.03 GiB memory in use. Process 1556924 has 956.00 MiB memory in use. Process 1556893 has 862.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 922.00 MiB memory in use. Process 1559500 has 1018.00 MiB memory in use. Process 1559499 has 1.02 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 898.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 946.00 MiB memory in use. Process 1559815 has 2.04 GiB memory in use. Process 1560128 has 1.25 GiB memory in use. Process 1560126 has 874.00 MiB memory in use. Process 1560129 has 1.05 GiB memory in use. Process 1560127 has 1.26 GiB memory in use. Process 1560439 has 970.00 MiB memory in use. Process 1560440 has 406.00 MiB memory in use. Process 1560441 has 986.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 40.96 MiB is allocated by PyTorch, and 27.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ecd28de7,"{'temperature': 1.4000000000000001, 'latent_dim': 11, 'transform_funcs': (4, 7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.03 GiB memory in use. Process 1556924 has 956.00 MiB memory in use. Process 1556893 has 862.00 MiB memory in use. Process 1556896 has 1.98 GiB memory in use. Process 1559502 has 606.00 MiB memory in use. Process 1559500 has 1018.00 MiB memory in use. Process 1559499 has 1.02 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 988.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 946.00 MiB memory in use. Process 1559815 has 2.04 GiB memory in use. Process 1560128 has 1.25 GiB memory in use. Process 1560126 has 874.00 MiB memory in use. Process 1560129 has 1.05 GiB memory in use. Process 1560127 has 1.26 GiB memory in use. Process 1560439 has 1.16 GiB memory in use. Process 1560440 has 428.00 MiB memory in use. Process 1560441 has 986.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 66.95 MiB is allocated by PyTorch, and 23.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
92cf0b10,"{'temperature': 1.3, 'latent_dim': 21, 'transform_funcs': (5, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.03 GiB memory in use. Process 1556924 has 956.00 MiB memory in use. Process 1556893 has 862.00 MiB memory in use. Process 1556896 has 1.99 GiB memory in use. Process 1559502 has 732.00 MiB memory in use. Process 1559500 has 1018.00 MiB memory in use. Process 1559499 has 1.02 GiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 988.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 946.00 MiB memory in use. Process 1559815 has 2.04 GiB memory in use. Process 1560128 has 1.25 GiB memory in use. Process 1560126 has 874.00 MiB memory in use. Process 1560129 has 910.00 MiB memory in use. Process 1560127 has 1.26 GiB memory in use. Process 1560439 has 1.16 GiB memory in use. Process 1560440 has 464.00 MiB memory in use. Process 1560441 has 986.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 76.51 MiB is allocated by PyTorch, and 49.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
be6cd354,"{'temperature': 1.2000000000000002, 'latent_dim': 77, 'transform_funcs': (0, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.03 GiB memory in use. Process 1556924 has 956.00 MiB memory in use. Process 1556893 has 862.00 MiB memory in use. Process 1556896 has 1.99 GiB memory in use. Process 1559502 has 748.00 MiB memory in use. Process 1559500 has 1018.00 MiB memory in use. Process 1559499 has 1012.00 MiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 988.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 946.00 MiB memory in use. Process 1559815 has 2.04 GiB memory in use. Process 1560128 has 1.25 GiB memory in use. Process 1560126 has 874.00 MiB memory in use. Process 1560129 has 954.00 MiB memory in use. Process 1560127 has 1.26 GiB memory in use. Process 1560439 has 1.16 GiB memory in use. Process 1560440 has 432.00 MiB memory in use. Process 1560441 has 986.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 67.46 MiB is allocated by PyTorch, and 26.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0faab28d,"{'temperature': 1.3, 'latent_dim': 68, 'transform_funcs': (1, 3, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.03 GiB memory in use. Process 1556924 has 956.00 MiB memory in use. Process 1556893 has 862.00 MiB memory in use. Process 1556896 has 1.99 GiB memory in use. Process 1559502 has 902.00 MiB memory in use. Process 1559500 has 1018.00 MiB memory in use. Process 1559499 has 470.00 MiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 988.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 946.00 MiB memory in use. Process 1559815 has 2.04 GiB memory in use. Process 1560128 has 1.25 GiB memory in use. Process 1560126 has 874.00 MiB memory in use. Process 1560129 has 954.00 MiB memory in use. Process 1560127 has 1.26 GiB memory in use. Process 1560439 has 1.34 GiB memory in use. Process 1560440 has 652.00 MiB memory in use. Process 1560441 has 986.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 259.01 MiB is allocated by PyTorch, and 54.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 32, in forward
    x = self.dropout3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
699d0133,"{'temperature': 1.2000000000000002, 'latent_dim': 70, 'transform_funcs': (1, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.03 GiB memory in use. Process 1556924 has 956.00 MiB memory in use. Process 1556893 has 862.00 MiB memory in use. Process 1556896 has 1.99 GiB memory in use. Process 1559502 has 902.00 MiB memory in use. Process 1559500 has 1018.00 MiB memory in use. Process 1559499 has 618.00 MiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 988.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 946.00 MiB memory in use. Process 1559815 has 2.04 GiB memory in use. Process 1560128 has 1.25 GiB memory in use. Process 1560126 has 874.00 MiB memory in use. Process 1560129 has 954.00 MiB memory in use. Process 1560127 has 1.26 GiB memory in use. Process 1560439 has 1.34 GiB memory in use. Process 1560440 has 472.00 MiB memory in use. Process 1560441 has 986.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 76.89 MiB is allocated by PyTorch, and 57.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
8c99f10f,"{'temperature': 0.8, 'latent_dim': 50, 'transform_funcs': (1, 3, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.03 GiB memory in use. Process 1556924 has 956.00 MiB memory in use. Process 1556893 has 866.00 MiB memory in use. Process 1556896 has 1.99 GiB memory in use. Process 1559502 has 902.00 MiB memory in use. Process 1559500 has 1018.00 MiB memory in use. Process 1559499 has 618.00 MiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 988.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 946.00 MiB memory in use. Process 1559815 has 2.04 GiB memory in use. Process 1560128 has 1.25 GiB memory in use. Process 1560126 has 874.00 MiB memory in use. Process 1560129 has 942.00 MiB memory in use. Process 1560127 has 1.26 GiB memory in use. Process 1560439 has 1.34 GiB memory in use. Process 1560440 has 504.00 MiB memory in use. Process 1560441 has 986.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 114.74 MiB is allocated by PyTorch, and 51.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
caed81a5,"{'temperature': 0.7000000000000001, 'latent_dim': 12, 'transform_funcs': (0, 4, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.03 GiB memory in use. Process 1556924 has 956.00 MiB memory in use. Process 1556893 has 866.00 MiB memory in use. Process 1556896 has 1.99 GiB memory in use. Process 1559502 has 902.00 MiB memory in use. Process 1559500 has 1018.00 MiB memory in use. Process 1559499 has 618.00 MiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 988.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 946.00 MiB memory in use. Process 1559815 has 2.04 GiB memory in use. Process 1560128 has 1.25 GiB memory in use. Process 1560126 has 874.00 MiB memory in use. Process 1560129 has 942.00 MiB memory in use. Process 1560127 has 1.26 GiB memory in use. Process 1560439 has 1.34 GiB memory in use. Process 1560440 has 510.00 MiB memory in use. Process 1560441 has 986.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 114.44 MiB is allocated by PyTorch, and 57.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dd1af0f8,"{'temperature': 1.2000000000000002, 'latent_dim': 48, 'transform_funcs': (7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.03 GiB memory in use. Process 1556924 has 956.00 MiB memory in use. Process 1556893 has 866.00 MiB memory in use. Process 1556896 has 1.99 GiB memory in use. Process 1559502 has 942.00 MiB memory in use. Process 1559500 has 1018.00 MiB memory in use. Process 1559499 has 930.00 MiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 988.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 946.00 MiB memory in use. Process 1559815 has 2.04 GiB memory in use. Process 1560128 has 1.25 GiB memory in use. Process 1560126 has 874.00 MiB memory in use. Process 1560129 has 668.00 MiB memory in use. Process 1560127 has 1.26 GiB memory in use. Process 1560439 has 1.34 GiB memory in use. Process 1560440 has 400.00 MiB memory in use. Process 1560441 has 986.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 41.23 MiB is allocated by PyTorch, and 20.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
35f50cc8,"{'temperature': 1.2000000000000002, 'latent_dim': 35, 'transform_funcs': (1, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.03 GiB memory in use. Process 1556924 has 956.00 MiB memory in use. Process 1556893 has 866.00 MiB memory in use. Process 1556896 has 1.99 GiB memory in use. Process 1559502 has 940.00 MiB memory in use. Process 1559500 has 1018.00 MiB memory in use. Process 1559499 has 932.00 MiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 988.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 946.00 MiB memory in use. Process 1559815 has 2.04 GiB memory in use. Process 1560128 has 1.25 GiB memory in use. Process 1560126 has 874.00 MiB memory in use. Process 1560129 has 668.00 MiB memory in use. Process 1560127 has 1.26 GiB memory in use. Process 1560439 has 1.34 GiB memory in use. Process 1560440 has 404.00 MiB memory in use. Process 1560441 has 986.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 41.13 MiB is allocated by PyTorch, and 24.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5fb8be44,"{'temperature': 0.8, 'latent_dim': 32, 'transform_funcs': (0, 3, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.03 GiB memory in use. Process 1556924 has 956.00 MiB memory in use. Process 1556893 has 866.00 MiB memory in use. Process 1556896 has 1.99 GiB memory in use. Process 1559502 has 942.00 MiB memory in use. Process 1559500 has 1018.00 MiB memory in use. Process 1559499 has 472.00 MiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 988.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 946.00 MiB memory in use. Process 1559815 has 2.04 GiB memory in use. Process 1560128 has 1.25 GiB memory in use. Process 1560126 has 874.00 MiB memory in use. Process 1560129 has 966.00 MiB memory in use. Process 1560127 has 1.26 GiB memory in use. Process 1560439 has 1.34 GiB memory in use. Process 1560440 has 570.00 MiB memory in use. Process 1560441 has 986.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 171.87 MiB is allocated by PyTorch, and 60.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
e315f025,"{'temperature': 0.9, 'latent_dim': 34, 'transform_funcs': (0, 2, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.03 GiB memory in use. Process 1556924 has 956.00 MiB memory in use. Process 1556893 has 866.00 MiB memory in use. Process 1556896 has 1.99 GiB memory in use. Process 1559502 has 942.00 MiB memory in use. Process 1559500 has 1018.00 MiB memory in use. Process 1559499 has 470.00 MiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 988.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 946.00 MiB memory in use. Process 1559815 has 2.04 GiB memory in use. Process 1560128 has 1.25 GiB memory in use. Process 1560126 has 874.00 MiB memory in use. Process 1560129 has 966.00 MiB memory in use. Process 1560127 has 1.26 GiB memory in use. Process 1560439 has 1.34 GiB memory in use. Process 1560440 has 572.00 MiB memory in use. Process 1560441 has 986.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 171.89 MiB is allocated by PyTorch, and 62.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
0cea99a0,"{'temperature': 1.0, 'latent_dim': 53, 'transform_funcs': (0, 1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.06 MiB is free. Process 1246457 has 584.00 MiB memory in use. Process 1247099 has 606.00 MiB memory in use. Process 1247181 has 420.00 MiB memory in use. Process 1556922 has 1.03 GiB memory in use. Process 1556924 has 956.00 MiB memory in use. Process 1556893 has 866.00 MiB memory in use. Process 1556896 has 1.99 GiB memory in use. Process 1559502 has 942.00 MiB memory in use. Process 1559500 has 1018.00 MiB memory in use. Process 1559499 has 472.00 MiB memory in use. Process 1559501 has 1.37 GiB memory in use. Process 1559809 has 988.00 MiB memory in use. Process 1559814 has 1.16 GiB memory in use. Process 1559808 has 946.00 MiB memory in use. Process 1559815 has 2.04 GiB memory in use. Process 1560128 has 1.25 GiB memory in use. Process 1560126 has 874.00 MiB memory in use. Process 1560129 has 966.00 MiB memory in use. Process 1560127 has 1.26 GiB memory in use. Process 1560439 has 1.34 GiB memory in use. Process 1560440 has 572.00 MiB memory in use. Process 1560441 has 986.00 MiB memory in use. Process 1560444 has 1.20 GiB memory in use. Of the allocated memory 172.04 MiB is allocated by PyTorch, and 61.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
