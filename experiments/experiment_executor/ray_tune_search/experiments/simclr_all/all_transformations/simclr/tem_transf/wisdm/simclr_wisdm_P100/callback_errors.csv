trial_id,config,error_type,error_message,error_traceback
c151f58c,"{'temperature': 0.6000000000000001, 'latent_dim': 213, 'transform_funcs': (2, 7, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.19 MiB is free. Process 1194559 has 1.16 GiB memory in use. Process 1194563 has 1012.00 MiB memory in use. Process 1194561 has 820.00 MiB memory in use. Process 1194517 has 750.00 MiB memory in use. Process 1194518 has 1.56 GiB memory in use. Process 1197762 has 468.00 MiB memory in use. Process 1197764 has 1.19 GiB memory in use. Process 1197769 has 880.00 MiB memory in use. Process 1197763 has 946.00 MiB memory in use. Process 1197770 has 1.85 GiB memory in use. Process 1198152 has 466.00 MiB memory in use. Process 1198160 has 1.23 GiB memory in use. Process 1198156 has 850.00 MiB memory in use. Process 1198164 has 754.00 MiB memory in use. Process 1198163 has 1.07 GiB memory in use. Process 1198554 has 846.00 MiB memory in use. Process 1198545 has 1.08 GiB memory in use. Process 1198555 has 1004.00 MiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 752.00 MiB memory in use. Process 1198934 has 884.00 MiB memory in use. Process 1198980 has 1.01 GiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 464.00 MiB memory in use. Process 1198942 has 1.05 GiB memory in use. Of the allocated memory 83.65 MiB is allocated by PyTorch, and 46.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d5587e59,"{'temperature': 1.2000000000000002, 'latent_dim': 233, 'transform_funcs': (1, 3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.19 MiB is free. Process 1194559 has 1.17 GiB memory in use. Process 1194563 has 1012.00 MiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 448.00 MiB memory in use. Process 1194518 has 1.56 GiB memory in use. Process 1197762 has 860.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 880.00 MiB memory in use. Process 1197763 has 1.07 GiB memory in use. Process 1197770 has 1.84 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 1.23 GiB memory in use. Process 1198156 has 918.00 MiB memory in use. Process 1198164 has 752.00 MiB memory in use. Process 1198163 has 1.01 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.08 GiB memory in use. Process 1198555 has 1004.00 MiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 750.00 MiB memory in use. Process 1198934 has 750.00 MiB memory in use. Process 1198980 has 1.01 GiB memory in use. Process 1198939 has 466.00 MiB memory in use. Process 1198975 has 546.00 MiB memory in use. Process 1198942 has 1.05 GiB memory in use. Of the allocated memory 83.80 MiB is allocated by PyTorch, and 44.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
75df05b1,"{'temperature': 0.8, 'latent_dim': 228, 'transform_funcs': (1, 2, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 1194559 has 1.18 GiB memory in use. Process 1194563 has 466.00 MiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 460.00 MiB memory in use. Process 1194518 has 1.56 GiB memory in use. Process 1197762 has 860.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 880.00 MiB memory in use. Process 1197763 has 1.07 GiB memory in use. Process 1197770 has 1.90 GiB memory in use. Process 1198152 has 448.00 MiB memory in use. Process 1198160 has 1.23 GiB memory in use. Process 1198156 has 918.00 MiB memory in use. Process 1198164 has 752.00 MiB memory in use. Process 1198163 has 1.01 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.08 GiB memory in use. Process 1198555 has 1004.00 MiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 528.00 MiB memory in use. Process 1198934 has 776.00 MiB memory in use. Process 1198980 has 1.15 GiB memory in use. Process 1198939 has 986.00 MiB memory in use. Process 1198975 has 548.00 MiB memory in use. Process 1198942 has 1.05 GiB memory in use. Of the allocated memory 456.14 MiB is allocated by PyTorch, and 191.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 32, in forward
    x = self.dropout3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
b36f5da5,"{'temperature': 0.9, 'latent_dim': 144, 'transform_funcs': (3, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.19 MiB is free. Process 1194559 has 1.23 GiB memory in use. Process 1194563 has 468.00 MiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 1.41 GiB memory in use. Process 1197762 has 866.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 880.00 MiB memory in use. Process 1197763 has 1.07 GiB memory in use. Process 1197770 has 1.88 GiB memory in use. Process 1198152 has 448.00 MiB memory in use. Process 1198160 has 1.23 GiB memory in use. Process 1198156 has 918.00 MiB memory in use. Process 1198164 has 750.00 MiB memory in use. Process 1198163 has 1.01 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.08 GiB memory in use. Process 1198555 has 1004.00 MiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 532.00 MiB memory in use. Process 1198934 has 748.00 MiB memory in use. Process 1198980 has 1.15 GiB memory in use. Process 1198939 has 512.00 MiB memory in use. Process 1198975 has 718.00 MiB memory in use. Process 1198942 has 1.05 GiB memory in use. Of the allocated memory 95.44 MiB is allocated by PyTorch, and 78.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
28bf6b7a,"{'temperature': 1.4000000000000001, 'latent_dim': 198, 'transform_funcs': (2, 4, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 1194559 has 1.23 GiB memory in use. Process 1194563 has 800.00 MiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 1.41 GiB memory in use. Process 1197762 has 448.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 880.00 MiB memory in use. Process 1197763 has 1.07 GiB memory in use. Process 1197770 has 1.88 GiB memory in use. Process 1198152 has 614.00 MiB memory in use. Process 1198160 has 1.23 GiB memory in use. Process 1198156 has 918.00 MiB memory in use. Process 1198164 has 752.00 MiB memory in use. Process 1198163 has 1.01 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.08 GiB memory in use. Process 1198555 has 1004.00 MiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 590.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 1.15 GiB memory in use. Process 1198939 has 654.00 MiB memory in use. Process 1198975 has 718.00 MiB memory in use. Process 1198942 has 1.05 GiB memory in use. Of the allocated memory 219.18 MiB is allocated by PyTorch, and 96.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
3d3362a4,"{'temperature': 0.6000000000000001, 'latent_dim': 89, 'transform_funcs': (0, 2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 1194559 has 1.23 GiB memory in use. Process 1194563 has 800.00 MiB memory in use. Process 1194561 has 478.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 1.46 GiB memory in use. Process 1197762 has 448.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 882.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 1.88 GiB memory in use. Process 1198152 has 674.00 MiB memory in use. Process 1198160 has 1.23 GiB memory in use. Process 1198156 has 918.00 MiB memory in use. Process 1198164 has 526.00 MiB memory in use. Process 1198163 has 1.01 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.08 GiB memory in use. Process 1198555 has 1004.00 MiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 590.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 1.15 GiB memory in use. Process 1198939 has 586.00 MiB memory in use. Process 1198975 has 718.00 MiB memory in use. Process 1198942 has 1.05 GiB memory in use. Of the allocated memory 203.66 MiB is allocated by PyTorch, and 44.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e153222a,"{'temperature': 0.7000000000000001, 'latent_dim': 315, 'transform_funcs': (1, 2, 3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 1194559 has 1.23 GiB memory in use. Process 1194563 has 468.00 MiB memory in use. Process 1194561 has 806.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 1.54 GiB memory in use. Process 1197762 has 468.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 882.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 1.94 GiB memory in use. Process 1198152 has 734.00 MiB memory in use. Process 1198160 has 1.23 GiB memory in use. Process 1198156 has 918.00 MiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 1.01 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.08 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 760.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 894.00 MiB memory in use. Process 1198975 has 718.00 MiB memory in use. Process 1198942 has 1.05 GiB memory in use. Of the allocated memory 475.57 MiB is allocated by PyTorch, and 80.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a9ad6cd3,"{'temperature': 0.5, 'latent_dim': 91, 'transform_funcs': (3, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 1194559 has 1.23 GiB memory in use. Process 1194563 has 468.00 MiB memory in use. Process 1194561 has 806.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 1.54 GiB memory in use. Process 1197762 has 644.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 882.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 1.94 GiB memory in use. Process 1198152 has 786.00 MiB memory in use. Process 1198160 has 1.23 GiB memory in use. Process 1198156 has 918.00 MiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 1.01 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.08 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 760.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 646.00 MiB memory in use. Process 1198975 has 1.30 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 218.34 MiB is allocated by PyTorch, and 89.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
e19edfc9,"{'temperature': 0.9, 'latent_dim': 347, 'transform_funcs': (1, 3, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 1194559 has 1.23 GiB memory in use. Process 1194563 has 448.00 MiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 534.00 MiB memory in use. Process 1197762 has 704.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 882.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 1.94 GiB memory in use. Process 1198152 has 830.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 918.00 MiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.08 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 772.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 1.30 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 84.70 MiB is allocated by PyTorch, and 41.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4876ae71,"{'temperature': 1.2000000000000002, 'latent_dim': 124, 'transform_funcs': (0, 2, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.20 GiB memory in use. Process 1194563 has 448.00 MiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 728.00 MiB memory in use. Process 1197762 has 470.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 882.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 1.94 GiB memory in use. Process 1198152 has 832.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 918.00 MiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.08 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 772.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 518.00 MiB memory in use. Process 1198975 has 1.30 GiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 95.28 MiB is allocated by PyTorch, and 84.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
f22c0263,"{'temperature': 0.8, 'latent_dim': 186, 'transform_funcs': (0, 2, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 1194559 has 1.20 GiB memory in use. Process 1194563 has 468.00 MiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 728.00 MiB memory in use. Process 1197762 has 468.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 882.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 1.94 GiB memory in use. Process 1198152 has 832.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 918.00 MiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.08 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 772.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 516.00 MiB memory in use. Process 1198975 has 1.30 GiB memory in use. Process 1198942 has 466.00 MiB memory in use. Of the allocated memory 95.77 MiB is allocated by PyTorch, and 82.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
9e84e704,"{'temperature': 1.2000000000000002, 'latent_dim': 269, 'transform_funcs': (4, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 448.00 MiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 532.00 MiB memory in use. Process 1197762 has 468.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 882.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 1.94 GiB memory in use. Process 1198152 has 838.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 918.00 MiB memory in use. Process 1198164 has 470.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.08 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 766.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 560.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 146.42 MiB is allocated by PyTorch, and 75.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1ac90520,"{'temperature': 0.8, 'latent_dim': 312, 'transform_funcs': (3, 4, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 468.00 MiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 582.00 MiB memory in use. Process 1197762 has 648.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 882.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 1.94 GiB memory in use. Process 1198152 has 840.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 918.00 MiB memory in use. Process 1198164 has 470.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.08 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 618.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 205.40 MiB is allocated by PyTorch, and 74.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6c1c71de,"{'temperature': 1.1, 'latent_dim': 179, 'transform_funcs': (6, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 13.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 446.00 MiB memory in use. Process 1194561 has 446.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 584.00 MiB memory in use. Process 1197762 has 448.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 882.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 1.98 GiB memory in use. Process 1198152 has 840.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 918.00 MiB memory in use. Process 1198164 has 706.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.08 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 592.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 204.36 MiB is allocated by PyTorch, and 49.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2ceb4254,"{'temperature': 1.1, 'latent_dim': 159, 'transform_funcs': (0, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 448.00 MiB memory in use. Process 1194561 has 750.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 480.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 882.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 1.98 GiB memory in use. Process 1198152 has 848.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 926.00 MiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.08 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 562.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 145.56 MiB is allocated by PyTorch, and 78.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
337f9122,"{'temperature': 0.9, 'latent_dim': 78, 'transform_funcs': (0, 3, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 480.00 MiB memory in use. Process 1194561 has 782.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 468.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 888.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 1.98 GiB memory in use. Process 1198152 has 446.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 926.00 MiB memory in use. Process 1198164 has 870.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.08 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 518.00 MiB memory in use. Of the allocated memory 82.59 MiB is allocated by PyTorch, and 43.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3079871b,"{'temperature': 1.4000000000000001, 'latent_dim': 356, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 468.00 MiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 470.00 MiB memory in use. Process 1197762 has 934.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 888.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.03 GiB memory in use. Process 1198152 has 478.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 926.00 MiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 466.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 622.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 518.00 MiB memory in use. Of the allocated memory 205.75 MiB is allocated by PyTorch, and 78.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
58886d16,"{'temperature': 1.4000000000000001, 'latent_dim': 131, 'transform_funcs': (3, 5, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 468.00 MiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 934.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 888.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.03 GiB memory in use. Process 1198152 has 480.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 926.00 MiB memory in use. Process 1198164 has 708.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 83.01 MiB is allocated by PyTorch, and 42.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fc9b0f09,"{'temperature': 1.3, 'latent_dim': 41, 'transform_funcs': (0, 4, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 444.00 MiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 518.00 MiB memory in use. Process 1197762 has 934.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 888.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 926.00 MiB memory in use. Process 1198164 has 538.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 470.00 MiB memory in use. Process 1198939 has 424.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 466.00 MiB memory in use. Of the allocated memory 47.30 MiB is allocated by PyTorch, and 38.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e82f7676,"{'temperature': 1.5, 'latent_dim': 93, 'transform_funcs': (3, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 466.00 MiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 518.00 MiB memory in use. Process 1197762 has 934.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 888.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 926.00 MiB memory in use. Process 1198164 has 538.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 470.00 MiB memory in use. Process 1198939 has 426.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 466.00 MiB memory in use. Of the allocated memory 59.33 MiB is allocated by PyTorch, and 28.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
57e96095,"{'temperature': 1.4000000000000001, 'latent_dim': 115, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 466.00 MiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 518.00 MiB memory in use. Process 1197762 has 934.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 888.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 926.00 MiB memory in use. Process 1198164 has 538.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 470.00 MiB memory in use. Process 1198939 has 426.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 466.00 MiB memory in use. Of the allocated memory 59.46 MiB is allocated by PyTorch, and 28.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
3d7bc7f8,"{'temperature': 1.1, 'latent_dim': 158, 'transform_funcs': (0, 1, 2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 466.00 MiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 518.00 MiB memory in use. Process 1197762 has 934.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 888.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 926.00 MiB memory in use. Process 1198164 has 538.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 470.00 MiB memory in use. Process 1198939 has 444.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 74.83 MiB is allocated by PyTorch, and 31.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
fcfe63bc,"{'temperature': 1.3, 'latent_dim': 46, 'transform_funcs': (6, 9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 466.00 MiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 518.00 MiB memory in use. Process 1197762 has 934.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 888.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 926.00 MiB memory in use. Process 1198164 has 538.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 470.00 MiB memory in use. Process 1198939 has 444.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 75.23 MiB is allocated by PyTorch, and 30.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
f2f235b4,"{'temperature': 1.2000000000000002, 'latent_dim': 79, 'transform_funcs': (0, 4, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 466.00 MiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 518.00 MiB memory in use. Process 1197762 has 934.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 888.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 926.00 MiB memory in use. Process 1198164 has 538.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 470.00 MiB memory in use. Process 1198939 has 444.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 75.42 MiB is allocated by PyTorch, and 30.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
d48ad742,"{'temperature': 1.5, 'latent_dim': 208, 'transform_funcs': (0, 2, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 466.00 MiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 518.00 MiB memory in use. Process 1197762 has 934.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 888.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 926.00 MiB memory in use. Process 1198164 has 538.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 470.00 MiB memory in use. Process 1198939 has 444.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 75.48 MiB is allocated by PyTorch, and 30.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
30669ccc,"{'temperature': 0.5, 'latent_dim': 231, 'transform_funcs': (3, 4, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 5.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 468.00 MiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 524.00 MiB memory in use. Process 1197762 has 934.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 888.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 446.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 538.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.68 GiB memory in use. Process 1198934 has 466.00 MiB memory in use. Process 1198980 has 470.00 MiB memory in use. Process 1198939 has 514.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 446.00 MiB memory in use. Of the allocated memory 96.12 MiB is allocated by PyTorch, and 79.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
8fff186a,"{'temperature': 1.5, 'latent_dim': 263, 'transform_funcs': (2, 3, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 468.00 MiB memory in use. Process 1194561 has 750.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 526.00 MiB memory in use. Process 1197762 has 936.00 MiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 882.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 470.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 618.00 MiB memory in use. Process 1198939 has 1.01 GiB memory in use. Process 1198975 has 528.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 483.76 MiB is allocated by PyTorch, and 208.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 32, in forward
    x = self.dropout3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
4a535ab1,"{'temperature': 1.1, 'latent_dim': 119, 'transform_funcs': (1, 5, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 468.00 MiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.07 GiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 882.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 544.00 MiB memory in use. Process 1198163 has 1.17 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 842.00 MiB memory in use. Process 1198980 has 788.00 MiB memory in use. Process 1198939 has 594.00 MiB memory in use. Process 1198975 has 512.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 203.89 MiB is allocated by PyTorch, and 52.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
80bd787d,"{'temperature': 0.8, 'latent_dim': 15, 'transform_funcs': (1, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 468.00 MiB memory in use. Process 1194561 has 446.00 MiB memory in use. Process 1194517 has 930.00 MiB memory in use. Process 1194518 has 492.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 882.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 448.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 488.00 MiB memory in use. Process 1198163 has 994.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 942.00 MiB memory in use. Process 1198980 has 784.00 MiB memory in use. Process 1198939 has 462.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 756.00 MiB memory in use. Of the allocated memory 82.10 MiB is allocated by PyTorch, and 41.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
71f55349,"{'temperature': 1.3, 'latent_dim': 86, 'transform_funcs': (5, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 5.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 938.00 MiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 978.00 MiB memory in use. Process 1194518 has 484.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 882.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 752.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 488.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 942.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 512.00 MiB memory in use. Process 1198975 has 494.00 MiB memory in use. Process 1198942 has 756.00 MiB memory in use. Of the allocated memory 94.98 MiB is allocated by PyTorch, and 79.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
1e81fcb6,"{'temperature': 1.4000000000000001, 'latent_dim': 124, 'transform_funcs': (2, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 468.00 MiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 978.00 MiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 882.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 750.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 518.00 MiB memory in use. Process 1198163 has 906.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 942.00 MiB memory in use. Process 1198980 has 480.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 470.00 MiB memory in use. Process 1198942 has 754.00 MiB memory in use. Of the allocated memory 82.95 MiB is allocated by PyTorch, and 43.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8b067dff,"{'temperature': 0.5, 'latent_dim': 290, 'transform_funcs': (1, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 468.00 MiB memory in use. Process 1194561 has 446.00 MiB memory in use. Process 1194517 has 978.00 MiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.24 GiB memory in use. Process 1197769 has 882.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 736.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 942.00 MiB memory in use. Process 1198980 has 568.00 MiB memory in use. Process 1198939 has 712.00 MiB memory in use. Process 1198975 has 544.00 MiB memory in use. Process 1198942 has 898.00 MiB memory in use. Of the allocated memory 278.55 MiB is allocated by PyTorch, and 95.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e07b537e,"{'temperature': 0.6000000000000001, 'latent_dim': 252, 'transform_funcs': (3, 4, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 518.00 MiB memory in use. Process 1194561 has 466.00 MiB memory in use. Process 1194517 has 978.00 MiB memory in use. Process 1194518 has 466.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 994.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 470.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 942.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 436.00 MiB memory in use. Process 1198975 has 1006.00 MiB memory in use. Process 1198942 has 878.00 MiB memory in use. Of the allocated memory 48.95 MiB is allocated by PyTorch, and 49.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5c9b4a90,"{'temperature': 1.3, 'latent_dim': 300, 'transform_funcs': (0, 1, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 468.00 MiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 978.00 MiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 994.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 946.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 470.00 MiB memory in use. Process 1198163 has 448.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 942.00 MiB memory in use. Process 1198980 has 892.00 MiB memory in use. Process 1198939 has 514.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 96.66 MiB is allocated by PyTorch, and 79.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
f0258d6d,"{'temperature': 0.9, 'latent_dim': 109, 'transform_funcs': (0, 4, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 468.00 MiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 978.00 MiB memory in use. Process 1194518 has 470.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 994.00 MiB memory in use. Process 1197763 has 1.24 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 900.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 448.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 942.00 MiB memory in use. Process 1198980 has 948.00 MiB memory in use. Process 1198939 has 466.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 82.83 MiB is allocated by PyTorch, and 45.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
40c64d1d,"{'temperature': 0.5, 'latent_dim': 259, 'transform_funcs': (5, 8, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 468.00 MiB memory in use. Process 1194561 has 874.00 MiB memory in use. Process 1194517 has 978.00 MiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 994.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 470.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 888.00 MiB memory in use. Process 1198980 has 1012.00 MiB memory in use. Process 1198939 has 456.00 MiB memory in use. Process 1198975 has 446.00 MiB memory in use. Process 1198942 has 568.00 MiB memory in use. Of the allocated memory 84.01 MiB is allocated by PyTorch, and 33.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
73d45705,"{'temperature': 1.5, 'latent_dim': 323, 'transform_funcs': (4, 5, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 202.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 129.19 MiB is free. Process 1194559 has 1.26 GiB memory in use. Process 1194563 has 466.00 MiB memory in use. Process 1194561 has 494.00 MiB memory in use. Process 1194517 has 978.00 MiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 994.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 470.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 470.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 946.00 MiB memory in use. Process 1198980 has 1012.00 MiB memory in use. Process 1198939 has 682.00 MiB memory in use. Process 1198975 has 448.00 MiB memory in use. Process 1198942 has 568.00 MiB memory in use. Of the allocated memory 278.81 MiB is allocated by PyTorch, and 65.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e28a7c7a,"{'temperature': 0.9, 'latent_dim': 343, 'transform_funcs': (0, 3, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 59.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 518.00 MiB memory in use. Process 1194561 has 520.00 MiB memory in use. Process 1194517 has 978.00 MiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 994.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 466.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 518.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.09 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 946.00 MiB memory in use. Process 1198980 has 1012.00 MiB memory in use. Process 1198939 has 678.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 278.96 MiB is allocated by PyTorch, and 61.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3c4c0e1d,"{'temperature': 1.3, 'latent_dim': 200, 'transform_funcs': (1, 5, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 5.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 518.00 MiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 978.00 MiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 754.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.11 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 946.00 MiB memory in use. Process 1198980 has 1012.00 MiB memory in use. Process 1198939 has 512.00 MiB memory in use. Process 1198975 has 482.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 95.88 MiB is allocated by PyTorch, and 78.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
3d8ff150,"{'temperature': 1.5, 'latent_dim': 284, 'transform_funcs': (0, 4, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 470.00 MiB memory in use. Process 1194561 has 586.00 MiB memory in use. Process 1194517 has 978.00 MiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.10 GiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 468.00 MiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 946.00 MiB memory in use. Process 1198980 has 1.13 GiB memory in use. Process 1198939 has 510.00 MiB memory in use. Process 1198975 has 492.00 MiB memory in use. Process 1198942 has 486.00 MiB memory in use. Of the allocated memory 96.53 MiB is allocated by PyTorch, and 75.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
cc34f063,"{'temperature': 1.4000000000000001, 'latent_dim': 229, 'transform_funcs': (1, 2, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 468.00 MiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 978.00 MiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 476.00 MiB memory in use. Process 1198160 has 1.24 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.10 GiB memory in use. Process 1198163 has 518.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 470.00 MiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 946.00 MiB memory in use. Process 1198980 has 1.13 GiB memory in use. Process 1198939 has 564.00 MiB memory in use. Process 1198975 has 516.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 146.10 MiB is allocated by PyTorch, and 79.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b624b780,"{'temperature': 1.5, 'latent_dim': 216, 'transform_funcs': (0, 4, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 13.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1014.00 MiB memory in use. Process 1194561 has 486.00 MiB memory in use. Process 1194517 has 978.00 MiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 570.00 MiB memory in use. Process 1198160 has 1.20 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 520.00 MiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.03 GiB memory in use. Process 1198980 has 1.13 GiB memory in use. Process 1198939 has 516.00 MiB memory in use. Process 1198975 has 494.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 96.00 MiB is allocated by PyTorch, and 82.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
a79f72af,"{'temperature': 1.1, 'latent_dim': 304, 'transform_funcs': (1, 4, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1014.00 MiB memory in use. Process 1194561 has 508.00 MiB memory in use. Process 1194517 has 978.00 MiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 830.00 MiB memory in use. Process 1198160 has 462.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.14 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.03 GiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 470.00 MiB memory in use. Process 1198975 has 494.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 84.36 MiB is allocated by PyTorch, and 39.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b0046a5f,"{'temperature': 1.4000000000000001, 'latent_dim': 251, 'transform_funcs': (1, 4, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1014.00 MiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 978.00 MiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 864.00 MiB memory in use. Process 1198160 has 466.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.14 GiB memory in use. Process 1198555 has 1.04 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.03 GiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 494.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 83.94 MiB is allocated by PyTorch, and 42.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
da0e9872,"{'temperature': 1.3, 'latent_dim': 70, 'transform_funcs': (1, 3, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 978.00 MiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 882.00 MiB memory in use. Process 1198160 has 430.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 528.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.14 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.03 GiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 986.00 MiB memory in use. Process 1198975 has 448.00 MiB memory in use. Process 1198942 has 474.00 MiB memory in use. Of the allocated memory 47.52 MiB is allocated by PyTorch, and 44.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ab4942b4,"{'temperature': 1.3, 'latent_dim': 185, 'transform_funcs': (0, 5, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 116.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 518.00 MiB memory in use. Process 1194517 has 978.00 MiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 470.00 MiB memory in use. Process 1198160 has 816.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 528.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.03 GiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 986.00 MiB memory in use. Process 1198975 has 448.00 MiB memory in use. Process 1198942 has 474.00 MiB memory in use. Of the allocated memory 393.73 MiB is allocated by PyTorch, and 84.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
53549595,"{'temperature': 1.0, 'latent_dim': 156, 'transform_funcs': (1, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 888.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 522.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 426.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 1.23 GiB memory in use. Process 1198975 has 780.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 48.20 MiB is allocated by PyTorch, and 39.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ba041fab,"{'temperature': 1.3, 'latent_dim': 183, 'transform_funcs': (0, 1, 3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 892.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 740.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 472.00 MiB memory in use. Process 1198160 has 464.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 1.23 GiB memory in use. Process 1198975 has 518.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 83.41 MiB is allocated by PyTorch, and 42.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5b39bdcf,"{'temperature': 1.1, 'latent_dim': 160, 'transform_funcs': (1, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 886.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 740.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 510.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 1.23 GiB memory in use. Process 1198975 has 518.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 95.56 MiB is allocated by PyTorch, and 76.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
e7fb379b,"{'temperature': 1.3, 'latent_dim': 129, 'transform_funcs': (4, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 53.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 888.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.12 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 476.00 MiB memory in use. Process 1198160 has 590.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 526.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 514.00 MiB memory in use. Process 1198980 has 466.00 MiB memory in use. Process 1198939 has 994.00 MiB memory in use. Process 1198975 has 776.00 MiB memory in use. Process 1198942 has 520.00 MiB memory in use. Of the allocated memory 203.97 MiB is allocated by PyTorch, and 48.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
059208cf,"{'temperature': 0.7000000000000001, 'latent_dim': 209, 'transform_funcs': (2, 3, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 888.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 586.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 476.00 MiB memory in use. Process 1198160 has 464.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 526.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 514.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 1.03 GiB memory in use. Process 1198975 has 764.00 MiB memory in use. Process 1198942 has 520.00 MiB memory in use. Of the allocated memory 83.62 MiB is allocated by PyTorch, and 42.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9cedc1c2,"{'temperature': 1.1, 'latent_dim': 359, 'transform_funcs': (1, 3, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 145.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 894.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 586.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 518.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 526.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 754.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 926.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 486.00 MiB memory in use. Of the allocated memory 503.41 MiB is allocated by PyTorch, and 84.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a423dd83,"{'temperature': 1.5, 'latent_dim': 79, 'transform_funcs': (2, 3, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 894.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 586.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 470.00 MiB memory in use. Process 1198160 has 568.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 754.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 982.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 486.00 MiB memory in use. Of the allocated memory 144.93 MiB is allocated by PyTorch, and 85.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f2fca930,"{'temperature': 1.3, 'latent_dim': 335, 'transform_funcs': (0, 1, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 121.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1004.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 586.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 470.00 MiB memory in use. Process 1198160 has 468.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 446.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 754.00 MiB memory in use. Process 1198980 has 466.00 MiB memory in use. Process 1198939 has 926.00 MiB memory in use. Process 1198975 has 512.00 MiB memory in use. Process 1198942 has 486.00 MiB memory in use. Of the allocated memory 488.22 MiB is allocated by PyTorch, and 99.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cc23ed77,"{'temperature': 0.8, 'latent_dim': 222, 'transform_funcs': (5, 7, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1004.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 522.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 566.00 MiB memory in use. Process 1198160 has 432.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 526.00 MiB memory in use. Process 1198163 has 448.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 758.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 980.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 486.00 MiB memory in use. Of the allocated memory 48.71 MiB is allocated by PyTorch, and 45.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1eb93762,"{'temperature': 1.4000000000000001, 'latent_dim': 164, 'transform_funcs': (2, 3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 486.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 524.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 510.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 528.00 MiB memory in use. Process 1198163 has 750.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 852.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 980.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 646.00 MiB memory in use. Of the allocated memory 95.59 MiB is allocated by PyTorch, and 76.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
9798b904,"{'temperature': 1.1, 'latent_dim': 272, 'transform_funcs': (0, 1, 3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 127.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 486.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 524.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 518.00 MiB memory in use. Process 1198160 has 700.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 490.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 852.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 980.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 646.00 MiB memory in use. Of the allocated memory 278.41 MiB is allocated by PyTorch, and 83.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7d88db0b,"{'temperature': 1.4000000000000001, 'latent_dim': 231, 'transform_funcs': (3, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 147.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 442.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 756.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 500.00 MiB memory in use. Process 1198163 has 442.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 852.00 MiB memory in use. Process 1198980 has 478.00 MiB memory in use. Process 1198939 has 928.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 756.00 MiB memory in use. Of the allocated memory 422.43 MiB is allocated by PyTorch, and 167.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
60fae12d,"{'temperature': 1.3, 'latent_dim': 257, 'transform_funcs': (0, 1, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 69.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 518.00 MiB memory in use. Process 1198160 has 704.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 490.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 852.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 980.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 756.00 MiB memory in use. Of the allocated memory 278.29 MiB is allocated by PyTorch, and 87.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
48a43eaf,"{'temperature': 1.4000000000000001, 'latent_dim': 335, 'transform_funcs': (4, 5, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 5.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 444.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 512.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 910.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 448.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 846.00 MiB memory in use. Process 1198980 has 466.00 MiB memory in use. Process 1198939 has 1.11 GiB memory in use. Process 1198975 has 528.00 MiB memory in use. Process 1198942 has 466.00 MiB memory in use. Of the allocated memory 488.90 MiB is allocated by PyTorch, and 83.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e067669a,"{'temperature': 1.1, 'latent_dim': 303, 'transform_funcs': (2, 3, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 460.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 818.00 MiB memory in use. Process 1198160 has 512.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 480.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 846.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 1.11 GiB memory in use. Process 1198975 has 528.00 MiB memory in use. Process 1198942 has 486.00 MiB memory in use. Of the allocated memory 96.68 MiB is allocated by PyTorch, and 77.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
df6156c9,"{'temperature': 1.5, 'latent_dim': 248, 'transform_funcs': (8, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 510.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 2.04 GiB memory in use. Process 1198152 has 882.00 MiB memory in use. Process 1198160 has 430.00 MiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 846.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 1.11 GiB memory in use. Process 1198975 has 512.00 MiB memory in use. Process 1198942 has 486.00 MiB memory in use. Of the allocated memory 48.92 MiB is allocated by PyTorch, and 43.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2b01d322,"{'temperature': 1.4000000000000001, 'latent_dim': 324, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 544.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 466.00 MiB memory in use. Process 1198160 has 1.25 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 566.00 MiB memory in use. Process 1198163 has 448.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 940.00 MiB memory in use. Process 1198980 has 1002.00 MiB memory in use. Process 1198939 has 1.11 GiB memory in use. Process 1198975 has 1012.00 MiB memory in use. Process 1198942 has 446.00 MiB memory in use. Of the allocated memory 531.88 MiB is allocated by PyTorch, and 262.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 32, in forward
    x = self.dropout3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
6f5e1255,"{'temperature': 1.4000000000000001, 'latent_dim': 274, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 446.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 544.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 644.00 MiB memory in use. Process 1198160 has 1.25 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 566.00 MiB memory in use. Process 1198163 has 448.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 940.00 MiB memory in use. Process 1198980 has 934.00 MiB memory in use. Process 1198939 has 558.00 MiB memory in use. Process 1198975 has 1.43 GiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 146.46 MiB is allocated by PyTorch, and 73.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5a1620c2,"{'temperature': 0.5, 'latent_dim': 134, 'transform_funcs': (2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 650.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 448.00 MiB memory in use. Process 1198160 has 1.21 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 652.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1018.00 MiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.01 GiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 466.00 MiB memory in use. Process 1198975 has 1.43 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 83.03 MiB is allocated by PyTorch, and 44.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
53b41dc3,"{'temperature': 1.5, 'latent_dim': 182, 'transform_funcs': (5, 6, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 650.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 448.00 MiB memory in use. Process 1198160 has 1.21 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 516.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.01 GiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 618.00 MiB memory in use. Process 1198975 has 1.43 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 204.39 MiB is allocated by PyTorch, and 75.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fa99920c,"{'temperature': 1.1, 'latent_dim': 212, 'transform_funcs': (1, 3, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 512.00 MiB memory in use. Process 1198152 has 446.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 518.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.11 GiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 594.00 MiB memory in use. Process 1198975 has 1.43 GiB memory in use. Process 1198942 has 480.00 MiB memory in use. Of the allocated memory 204.62 MiB is allocated by PyTorch, and 51.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d2b55831,"{'temperature': 1.3, 'latent_dim': 116, 'transform_funcs': (0, 2, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 528.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 448.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 518.00 MiB memory in use. Process 1198163 has 448.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.11 GiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 564.00 MiB memory in use. Process 1198975 has 1.43 GiB memory in use. Process 1198942 has 480.00 MiB memory in use. Of the allocated memory 145.22 MiB is allocated by PyTorch, and 80.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e69cb731,"{'temperature': 1.5, 'latent_dim': 235, 'transform_funcs': (2, 4, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 608.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 492.00 MiB memory in use. Process 1198152 has 448.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 516.00 MiB memory in use. Process 1198163 has 448.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.11 GiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 516.00 MiB memory in use. Process 1198975 has 1.43 GiB memory in use. Process 1198942 has 480.00 MiB memory in use. Of the allocated memory 96.15 MiB is allocated by PyTorch, and 81.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
fed67337,"{'temperature': 1.2000000000000002, 'latent_dim': 257, 'transform_funcs': (0, 4, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 446.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 448.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 442.00 MiB memory in use. Process 1198163 has 514.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.11 GiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 646.00 MiB memory in use. Process 1198975 has 1.43 GiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 219.64 MiB is allocated by PyTorch, and 88.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
90038ee7,"{'temperature': 1.1, 'latent_dim': 217, 'transform_funcs': (1, 2, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 446.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 514.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 614.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.11 GiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 426.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 446.00 MiB memory in use. Of the allocated memory 48.67 MiB is allocated by PyTorch, and 39.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
01760db3,"{'temperature': 1.3, 'latent_dim': 340, 'transform_funcs': (1, 3, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 17.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 446.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 492.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.25 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 518.00 MiB memory in use. Process 1198152 has 514.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 614.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.11 GiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 416.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 446.00 MiB memory in use. Of the allocated memory 72.86 MiB is allocated by PyTorch, and 5.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
63682570,"{'temperature': 1.4000000000000001, 'latent_dim': 149, 'transform_funcs': (5, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 446.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.21 GiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 472.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 490.00 MiB memory in use. Process 1198163 has 614.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.11 GiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 466.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 83.15 MiB is allocated by PyTorch, and 44.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fd3e734e,"{'temperature': 0.7000000000000001, 'latent_dim': 229, 'transform_funcs': (0, 1, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 752.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 650.00 MiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 532.00 MiB memory in use. Process 1198163 has 884.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.11 GiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 448.00 MiB memory in use. Process 1198975 has 1.46 GiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 220.33 MiB is allocated by PyTorch, and 91.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
5912403a,"{'temperature': 0.5, 'latent_dim': 66, 'transform_funcs': (1, 2, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 752.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 534.00 MiB memory in use. Process 1198163 has 884.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.11 GiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 586.00 MiB memory in use. Process 1198975 has 1.47 GiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 203.48 MiB is allocated by PyTorch, and 44.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f340915c,"{'temperature': 1.1, 'latent_dim': 287, 'transform_funcs': (0, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 752.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 460.00 MiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 534.00 MiB memory in use. Process 1198163 has 996.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.11 GiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 1.47 GiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 85.14 MiB is allocated by PyTorch, and 36.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
38853e66,"{'temperature': 1.5, 'latent_dim': 266, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 752.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 528.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 470.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 534.00 MiB memory in use. Process 1198163 has 996.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.69 GiB memory in use. Process 1198934 has 1.11 GiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 462.00 MiB memory in use. Process 1198975 has 1.47 GiB memory in use. Process 1198942 has 446.00 MiB memory in use. Of the allocated memory 84.06 MiB is allocated by PyTorch, and 39.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
26fdcfc1,"{'temperature': 1.0, 'latent_dim': 302, 'transform_funcs': (0, 1, 2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 528.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 650.00 MiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 586.00 MiB memory in use. Process 1198152 has 470.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 996.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.74 GiB memory in use. Process 1198934 has 1.11 GiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 1.47 GiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 220.90 MiB is allocated by PyTorch, and 91.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
babc2969,"{'temperature': 1.2000000000000002, 'latent_dim': 183, 'transform_funcs': (5, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 528.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 586.00 MiB memory in use. Process 1198152 has 470.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 996.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.74 GiB memory in use. Process 1198934 has 1.11 GiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 654.00 MiB memory in use. Process 1198975 has 1.47 GiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 219.06 MiB is allocated by PyTorch, and 96.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
2e617eab,"{'temperature': 1.3, 'latent_dim': 312, 'transform_funcs': (0, 1, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 528.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 982.00 MiB memory in use. Process 1197769 has 996.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 838.00 MiB memory in use. Process 1198152 has 470.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 490.00 MiB memory in use. Process 1198163 has 996.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.74 GiB memory in use. Process 1198934 has 518.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 460.00 MiB memory in use. Process 1198975 has 1.47 GiB memory in use. Process 1198942 has 486.00 MiB memory in use. Of the allocated memory 84.42 MiB is allocated by PyTorch, and 37.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5692ba42,"{'temperature': 1.2000000000000002, 'latent_dim': 97, 'transform_funcs': (4, 5, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 61.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 564.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 982.00 MiB memory in use. Process 1197769 has 1004.00 MiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 754.00 MiB memory in use. Process 1198152 has 470.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 490.00 MiB memory in use. Process 1198163 has 996.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.74 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 532.00 MiB memory in use. Process 1198975 has 1.47 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 145.07 MiB is allocated by PyTorch, and 48.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
76efa9b3,"{'temperature': 1.1, 'latent_dim': 147, 'transform_funcs': (1, 4, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 13.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 564.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 982.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 468.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 650.00 MiB memory in use. Process 1198163 has 996.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.74 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 590.00 MiB memory in use. Process 1198975 has 1.47 GiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 204.11 MiB is allocated by PyTorch, and 47.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d08da87a,"{'temperature': 1.3, 'latent_dim': 156, 'transform_funcs': (0, 4, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 13.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 570.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 982.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 446.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 650.00 MiB memory in use. Process 1198163 has 1.09 GiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.74 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 508.00 MiB memory in use. Process 1198975 has 1.47 GiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 95.53 MiB is allocated by PyTorch, and 74.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
ff3939c5,"{'temperature': 1.5, 'latent_dim': 162, 'transform_funcs': (0, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 982.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 516.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 650.00 MiB memory in use. Process 1198163 has 912.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.74 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 710.00 MiB memory in use. Process 1198975 has 1.47 GiB memory in use. Process 1198942 has 442.00 MiB memory in use. Of the allocated memory 277.55 MiB is allocated by PyTorch, and 94.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4fe67c1a,"{'temperature': 1.3, 'latent_dim': 76, 'transform_funcs': (3, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.07 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 518.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 470.00 MiB memory in use. Process 1198163 has 964.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.74 GiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 704.00 MiB memory in use. Process 1198975 has 1.47 GiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 276.87 MiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
64cd2599,"{'temperature': 1.0, 'latent_dim': 188, 'transform_funcs': (3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 700.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.07 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 482.00 MiB memory in use. Process 1198152 has 518.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 496.00 MiB memory in use. Process 1198163 has 966.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.74 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 428.00 MiB memory in use. Process 1198975 has 1.47 GiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 48.45 MiB is allocated by PyTorch, and 41.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f89544f1,"{'temperature': 1.1, 'latent_dim': 180, 'transform_funcs': (0, 2, 3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 700.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.07 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 482.00 MiB memory in use. Process 1198152 has 518.00 MiB memory in use. Process 1198160 has 1.26 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 476.00 MiB memory in use. Process 1198163 has 966.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 1.74 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 418.00 MiB memory in use. Process 1198975 has 1.47 GiB memory in use. Process 1198942 has 524.00 MiB memory in use. Of the allocated memory 74.37 MiB is allocated by PyTorch, and 5.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
93084b25,"{'temperature': 1.0, 'latent_dim': 165, 'transform_funcs': (4, 8, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 760.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 492.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.07 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 1.23 GiB memory in use. Process 1198152 has 464.00 MiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 492.00 MiB memory in use. Process 1198163 has 966.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 958.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 462.00 MiB memory in use. Process 1198975 has 1.47 GiB memory in use. Process 1198942 has 486.00 MiB memory in use. Of the allocated memory 83.27 MiB is allocated by PyTorch, and 40.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4fce551b,"{'temperature': 1.0, 'latent_dim': 360, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 179.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.22 GiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 518.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 702.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 494.00 MiB memory in use. Process 1198152 has 1.09 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 970.00 MiB memory in use. Process 1198163 has 966.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.15 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 492.00 MiB memory in use. Process 1198934 has 700.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 1.03 GiB memory in use. Process 1198975 has 540.00 MiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 280.01 MiB is allocated by PyTorch, and 83.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
90a43b94,"{'temperature': 1.2000000000000002, 'latent_dim': 338, 'transform_funcs': (3, 5, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 89.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.23 GiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 512.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 918.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 512.00 MiB memory in use. Process 1198152 has 1.09 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 970.00 MiB memory in use. Process 1198163 has 966.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.10 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 564.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 1.10 GiB memory in use. Process 1198975 has 540.00 MiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 491.83 MiB is allocated by PyTorch, and 88.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f2526ca6,"{'temperature': 1.4000000000000001, 'latent_dim': 142, 'transform_funcs': (2, 6, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.23 GiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 996.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.07 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.09 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 730.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 466.00 MiB memory in use. Process 1198551 has 566.00 MiB memory in use. Process 1198934 has 480.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 1010.00 MiB memory in use. Process 1198975 has 662.00 MiB memory in use. Process 1198942 has 822.00 MiB memory in use. Of the allocated memory 83.09 MiB is allocated by PyTorch, and 44.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
79448ea8,"{'temperature': 1.2000000000000002, 'latent_dim': 234, 'transform_funcs': (2, 3, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.23 GiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 996.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.12 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.09 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 730.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 568.00 MiB memory in use. Process 1198551 has 566.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 1010.00 MiB memory in use. Process 1198975 has 532.00 MiB memory in use. Process 1198942 has 822.00 MiB memory in use. Of the allocated memory 146.14 MiB is allocated by PyTorch, and 83.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d0563907,"{'temperature': 0.8, 'latent_dim': 113, 'transform_funcs': (1, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.23 GiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 518.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.12 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 928.00 MiB memory in use. Process 1198152 has 1.09 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 726.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 622.00 MiB memory in use. Process 1198551 has 566.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 1012.00 MiB memory in use. Process 1198975 has 532.00 MiB memory in use. Process 1198942 has 822.00 MiB memory in use. Of the allocated memory 203.85 MiB is allocated by PyTorch, and 80.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
13341d46,"{'temperature': 1.0, 'latent_dim': 281, 'transform_funcs': (1, 5, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 13.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.12 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 1.09 GiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 738.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.21 GiB memory in use. Process 1198551 has 758.00 MiB memory in use. Process 1198934 has 776.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 560.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 766.00 MiB memory in use. Of the allocated memory 146.51 MiB is allocated by PyTorch, and 75.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1c86d1db,"{'temperature': 1.5, 'latent_dim': 345, 'transform_funcs': (2, 3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 199.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.12 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.21 GiB memory in use. Process 1198551 has 1.31 GiB memory in use. Process 1198934 has 836.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 894.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 494.98 MiB is allocated by PyTorch, and 61.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
92445584,"{'temperature': 1.4000000000000001, 'latent_dim': 147, 'transform_funcs': (3, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 756.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 708.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.12 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 470.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.22 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 836.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 466.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 83.13 MiB is allocated by PyTorch, and 44.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8014d438,"{'temperature': 1.3, 'latent_dim': 34, 'transform_funcs': (3, 7, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 17.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 754.00 MiB memory in use. Process 1194517 has 982.00 MiB memory in use. Process 1194518 has 708.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.14 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 498.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 470.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.17 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 814.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 510.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 94.58 MiB is allocated by PyTorch, and 77.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
290213e9,"{'temperature': 1.4000000000000001, 'latent_dim': 170, 'transform_funcs': (4, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 59.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 824.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 766.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.20 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 498.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 470.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.23 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 560.00 MiB memory in use. Process 1198975 has 542.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 145.64 MiB is allocated by PyTorch, and 76.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b2fe0bab,"{'temperature': 1.0, 'latent_dim': 97, 'transform_funcs': (0, 2, 3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 952.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 766.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.20 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 538.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.23 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 436.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 430.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 47.74 MiB is allocated by PyTorch, and 44.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3bd21898,"{'temperature': 1.1, 'latent_dim': 80, 'transform_funcs': (5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 952.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 766.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.20 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 538.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.23 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 434.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 66.64 MiB is allocated by PyTorch, and 29.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
3ffedd1f,"{'temperature': 1.4000000000000001, 'latent_dim': 141, 'transform_funcs': (5, 6, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 952.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 766.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.20 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 538.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.23 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 422.00 MiB memory in use. Process 1198975 has 526.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 62.98 MiB is allocated by PyTorch, and 21.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 20, in forward
    projection_1 = self.projection_1(base_model_output)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
"
6e246858,"{'temperature': 0.8, 'latent_dim': 194, 'transform_funcs': (1, 7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 7.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 952.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 766.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.20 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 538.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.23 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 418.00 MiB memory in use. Process 1198975 has 526.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 74.20 MiB is allocated by PyTorch, and 5.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
111c1bde,"{'temperature': 1.3, 'latent_dim': 162, 'transform_funcs': (2, 3, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 7.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 952.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 766.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.20 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 538.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.23 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 418.00 MiB memory in use. Process 1198975 has 526.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 71.53 MiB is allocated by PyTorch, and 8.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
87fd5026,"{'temperature': 1.2000000000000002, 'latent_dim': 205, 'transform_funcs': (1, 2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1010.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 526.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.20 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 538.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.23 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 590.00 MiB memory in use. Process 1198975 has 528.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 204.57 MiB is allocated by PyTorch, and 47.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
342a3ad7,"{'temperature': 1.3, 'latent_dim': 261, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1010.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 526.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.20 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.23 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 584.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 518.00 MiB memory in use. Of the allocated memory 205.01 MiB is allocated by PyTorch, and 40.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ae836dce,"{'temperature': 0.5, 'latent_dim': 52, 'transform_funcs': (1, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.12 GiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 572.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.20 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.23 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 420.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 520.00 MiB memory in use. Of the allocated memory 47.38 MiB is allocated by PyTorch, and 34.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
946af16e,"{'temperature': 1.2000000000000002, 'latent_dim': 134, 'transform_funcs': (5, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.12 GiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.22 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.23 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 514.00 MiB memory in use. Process 1198975 has 510.00 MiB memory in use. Process 1198942 has 482.00 MiB memory in use. Of the allocated memory 95.36 MiB is allocated by PyTorch, and 80.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
43eef95e,"{'temperature': 1.5, 'latent_dim': 146, 'transform_funcs': (5, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.12 GiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 516.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.16 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 532.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 518.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.23 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 520.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 83.12 MiB is allocated by PyTorch, and 42.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7402f7b9,"{'temperature': 1.0, 'latent_dim': 305, 'transform_funcs': (3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 7.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.12 GiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.22 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 532.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 500.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.23 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 508.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 96.70 MiB is allocated by PyTorch, and 73.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
86ce7669,"{'temperature': 1.5, 'latent_dim': 23, 'transform_funcs': (0, 1, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.12 GiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.22 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 532.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 526.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.23 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 460.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 82.16 MiB is allocated by PyTorch, and 39.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
33d16d79,"{'temperature': 1.3, 'latent_dim': 86, 'transform_funcs': (2, 5, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.12 GiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 570.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.22 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.23 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 428.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 47.65 MiB is allocated by PyTorch, and 42.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e2a07062,"{'temperature': 1.2000000000000002, 'latent_dim': 169, 'transform_funcs': (2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.12 GiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 570.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.22 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.23 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 432.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 476.00 MiB memory in use. Of the allocated memory 72.75 MiB is allocated by PyTorch, and 21.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
e0ae044a,"{'temperature': 1.3, 'latent_dim': 237, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.12 GiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 570.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.22 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.23 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 430.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 476.00 MiB memory in use. Of the allocated memory 72.61 MiB is allocated by PyTorch, and 19.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7fd29085,"{'temperature': 1.1, 'latent_dim': 129, 'transform_funcs': (1, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 61.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.12 GiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.22 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 470.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 528.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 145.32 MiB is allocated by PyTorch, and 44.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
44d250b4,"{'temperature': 1.3, 'latent_dim': 139, 'transform_funcs': (1, 5, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 59.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.22 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 480.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 586.00 MiB memory in use. Process 1198975 has 1.05 GiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 204.05 MiB is allocated by PyTorch, and 43.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
454351b6,"{'temperature': 1.4000000000000001, 'latent_dim': 298, 'transform_funcs': (2, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 492.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.22 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 480.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 484.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 650.00 MiB memory in use. Process 1198975 has 1.05 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 219.96 MiB is allocated by PyTorch, and 92.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
9fc0e260,"{'temperature': 1.0, 'latent_dim': 152, 'transform_funcs': (0, 1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1024.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 460.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 700.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 706.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 432.00 MiB memory in use. Process 1198975 has 1.05 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 48.17 MiB is allocated by PyTorch, and 45.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
af1dbee7,"{'temperature': 1.1, 'latent_dim': 276, 'transform_funcs': (0, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1024.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 482.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 506.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 700.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 706.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 420.00 MiB memory in use. Process 1198975 has 1.05 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 97.38 MiB is allocated by PyTorch, and 70.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
366d2775,"{'temperature': 1.4000000000000001, 'latent_dim': 12, 'transform_funcs': (1, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1024.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 482.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 506.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 700.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 706.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 428.00 MiB memory in use. Process 1198975 has 1.05 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 60.97 MiB is allocated by PyTorch, and 29.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
5c5b224a,"{'temperature': 1.5, 'latent_dim': 255, 'transform_funcs': (2, 3, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 7.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 482.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1020.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 698.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 706.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 466.00 MiB memory in use. Process 1198975 has 1.05 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 479.02 MiB is allocated by PyTorch, and 202.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 32, in forward
    x = self.dropout3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
7caa24a7,"{'temperature': 1.2000000000000002, 'latent_dim': 100, 'transform_funcs': (2, 4, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 698.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 708.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 1.38 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 430.00 MiB memory in use. Process 1198975 has 1.05 GiB memory in use. Process 1198942 has 1010.00 MiB memory in use. Of the allocated memory 47.76 MiB is allocated by PyTorch, and 44.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b566ba8e,"{'temperature': 1.4000000000000001, 'latent_dim': 112, 'transform_funcs': (1, 3, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 61.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 592.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 708.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 544.00 MiB memory in use. Process 1198934 has 614.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 772.00 MiB memory in use. Process 1198975 has 1.45 GiB memory in use. Process 1198942 has 1010.00 MiB memory in use. Of the allocated memory 204.75 MiB is allocated by PyTorch, and 49.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
66603e4e,"{'temperature': 1.0, 'latent_dim': 344, 'transform_funcs': (0, 3, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 181.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 986.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 524.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 766.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 764.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 668.00 MiB memory in use. Process 1198975 has 1.45 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 278.97 MiB is allocated by PyTorch, and 51.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
86b0a6d5,"{'temperature': 1.0, 'latent_dim': 293, 'transform_funcs': (0, 1, 3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 986.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 524.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 592.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 766.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 764.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 724.00 MiB memory in use. Process 1198975 has 1.45 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 206.17 MiB is allocated by PyTorch, and 47.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8c531dcb,"{'temperature': 1.1, 'latent_dim': 308, 'transform_funcs': (3, 5, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 57.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 980.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 592.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 482.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 766.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 766.00 MiB memory in use. Process 1198934 has 526.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 670.00 MiB memory in use. Process 1198975 has 1.45 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 278.69 MiB is allocated by PyTorch, and 53.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c4f6e1bf,"{'temperature': 1.1, 'latent_dim': 329, 'transform_funcs': (1, 7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 7.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 980.00 MiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 592.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 562.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 766.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 762.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 722.00 MiB memory in use. Process 1198975 has 1.45 GiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 147.80 MiB is allocated by PyTorch, and 76.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
93975af1,"{'temperature': 1.1, 'latent_dim': 299, 'transform_funcs': (4, 5, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.01 GiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 1.52 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 508.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 742.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 762.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 724.00 MiB memory in use. Process 1198975 has 532.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 97.56 MiB is allocated by PyTorch, and 72.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
08eb140a,"{'temperature': 1.0, 'latent_dim': 244, 'transform_funcs': (0, 2, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 67.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.01 GiB memory in use. Process 1194517 has 986.00 MiB memory in use. Process 1194518 has 1.52 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 566.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 916.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 670.00 MiB memory in use. Process 1198975 has 532.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 278.19 MiB is allocated by PyTorch, and 53.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
75dff044,"{'temperature': 0.8, 'latent_dim': 280, 'transform_funcs': (1, 2, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.01 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.57 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 566.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 502.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 918.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 462.00 MiB memory in use. Process 1198975 has 530.00 MiB memory in use. Process 1198942 has 566.00 MiB memory in use. Of the allocated memory 84.17 MiB is allocated by PyTorch, and 39.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6b4a6b47,"{'temperature': 1.1, 'latent_dim': 269, 'transform_funcs': (0, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.01 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.57 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 622.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 502.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 918.00 MiB memory in use. Process 1198934 has 450.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 514.00 MiB memory in use. Process 1198975 has 512.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 205.98 MiB is allocated by PyTorch, and 78.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0f65e631,"{'temperature': 0.6000000000000001, 'latent_dim': 315, 'transform_funcs': (2, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.01 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 710.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 502.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 510.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 760.00 MiB memory in use. Process 1198934 has 460.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 516.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 279.65 MiB is allocated by PyTorch, and 92.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f8dca526,"{'temperature': 0.7000000000000001, 'latent_dim': 271, 'transform_funcs': (3, 4, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.02 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 462.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 758.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 510.00 MiB memory in use. Process 1198163 has 968.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.24 GiB memory in use. Process 1198551 has 762.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 516.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 85.01 MiB is allocated by PyTorch, and 38.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f61a4e94,"{'temperature': 0.7000000000000001, 'latent_dim': 255, 'transform_funcs': (4, 6, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.02 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 758.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 970.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 762.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 558.00 MiB memory in use. Process 1198975 has 466.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 146.31 MiB is allocated by PyTorch, and 73.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e6f8ecae,"{'temperature': 0.9, 'latent_dim': 259, 'transform_funcs': (0, 1, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.02 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 460.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 758.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 762.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 488.00 MiB memory in use. Process 1198975 has 564.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 84.92 MiB is allocated by PyTorch, and 37.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
022d2680,"{'temperature': 0.6000000000000001, 'latent_dim': 337, 'transform_funcs': (0, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.07 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 518.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 466.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 792.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 474.00 MiB memory in use. Process 1198942 has 754.00 MiB memory in use. Of the allocated memory 84.62 MiB is allocated by PyTorch, and 41.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
397862ef,"{'temperature': 1.0, 'latent_dim': 237, 'transform_funcs': (7, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.07 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 518.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 522.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 448.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 462.00 MiB memory in use. Process 1198975 has 754.00 MiB memory in use. Process 1198942 has 754.00 MiB memory in use. Of the allocated memory 83.83 MiB is allocated by PyTorch, and 40.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
05693693,"{'temperature': 0.5, 'latent_dim': 225, 'transform_funcs': (0, 1, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.07 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 512.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 522.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 448.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 462.00 MiB memory in use. Process 1198975 has 754.00 MiB memory in use. Process 1198942 has 754.00 MiB memory in use. Of the allocated memory 96.98 MiB is allocated by PyTorch, and 77.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
1e00558c,"{'temperature': 0.9, 'latent_dim': 348, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.07 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 462.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 738.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 448.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 474.00 MiB memory in use. Process 1198975 has 872.00 MiB memory in use. Process 1198942 has 450.00 MiB memory in use. Of the allocated memory 85.61 MiB is allocated by PyTorch, and 38.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
68543a0a,"{'temperature': 0.6000000000000001, 'latent_dim': 203, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.07 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 480.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 738.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 512.00 MiB memory in use. Process 1198975 has 818.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 95.90 MiB is allocated by PyTorch, and 78.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
d399b3f6,"{'temperature': 1.1, 'latent_dim': 199, 'transform_funcs': (0, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 69.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.07 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 826.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 480.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 738.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 446.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 403.09 MiB is allocated by PyTorch, and 84.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6d7e16e7,"{'temperature': 1.1, 'latent_dim': 193, 'transform_funcs': (0, 2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 101.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 824.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 480.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 806.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 1014.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 470.00 MiB memory in use. Process 1198975 has 430.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 399.29 MiB is allocated by PyTorch, and 86.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
400258d1,"{'temperature': 0.9, 'latent_dim': 237, 'transform_funcs': (0, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 480.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 806.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 1014.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 852.00 MiB memory in use. Process 1198975 has 480.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 426.22 MiB is allocated by PyTorch, and 87.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9b7f7045,"{'temperature': 0.5, 'latent_dim': 358, 'transform_funcs': (0, 2, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 938.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 826.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 844.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 460.00 MiB memory in use. Process 1198975 has 480.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 84.78 MiB is allocated by PyTorch, and 37.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e39550b5,"{'temperature': 1.2000000000000002, 'latent_dim': 168, 'transform_funcs': (2, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 938.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 828.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 844.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 466.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 83.30 MiB is allocated by PyTorch, and 44.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c538bd0e,"{'temperature': 1.1, 'latent_dim': 163, 'transform_funcs': (0, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 860.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 828.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 844.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 514.00 MiB memory in use. Process 1198975 has 506.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 95.59 MiB is allocated by PyTorch, and 80.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
ca73ceec,"{'temperature': 0.9, 'latent_dim': 187, 'transform_funcs': (2, 3, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.12 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 894.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 568.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 145.77 MiB is allocated by PyTorch, and 84.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7acf3ed1,"{'temperature': 1.0, 'latent_dim': 303, 'transform_funcs': (4, 5, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 61.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 472.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 530.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.12 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 894.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 147.59 MiB is allocated by PyTorch, and 44.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
530920d9,"{'temperature': 0.8, 'latent_dim': 146, 'transform_funcs': (2, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 476.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 584.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 474.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.12 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 894.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 83.12 MiB is allocated by PyTorch, and 42.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0feec638,"{'temperature': 1.2000000000000002, 'latent_dim': 134, 'transform_funcs': (4, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 590.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 474.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.12 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 488.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 520.00 MiB memory in use. Process 1198975 has 512.00 MiB memory in use. Process 1198942 has 852.00 MiB memory in use. Of the allocated memory 204.92 MiB is allocated by PyTorch, and 47.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
85243e4c,"{'temperature': 1.2000000000000002, 'latent_dim': 231, 'transform_funcs': (3, 4, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 460.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.12 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 588.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 520.00 MiB memory in use. Process 1198975 has 512.00 MiB memory in use. Process 1198942 has 852.00 MiB memory in use. Of the allocated memory 84.70 MiB is allocated by PyTorch, and 37.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5e39628f,"{'temperature': 0.7000000000000001, 'latent_dim': 350, 'transform_funcs': (0, 5, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 520.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.00 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 532.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 628.00 MiB memory in use. Process 1198975 has 512.00 MiB memory in use. Process 1198942 has 852.00 MiB memory in use. Of the allocated memory 205.70 MiB is allocated by PyTorch, and 84.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9b430748,"{'temperature': 0.9, 'latent_dim': 326, 'transform_funcs': (1, 2, 3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 682.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.00 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 532.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 852.00 MiB memory in use. Of the allocated memory 279.74 MiB is allocated by PyTorch, and 64.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dd5b5b22,"{'temperature': 1.1, 'latent_dim': 126, 'transform_funcs': (4, 7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 738.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.00 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 532.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 778.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 356.00 MiB is allocated by PyTorch, and 84.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9bd3b2b8,"{'temperature': 1.2000000000000002, 'latent_dim': 205, 'transform_funcs': (0, 1, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 79.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 472.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 682.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 756.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.03 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 532.00 MiB memory in use. Process 1198934 has 460.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 278.79 MiB is allocated by PyTorch, and 65.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e19fa2a9,"{'temperature': 0.8, 'latent_dim': 334, 'transform_funcs': (3, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 568.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 462.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 756.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.03 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 532.00 MiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 464.00 MiB memory in use. Of the allocated memory 85.50 MiB is allocated by PyTorch, and 38.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
afe89d09,"{'temperature': 0.9, 'latent_dim': 316, 'transform_funcs': (3, 5, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 568.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 698.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.03 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 532.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 706.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 278.75 MiB is allocated by PyTorch, and 89.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e7f96283,"{'temperature': 0.9, 'latent_dim': 292, 'transform_funcs': (1, 5, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 61.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 622.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.58 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 498.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.03 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 532.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 712.00 MiB memory in use. Process 1198975 has 518.00 MiB memory in use. Process 1198942 has 590.00 MiB memory in use. Of the allocated memory 278.56 MiB is allocated by PyTorch, and 95.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1da7f94f,"{'temperature': 1.1, 'latent_dim': 360, 'transform_funcs': (1, 2, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 89.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.64 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 964.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 550.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 714.00 MiB memory in use. Process 1198975 has 570.00 MiB memory in use. Process 1198942 has 646.00 MiB memory in use. Of the allocated memory 279.10 MiB is allocated by PyTorch, and 96.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c97d76c4,"{'temperature': 0.8, 'latent_dim': 185, 'transform_funcs': (1, 3, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 116.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 65.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.64 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 964.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 550.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 706.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 754.00 MiB memory in use. Of the allocated memory 277.73 MiB is allocated by PyTorch, and 90.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
118d3040,"{'temperature': 0.7000000000000001, 'latent_dim': 341, 'transform_funcs': (1, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 73.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.64 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 918.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 470.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 550.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 766.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 754.00 MiB memory in use. Of the allocated memory 493.86 MiB is allocated by PyTorch, and 86.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
afdee1fe,"{'temperature': 1.2000000000000002, 'latent_dim': 251, 'transform_funcs': (2, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 85.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 518.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.64 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 968.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 474.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 710.00 MiB memory in use. Process 1198975 has 492.00 MiB memory in use. Process 1198942 has 754.00 MiB memory in use. Of the allocated memory 278.24 MiB is allocated by PyTorch, and 93.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0c6144c0,"{'temperature': 0.5, 'latent_dim': 102, 'transform_funcs': (0, 1, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.64 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 510.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.27 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 754.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 510.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 95.11 MiB is allocated by PyTorch, and 76.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
cad59475,"{'temperature': 0.5, 'latent_dim': 85, 'transform_funcs': (2, 7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.64 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 480.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 510.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.27 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 754.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 528.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 144.98 MiB is allocated by PyTorch, and 45.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2c220513,"{'temperature': 0.6000000000000001, 'latent_dim': 82, 'transform_funcs': (1, 3, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 520.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.27 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 756.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 470.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 95.86 MiB is allocated by PyTorch, and 86.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
83a775cf,"{'temperature': 0.6000000000000001, 'latent_dim': 225, 'transform_funcs': (0, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 113.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.27 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 512.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 700.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 472.00 MiB memory in use. Of the allocated memory 278.04 MiB is allocated by PyTorch, and 83.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
faf700f5,"{'temperature': 0.5, 'latent_dim': 327, 'transform_funcs': (0, 5, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 113.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 510.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.27 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 488.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 698.00 MiB memory in use. Process 1198975 has 472.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 278.84 MiB is allocated by PyTorch, and 81.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8ed12a90,"{'temperature': 0.5, 'latent_dim': 69, 'transform_funcs': (0, 3, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 514.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 510.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.27 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 488.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 754.00 MiB memory in use. Process 1198975 has 474.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 95.76 MiB is allocated by PyTorch, and 80.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
74dcf169,"{'temperature': 0.6000000000000001, 'latent_dim': 114, 'transform_funcs': (0, 1, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 73.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 448.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 510.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.27 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 546.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 700.00 MiB memory in use. Process 1198975 has 470.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 277.17 MiB is allocated by PyTorch, and 84.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a0c81f67,"{'temperature': 0.7000000000000001, 'latent_dim': 45, 'transform_funcs': (3, 4, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 418.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 510.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.27 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 546.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 756.00 MiB memory in use. Process 1198975 has 470.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 48.24 MiB is allocated by PyTorch, and 31.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d63f3600,"{'temperature': 0.5, 'latent_dim': 351, 'transform_funcs': (1, 9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 444.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 510.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.27 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 546.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 756.00 MiB memory in use. Process 1198975 has 470.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 87.46 MiB is allocated by PyTorch, and 18.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
80a47cca,"{'temperature': 0.5, 'latent_dim': 319, 'transform_funcs': (4, 6, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 442.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 500.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.27 GiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 960.00 MiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 546.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 704.00 MiB memory in use. Process 1198975 has 502.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 278.77 MiB is allocated by PyTorch, and 87.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e21be44e,"{'temperature': 0.6000000000000001, 'latent_dim': 240, 'transform_funcs': (1, 6, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.03 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 526.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 564.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 546.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 430.00 MiB memory in use. Process 1198975 has 766.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 48.85 MiB is allocated by PyTorch, and 43.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
81a510dd,"{'temperature': 0.5, 'latent_dim': 123, 'transform_funcs': (2, 3, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.03 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 466.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 526.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 564.00 MiB memory in use. Process 1198163 has 972.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 546.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 480.00 MiB memory in use. Process 1198975 has 736.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 83.85 MiB is allocated by PyTorch, and 44.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ea064265,"{'temperature': 0.5, 'latent_dim': 220, 'transform_funcs': (7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.16 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 512.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 594.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 534.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 96.94 MiB is allocated by PyTorch, and 77.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
5d988b83,"{'temperature': 0.7000000000000001, 'latent_dim': 280, 'transform_funcs': (0, 1, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 7.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.16 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 568.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 488.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 534.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 456.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 526.00 MiB memory in use. Process 1198975 has 594.00 MiB memory in use. Process 1198942 has 476.00 MiB memory in use. Of the allocated memory 146.50 MiB is allocated by PyTorch, and 41.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b079902d,"{'temperature': 0.8, 'latent_dim': 141, 'transform_funcs': (0, 4, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.16 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 562.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 498.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 534.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 986.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 644.00 MiB memory in use. Of the allocated memory 146.33 MiB is allocated by PyTorch, and 77.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c046a76f,"{'temperature': 0.6000000000000001, 'latent_dim': 158, 'transform_funcs': (1, 3, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.01 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 512.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 644.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 648.00 MiB memory in use. Of the allocated memory 218.86 MiB is allocated by PyTorch, and 87.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
c33644a0,"{'temperature': 0.7000000000000001, 'latent_dim': 356, 'transform_funcs': (3, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 13.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 492.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 564.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 1.07 GiB memory in use. Of the allocated memory 147.10 MiB is allocated by PyTorch, and 78.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
47a831cd,"{'temperature': 0.6000000000000001, 'latent_dim': 305, 'transform_funcs': (2, 4, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 508.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 492.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 568.00 MiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 1.07 GiB memory in use. Of the allocated memory 97.61 MiB is allocated by PyTorch, and 72.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
50bff9ae,"{'temperature': 1.5, 'latent_dim': 206, 'transform_funcs': (0, 6, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 470.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 502.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 570.00 MiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 562.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 1.07 GiB memory in use. Of the allocated memory 145.92 MiB is allocated by PyTorch, and 78.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3878f2a6,"{'temperature': 1.4000000000000001, 'latent_dim': 149, 'transform_funcs': (1, 3, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 428.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 502.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 570.00 MiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 596.00 MiB memory in use. Process 1198942 has 1.08 GiB memory in use. Of the allocated memory 49.05 MiB is allocated by PyTorch, and 40.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f58bc67c,"{'temperature': 0.7000000000000001, 'latent_dim': 195, 'transform_funcs': (2, 5, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 484.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 518.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 570.00 MiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 532.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.08 GiB memory in use. Of the allocated memory 145.84 MiB is allocated by PyTorch, and 48.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ddc9254c,"{'temperature': 1.5, 'latent_dim': 182, 'transform_funcs': (2, 4, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 458.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 466.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 618.00 MiB memory in use. Process 1198934 has 700.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.08 GiB memory in use. Of the allocated memory 84.31 MiB is allocated by PyTorch, and 35.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
67011943,"{'temperature': 0.8, 'latent_dim': 110, 'transform_funcs': (0, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 510.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 764.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 508.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 620.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 984.00 MiB memory in use. Process 1198975 has 512.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 96.08 MiB is allocated by PyTorch, and 75.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
b311dc47,"{'temperature': 1.4000000000000001, 'latent_dim': 287, 'transform_funcs': (1, 2, 3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 139.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 470.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 500.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 510.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 624.00 MiB memory in use. Process 1198934 has 760.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 876.00 MiB memory in use. Process 1198975 has 484.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 458.52 MiB is allocated by PyTorch, and 79.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fd23845e,"{'temperature': 0.9, 'latent_dim': 224, 'transform_funcs': (4, 5, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 470.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 494.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 680.00 MiB memory in use. Process 1198934 has 854.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 650.00 MiB memory in use. Process 1198975 has 524.00 MiB memory in use. Process 1198942 has 618.00 MiB memory in use. Of the allocated memory 219.38 MiB is allocated by PyTorch, and 92.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
10ee337a,"{'temperature': 0.7000000000000001, 'latent_dim': 236, 'transform_funcs': (1, 4, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 466.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 464.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 462.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 680.00 MiB memory in use. Process 1198934 has 854.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 704.00 MiB memory in use. Process 1198975 has 524.00 MiB memory in use. Process 1198942 has 618.00 MiB memory in use. Of the allocated memory 84.74 MiB is allocated by PyTorch, and 41.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d8cd0cd2,"{'temperature': 1.3, 'latent_dim': 63, 'transform_funcs': (6, 7, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 7.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 466.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 680.00 MiB memory in use. Process 1198934 has 854.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 710.00 MiB memory in use. Process 1198975 has 524.00 MiB memory in use. Process 1198942 has 618.00 MiB memory in use. Of the allocated memory 316.14 MiB is allocated by PyTorch, and 55.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b28b5780,"{'temperature': 0.5, 'latent_dim': 243, 'transform_funcs': (5, 6, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 53.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 466.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 652.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 490.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 680.00 MiB memory in use. Process 1198934 has 854.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 618.00 MiB memory in use. Of the allocated memory 220.44 MiB is allocated by PyTorch, and 93.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
e66aa734,"{'temperature': 0.7000000000000001, 'latent_dim': 320, 'transform_funcs': (0, 1, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 890.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 448.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 854.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 506.00 MiB memory in use. Process 1198975 has 512.00 MiB memory in use. Process 1198942 has 620.00 MiB memory in use. Of the allocated memory 96.81 MiB is allocated by PyTorch, and 71.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
2deac2d8,"{'temperature': 1.4000000000000001, 'latent_dim': 231, 'transform_funcs': (0, 1, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 17.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 946.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 476.00 MiB memory in use. Process 1198152 has 1.11 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 488.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 854.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 654.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 476.00 MiB memory in use. Of the allocated memory 219.43 MiB is allocated by PyTorch, and 96.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
fbfa853f,"{'temperature': 1.3, 'latent_dim': 265, 'transform_funcs': (1, 3, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 161.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 878.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 520.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 490.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 854.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 482.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 445.26 MiB is allocated by PyTorch, and 94.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
633a1934,"{'temperature': 1.5, 'latent_dim': 293, 'transform_funcs': (1, 4, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 442.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 930.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 520.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 490.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 854.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 586.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 205.26 MiB is allocated by PyTorch, and 42.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
55c270a0,"{'temperature': 0.5, 'latent_dim': 212, 'transform_funcs': (2, 5, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 936.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 566.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.20 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 854.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 560.00 MiB memory in use. Process 1198975 has 470.00 MiB memory in use. Process 1198942 has 474.00 MiB memory in use. Of the allocated memory 145.97 MiB is allocated by PyTorch, and 76.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a55226f5,"{'temperature': 0.9, 'latent_dim': 138, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 474.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 938.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 568.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.20 GiB memory in use. Process 1198551 has 492.00 MiB memory in use. Process 1198934 has 854.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 466.00 MiB memory in use. Process 1198975 has 544.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 83.06 MiB is allocated by PyTorch, and 44.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fe34760a,"{'temperature': 0.6000000000000001, 'latent_dim': 202, 'transform_funcs': (2, 3, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 81.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 878.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 568.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.20 GiB memory in use. Process 1198551 has 492.00 MiB memory in use. Process 1198934 has 854.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 544.00 MiB memory in use. Process 1198942 has 472.00 MiB memory in use. Of the allocated memory 404.99 MiB is allocated by PyTorch, and 135.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6a509429,"{'temperature': 0.7000000000000001, 'latent_dim': 283, 'transform_funcs': (0, 2, 3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 115.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.65 GiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 470.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 680.00 MiB memory in use. Process 1198152 has 1.16 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 492.00 MiB memory in use. Process 1198934 has 854.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 698.00 MiB memory in use. Process 1198975 has 544.00 MiB memory in use. Process 1198942 has 472.00 MiB memory in use. Of the allocated memory 278.49 MiB is allocated by PyTorch, and 81.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6454d287,"{'temperature': 0.9, 'latent_dim': 255, 'transform_funcs': (0, 4, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 756.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 732.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.10 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 1014.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 526.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 854.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 508.00 MiB memory in use. Process 1198975 has 470.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 96.31 MiB is allocated by PyTorch, and 73.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
ecb67ad3,"{'temperature': 0.6000000000000001, 'latent_dim': 273, 'transform_funcs': (4, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 13.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 756.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.10 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 1014.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 770.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 490.00 MiB memory in use. Process 1198934 has 854.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 508.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 96.45 MiB is allocated by PyTorch, and 73.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
eb1be8b4,"{'temperature': 0.5, 'latent_dim': 207, 'transform_funcs': (3, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 474.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.10 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 1.00 GiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 770.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 490.00 MiB memory in use. Process 1198934 has 956.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 646.00 MiB memory in use. Process 1198975 has 538.00 MiB memory in use. Process 1198942 has 442.00 MiB memory in use. Of the allocated memory 219.25 MiB is allocated by PyTorch, and 88.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
4e626cc9,"{'temperature': 0.9, 'latent_dim': 228, 'transform_funcs': (5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 448.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.10 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 1.19 GiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 768.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 500.00 MiB memory in use. Process 1198934 has 956.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 538.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 83.76 MiB is allocated by PyTorch, and 46.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
16fdea4e,"{'temperature': 0.5, 'latent_dim': 266, 'transform_funcs': (1, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 129.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 472.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 470.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.10 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 1.19 GiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 768.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 500.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 872.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 444.57 MiB is allocated by PyTorch, and 89.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fb98b115,"{'temperature': 1.3, 'latent_dim': 240, 'transform_funcs': (5, 6, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 107.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 516.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.35 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 1.27 GiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 994.00 MiB memory in use. Process 1198939 has 868.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 486.00 MiB memory in use. Of the allocated memory 428.12 MiB is allocated by PyTorch, and 101.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d726484a,"{'temperature': 0.5, 'latent_dim': 281, 'transform_funcs': (1, 2, 3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 65.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.35 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 1.27 GiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 518.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 518.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 996.00 MiB memory in use. Process 1198939 has 874.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 454.48 MiB is allocated by PyTorch, and 81.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9d5d9a62,"{'temperature': 1.0, 'latent_dim': 155, 'transform_funcs': (5, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 484.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.35 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 1.27 GiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 996.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 446.00 MiB memory in use. Process 1198942 has 1016.00 MiB memory in use. Of the allocated memory 83.19 MiB is allocated by PyTorch, and 42.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2d6f6166,"{'temperature': 1.0, 'latent_dim': 69, 'transform_funcs': (0, 1, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 492.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 1.35 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 1.27 GiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 448.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 996.00 MiB memory in use. Process 1198939 has 708.00 MiB memory in use. Process 1198975 has 750.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 319.93 MiB is allocated by PyTorch, and 50.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c5e43a4d,"{'temperature': 1.3, 'latent_dim': 326, 'transform_funcs': (4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.05 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 522.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 650.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.01 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 758.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 996.00 MiB memory in use. Process 1198939 has 1.01 GiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 221.09 MiB is allocated by PyTorch, and 90.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
af0d4c68,"{'temperature': 1.1, 'latent_dim': 125, 'transform_funcs': (1, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 760.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 428.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 470.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 490.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 1.16 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 996.00 MiB memory in use. Process 1198939 has 1.06 GiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 48.86 MiB is allocated by PyTorch, and 41.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c527965b,"{'temperature': 1.3, 'latent_dim': 112, 'transform_funcs': (0, 3, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 592.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 526.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 498.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 1.16 GiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 996.00 MiB memory in use. Process 1198939 has 1.06 GiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 484.00 MiB memory in use. Of the allocated memory 204.75 MiB is allocated by PyTorch, and 49.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f206c063,"{'temperature': 0.5, 'latent_dim': 183, 'transform_funcs': (1, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.08 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 516.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 770.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 470.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 996.00 MiB memory in use. Process 1198939 has 1.06 GiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 1.03 GiB memory in use. Of the allocated memory 96.65 MiB is allocated by PyTorch, and 81.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
a5a57844,"{'temperature': 1.4000000000000001, 'latent_dim': 88, 'transform_funcs': (2, 3, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 7.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.13 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 650.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1018.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 646.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 996.00 MiB memory in use. Process 1198939 has 1.06 GiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 476.00 MiB memory in use. Of the allocated memory 219.23 MiB is allocated by PyTorch, and 92.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
174b2c41,"{'temperature': 0.5, 'latent_dim': 235, 'transform_funcs': (2, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.13 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 650.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1018.00 MiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 528.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 996.00 MiB memory in use. Process 1198939 has 1.18 GiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 220.38 MiB is allocated by PyTorch, and 91.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
9a0be87e,"{'temperature': 1.2000000000000002, 'latent_dim': 122, 'transform_funcs': (0, 3, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.13 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 492.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 514.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 470.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.65 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 528.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 996.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 502.00 MiB memory in use. Process 1198942 has 706.00 MiB memory in use. Of the allocated memory 96.18 MiB is allocated by PyTorch, and 79.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
159e89ea,"{'temperature': 0.9, 'latent_dim': 152, 'transform_funcs': (0, 5, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.13 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 756.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 470.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.65 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 528.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 996.00 MiB memory in use. Process 1198939 has 430.00 MiB memory in use. Process 1198975 has 502.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 48.17 MiB is allocated by PyTorch, and 43.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dc63e199,"{'temperature': 1.1, 'latent_dim': 318, 'transform_funcs': (1, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.13 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 756.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 460.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 474.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.65 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 528.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 470.00 MiB memory in use. Process 1198975 has 502.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 85.38 MiB is allocated by PyTorch, and 36.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
55ef767e,"{'temperature': 0.7000000000000001, 'latent_dim': 247, 'transform_funcs': (7, 8, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.08 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 464.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 488.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 474.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.65 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 586.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 432.00 MiB memory in use. Process 1198975 has 760.00 MiB memory in use. Process 1198942 has 486.00 MiB memory in use. Of the allocated memory 48.91 MiB is allocated by PyTorch, and 45.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e1078020,"{'temperature': 1.3, 'latent_dim': 344, 'transform_funcs': (0, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.08 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 464.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 530.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 474.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.65 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 586.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 432.00 MiB memory in use. Process 1198975 has 760.00 MiB memory in use. Process 1198942 has 486.00 MiB memory in use. Of the allocated memory 147.91 MiB is allocated by PyTorch, and 44.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
899f1f5d,"{'temperature': 0.9, 'latent_dim': 302, 'transform_funcs': (0, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 5.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.13 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 512.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 530.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 756.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 470.00 MiB memory in use. Process 1198975 has 512.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 147.58 MiB is allocated by PyTorch, and 44.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3d08dff1,"{'temperature': 1.1, 'latent_dim': 205, 'transform_funcs': (0, 3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.13 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 512.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 470.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 756.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 462.00 MiB memory in use. Process 1198975 has 566.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 83.58 MiB is allocated by PyTorch, and 40.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ec5ad5b3,"{'temperature': 0.8, 'latent_dim': 254, 'transform_funcs': (2, 6, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.13 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 512.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 460.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 756.00 MiB memory in use. Process 1198934 has 424.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 518.00 MiB memory in use. Process 1198975 has 470.00 MiB memory in use. Process 1198942 has 512.00 MiB memory in use. Of the allocated memory 84.88 MiB is allocated by PyTorch, and 37.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c5f32946,"{'temperature': 1.1, 'latent_dim': 187, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 13.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.13 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 518.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 448.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 758.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 510.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 95.77 MiB is allocated by PyTorch, and 76.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
c27a8532,"{'temperature': 1.0, 'latent_dim': 144, 'transform_funcs': (0, 3, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.13 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.13 GiB memory in use. Process 1197764 has 564.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 448.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 758.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 146.35 MiB is allocated by PyTorch, and 79.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
805514b0,"{'temperature': 1.4000000000000001, 'latent_dim': 106, 'transform_funcs': (2, 5, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 17.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.13 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.18 GiB memory in use. Process 1197764 has 518.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 470.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 702.00 MiB memory in use. Process 1198934 has 454.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 500.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 96.05 MiB is allocated by PyTorch, and 83.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
d6f3df5d,"{'temperature': 0.7000000000000001, 'latent_dim': 178, 'transform_funcs': (1, 4, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.13 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.18 GiB memory in use. Process 1197764 has 570.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 500.00 MiB memory in use. Process 1198934 has 460.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 590.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 480.00 MiB memory in use. Of the allocated memory 204.36 MiB is allocated by PyTorch, and 47.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b7c7f95b,"{'temperature': 1.1, 'latent_dim': 198, 'transform_funcs': (5, 6, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 53.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.13 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.18 GiB memory in use. Process 1197764 has 684.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 528.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 448.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 482.00 MiB memory in use. Of the allocated memory 278.74 MiB is allocated by PyTorch, and 67.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d1bd5281,"{'temperature': 1.0, 'latent_dim': 83, 'transform_funcs': (0, 2, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.09 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.18 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 528.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 458.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 712.00 MiB memory in use. Of the allocated memory 82.63 MiB is allocated by PyTorch, and 37.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1b866e66,"{'temperature': 1.4000000000000001, 'latent_dim': 164, 'transform_funcs': (1, 2, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.09 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.18 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 522.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 768.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 462.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 83.26 MiB is allocated by PyTorch, and 40.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2e15f9ad,"{'temperature': 1.2000000000000002, 'latent_dim': 272, 'transform_funcs': (1, 6, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.09 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.18 GiB memory in use. Process 1197764 has 460.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 522.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 768.00 MiB memory in use. Process 1198934 has 444.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 484.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 85.02 MiB is allocated by PyTorch, and 36.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
007d42af,"{'temperature': 1.5, 'latent_dim': 307, 'transform_funcs': (0, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.00 GiB memory in use. Process 1197762 has 1.18 GiB memory in use. Process 1197764 has 466.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 522.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 768.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 590.00 MiB memory in use. Process 1198975 has 470.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 205.37 MiB is allocated by PyTorch, and 46.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
66a81b63,"{'temperature': 1.1, 'latent_dim': 240, 'transform_funcs': (0, 7, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 5.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.00 GiB memory in use. Process 1197762 has 1.18 GiB memory in use. Process 1197764 has 646.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 522.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 768.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 446.00 MiB memory in use. Process 1198975 has 470.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 220.41 MiB is allocated by PyTorch, and 87.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
57e8ac25,"{'temperature': 1.2000000000000002, 'latent_dim': 72, 'transform_funcs': (1, 5, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.00 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 522.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 768.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 426.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 644.00 MiB memory in use. Of the allocated memory 47.54 MiB is allocated by PyTorch, and 40.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4b50a667,"{'temperature': 0.7000000000000001, 'latent_dim': 149, 'transform_funcs': (5, 7, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.00 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 432.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 522.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 770.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 448.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 644.00 MiB memory in use. Of the allocated memory 49.05 MiB is allocated by PyTorch, and 44.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e0dd9040,"{'temperature': 0.5, 'latent_dim': 100, 'transform_funcs': (0, 3, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 13.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.00 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 770.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 646.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 218.41 MiB is allocated by PyTorch, and 89.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
657bef0a,"{'temperature': 1.2000000000000002, 'latent_dim': 233, 'transform_funcs': (6, 7, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.00 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 434.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 770.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 646.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 49.71 MiB is allocated by PyTorch, and 46.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4c338cf1,"{'temperature': 1.3, 'latent_dim': 295, 'transform_funcs': (1, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 474.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.14 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 484.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 770.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 530.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 430.00 MiB memory in use. Of the allocated memory 146.62 MiB is allocated by PyTorch, and 45.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3c68e0d1,"{'temperature': 0.9, 'latent_dim': 173, 'transform_funcs': (2, 4, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 486.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.14 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 650.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 516.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 540.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 448.00 MiB memory in use. Process 1198975 has 512.00 MiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 219.89 MiB is allocated by PyTorch, and 92.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
23324edf,"{'temperature': 0.7000000000000001, 'latent_dim': 91, 'transform_funcs': (1, 4, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 526.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 704.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 566.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 542.00 MiB memory in use. Process 1198934 has 850.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 584.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 203.68 MiB is allocated by PyTorch, and 42.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bfc56d3f,"{'temperature': 0.8, 'latent_dim': 124, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 592.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 714.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 566.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.11 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 542.00 MiB memory in use. Process 1198934 has 960.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 448.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 278.16 MiB is allocated by PyTorch, and 97.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f0e1e1f4,"{'temperature': 1.1, 'latent_dim': 56, 'transform_funcs': (6, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 764.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 566.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.21 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.11 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 542.00 MiB memory in use. Process 1198934 has 960.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 584.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 203.40 MiB is allocated by PyTorch, and 42.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
005a9323,"{'temperature': 1.0, 'latent_dim': 212, 'transform_funcs': (0, 1, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 134.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 67.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 484.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 710.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 526.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 528.00 MiB memory in use. Process 1198934 has 960.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 482.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 562.00 MiB memory in use. Of the allocated memory 278.85 MiB is allocated by PyTorch, and 93.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2121741e,"{'temperature': 0.5, 'latent_dim': 316, 'transform_funcs': (0, 2, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 846.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 526.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 528.00 MiB memory in use. Process 1198934 has 960.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 460.00 MiB memory in use. Process 1198975 has 498.00 MiB memory in use. Process 1198942 has 472.00 MiB memory in use. Of the allocated memory 84.45 MiB is allocated by PyTorch, and 37.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cdee7ea6,"{'temperature': 1.0, 'latent_dim': 138, 'transform_funcs': (2, 5, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 652.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 470.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 492.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 524.00 MiB memory in use. Process 1198934 has 960.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 466.00 MiB memory in use. Process 1198975 has 730.00 MiB memory in use. Process 1198942 has 474.00 MiB memory in use. Of the allocated memory 83.06 MiB is allocated by PyTorch, and 44.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
da12d4c3,"{'temperature': 1.5, 'latent_dim': 129, 'transform_funcs': (1, 6, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 652.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 462.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 524.00 MiB memory in use. Process 1198934 has 960.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 730.00 MiB memory in use. Process 1198942 has 476.00 MiB memory in use. Of the allocated memory 83.90 MiB is allocated by PyTorch, and 40.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4205b0db,"{'temperature': 1.1, 'latent_dim': 194, 'transform_funcs': (1, 3, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 652.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 470.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 524.00 MiB memory in use. Process 1198934 has 960.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 712.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 476.00 MiB memory in use. Of the allocated memory 277.80 MiB is allocated by PyTorch, and 96.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0737884e,"{'temperature': 1.4000000000000001, 'latent_dim': 254, 'transform_funcs': (0, 1, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 650.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 524.00 MiB memory in use. Process 1198934 has 960.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 448.00 MiB memory in use. Process 1198975 has 446.00 MiB memory in use. Process 1198942 has 758.00 MiB memory in use. Of the allocated memory 220.52 MiB is allocated by PyTorch, and 91.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
9bf03b2e,"{'temperature': 1.1, 'latent_dim': 218, 'transform_funcs': (2, 7, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 464.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 524.00 MiB memory in use. Process 1198934 has 960.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 448.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 892.00 MiB memory in use. Of the allocated memory 84.60 MiB is allocated by PyTorch, and 41.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0f661f92,"{'temperature': 0.8, 'latent_dim': 78, 'transform_funcs': (1, 6, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 464.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 524.00 MiB memory in use. Process 1198934 has 960.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 892.00 MiB memory in use. Of the allocated memory 82.59 MiB is allocated by PyTorch, and 43.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2543e1ff,"{'temperature': 1.2000000000000002, 'latent_dim': 247, 'transform_funcs': (0, 4, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 882.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 524.00 MiB memory in use. Process 1198934 has 960.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 428.00 MiB memory in use. Process 1198975 has 516.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 48.91 MiB is allocated by PyTorch, and 41.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2042e4f7,"{'temperature': 1.1, 'latent_dim': 345, 'transform_funcs': (4, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 518.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 514.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 598.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.05 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 732.00 MiB memory in use. Process 1198934 has 960.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 470.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 206.57 MiB is allocated by PyTorch, and 53.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2b868cc2,"{'temperature': 0.6000000000000001, 'latent_dim': 298, 'transform_funcs': (0, 2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 518.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 650.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 732.00 MiB memory in use. Process 1198934 has 960.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 466.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 84.31 MiB is allocated by PyTorch, and 43.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cdc7b451,"{'temperature': 0.8, 'latent_dim': 326, 'transform_funcs': (3, 4, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 520.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 654.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 514.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 732.00 MiB memory in use. Process 1198934 has 960.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 448.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 97.77 MiB is allocated by PyTorch, and 78.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
61ff3178,"{'temperature': 1.3, 'latent_dim': 37, 'transform_funcs': (1, 2, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 564.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 770.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 960.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 424.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 594.00 MiB memory in use. Of the allocated memory 47.27 MiB is allocated by PyTorch, and 38.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0d7f5f62,"{'temperature': 1.2000000000000002, 'latent_dim': 106, 'transform_funcs': (0, 4, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 770.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 466.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 960.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 458.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 646.00 MiB memory in use. Of the allocated memory 82.81 MiB is allocated by PyTorch, and 37.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f08cdcc5,"{'temperature': 0.9, 'latent_dim': 285, 'transform_funcs': (1, 3, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 770.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 512.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 466.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 960.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 458.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 646.00 MiB memory in use. Of the allocated memory 97.45 MiB is allocated by PyTorch, and 76.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
aae92335,"{'temperature': 0.7000000000000001, 'latent_dim': 203, 'transform_funcs': (2, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 810.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 488.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 586.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 434.00 MiB memory in use. Process 1198975 has 506.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 48.57 MiB is allocated by PyTorch, and 47.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5e87fc61,"{'temperature': 0.5, 'latent_dim': 180, 'transform_funcs': (1, 2, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 486.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 488.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 708.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 586.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 566.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 278.60 MiB is allocated by PyTorch, and 91.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
04b9b985,"{'temperature': 1.2000000000000002, 'latent_dim': 232, 'transform_funcs': (0, 3, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 486.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 756.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 560.00 MiB memory in use. Process 1198975 has 566.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 146.13 MiB is allocated by PyTorch, and 75.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6add6162,"{'temperature': 0.9, 'latent_dim': 168, 'transform_funcs': (0, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 486.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 470.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 564.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 756.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 566.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 146.54 MiB is allocated by PyTorch, and 79.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ee8ae747,"{'temperature': 1.5, 'latent_dim': 320, 'transform_funcs': (0, 5, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 17.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 646.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 470.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 470.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 488.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 510.00 MiB memory in use. Process 1198975 has 736.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 96.81 MiB is allocated by PyTorch, and 75.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
4bc0ceba,"{'temperature': 1.2000000000000002, 'latent_dim': 240, 'transform_funcs': (0, 8, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 470.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 464.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 656.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 736.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 84.77 MiB is allocated by PyTorch, and 41.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fd932fe4,"{'temperature': 1.0, 'latent_dim': 185, 'transform_funcs': (0, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 910.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 466.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 83.43 MiB is allocated by PyTorch, and 44.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8c9b5033,"{'temperature': 1.0, 'latent_dim': 142, 'transform_funcs': (4, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 832.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 516.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.20 GiB memory in use. Process 1198551 has 522.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 520.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 96.33 MiB is allocated by PyTorch, and 81.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
a2e5cb28,"{'temperature': 1.2000000000000002, 'latent_dim': 3, 'transform_funcs': (0, 1, 2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 890.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 460.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.20 GiB memory in use. Process 1198551 has 510.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 520.00 MiB memory in use. Process 1198975 has 482.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 82.92 MiB is allocated by PyTorch, and 39.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2aee0828,"{'temperature': 1.4000000000000001, 'latent_dim': 279, 'transform_funcs': (1, 2, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 890.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 466.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.20 GiB memory in use. Process 1198551 has 510.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 512.00 MiB memory in use. Process 1198975 has 482.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 96.49 MiB is allocated by PyTorch, and 77.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
140fb421,"{'temperature': 1.5, 'latent_dim': 111, 'transform_funcs': (5, 6, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 884.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 492.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 510.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 462.00 MiB memory in use. Process 1198975 has 482.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 82.85 MiB is allocated by PyTorch, and 41.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f8bd24f7,"{'temperature': 0.7000000000000001, 'latent_dim': 99, 'transform_funcs': (1, 2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 884.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 518.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 430.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 488.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 482.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 48.66 MiB is allocated by PyTorch, and 43.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d88e59fa,"{'temperature': 0.9, 'latent_dim': 154, 'transform_funcs': (2, 6, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 884.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 520.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 434.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 488.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 482.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 49.09 MiB is allocated by PyTorch, and 46.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
56468059,"{'temperature': 1.0, 'latent_dim': 336, 'transform_funcs': (2, 3, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 884.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 520.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 488.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 478.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 84.61 MiB is allocated by PyTorch, and 41.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
02e7c1d4,"{'temperature': 1.3, 'latent_dim': 78, 'transform_funcs': (0, 3, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 886.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 520.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 470.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 488.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 492.00 MiB memory in use. Process 1198942 has 460.00 MiB memory in use. Of the allocated memory 83.50 MiB is allocated by PyTorch, and 48.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4578a6e1,"{'temperature': 0.6000000000000001, 'latent_dim': 292, 'transform_funcs': (0, 2, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 758.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 588.00 MiB memory in use. Process 1198975 has 494.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 205.25 MiB is allocated by PyTorch, and 44.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d35c546d,"{'temperature': 1.1, 'latent_dim': 89, 'transform_funcs': (1, 3, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 590.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 758.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 494.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 204.57 MiB is allocated by PyTorch, and 47.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6da60231,"{'temperature': 0.9, 'latent_dim': 221, 'transform_funcs': (1, 4, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 644.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 484.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 758.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 460.00 MiB memory in use. Process 1198975 has 470.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 83.71 MiB is allocated by PyTorch, and 38.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
98815e16,"{'temperature': 1.0, 'latent_dim': 145, 'transform_funcs': (0, 2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 492.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 644.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 594.00 MiB memory in use. Process 1198975 has 620.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 204.10 MiB is allocated by PyTorch, and 51.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2b400876,"{'temperature': 1.5, 'latent_dim': 199, 'transform_funcs': (0, 1, 2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 492.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 714.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 620.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 278.75 MiB is allocated by PyTorch, and 97.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
feb8dfff,"{'temperature': 1.1, 'latent_dim': 331, 'transform_funcs': (1, 2, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 492.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 706.00 MiB memory in use. Process 1198975 has 678.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 278.87 MiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
95d1f8c4,"{'temperature': 1.0, 'latent_dim': 176, 'transform_funcs': (1, 7, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 734.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 514.00 MiB memory in use. Process 1198975 has 686.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 95.69 MiB is allocated by PyTorch, and 80.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
e850b7df,"{'temperature': 0.7000000000000001, 'latent_dim': 119, 'transform_funcs': (9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 514.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 734.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 686.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 96.15 MiB is allocated by PyTorch, and 79.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
62b5a610,"{'temperature': 1.1, 'latent_dim': 157, 'transform_funcs': (1, 3, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 5.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 476.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 708.00 MiB memory in use. Process 1198975 has 740.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 277.51 MiB is allocated by PyTorch, and 92.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
123a2ac0,"{'temperature': 1.2000000000000002, 'latent_dim': 164, 'transform_funcs': (2, 4, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 508.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 654.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 490.00 MiB memory in use. Process 1198975 has 740.00 MiB memory in use. Process 1198942 has 474.00 MiB memory in use. Of the allocated memory 96.50 MiB is allocated by PyTorch, and 73.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
178ef1c4,"{'temperature': 1.1, 'latent_dim': 345, 'transform_funcs': (0, 3, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 570.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 594.00 MiB memory in use. Process 1198975 has 740.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 205.66 MiB is allocated by PyTorch, and 50.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
91fe1525,"{'temperature': 1.4000000000000001, 'latent_dim': 232, 'transform_funcs': (1, 3, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 682.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.16 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 748.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 279.00 MiB is allocated by PyTorch, and 65.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
43ef299f,"{'temperature': 1.5, 'latent_dim': 313, 'transform_funcs': (0, 6, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 7.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 644.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 458.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 512.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 510.00 MiB memory in use. Process 1198975 has 750.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 96.76 MiB is allocated by PyTorch, and 75.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
7c4f2acb,"{'temperature': 1.2000000000000002, 'latent_dim': 135, 'transform_funcs': (4, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 646.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 464.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 512.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 750.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 83.95 MiB is allocated by PyTorch, and 42.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b9e30cd2,"{'temperature': 1.0, 'latent_dim': 307, 'transform_funcs': (2, 3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 470.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 510.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 838.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 520.00 MiB memory in use. Of the allocated memory 97.62 MiB is allocated by PyTorch, and 74.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
38465dae,"{'temperature': 0.5, 'latent_dim': 274, 'transform_funcs': (1, 2, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 5.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 494.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 512.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 472.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 892.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 504.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 96.46 MiB is allocated by PyTorch, and 69.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
1e78d994,"{'temperature': 1.0, 'latent_dim': 215, 'transform_funcs': (3, 4, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 512.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 462.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 892.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 504.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 84.57 MiB is allocated by PyTorch, and 39.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
50833df5,"{'temperature': 0.9, 'latent_dim': 207, 'transform_funcs': (2, 4, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 512.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 442.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 892.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 564.00 MiB memory in use. Process 1198975 has 466.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 74.62 MiB is allocated by PyTorch, and 29.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
e7952d57,"{'temperature': 1.0, 'latent_dim': 219, 'transform_funcs': (3, 6, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 512.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 446.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 892.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 564.00 MiB memory in use. Process 1198975 has 462.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 78.21 MiB is allocated by PyTorch, and 29.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
e402120d,"{'temperature': 1.0, 'latent_dim': 222, 'transform_funcs': (1, 4, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 512.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 442.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 892.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 564.00 MiB memory in use. Process 1198975 has 466.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 74.36 MiB is allocated by PyTorch, and 29.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
ac464d75,"{'temperature': 0.9, 'latent_dim': 203, 'transform_funcs': (1, 2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 512.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 446.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 892.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 564.00 MiB memory in use. Process 1198975 has 462.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 78.11 MiB is allocated by PyTorch, and 29.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
cf1911f8,"{'temperature': 1.0, 'latent_dim': 228, 'transform_funcs': (5, 6, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 512.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 438.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 892.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 566.00 MiB memory in use. Process 1198975 has 450.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 73.12 MiB is allocated by PyTorch, and 26.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d06edffe,"{'temperature': 0.9, 'latent_dim': 209, 'transform_funcs': (0, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 512.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 438.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 892.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 566.00 MiB memory in use. Process 1198975 has 466.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 71.12 MiB is allocated by PyTorch, and 28.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
9fcf7dd9,"{'temperature': 1.0, 'latent_dim': 236, 'transform_funcs': (2, 8, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 704.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 646.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 558.00 MiB memory in use. Process 1198975 has 470.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 146.16 MiB is allocated by PyTorch, and 73.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
15a6c515,"{'temperature': 0.9, 'latent_dim': 200, 'transform_funcs': (2, 7, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 524.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 590.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 656.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 614.00 MiB memory in use. Process 1198975 has 470.00 MiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 205.44 MiB is allocated by PyTorch, and 46.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5801067a,"{'temperature': 1.1, 'latent_dim': 194, 'transform_funcs': (1, 3, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 103.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 524.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 470.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 656.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 680.00 MiB memory in use. Process 1198975 has 470.00 MiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 277.80 MiB is allocated by PyTorch, and 64.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
87ec372b,"{'temperature': 1.0, 'latent_dim': 227, 'transform_funcs': (0, 4, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 524.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 434.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 656.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 736.00 MiB memory in use. Process 1198975 has 492.00 MiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 49.66 MiB is allocated by PyTorch, and 46.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9c1fac8c,"{'temperature': 0.9, 'latent_dim': 236, 'transform_funcs': (0, 1, 2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 97.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 460.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 512.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 826.00 MiB memory in use. Process 1198975 has 492.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 426.12 MiB is allocated by PyTorch, and 61.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a7529d3c,"{'temperature': 1.0, 'latent_dim': 198, 'transform_funcs': (3, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 512.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 882.00 MiB memory in use. Process 1198975 has 492.00 MiB memory in use. Process 1198942 has 446.00 MiB memory in use. Of the allocated memory 96.77 MiB is allocated by PyTorch, and 77.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
ba7e1874,"{'temperature': 0.9, 'latent_dim': 218, 'transform_funcs': (0, 5, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 139.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 470.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 830.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 414.20 MiB is allocated by PyTorch, and 77.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
18aa5e10,"{'temperature': 1.1, 'latent_dim': 244, 'transform_funcs': (0, 3, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 518.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 884.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 448.00 MiB memory in use. Of the allocated memory 97.13 MiB is allocated by PyTorch, and 82.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
13f1dedc,"{'temperature': 1.1, 'latent_dim': 175, 'transform_funcs': (2, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 446.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 462.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 480.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 884.00 MiB memory in use. Process 1198975 has 536.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 84.26 MiB is allocated by PyTorch, and 39.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a5e77543,"{'temperature': 1.0, 'latent_dim': 252, 'transform_funcs': (1, 2, 3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 75.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 448.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 480.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 1.62 GiB memory in use. Process 1198163 has 974.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 842.00 MiB memory in use. Process 1198975 has 536.00 MiB memory in use. Process 1198942 has 500.00 MiB memory in use. Of the allocated memory 436.25 MiB is allocated by PyTorch, and 67.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cbeb58c3,"{'temperature': 0.8, 'latent_dim': 182, 'transform_funcs': (4, 5, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 512.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 966.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 966.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 976.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 588.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 204.39 MiB is allocated by PyTorch, and 45.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
69d050bd,"{'temperature': 1.0, 'latent_dim': 218, 'transform_funcs': (3, 4, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 470.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1012.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 762.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 852.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 518.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 838.00 MiB memory in use. Process 1198975 has 470.00 MiB memory in use. Process 1198942 has 474.00 MiB memory in use. Of the allocated memory 414.20 MiB is allocated by PyTorch, and 85.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c2443479,"{'temperature': 1.1, 'latent_dim': 340, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 145.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 468.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 912.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 766.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 852.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.25 GiB memory in use. Process 1198551 has 918.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 436.00 MiB memory in use. Of the allocated memory 492.30 MiB is allocated by PyTorch, and 81.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c9b9f05c,"{'temperature': 0.9, 'latent_dim': 166, 'transform_funcs': (3, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 884.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 500.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 968.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 756.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 918.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 430.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 484.00 MiB memory in use. Of the allocated memory 48.28 MiB is allocated by PyTorch, and 43.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5935d384,"{'temperature': 0.5, 'latent_dim': 114, 'transform_funcs': (1, 5, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 886.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 570.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 968.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 756.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 706.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 448.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 590.00 MiB memory in use. Process 1198975 has 512.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 203.85 MiB is allocated by PyTorch, and 48.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
887923cb,"{'temperature': 1.2000000000000002, 'latent_dim': 148, 'transform_funcs': (0, 2, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 886.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 740.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.07 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 754.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 448.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 518.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 95.47 MiB is allocated by PyTorch, and 84.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
1ebfaa85,"{'temperature': 1.1, 'latent_dim': 355, 'transform_funcs': (0, 4, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 201.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 910.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 742.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 918.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 756.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 488.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 476.00 MiB memory in use. Of the allocated memory 501.97 MiB is allocated by PyTorch, and 78.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b566e448,"{'temperature': 1.0, 'latent_dim': 318, 'transform_funcs': (0, 1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 910.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 742.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 756.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 896.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 646.00 MiB memory in use. Of the allocated memory 477.47 MiB is allocated by PyTorch, and 80.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
81c0a5fa,"{'temperature': 0.6000000000000001, 'latent_dim': 247, 'transform_funcs': (0, 1, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 61.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 910.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.00 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 592.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 758.00 MiB memory in use. Process 1198942 has 646.00 MiB memory in use. Of the allocated memory 205.81 MiB is allocated by PyTorch, and 48.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ceb76920,"{'temperature': 1.0, 'latent_dim': 122, 'transform_funcs': (1, 3, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 910.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.00 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 644.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 478.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 466.00 MiB memory in use. Process 1198975 has 760.00 MiB memory in use. Process 1198942 has 646.00 MiB memory in use. Of the allocated memory 82.93 MiB is allocated by PyTorch, and 45.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b46e05fd,"{'temperature': 1.3, 'latent_dim': 332, 'transform_funcs': (3, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 910.00 MiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.00 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 644.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 478.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 508.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 444.00 MiB memory in use. Process 1198975 has 760.00 MiB memory in use. Process 1198942 has 646.00 MiB memory in use. Of the allocated memory 74.80 MiB is allocated by PyTorch, and 31.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
353d62c8,"{'temperature': 1.5, 'latent_dim': 160, 'transform_funcs': (0, 3, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.01 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 650.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 480.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 470.00 MiB memory in use. Process 1198975 has 760.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 219.79 MiB is allocated by PyTorch, and 92.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
7f23d084,"{'temperature': 0.8, 'latent_dim': 253, 'transform_funcs': (0, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 17.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.01 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 480.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 710.00 MiB memory in use. Process 1198975 has 760.00 MiB memory in use. Process 1198942 has 408.00 MiB memory in use. Of the allocated memory 278.26 MiB is allocated by PyTorch, and 93.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dbc45e09,"{'temperature': 1.2000000000000002, 'latent_dim': 291, 'transform_funcs': (0, 1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.01 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 652.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 480.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 760.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 220.81 MiB is allocated by PyTorch, and 93.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
79eca258,"{'temperature': 1.0, 'latent_dim': 213, 'transform_funcs': (0, 2, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.14 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 514.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 762.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 96.89 MiB is allocated by PyTorch, and 79.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
7c9488e0,"{'temperature': 0.7000000000000001, 'latent_dim': 172, 'transform_funcs': (3, 4, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.15 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 512.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 474.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 490.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 762.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 96.57 MiB is allocated by PyTorch, and 77.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
6266daf9,"{'temperature': 0.5, 'latent_dim': 140, 'transform_funcs': (1, 3, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.15 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 474.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 494.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 514.00 MiB memory in use. Process 1198975 has 762.00 MiB memory in use. Process 1198942 has 468.00 MiB memory in use. Of the allocated memory 95.41 MiB is allocated by PyTorch, and 80.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
4d3299b8,"{'temperature': 0.8, 'latent_dim': 149, 'transform_funcs': (5, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.16 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 432.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 516.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 488.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 570.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 648.00 MiB memory in use. Of the allocated memory 49.05 MiB is allocated by PyTorch, and 44.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ac796767,"{'temperature': 1.2000000000000002, 'latent_dim': 99, 'transform_funcs': (0, 2, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.16 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 438.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 516.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 488.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 570.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 458.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 686.00 MiB memory in use. Of the allocated memory 82.75 MiB is allocated by PyTorch, and 37.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
16ecc668,"{'temperature': 1.0, 'latent_dim': 118, 'transform_funcs': (6, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.16 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 646.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 516.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 488.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 520.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 522.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 219.46 MiB is allocated by PyTorch, and 88.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
17b76b1d,"{'temperature': 1.1, 'latent_dim': 202, 'transform_funcs': (0, 2, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.16 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 516.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 488.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 522.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 684.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 277.86 MiB is allocated by PyTorch, and 68.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8ab79422,"{'temperature': 1.5, 'latent_dim': 231, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 57.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.16 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 650.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 518.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 522.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 220.34 MiB is allocated by PyTorch, and 91.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
f3cf624d,"{'temperature': 1.0, 'latent_dim': 111, 'transform_funcs': (3, 5, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.16 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 704.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 512.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 522.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 462.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 82.85 MiB is allocated by PyTorch, and 41.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a30d6673,"{'temperature': 0.9, 'latent_dim': 131, 'transform_funcs': (0, 3, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 65.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.15 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 708.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 470.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 278.21 MiB is allocated by PyTorch, and 91.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7dbe586a,"{'temperature': 1.3, 'latent_dim': 210, 'transform_funcs': (1, 6, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.15 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 764.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 432.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 470.00 MiB memory in use. Of the allocated memory 48.62 MiB is allocated by PyTorch, and 45.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
870787de,"{'temperature': 1.4000000000000001, 'latent_dim': 179, 'transform_funcs': (2, 3, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.15 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 764.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 470.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 430.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 484.00 MiB memory in use. Of the allocated memory 48.38 MiB is allocated by PyTorch, and 43.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
090550bc,"{'temperature': 1.2000000000000002, 'latent_dim': 221, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.06 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1004.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 470.00 MiB memory in use. Process 1198942 has 890.00 MiB memory in use. Of the allocated memory 83.71 MiB is allocated by PyTorch, and 46.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a6cea1fd,"{'temperature': 1.3, 'latent_dim': 337, 'transform_funcs': (8, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.07 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 500.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1006.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 472.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 510.00 MiB memory in use. Process 1198975 has 470.00 MiB memory in use. Process 1198942 has 890.00 MiB memory in use. Of the allocated memory 96.95 MiB is allocated by PyTorch, and 75.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
a3ca603f,"{'temperature': 0.8, 'latent_dim': 360, 'transform_funcs': (0, 1, 3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 81.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.07 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 936.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 472.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 528.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 894.00 MiB memory in use. Of the allocated memory 504.95 MiB is allocated by PyTorch, and 93.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
aa855410,"{'temperature': 1.1, 'latent_dim': 275, 'transform_funcs': (0, 2, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 510.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 512.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 586.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 448.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 97.37 MiB is allocated by PyTorch, and 74.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
d309b969,"{'temperature': 1.5, 'latent_dim': 160, 'transform_funcs': (1, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 510.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 512.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 586.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 460.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 83.23 MiB is allocated by PyTorch, and 42.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
662abe32,"{'temperature': 1.2000000000000002, 'latent_dim': 135, 'transform_funcs': (3, 5, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 448.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 518.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 594.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 512.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 83.04 MiB is allocated by PyTorch, and 42.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e706947b,"{'temperature': 0.5, 'latent_dim': 185, 'transform_funcs': (0, 4, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 448.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 598.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 496.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 518.00 MiB memory in use. Process 1198975 has 492.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 84.34 MiB is allocated by PyTorch, and 45.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5e719f52,"{'temperature': 1.1, 'latent_dim': 118, 'transform_funcs': (2, 5, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 488.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 512.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 534.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 518.00 MiB memory in use. Process 1198975 has 492.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 96.14 MiB is allocated by PyTorch, and 77.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
9dc6d631,"{'temperature': 0.6000000000000001, 'latent_dim': 76, 'transform_funcs': (1, 2, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 512.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 534.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 512.00 MiB memory in use. Process 1198975 has 492.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 94.91 MiB is allocated by PyTorch, and 79.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
8be38f58,"{'temperature': 1.4000000000000001, 'latent_dim': 313, 'transform_funcs': (7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 512.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 458.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 596.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 492.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 85.34 MiB is allocated by PyTorch, and 34.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a67876c0,"{'temperature': 1.0, 'latent_dim': 101, 'transform_funcs': (1, 2, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 17.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 596.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 512.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 512.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 95.10 MiB is allocated by PyTorch, and 78.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
54bd9582,"{'temperature': 0.5, 'latent_dim': 154, 'transform_funcs': (1, 2, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 528.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 570.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 146.43 MiB is allocated by PyTorch, and 43.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5985fbb0,"{'temperature': 0.8, 'latent_dim': 257, 'transform_funcs': (0, 3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 622.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 204.98 MiB is allocated by PyTorch, and 79.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bed8af74,"{'temperature': 1.3, 'latent_dim': 328, 'transform_funcs': (4, 6, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 492.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 530.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 590.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 205.53 MiB is allocated by PyTorch, and 46.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b13263ab,"{'temperature': 0.9, 'latent_dim': 143, 'transform_funcs': (1, 2, 3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 634.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 466.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 530.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 968.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 84.01 MiB is allocated by PyTorch, and 43.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
34520e2c,"{'temperature': 1.2000000000000002, 'latent_dim': 128, 'transform_funcs': (6, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 650.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 560.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 530.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 854.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 462.00 MiB memory in use. Process 1198975 has 448.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 82.98 MiB is allocated by PyTorch, and 41.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6219aeb7,"{'temperature': 0.6000000000000001, 'latent_dim': 287, 'transform_funcs': (0, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 526.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 586.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 530.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 448.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 470.00 MiB memory in use. Process 1198975 has 544.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 147.47 MiB is allocated by PyTorch, and 40.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b30ff68b,"{'temperature': 1.1, 'latent_dim': 236, 'transform_funcs': (0, 1, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 13.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 488.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 596.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 448.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 514.00 MiB memory in use. Process 1198975 has 544.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 96.16 MiB is allocated by PyTorch, and 79.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
81afb413,"{'temperature': 0.9, 'latent_dim': 343, 'transform_funcs': (5, 7, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 508.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 596.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 448.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 544.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 97.90 MiB is allocated by PyTorch, and 72.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
eb3d9eb3,"{'temperature': 0.5, 'latent_dim': 123, 'transform_funcs': (2, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 446.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 704.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 520.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 484.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 434.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 47.94 MiB is allocated by PyTorch, and 48.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3a61218a,"{'temperature': 1.5, 'latent_dim': 211, 'transform_funcs': (0, 1, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 466.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 704.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 520.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 446.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 77.25 MiB is allocated by PyTorch, and 30.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
55a6ae34,"{'temperature': 0.6000000000000001, 'latent_dim': 201, 'transform_funcs': (0, 1, 3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 466.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 704.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 520.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 446.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 77.19 MiB is allocated by PyTorch, and 30.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
110986ab,"{'temperature': 1.1, 'latent_dim': 187, 'transform_funcs': (3, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 466.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 704.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 520.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 446.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 77.11 MiB is allocated by PyTorch, and 30.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
b74fd133,"{'temperature': 0.9, 'latent_dim': 54, 'transform_funcs': (0, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 466.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 704.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 520.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 446.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 76.33 MiB is allocated by PyTorch, and 31.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
1d72b961,"{'temperature': 1.0, 'latent_dim': 147, 'transform_funcs': (2, 3, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 53.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 466.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 650.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 470.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 520.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 448.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 219.69 MiB is allocated by PyTorch, and 92.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
0c4ea165,"{'temperature': 1.4000000000000001, 'latent_dim': 322, 'transform_funcs': (4, 5, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 648.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 520.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 448.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 221.06 MiB is allocated by PyTorch, and 88.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
8831a5b1,"{'temperature': 0.7000000000000001, 'latent_dim': 84, 'transform_funcs': (2, 4, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 570.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 466.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 570.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 488.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 460.00 MiB memory in use. Process 1198975 has 524.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 82.64 MiB is allocated by PyTorch, and 39.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d32cce13,"{'temperature': 1.0, 'latent_dim': 102, 'transform_funcs': (3, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 570.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 430.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 570.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 488.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 524.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 48.69 MiB is allocated by PyTorch, and 43.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9ceb92ef,"{'temperature': 0.9, 'latent_dim': 183, 'transform_funcs': (0, 7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 570.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 516.00 MiB memory in use. Process 1198975 has 526.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 95.74 MiB is allocated by PyTorch, and 82.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
0df46f79,"{'temperature': 1.0, 'latent_dim': 154, 'transform_funcs': (0, 1, 2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 570.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 514.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 526.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 96.43 MiB is allocated by PyTorch, and 79.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
3447e170,"{'temperature': 1.2000000000000002, 'latent_dim': 194, 'transform_funcs': (1, 2, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 570.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 516.00 MiB memory in use. Process 1198975 has 526.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 95.83 MiB is allocated by PyTorch, and 82.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
27b9e57a,"{'temperature': 1.1, 'latent_dim': 232, 'transform_funcs': (1, 5, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 592.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 464.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 566.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 528.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 84.71 MiB is allocated by PyTorch, and 41.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f29da40a,"{'temperature': 1.0, 'latent_dim': 206, 'transform_funcs': (6, 7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 17.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 546.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 512.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 568.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 476.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 528.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 96.83 MiB is allocated by PyTorch, and 77.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
a63468b1,"{'temperature': 0.5, 'latent_dim': 108, 'transform_funcs': (1, 4, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 546.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 470.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 568.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 476.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 512.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 82.83 MiB is allocated by PyTorch, and 43.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c131da32,"{'temperature': 1.2000000000000002, 'latent_dim': 241, 'transform_funcs': (2, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 532.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 466.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 568.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 490.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 518.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 84.78 MiB is allocated by PyTorch, and 43.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6cf9c577,"{'temperature': 1.1, 'latent_dim': 216, 'transform_funcs': (0, 1, 2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 532.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 568.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 490.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 522.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 79.15 MiB is allocated by PyTorch, and 50.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
010d2668,"{'temperature': 1.1, 'latent_dim': 332, 'transform_funcs': (3, 6, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 532.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 486.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 568.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 466.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 522.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 84.58 MiB is allocated by PyTorch, and 41.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
39c169db,"{'temperature': 1.5, 'latent_dim': 309, 'transform_funcs': (0, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 532.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 510.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 568.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 462.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 522.00 MiB memory in use. Process 1198934 has 912.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 97.64 MiB is allocated by PyTorch, and 74.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
ae257047,"{'temperature': 0.5, 'latent_dim': 360, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 534.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 596.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 532.00 MiB memory in use. Process 1198934 has 924.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 448.00 MiB memory in use. Process 1198975 has 470.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 206.69 MiB is allocated by PyTorch, and 51.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
401449dd,"{'temperature': 0.7000000000000001, 'latent_dim': 73, 'transform_funcs': (1, 3, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 534.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 590.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 532.00 MiB memory in use. Process 1198934 has 924.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 462.00 MiB memory in use. Process 1198975 has 472.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 82.55 MiB is allocated by PyTorch, and 41.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fe2a8e58,"{'temperature': 1.4000000000000001, 'latent_dim': 252, 'transform_funcs': (5, 8, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 105.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 590.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 482.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 724.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 680.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 278.25 MiB is allocated by PyTorch, and 63.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d5899dfe,"{'temperature': 1.1, 'latent_dim': 89, 'transform_funcs': (4, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 592.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 482.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 518.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 724.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 740.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 332.98 MiB is allocated by PyTorch, and 69.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
66fecfcf,"{'temperature': 1.0, 'latent_dim': 131, 'transform_funcs': (1, 5, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 17.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 596.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 710.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 482.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 518.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 724.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 278.21 MiB is allocated by PyTorch, and 93.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a81fd69b,"{'temperature': 1.3, 'latent_dim': 283, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 650.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 448.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 748.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 622.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 488.00 MiB memory in use. Process 1198934 has 460.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 460.00 MiB memory in use. Process 1198975 has 570.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 84.20 MiB is allocated by PyTorch, and 37.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f8dbe3d4,"{'temperature': 0.9, 'latent_dim': 63, 'transform_funcs': (1, 2, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 424.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 750.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 732.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 514.00 MiB memory in use. Process 1198975 has 466.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 48.38 MiB is allocated by PyTorch, and 37.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c7820afc,"{'temperature': 1.0, 'latent_dim': 208, 'transform_funcs': (0, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 418.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 750.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 732.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 472.00 MiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 514.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 75.78 MiB is allocated by PyTorch, and 4.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
f5b723f2,"{'temperature': 1.4000000000000001, 'latent_dim': 105, 'transform_funcs': (1, 3, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 424.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 750.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 732.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 474.00 MiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 514.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 58.56 MiB is allocated by PyTorch, and 27.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
f1a94650,"{'temperature': 0.7000000000000001, 'latent_dim': 244, 'transform_funcs': (4, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 416.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 750.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 732.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 474.00 MiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 514.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 72.78 MiB is allocated by PyTorch, and 5.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
740d826e,"{'temperature': 0.9, 'latent_dim': 187, 'transform_funcs': (4, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 418.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 750.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 732.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 480.00 MiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 514.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 76.77 MiB is allocated by PyTorch, and 3.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 46, in calculate_loss
    logits = torch.cat([torch.cat([logits_ab, logits_aa], dim=1), torch.cat([logits_ba, logits_bb], dim=1)], dim=0)
"
002d3b22,"{'temperature': 1.3, 'latent_dim': 218, 'transform_funcs': (0, 1, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 5.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 416.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 750.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 732.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 480.00 MiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 514.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 71.77 MiB is allocated by PyTorch, and 6.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2ff54bb9,"{'temperature': 0.6000000000000001, 'latent_dim': 120, 'transform_funcs': (1, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 416.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 750.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 732.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 480.00 MiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 510.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 95.25 MiB is allocated by PyTorch, and 76.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
b5dcf8be,"{'temperature': 1.5, 'latent_dim': 234, 'transform_funcs': (3, 4, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 416.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 750.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 732.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 480.00 MiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 510.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 72.39 MiB is allocated by PyTorch, and 5.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
aad52001,"{'temperature': 1.2000000000000002, 'latent_dim': 167, 'transform_funcs': (2, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 470.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 444.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 750.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 732.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 480.00 MiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 76.15 MiB is allocated by PyTorch, and 29.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
6c1bde31,"{'temperature': 1.1, 'latent_dim': 349, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 470.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 438.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 750.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 732.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 480.00 MiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 86.02 MiB is allocated by PyTorch, and 13.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
ee6d5be7,"{'temperature': 0.8, 'latent_dim': 152, 'transform_funcs': (0, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 470.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 444.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 750.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 732.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 480.00 MiB memory in use. Process 1198934 has 640.00 MiB memory in use. Process 1198980 has 998.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 76.06 MiB is allocated by PyTorch, and 29.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
a37a8a4b,"{'temperature': 1.1, 'latent_dim': 302, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 476.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 468.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 756.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 914.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 518.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 932.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 84.34 MiB is allocated by PyTorch, and 41.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1c41ca3c,"{'temperature': 1.5, 'latent_dim': 182, 'transform_funcs': (2, 4, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 107.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 472.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 756.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 914.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 518.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 814.00 MiB memory in use. Process 1198975 has 512.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 391.70 MiB is allocated by PyTorch, and 84.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
72d19243,"{'temperature': 1.2000000000000002, 'latent_dim': 202, 'transform_funcs': (2, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 93.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 700.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 886.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 518.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 868.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 278.77 MiB is allocated by PyTorch, and 83.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
557f365a,"{'temperature': 1.1, 'latent_dim': 275, 'transform_funcs': (2, 3, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 105.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 526.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 700.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 888.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 492.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 488.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 882.00 MiB memory in use. Process 1198975 has 496.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 279.34 MiB is allocated by PyTorch, and 82.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
28c707b6,"{'temperature': 0.9, 'latent_dim': 226, 'transform_funcs': (1, 5, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 526.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.01 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 448.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 760.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 490.00 MiB memory in use. Process 1198934 has 612.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 592.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 204.73 MiB is allocated by PyTorch, and 49.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cc69b6e8,"{'temperature': 1.4000000000000001, 'latent_dim': 338, 'transform_funcs': (2, 3, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 526.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.01 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 448.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 614.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 914.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 490.92 MiB is allocated by PyTorch, and 85.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8b58513f,"{'temperature': 1.0, 'latent_dim': 319, 'transform_funcs': (4, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 155.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 526.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 900.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 454.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 898.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 624.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 486.00 MiB memory in use. Process 1198975 has 512.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 479.69 MiB is allocated by PyTorch, and 82.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fe2cbc16,"{'temperature': 1.1, 'latent_dim': 329, 'transform_funcs': (7, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 526.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 954.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 516.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 898.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 650.00 MiB memory in use. Process 1198975 has 514.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 220.20 MiB is allocated by PyTorch, and 91.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
03d67197,"{'temperature': 0.6000000000000001, 'latent_dim': 211, 'transform_funcs': (6, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 516.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 968.00 MiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 516.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 898.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 466.00 MiB memory in use. Process 1198975 has 710.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 83.63 MiB is allocated by PyTorch, and 44.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c2826651,"{'temperature': 0.9, 'latent_dim': 137, 'transform_funcs': (1, 2, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 13.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 770.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.15 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 520.00 MiB memory in use. Process 1198939 has 592.00 MiB memory in use. Process 1198975 has 568.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 204.04 MiB is allocated by PyTorch, and 49.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
dfbd4570,"{'temperature': 1.4000000000000001, 'latent_dim': 125, 'transform_funcs': (2, 3, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 972.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.15 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 464.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 526.00 MiB memory in use. Process 1198939 has 466.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 82.96 MiB is allocated by PyTorch, and 45.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
29537418,"{'temperature': 1.2000000000000002, 'latent_dim': 231, 'transform_funcs': (0, 1, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 13.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 972.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.15 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 516.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 544.00 MiB memory in use. Process 1198939 has 416.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 71.47 MiB is allocated by PyTorch, and 6.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f3267f6b,"{'temperature': 1.1, 'latent_dim': 255, 'transform_funcs': (2, 3, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 972.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.15 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 518.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 518.00 MiB memory in use. Process 1198939 has 432.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 75.45 MiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d28e639d,"{'temperature': 1.0, 'latent_dim': 312, 'transform_funcs': (1, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 13.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 448.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 698.00 MiB memory in use. Process 1198980 has 528.00 MiB memory in use. Process 1198939 has 512.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 96.75 MiB is allocated by PyTorch, and 77.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
7c2bba24,"{'temperature': 0.9, 'latent_dim': 354, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 448.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 700.00 MiB memory in use. Process 1198980 has 528.00 MiB memory in use. Process 1198939 has 514.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 97.08 MiB is allocated by PyTorch, and 78.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
3d78b38f,"{'temperature': 1.2000000000000002, 'latent_dim': 190, 'transform_funcs': (3, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 446.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 466.00 MiB memory in use. Process 1198934 has 816.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 428.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 48.46 MiB is allocated by PyTorch, and 41.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
efcb1673,"{'temperature': 1.1, 'latent_dim': 248, 'transform_funcs': (0, 1, 3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 466.00 MiB memory in use. Process 1198934 has 816.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 446.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 76.77 MiB is allocated by PyTorch, and 31.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
5b77792b,"{'temperature': 0.6000000000000001, 'latent_dim': 204, 'transform_funcs': (3, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 466.00 MiB memory in use. Process 1198934 has 816.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 446.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 77.21 MiB is allocated by PyTorch, and 30.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
6dd1ddd9,"{'temperature': 0.5, 'latent_dim': 104, 'transform_funcs': (0, 3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 5.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 754.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 526.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 145.12 MiB is allocated by PyTorch, and 42.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
42aa05fe,"{'temperature': 0.7000000000000001, 'latent_dim': 165, 'transform_funcs': (8, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 418.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 452.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 868.00 MiB memory in use. Process 1198934 has 458.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 430.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 48.27 MiB is allocated by PyTorch, and 43.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e7d8a1f7,"{'temperature': 1.1, 'latent_dim': 154, 'transform_funcs': (4, 7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 442.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 466.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 868.00 MiB memory in use. Process 1198934 has 458.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 434.00 MiB memory in use. Process 1198975 has 464.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 66.37 MiB is allocated by PyTorch, and 29.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
b9b32357,"{'temperature': 1.1, 'latent_dim': 186, 'transform_funcs': (1, 3, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 442.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 448.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 466.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 868.00 MiB memory in use. Process 1198934 has 458.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 432.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 74.67 MiB is allocated by PyTorch, and 19.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
730aaff6,"{'temperature': 1.1, 'latent_dim': 157, 'transform_funcs': (1, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 468.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 516.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 480.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 756.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 446.00 MiB memory in use. Process 1198939 has 462.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 83.21 MiB is allocated by PyTorch, and 40.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fe7f9a67,"{'temperature': 1.2000000000000002, 'latent_dim': 171, 'transform_funcs': (0, 1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 756.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 448.00 MiB memory in use. Process 1198939 has 460.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 83.32 MiB is allocated by PyTorch, and 38.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
51a8b74f,"{'temperature': 1.2000000000000002, 'latent_dim': 159, 'transform_funcs': (1, 4, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 516.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 514.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 446.00 MiB memory in use. Process 1198939 has 706.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 277.52 MiB is allocated by PyTorch, and 90.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
306376d9,"{'temperature': 1.0, 'latent_dim': 172, 'transform_funcs': (1, 2, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 738.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 512.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 448.00 MiB memory in use. Process 1198939 has 460.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 83.33 MiB is allocated by PyTorch, and 38.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1d6aa940,"{'temperature': 1.2000000000000002, 'latent_dim': 132, 'transform_funcs': (1, 2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 13.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 748.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 492.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 448.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 514.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 448.00 MiB memory in use. Process 1198939 has 512.00 MiB memory in use. Process 1198975 has 448.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 95.34 MiB is allocated by PyTorch, and 78.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
892dfba0,"{'temperature': 1.1, 'latent_dim': 152, 'transform_funcs': (9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 466.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 492.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 476.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 516.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 710.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 277.47 MiB is allocated by PyTorch, and 94.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cfa51521,"{'temperature': 1.2000000000000002, 'latent_dim': 214, 'transform_funcs': (1, 5, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 764.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 490.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 442.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 460.00 MiB memory in use. Process 1198939 has 462.00 MiB memory in use. Process 1198975 has 492.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 83.65 MiB is allocated by PyTorch, and 40.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8cbb8ea6,"{'temperature': 1.1, 'latent_dim': 122, 'transform_funcs': (2, 4, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 764.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 500.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 448.00 MiB memory in use. Process 1198939 has 462.00 MiB memory in use. Process 1198975 has 492.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 82.93 MiB is allocated by PyTorch, and 41.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a1cf828a,"{'temperature': 0.9, 'latent_dim': 219, 'transform_funcs': (0, 1, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 772.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 470.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 486.00 MiB memory in use. Process 1198163 has 978.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 492.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 448.00 MiB memory in use. Process 1198939 has 466.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 83.69 MiB is allocated by PyTorch, and 44.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
69a3089b,"{'temperature': 1.0, 'latent_dim': 209, 'transform_funcs': (4, 5, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.21 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 448.00 MiB memory in use. Process 1198163 has 448.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 518.00 MiB memory in use. Process 1198939 has 518.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 95.95 MiB is allocated by PyTorch, and 84.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
5fa443fb,"{'temperature': 1.0, 'latent_dim': 215, 'transform_funcs': (3, 7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.21 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 518.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 492.00 MiB memory in use. Process 1198163 has 448.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 520.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 448.00 MiB memory in use. Process 1198939 has 428.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 48.66 MiB is allocated by PyTorch, and 41.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0ffc5129,"{'temperature': 1.0, 'latent_dim': 142, 'transform_funcs': (2, 3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.21 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 470.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 490.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 456.00 MiB memory in use. Process 1198980 has 450.00 MiB memory in use. Process 1198939 has 464.00 MiB memory in use. Process 1198975 has 498.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 83.09 MiB is allocated by PyTorch, and 42.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9a0dd288,"{'temperature': 1.0, 'latent_dim': 184, 'transform_funcs': (1, 2, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.21 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 470.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 490.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 460.00 MiB memory in use. Process 1198980 has 446.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 500.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 83.42 MiB is allocated by PyTorch, and 46.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fd07b10a,"{'temperature': 0.9, 'latent_dim': 111, 'transform_funcs': (3, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.21 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 474.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 492.00 MiB memory in use. Process 1198163 has 462.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 460.00 MiB memory in use. Process 1198980 has 448.00 MiB memory in use. Process 1198939 has 460.00 MiB memory in use. Process 1198975 has 502.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 82.85 MiB is allocated by PyTorch, and 39.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
672c4780,"{'temperature': 0.9, 'latent_dim': 335, 'transform_funcs': (3, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.21 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 500.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 462.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 84.60 MiB is allocated by PyTorch, and 39.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8fa93fbb,"{'temperature': 1.0, 'latent_dim': 120, 'transform_funcs': (0, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 1.12 GiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 500.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 518.00 MiB memory in use. Process 1198163 has 468.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 468.00 MiB memory in use. Process 1198939 has 516.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 95.25 MiB is allocated by PyTorch, and 82.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
24f8b611,"{'temperature': 0.9, 'latent_dim': 103, 'transform_funcs': (4, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 524.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 448.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 618.00 MiB memory in use. Process 1198163 has 568.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 532.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 848.00 MiB memory in use. Process 1198939 has 514.00 MiB memory in use. Process 1198975 has 538.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 95.12 MiB is allocated by PyTorch, and 80.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
a8d994d7,"{'temperature': 1.0, 'latent_dim': 345, 'transform_funcs': (3, 4, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 470.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 514.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 740.00 MiB memory in use. Process 1198163 has 456.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 494.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 860.00 MiB memory in use. Process 1198939 has 568.00 MiB memory in use. Process 1198975 has 476.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 147.01 MiB is allocated by PyTorch, and 82.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1e1a688c,"{'temperature': 1.0, 'latent_dim': 94, 'transform_funcs': (5, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 470.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 486.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 490.00 MiB memory in use. Process 1198163 has 456.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 516.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 842.00 MiB memory in use. Process 1198939 has 560.00 MiB memory in use. Process 1198975 has 760.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 145.05 MiB is allocated by PyTorch, and 76.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ec943d27,"{'temperature': 1.5, 'latent_dim': 136, 'transform_funcs': (5, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 17.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 512.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 448.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 516.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 896.00 MiB memory in use. Process 1198939 has 514.00 MiB memory in use. Process 1198975 has 760.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 95.38 MiB is allocated by PyTorch, and 80.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 26, in forward
    x = self.dropout1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
747c3c82,"{'temperature': 0.9, 'latent_dim': 124, 'transform_funcs': (4, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 59.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 436.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 446.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 466.00 MiB memory in use. Process 1198163 has 448.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 470.00 MiB memory in use. Process 1198934 has 480.00 MiB memory in use. Process 1198980 has 844.00 MiB memory in use. Process 1198939 has 652.00 MiB memory in use. Process 1198975 has 760.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 218.60 MiB is allocated by PyTorch, and 95.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 29, in forward
    x = self.dropout2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py"", line 58, in forward
    return F.dropout(input, self.p, self.training, self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1266, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
"
a818ecda,"{'temperature': 1.3, 'latent_dim': 109, 'transform_funcs': (2, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 486.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 448.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 470.00 MiB memory in use. Process 1198163 has 804.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 488.00 MiB memory in use. Process 1198934 has 480.00 MiB memory in use. Process 1198980 has 898.00 MiB memory in use. Process 1198939 has 460.00 MiB memory in use. Process 1198975 has 486.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 82.83 MiB is allocated by PyTorch, and 39.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6a205c4a,"{'temperature': 0.9, 'latent_dim': 199, 'transform_funcs': (3, 6, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 470.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 440.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 870.00 MiB memory in use. Process 1198163 has 446.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 526.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 898.00 MiB memory in use. Process 1198939 has 426.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 48.53 MiB is allocated by PyTorch, and 39.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c34f44dd,"{'temperature': 1.4000000000000001, 'latent_dim': 187, 'transform_funcs': (3, 5, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 470.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 446.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 526.00 MiB memory in use. Process 1198934 has 864.00 MiB memory in use. Process 1198980 has 898.00 MiB memory in use. Process 1198939 has 418.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 73.88 MiB is allocated by PyTorch, and 6.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
484a3f8d,"{'temperature': 0.6000000000000001, 'latent_dim': 360, 'transform_funcs': (5, 6, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 470.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 470.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 446.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 526.00 MiB memory in use. Process 1198934 has 864.00 MiB memory in use. Process 1198980 has 898.00 MiB memory in use. Process 1198939 has 416.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 74.09 MiB is allocated by PyTorch, and 3.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f9d59d18,"{'temperature': 1.5, 'latent_dim': 135, 'transform_funcs': (4, 5, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 470.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 470.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 446.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 526.00 MiB memory in use. Process 1198934 has 864.00 MiB memory in use. Process 1198980 has 898.00 MiB memory in use. Process 1198939 has 428.00 MiB memory in use. Process 1198975 has 468.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 60.99 MiB is allocated by PyTorch, and 29.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
e4689152,"{'temperature': 1.1, 'latent_dim': 142, 'transform_funcs': (1, 4, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 79.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 470.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 466.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 448.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 528.00 MiB memory in use. Process 1198934 has 446.00 MiB memory in use. Process 1198980 has 898.00 MiB memory in use. Process 1198939 has 790.00 MiB memory in use. Process 1198975 has 448.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 366.12 MiB is allocated by PyTorch, and 85.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
661a89fb,"{'temperature': 0.7000000000000001, 'latent_dim': 129, 'transform_funcs': (2, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 61.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 492.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 468.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 446.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 486.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 524.00 MiB memory in use. Process 1198939 has 790.00 MiB memory in use. Process 1198975 has 858.00 MiB memory in use. Process 1198942 has 1.06 GiB memory in use. Of the allocated memory 357.89 MiB is allocated by PyTorch, and 94.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6ce9c674,"{'temperature': 1.0, 'latent_dim': 254, 'transform_funcs': (2, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 490.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 758.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 468.00 MiB memory in use. Process 1198163 has 450.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 468.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 580.00 MiB memory in use. Process 1198939 has 468.00 MiB memory in use. Process 1198975 has 858.00 MiB memory in use. Process 1198942 has 1.07 GiB memory in use. Of the allocated memory 83.97 MiB is allocated by PyTorch, and 46.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ec266e1c,"{'temperature': 1.1, 'latent_dim': 339, 'transform_funcs': (0, 5, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.19 MiB is free. Process 1194559 has 1.29 GiB memory in use. Process 1194563 has 1.00 GiB memory in use. Process 1194561 has 1.29 GiB memory in use. Process 1194517 has 1.08 GiB memory in use. Process 1194518 has 650.00 MiB memory in use. Process 1197762 has 1.19 GiB memory in use. Process 1197764 has 1.39 GiB memory in use. Process 1197769 has 1.10 GiB memory in use. Process 1197763 has 1.25 GiB memory in use. Process 1197770 has 1020.00 MiB memory in use. Process 1198152 has 1.17 GiB memory in use. Process 1198160 has 1.27 GiB memory in use. Process 1198156 has 1.02 GiB memory in use. Process 1198164 has 446.00 MiB memory in use. Process 1198163 has 448.00 MiB memory in use. Process 1198554 has 1.05 GiB memory in use. Process 1198545 has 1.17 GiB memory in use. Process 1198555 has 1.06 GiB memory in use. Process 1198550 has 1.26 GiB memory in use. Process 1198551 has 448.00 MiB memory in use. Process 1198934 has 448.00 MiB memory in use. Process 1198980 has 466.00 MiB memory in use. Process 1198939 has 590.00 MiB memory in use. Process 1198975 has 490.00 MiB memory in use. Process 1198942 has 1.07 GiB memory in use. Of the allocated memory 205.62 MiB is allocated by PyTorch, and 46.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 153, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
