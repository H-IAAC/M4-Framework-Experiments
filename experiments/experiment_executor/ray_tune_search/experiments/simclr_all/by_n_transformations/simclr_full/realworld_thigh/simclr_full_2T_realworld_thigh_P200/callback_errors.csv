trial_id,config,error_type,error_message,error_traceback
825528f8,"{'temperature_head': 0.4, 'latent_dim': 471, 'batch_size': 285, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 59.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 644.00 MiB memory in use. Process 4053180 has 662.00 MiB memory in use. Process 4053182 has 872.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 742.00 MiB memory in use. Process 4056411 has 748.00 MiB memory in use. Process 4056414 has 642.00 MiB memory in use. Process 4056409 has 934.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 816.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 642.00 MiB memory in use. Process 4056798 has 744.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 436.00 MiB memory in use. Process 4057186 has 820.00 MiB memory in use. Process 4057191 has 642.00 MiB memory in use. Process 4057198 has 746.00 MiB memory in use. Process 4057300 has 464.00 MiB memory in use. Process 4057580 has 444.00 MiB memory in use. Process 4057583 has 576.00 MiB memory in use. Process 4057577 has 442.00 MiB memory in use. Process 4057586 has 474.00 MiB memory in use. Process 4057597 has 422.00 MiB memory in use. Of the allocated memory 116.55 MiB is allocated by PyTorch, and 19.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2983eb59,"{'temperature_head': 0.6000000000000001, 'latent_dim': 427, 'batch_size': 386, 'transform_funcs': (2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 65.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 444.00 MiB memory in use. Process 4053180 has 662.00 MiB memory in use. Process 4053182 has 872.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 742.00 MiB memory in use. Process 4056411 has 748.00 MiB memory in use. Process 4056414 has 642.00 MiB memory in use. Process 4056409 has 934.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 816.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 642.00 MiB memory in use. Process 4056798 has 744.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 442.00 MiB memory in use. Process 4057186 has 820.00 MiB memory in use. Process 4057191 has 642.00 MiB memory in use. Process 4057198 has 746.00 MiB memory in use. Process 4057300 has 464.00 MiB memory in use. Process 4057580 has 590.00 MiB memory in use. Process 4057583 has 576.00 MiB memory in use. Process 4057577 has 442.00 MiB memory in use. Process 4057586 has 474.00 MiB memory in use. Process 4057597 has 464.00 MiB memory in use. Of the allocated memory 116.20 MiB is allocated by PyTorch, and 19.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0b4b56ca,"{'temperature_head': 0.4, 'latent_dim': 355, 'batch_size': 257, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 147.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 444.00 MiB memory in use. Process 4053180 has 662.00 MiB memory in use. Process 4053182 has 1000.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 742.00 MiB memory in use. Process 4056411 has 750.00 MiB memory in use. Process 4056414 has 642.00 MiB memory in use. Process 4056409 has 934.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 816.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 644.00 MiB memory in use. Process 4056798 has 656.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 442.00 MiB memory in use. Process 4057186 has 820.00 MiB memory in use. Process 4057191 has 714.00 MiB memory in use. Process 4057198 has 612.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 590.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 526.00 MiB memory in use. Process 4057586 has 514.00 MiB memory in use. Process 4057597 has 430.00 MiB memory in use. Of the allocated memory 286.40 MiB is allocated by PyTorch, and 31.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
361b4134,"{'temperature_head': 0.2, 'latent_dim': 487, 'batch_size': 395, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 236.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 59.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 470.00 MiB memory in use. Process 4053180 has 662.00 MiB memory in use. Process 4053182 has 1000.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 742.00 MiB memory in use. Process 4056411 has 750.00 MiB memory in use. Process 4056414 has 642.00 MiB memory in use. Process 4056409 has 934.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 816.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 604.00 MiB memory in use. Process 4056798 has 694.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 442.00 MiB memory in use. Process 4057186 has 820.00 MiB memory in use. Process 4057191 has 714.00 MiB memory in use. Process 4057198 has 612.00 MiB memory in use. Process 4057300 has 442.00 MiB memory in use. Process 4057580 has 636.00 MiB memory in use. Process 4057583 has 490.00 MiB memory in use. Process 4057577 has 526.00 MiB memory in use. Process 4057586 has 470.00 MiB memory in use. Process 4057597 has 444.00 MiB memory in use. Of the allocated memory 116.67 MiB is allocated by PyTorch, and 15.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
066beced,"{'temperature_head': 0.8, 'latent_dim': 556, 'batch_size': 240, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 185.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 510.00 MiB memory in use. Process 4053180 has 662.00 MiB memory in use. Process 4053182 has 1000.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 742.00 MiB memory in use. Process 4056411 has 772.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 758.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 818.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 604.00 MiB memory in use. Process 4056798 has 694.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 442.00 MiB memory in use. Process 4057186 has 768.00 MiB memory in use. Process 4057191 has 714.00 MiB memory in use. Process 4057198 has 612.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 636.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 536.00 MiB memory in use. Process 4057586 has 460.00 MiB memory in use. Process 4057597 has 444.00 MiB memory in use. Of the allocated memory 385.65 MiB is allocated by PyTorch, and 34.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
51042977,"{'temperature_head': 0.8, 'latent_dim': 489, 'batch_size': 445, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 236.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 510.00 MiB memory in use. Process 4053180 has 662.00 MiB memory in use. Process 4053182 has 1000.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 742.00 MiB memory in use. Process 4056411 has 772.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 760.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 818.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 604.00 MiB memory in use. Process 4056798 has 846.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 442.00 MiB memory in use. Process 4057186 has 768.00 MiB memory in use. Process 4057191 has 714.00 MiB memory in use. Process 4057198 has 612.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 636.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 536.00 MiB memory in use. Process 4057586 has 460.00 MiB memory in use. Process 4057597 has 444.00 MiB memory in use. Of the allocated memory 351.93 MiB is allocated by PyTorch, and 156.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ceb65105,"{'temperature_head': 0.6000000000000001, 'latent_dim': 262, 'batch_size': 237, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 77.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 506.00 MiB memory in use. Process 4053180 has 662.00 MiB memory in use. Process 4053182 has 1000.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 742.00 MiB memory in use. Process 4056411 has 772.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 488.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 818.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 420.00 MiB memory in use. Process 4056798 has 882.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 442.00 MiB memory in use. Process 4057186 has 768.00 MiB memory in use. Process 4057191 has 714.00 MiB memory in use. Process 4057198 has 656.00 MiB memory in use. Process 4057300 has 526.00 MiB memory in use. Process 4057580 has 638.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 442.00 MiB memory in use. Process 4057586 has 596.00 MiB memory in use. Process 4057597 has 652.00 MiB memory in use. Of the allocated memory 240.91 MiB is allocated by PyTorch, and 17.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
da39e685,"{'temperature_head': 0.30000000000000004, 'latent_dim': 358, 'batch_size': 461, 'transform_funcs': (0, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 508.00 MiB memory in use. Process 4053180 has 662.00 MiB memory in use. Process 4053182 has 1000.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 742.00 MiB memory in use. Process 4056411 has 772.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 470.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 818.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 422.00 MiB memory in use. Process 4056798 has 882.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 526.00 MiB memory in use. Process 4057186 has 768.00 MiB memory in use. Process 4057191 has 714.00 MiB memory in use. Process 4057198 has 656.00 MiB memory in use. Process 4057300 has 526.00 MiB memory in use. Process 4057580 has 782.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 442.00 MiB memory in use. Process 4057586 has 422.00 MiB memory in use. Process 4057597 has 652.00 MiB memory in use. Of the allocated memory 115.66 MiB is allocated by PyTorch, and 16.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
852bca97,"{'temperature_head': 0.30000000000000004, 'latent_dim': 522, 'batch_size': 428, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 508.00 MiB memory in use. Process 4053180 has 662.00 MiB memory in use. Process 4053182 has 1000.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 742.00 MiB memory in use. Process 4056411 has 810.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 462.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 818.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 422.00 MiB memory in use. Process 4056798 has 858.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 526.00 MiB memory in use. Process 4057186 has 768.00 MiB memory in use. Process 4057191 has 714.00 MiB memory in use. Process 4057198 has 656.00 MiB memory in use. Process 4057300 has 526.00 MiB memory in use. Process 4057580 has 782.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 426.00 MiB memory in use. Process 4057586 has 436.00 MiB memory in use. Process 4057597 has 652.00 MiB memory in use. Of the allocated memory 367.68 MiB is allocated by PyTorch, and 152.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
02c45c80,"{'temperature_head': 0.4, 'latent_dim': 57, 'batch_size': 510, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 794.00 MiB memory in use. Process 4053180 has 662.00 MiB memory in use. Process 4053182 has 1000.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 742.00 MiB memory in use. Process 4056411 has 810.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 462.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 818.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 512.00 MiB memory in use. Process 4056798 has 476.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 526.00 MiB memory in use. Process 4057186 has 768.00 MiB memory in use. Process 4057191 has 714.00 MiB memory in use. Process 4057198 has 656.00 MiB memory in use. Process 4057300 has 526.00 MiB memory in use. Process 4057580 has 782.00 MiB memory in use. Process 4057583 has 440.00 MiB memory in use. Process 4057577 has 436.00 MiB memory in use. Process 4057586 has 422.00 MiB memory in use. Process 4057597 has 652.00 MiB memory in use. Of the allocated memory 67.31 MiB is allocated by PyTorch, and 16.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9259a983,"{'temperature_head': 0.1, 'latent_dim': 473, 'batch_size': 205, 'transform_funcs': (6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 111.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 794.00 MiB memory in use. Process 4053180 has 770.00 MiB memory in use. Process 4053182 has 1000.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 742.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 462.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 658.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 512.00 MiB memory in use. Process 4056798 has 520.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 460.00 MiB memory in use. Process 4057191 has 586.00 MiB memory in use. Process 4057198 has 486.00 MiB memory in use. Process 4057300 has 612.00 MiB memory in use. Process 4057580 has 782.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 482.00 MiB memory in use. Process 4057586 has 460.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 116.69 MiB is allocated by PyTorch, and 31.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7519ce5e,"{'temperature_head': 0.8, 'latent_dim': 345, 'batch_size': 456, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 157.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 794.00 MiB memory in use. Process 4053180 has 770.00 MiB memory in use. Process 4053182 has 1000.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 742.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 462.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 658.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 512.00 MiB memory in use. Process 4056798 has 520.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 460.00 MiB memory in use. Process 4057191 has 586.00 MiB memory in use. Process 4057198 has 486.00 MiB memory in use. Process 4057300 has 612.00 MiB memory in use. Process 4057580 has 782.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 482.00 MiB memory in use. Process 4057586 has 460.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 114.80 MiB is allocated by PyTorch, and 67.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b31fcf4e,"{'temperature_head': 0.8, 'latent_dim': 359, 'batch_size': 142, 'transform_funcs': (5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 123.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 794.00 MiB memory in use. Process 4053180 has 770.00 MiB memory in use. Process 4053182 has 1000.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 742.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 472.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 658.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 512.00 MiB memory in use. Process 4056798 has 520.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 460.00 MiB memory in use. Process 4057191 has 586.00 MiB memory in use. Process 4057198 has 486.00 MiB memory in use. Process 4057300 has 612.00 MiB memory in use. Process 4057580 has 782.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 506.00 MiB memory in use. Process 4057586 has 460.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 115.67 MiB is allocated by PyTorch, and 18.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6d924b66,"{'temperature_head': 0.7000000000000001, 'latent_dim': 15, 'batch_size': 498, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 794.00 MiB memory in use. Process 4053180 has 770.00 MiB memory in use. Process 4053182 has 1000.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 742.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 476.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 658.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 552.00 MiB memory in use. Process 4056798 has 444.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 586.00 MiB memory in use. Process 4057198 has 520.00 MiB memory in use. Process 4057300 has 614.00 MiB memory in use. Process 4057580 has 782.00 MiB memory in use. Process 4057583 has 526.00 MiB memory in use. Process 4057577 has 520.00 MiB memory in use. Process 4057586 has 470.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 112.92 MiB is allocated by PyTorch, and 25.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ba828a23,"{'temperature_head': 0.5, 'latent_dim': 202, 'batch_size': 201, 'transform_funcs': (9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 794.00 MiB memory in use. Process 4053180 has 770.00 MiB memory in use. Process 4053182 has 1000.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 742.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 476.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 658.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 552.00 MiB memory in use. Process 4056798 has 444.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 586.00 MiB memory in use. Process 4057198 has 520.00 MiB memory in use. Process 4057300 has 614.00 MiB memory in use. Process 4057580 has 782.00 MiB memory in use. Process 4057583 has 526.00 MiB memory in use. Process 4057577 has 520.00 MiB memory in use. Process 4057586 has 470.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 114.44 MiB is allocated by PyTorch, and 17.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fa16b3f6,"{'temperature_head': 0.7000000000000001, 'latent_dim': 707, 'batch_size': 508, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 65.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 794.00 MiB memory in use. Process 4053180 has 770.00 MiB memory in use. Process 4053182 has 1000.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 742.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 476.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 658.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 552.00 MiB memory in use. Process 4056798 has 444.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 586.00 MiB memory in use. Process 4057198 has 484.00 MiB memory in use. Process 4057300 has 614.00 MiB memory in use. Process 4057580 has 782.00 MiB memory in use. Process 4057583 has 526.00 MiB memory in use. Process 4057577 has 520.00 MiB memory in use. Process 4057586 has 470.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 119.80 MiB is allocated by PyTorch, and 26.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
87815cb2,"{'temperature_head': 1.0, 'latent_dim': 136, 'batch_size': 330, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 794.00 MiB memory in use. Process 4053180 has 770.00 MiB memory in use. Process 4053182 has 1000.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 742.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 514.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 658.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 552.00 MiB memory in use. Process 4056798 has 446.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 586.00 MiB memory in use. Process 4057198 has 484.00 MiB memory in use. Process 4057300 has 614.00 MiB memory in use. Process 4057580 has 810.00 MiB memory in use. Process 4057583 has 526.00 MiB memory in use. Process 4057577 has 520.00 MiB memory in use. Process 4057586 has 420.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 67.59 MiB is allocated by PyTorch, and 40.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
75d37b34,"{'temperature_head': 0.7000000000000001, 'latent_dim': 2, 'batch_size': 489, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 794.00 MiB memory in use. Process 4053180 has 770.00 MiB memory in use. Process 4053182 has 728.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 616.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 516.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 482.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 526.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 442.00 MiB memory in use. Process 4057300 has 734.00 MiB memory in use. Process 4057580 has 822.00 MiB memory in use. Process 4057583 has 536.00 MiB memory in use. Process 4057577 has 692.00 MiB memory in use. Process 4057586 has 424.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 66.88 MiB is allocated by PyTorch, and 19.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b9fb2668,"{'temperature_head': 0.9, 'latent_dim': 106, 'batch_size': 387, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 794.00 MiB memory in use. Process 4053180 has 770.00 MiB memory in use. Process 4053182 has 728.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 616.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 516.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 482.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 528.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 416.00 MiB memory in use. Process 4057300 has 734.00 MiB memory in use. Process 4057580 has 772.00 MiB memory in use. Process 4057583 has 536.00 MiB memory in use. Process 4057577 has 692.00 MiB memory in use. Process 4057586 has 498.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 41.35 MiB is allocated by PyTorch, and 36.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6e5e3610,"{'temperature_head': 0.30000000000000004, 'latent_dim': 154, 'batch_size': 353, 'transform_funcs': (6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 794.00 MiB memory in use. Process 4053180 has 770.00 MiB memory in use. Process 4053182 has 728.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 616.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 552.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 482.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 528.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 454.00 MiB memory in use. Process 4057300 has 734.00 MiB memory in use. Process 4057580 has 772.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 692.00 MiB memory in use. Process 4057586 has 496.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 188.03 MiB is allocated by PyTorch, and 25.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2f63f373,"{'temperature_head': 0.1, 'latent_dim': 286, 'batch_size': 478, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 794.00 MiB memory in use. Process 4053180 has 770.00 MiB memory in use. Process 4053182 has 728.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 616.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 592.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 490.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 528.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 454.00 MiB memory in use. Process 4057300 has 734.00 MiB memory in use. Process 4057580 has 772.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 692.00 MiB memory in use. Process 4057586 has 496.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 114.76 MiB is allocated by PyTorch, and 37.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e6d80021,"{'temperature_head': 0.9, 'latent_dim': 708, 'batch_size': 356, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 342.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 794.00 MiB memory in use. Process 4053180 has 770.00 MiB memory in use. Process 4053182 has 728.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 616.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 592.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 526.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 454.00 MiB memory in use. Process 4057300 has 734.00 MiB memory in use. Process 4057580 has 772.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 692.00 MiB memory in use. Process 4057586 has 494.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 118.30 MiB is allocated by PyTorch, and 37.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0c3b4f24,"{'temperature_head': 1.0, 'latent_dim': 216, 'batch_size': 475, 'transform_funcs': (4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 53.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 794.00 MiB memory in use. Process 4053180 has 770.00 MiB memory in use. Process 4053182 has 728.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 616.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 592.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 488.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 454.00 MiB memory in use. Process 4057300 has 734.00 MiB memory in use. Process 4057580 has 772.00 MiB memory in use. Process 4057583 has 444.00 MiB memory in use. Process 4057577 has 692.00 MiB memory in use. Process 4057586 has 530.00 MiB memory in use. Process 4057597 has 690.00 MiB memory in use. Of the allocated memory 114.21 MiB is allocated by PyTorch, and 35.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dd6b9f4c,"{'temperature_head': 0.6000000000000001, 'latent_dim': 633, 'batch_size': 420, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 306.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 137.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 794.00 MiB memory in use. Process 4053180 has 770.00 MiB memory in use. Process 4053182 has 728.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 616.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 508.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 488.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 454.00 MiB memory in use. Process 4057300 has 734.00 MiB memory in use. Process 4057580 has 772.00 MiB memory in use. Process 4057583 has 444.00 MiB memory in use. Process 4057577 has 692.00 MiB memory in use. Process 4057586 has 530.00 MiB memory in use. Process 4057597 has 690.00 MiB memory in use. Of the allocated memory 117.75 MiB is allocated by PyTorch, and 52.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5e240b6f,"{'temperature_head': 0.4, 'latent_dim': 106, 'batch_size': 298, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 52.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 768.00 MiB memory in use. Process 4053180 has 770.00 MiB memory in use. Process 4053182 has 728.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 486.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 530.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 454.00 MiB memory in use. Process 4057300 has 734.00 MiB memory in use. Process 4057580 has 772.00 MiB memory in use. Process 4057583 has 480.00 MiB memory in use. Process 4057577 has 730.00 MiB memory in use. Process 4057586 has 532.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 164.58 MiB is allocated by PyTorch, and 29.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
92366d46,"{'temperature_head': 0.6000000000000001, 'latent_dim': 297, 'batch_size': 367, 'transform_funcs': (4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 101.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 768.00 MiB memory in use. Process 4053180 has 770.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 488.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 492.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 734.00 MiB memory in use. Process 4057300 has 770.00 MiB memory in use. Process 4057580 has 772.00 MiB memory in use. Process 4057583 has 526.00 MiB memory in use. Process 4057577 has 730.00 MiB memory in use. Process 4057586 has 422.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 114.85 MiB is allocated by PyTorch, and 39.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
be6b5056,"{'temperature_head': 0.7000000000000001, 'latent_dim': 88, 'batch_size': 417, 'transform_funcs': (3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 768.00 MiB memory in use. Process 4053180 has 590.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 512.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 534.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 418.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 536.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 734.00 MiB memory in use. Process 4057300 has 770.00 MiB memory in use. Process 4057580 has 808.00 MiB memory in use. Process 4057583 has 600.00 MiB memory in use. Process 4057577 has 730.00 MiB memory in use. Process 4057586 has 422.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 41.21 MiB is allocated by PyTorch, and 38.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
362ebafa,"{'temperature_head': 0.5, 'latent_dim': 34, 'batch_size': 169, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 768.00 MiB memory in use. Process 4053180 has 590.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 512.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 534.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 418.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 536.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 734.00 MiB memory in use. Process 4057300 has 770.00 MiB memory in use. Process 4057580 has 808.00 MiB memory in use. Process 4057583 has 600.00 MiB memory in use. Process 4057577 has 730.00 MiB memory in use. Process 4057586 has 424.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 67.13 MiB is allocated by PyTorch, and 18.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f5fc3194,"{'temperature_head': 0.5, 'latent_dim': 395, 'batch_size': 443, 'transform_funcs': (0, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 768.00 MiB memory in use. Process 4053180 has 590.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 512.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 534.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 446.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 536.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 734.00 MiB memory in use. Process 4057300 has 770.00 MiB memory in use. Process 4057580 has 808.00 MiB memory in use. Process 4057583 has 600.00 MiB memory in use. Process 4057577 has 730.00 MiB memory in use. Process 4057586 has 426.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 77.31 MiB is allocated by PyTorch, and 10.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/simcrl_head.py"", line 22, in forward
    projection_2 = self.projection_2(projection_1)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
"
b3f9922f,"{'temperature_head': 0.2, 'latent_dim': 423, 'batch_size': 331, 'transform_funcs': (9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 147.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 768.00 MiB memory in use. Process 4053180 has 590.00 MiB memory in use. Process 4053182 has 416.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 472.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 444.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 536.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 734.00 MiB memory in use. Process 4057300 has 770.00 MiB memory in use. Process 4057580 has 808.00 MiB memory in use. Process 4057583 has 600.00 MiB memory in use. Process 4057577 has 730.00 MiB memory in use. Process 4057586 has 442.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 116.17 MiB is allocated by PyTorch, and 17.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b2e42df7,"{'temperature_head': 0.30000000000000004, 'latent_dim': 8, 'batch_size': 466, 'transform_funcs': (3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 768.00 MiB memory in use. Process 4053180 has 590.00 MiB memory in use. Process 4053182 has 454.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 508.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 444.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 536.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 736.00 MiB memory in use. Process 4057300 has 770.00 MiB memory in use. Process 4057580 has 808.00 MiB memory in use. Process 4057583 has 600.00 MiB memory in use. Process 4057577 has 730.00 MiB memory in use. Process 4057586 has 470.00 MiB memory in use. Process 4057597 has 688.00 MiB memory in use. Of the allocated memory 112.93 MiB is allocated by PyTorch, and 19.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
90032f85,"{'temperature_head': 0.4, 'latent_dim': 234, 'batch_size': 511, 'transform_funcs': (8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 422.00 MiB memory in use. Process 4053180 has 626.00 MiB memory in use. Process 4053182 has 454.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 698.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 604.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 574.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 736.00 MiB memory in use. Process 4057300 has 770.00 MiB memory in use. Process 4057580 has 808.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 730.00 MiB memory in use. Process 4057586 has 510.00 MiB memory in use. Process 4057597 has 722.00 MiB memory in use. Of the allocated memory 226.83 MiB is allocated by PyTorch, and 39.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bf609659,"{'temperature_head': 0.6000000000000001, 'latent_dim': 316, 'batch_size': 490, 'transform_funcs': (0, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 149.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 422.00 MiB memory in use. Process 4053180 has 626.00 MiB memory in use. Process 4053182 has 454.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 698.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 604.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 574.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 634.00 MiB memory in use. Process 4057300 has 770.00 MiB memory in use. Process 4057580 has 808.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 730.00 MiB memory in use. Process 4057586 has 510.00 MiB memory in use. Process 4057597 has 722.00 MiB memory in use. Of the allocated memory 267.46 MiB is allocated by PyTorch, and 28.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
48e8c904,"{'temperature_head': 0.2, 'latent_dim': 261, 'batch_size': 266, 'transform_funcs': (3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 77.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 508.00 MiB memory in use. Process 4053180 has 626.00 MiB memory in use. Process 4053182 has 436.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 698.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 778.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 444.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 672.00 MiB memory in use. Process 4057300 has 770.00 MiB memory in use. Process 4057580 has 772.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 730.00 MiB memory in use. Process 4057586 has 470.00 MiB memory in use. Process 4057597 has 722.00 MiB memory in use. Of the allocated memory 114.91 MiB is allocated by PyTorch, and 17.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2fc5ae72,"{'temperature_head': 0.4, 'latent_dim': 401, 'batch_size': 443, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 508.00 MiB memory in use. Process 4053180 has 626.00 MiB memory in use. Process 4053182 has 418.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 698.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 778.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 480.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 650.00 MiB memory in use. Process 4057300 has 770.00 MiB memory in use. Process 4057580 has 808.00 MiB memory in use. Process 4057583 has 454.00 MiB memory in use. Process 4057577 has 730.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 722.00 MiB memory in use. Of the allocated memory 116.00 MiB is allocated by PyTorch, and 18.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b25fa466,"{'temperature_head': 0.6000000000000001, 'latent_dim': 252, 'batch_size': 431, 'transform_funcs': (2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 101.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 444.00 MiB memory in use. Process 4053180 has 578.00 MiB memory in use. Process 4053182 has 444.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 462.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 778.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 526.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 650.00 MiB memory in use. Process 4057300 has 770.00 MiB memory in use. Process 4057580 has 808.00 MiB memory in use. Process 4057583 has 662.00 MiB memory in use. Process 4057577 has 730.00 MiB memory in use. Process 4057586 has 470.00 MiB memory in use. Process 4057597 has 722.00 MiB memory in use. Of the allocated memory 114.83 MiB is allocated by PyTorch, and 17.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6746cce0,"{'temperature_head': 0.2, 'latent_dim': 324, 'batch_size': 379, 'transform_funcs': (1, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 156.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 61.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 444.00 MiB memory in use. Process 4053180 has 578.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 468.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 778.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 526.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 650.00 MiB memory in use. Process 4057300 has 770.00 MiB memory in use. Process 4057580 has 808.00 MiB memory in use. Process 4057583 has 662.00 MiB memory in use. Process 4057577 has 730.00 MiB memory in use. Process 4057586 has 506.00 MiB memory in use. Process 4057597 has 722.00 MiB memory in use. Of the allocated memory 115.40 MiB is allocated by PyTorch, and 14.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cc2cdc48,"{'temperature_head': 0.1, 'latent_dim': 221, 'batch_size': 270, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 89.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 506.00 MiB memory in use. Process 4053180 has 614.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 444.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 538.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 612.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 688.00 MiB memory in use. Process 4057300 has 772.00 MiB memory in use. Process 4057580 has 810.00 MiB memory in use. Process 4057583 has 662.00 MiB memory in use. Process 4057577 has 744.00 MiB memory in use. Process 4057586 has 470.00 MiB memory in use. Process 4057597 has 754.00 MiB memory in use. Of the allocated memory 114.59 MiB is allocated by PyTorch, and 17.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3a99196c,"{'temperature_head': 0.5, 'latent_dim': 628, 'batch_size': 396, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 302.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 101.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 506.00 MiB memory in use. Process 4053180 has 614.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 444.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 490.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 612.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 688.00 MiB memory in use. Process 4057300 has 772.00 MiB memory in use. Process 4057580 has 810.00 MiB memory in use. Process 4057583 has 662.00 MiB memory in use. Process 4057577 has 744.00 MiB memory in use. Process 4057586 has 506.00 MiB memory in use. Process 4057597 has 754.00 MiB memory in use. Of the allocated memory 118.09 MiB is allocated by PyTorch, and 33.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d36b7690,"{'temperature_head': 0.30000000000000004, 'latent_dim': 186, 'batch_size': 238, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 73.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 506.00 MiB memory in use. Process 4053180 has 614.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 470.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 490.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 612.00 MiB memory in use. Process 4057191 has 622.00 MiB memory in use. Process 4057198 has 688.00 MiB memory in use. Process 4057300 has 772.00 MiB memory in use. Process 4057580 has 810.00 MiB memory in use. Process 4057583 has 662.00 MiB memory in use. Process 4057577 has 744.00 MiB memory in use. Process 4057586 has 508.00 MiB memory in use. Process 4057597 has 754.00 MiB memory in use. Of the allocated memory 114.32 MiB is allocated by PyTorch, and 17.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0bfca10f,"{'temperature_head': 0.4, 'latent_dim': 283, 'batch_size': 453, 'transform_funcs': (0, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 506.00 MiB memory in use. Process 4053180 has 582.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 508.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 528.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 612.00 MiB memory in use. Process 4057191 has 636.00 MiB memory in use. Process 4057198 has 688.00 MiB memory in use. Process 4057300 has 796.00 MiB memory in use. Process 4057580 has 810.00 MiB memory in use. Process 4057583 has 662.00 MiB memory in use. Process 4057577 has 744.00 MiB memory in use. Process 4057586 has 470.00 MiB memory in use. Process 4057597 has 754.00 MiB memory in use. Of the allocated memory 115.08 MiB is allocated by PyTorch, and 16.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ef54e0c8,"{'temperature_head': 0.6000000000000001, 'latent_dim': 387, 'batch_size': 494, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 77.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 506.00 MiB memory in use. Process 4053180 has 582.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 478.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 528.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 612.00 MiB memory in use. Process 4057191 has 636.00 MiB memory in use. Process 4057198 has 688.00 MiB memory in use. Process 4057300 has 796.00 MiB memory in use. Process 4057580 has 774.00 MiB memory in use. Process 4057583 has 662.00 MiB memory in use. Process 4057577 has 744.00 MiB memory in use. Process 4057586 has 508.00 MiB memory in use. Process 4057597 has 754.00 MiB memory in use. Of the allocated memory 115.83 MiB is allocated by PyTorch, and 24.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
881e857c,"{'temperature_head': 0.5, 'latent_dim': 527, 'batch_size': 480, 'transform_funcs': (4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 574.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 480.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 514.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 770.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 612.00 MiB memory in use. Process 4057191 has 636.00 MiB memory in use. Process 4057198 has 688.00 MiB memory in use. Process 4057300 has 796.00 MiB memory in use. Process 4057580 has 422.00 MiB memory in use. Process 4057583 has 598.00 MiB memory in use. Process 4057577 has 780.00 MiB memory in use. Process 4057586 has 470.00 MiB memory in use. Process 4057597 has 754.00 MiB memory in use. Of the allocated memory 117.74 MiB is allocated by PyTorch, and 14.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
97fcca84,"{'temperature_head': 0.8, 'latent_dim': 434, 'batch_size': 227, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 91.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 574.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 518.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 516.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 770.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 612.00 MiB memory in use. Process 4057191 has 636.00 MiB memory in use. Process 4057198 has 688.00 MiB memory in use. Process 4057300 has 796.00 MiB memory in use. Process 4057580 has 442.00 MiB memory in use. Process 4057583 has 598.00 MiB memory in use. Process 4057577 has 780.00 MiB memory in use. Process 4057586 has 684.00 MiB memory in use. Process 4057597 has 442.00 MiB memory in use. Of the allocated memory 324.86 MiB is allocated by PyTorch, and 21.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
15e4f365,"{'temperature_head': 0.1, 'latent_dim': 199, 'batch_size': 399, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 69.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 610.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 528.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 574.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 770.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 690.00 MiB memory in use. Process 4057186 has 612.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 688.00 MiB memory in use. Process 4057300 has 836.00 MiB memory in use. Process 4057580 has 442.00 MiB memory in use. Process 4057583 has 636.00 MiB memory in use. Process 4057577 has 780.00 MiB memory in use. Process 4057586 has 488.00 MiB memory in use. Process 4057597 has 442.00 MiB memory in use. Of the allocated memory 210.36 MiB is allocated by PyTorch, and 23.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6fd785de,"{'temperature_head': 0.6000000000000001, 'latent_dim': 449, 'batch_size': 252, 'transform_funcs': (3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 93.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 690.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 564.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 612.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 456.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 770.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 636.00 MiB memory in use. Process 4057186 has 612.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 688.00 MiB memory in use. Process 4057300 has 460.00 MiB memory in use. Process 4057580 has 506.00 MiB memory in use. Process 4057583 has 636.00 MiB memory in use. Process 4057577 has 780.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 634.00 MiB memory in use. Of the allocated memory 116.38 MiB is allocated by PyTorch, and 17.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6ebd8f35,"{'temperature_head': 0.6000000000000001, 'latent_dim': 2, 'batch_size': 502, 'transform_funcs': (8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 730.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 576.00 MiB memory in use. Process 4056402 has 838.00 MiB memory in use. Process 4056410 has 644.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 416.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 442.00 MiB memory in use. Process 4057186 has 786.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 666.00 MiB memory in use. Process 4057300 has 524.00 MiB memory in use. Process 4057580 has 664.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 780.00 MiB memory in use. Process 4057586 has 644.00 MiB memory in use. Process 4057597 has 610.00 MiB memory in use. Of the allocated memory 40.54 MiB is allocated by PyTorch, and 37.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c4111573,"{'temperature_head': 0.9, 'latent_dim': 103, 'batch_size': 332, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 592.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 520.00 MiB memory in use. Process 4056402 has 724.00 MiB memory in use. Process 4056410 has 684.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 554.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 442.00 MiB memory in use. Process 4057186 has 786.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 706.00 MiB memory in use. Process 4057300 has 478.00 MiB memory in use. Process 4057580 has 664.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 780.00 MiB memory in use. Process 4057586 has 760.00 MiB memory in use. Process 4057597 has 646.00 MiB memory in use. Of the allocated memory 163.67 MiB is allocated by PyTorch, and 16.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c6212d1d,"{'temperature_head': 0.7000000000000001, 'latent_dim': 225, 'batch_size': 362, 'transform_funcs': (2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 592.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 434.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 444.00 MiB memory in use. Process 4056402 has 724.00 MiB memory in use. Process 4056410 has 684.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 554.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 492.00 MiB memory in use. Process 4057186 has 786.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 698.00 MiB memory in use. Process 4057300 has 478.00 MiB memory in use. Process 4057580 has 664.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 780.00 MiB memory in use. Process 4057586 has 760.00 MiB memory in use. Process 4057597 has 646.00 MiB memory in use. Of the allocated memory 222.01 MiB is allocated by PyTorch, and 137.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
53f7b027,"{'temperature_head': 0.8, 'latent_dim': 203, 'batch_size': 319, 'transform_funcs': (2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 594.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 472.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 472.00 MiB memory in use. Process 4056402 has 724.00 MiB memory in use. Process 4056410 has 684.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 442.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 526.00 MiB memory in use. Process 4057186 has 786.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 736.00 MiB memory in use. Process 4057300 has 488.00 MiB memory in use. Process 4057580 has 664.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 780.00 MiB memory in use. Process 4057586 has 760.00 MiB memory in use. Process 4057597 has 634.00 MiB memory in use. Of the allocated memory 114.45 MiB is allocated by PyTorch, and 17.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
acce3a35,"{'temperature_head': 0.7000000000000001, 'latent_dim': 323, 'batch_size': 224, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 156.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 598.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 520.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 510.00 MiB memory in use. Process 4056402 has 724.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 622.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 534.00 MiB memory in use. Process 4057186 has 788.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 702.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 664.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 780.00 MiB memory in use. Process 4057586 has 754.00 MiB memory in use. Process 4057597 has 634.00 MiB memory in use. Of the allocated memory 270.63 MiB is allocated by PyTorch, and 93.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e185f8d7,"{'temperature_head': 1.0, 'latent_dim': 300, 'batch_size': 274, 'transform_funcs': (5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 442.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 572.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 628.00 MiB memory in use. Process 4056402 has 724.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 622.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 534.00 MiB memory in use. Process 4057186 has 788.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 702.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 664.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 780.00 MiB memory in use. Process 4057586 has 754.00 MiB memory in use. Process 4057597 has 634.00 MiB memory in use. Of the allocated memory 259.35 MiB is allocated by PyTorch, and 28.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
13ea0d65,"{'temperature_head': 0.9, 'latent_dim': 342, 'batch_size': 343, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 113.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 460.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 456.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 748.00 MiB memory in use. Process 4056402 has 760.00 MiB memory in use. Process 4056410 has 660.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 662.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 604.00 MiB memory in use. Process 4057186 has 444.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 740.00 MiB memory in use. Process 4057300 has 558.00 MiB memory in use. Process 4057580 has 444.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 780.00 MiB memory in use. Process 4057586 has 790.00 MiB memory in use. Process 4057597 has 554.00 MiB memory in use. Of the allocated memory 278.98 MiB is allocated by PyTorch, and 129.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
13409ac2,"{'temperature_head': 0.9, 'latent_dim': 272, 'batch_size': 373, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 125.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 460.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 456.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 748.00 MiB memory in use. Process 4056402 has 760.00 MiB memory in use. Process 4056410 has 660.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 662.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 604.00 MiB memory in use. Process 4057186 has 444.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 700.00 MiB memory in use. Process 4057300 has 586.00 MiB memory in use. Process 4057580 has 444.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 780.00 MiB memory in use. Process 4057586 has 790.00 MiB memory in use. Process 4057597 has 554.00 MiB memory in use. Of the allocated memory 244.97 MiB is allocated by PyTorch, and 117.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c20881a6,"{'temperature_head': 1.0, 'latent_dim': 380, 'batch_size': 351, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 109.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 462.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 456.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 784.00 MiB memory in use. Process 4056402 has 760.00 MiB memory in use. Process 4056410 has 742.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 662.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 604.00 MiB memory in use. Process 4057186 has 444.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 742.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 504.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 780.00 MiB memory in use. Process 4057586 has 726.00 MiB memory in use. Process 4057597 has 554.00 MiB memory in use. Of the allocated memory 297.60 MiB is allocated by PyTorch, and 90.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
435e387e,"{'temperature_head': 1.0, 'latent_dim': 595, 'batch_size': 485, 'transform_funcs': (2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 286.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 219.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 462.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 456.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 784.00 MiB memory in use. Process 4056402 has 760.00 MiB memory in use. Process 4056410 has 742.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 512.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 604.00 MiB memory in use. Process 4057186 has 444.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 742.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 506.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 780.00 MiB memory in use. Process 4057586 has 764.00 MiB memory in use. Process 4057597 has 554.00 MiB memory in use. Of the allocated memory 116.30 MiB is allocated by PyTorch, and 55.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2e093f28,"{'temperature_head': 0.4, 'latent_dim': 372, 'batch_size': 460, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 141.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 462.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 456.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 784.00 MiB memory in use. Process 4056402 has 762.00 MiB memory in use. Process 4056410 has 742.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 550.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 604.00 MiB memory in use. Process 4057186 has 444.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 728.00 MiB memory in use. Process 4057300 has 606.00 MiB memory in use. Process 4057580 has 506.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 780.00 MiB memory in use. Process 4057586 has 766.00 MiB memory in use. Process 4057597 has 442.00 MiB memory in use. Of the allocated memory 293.82 MiB is allocated by PyTorch, and 96.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
80bec511,"{'temperature_head': 0.9, 'latent_dim': 521, 'batch_size': 390, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 91.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 462.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 456.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 832.00 MiB memory in use. Process 4056402 has 762.00 MiB memory in use. Process 4056410 has 742.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 550.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 604.00 MiB memory in use. Process 4057186 has 444.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 728.00 MiB memory in use. Process 4057300 has 606.00 MiB memory in use. Process 4057580 has 506.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 780.00 MiB memory in use. Process 4057586 has 766.00 MiB memory in use. Process 4057597 has 444.00 MiB memory in use. Of the allocated memory 366.42 MiB is allocated by PyTorch, and 125.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cc786857,"{'temperature_head': 0.8, 'latent_dim': 464, 'batch_size': 502, 'transform_funcs': (1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 197.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 462.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 456.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 868.00 MiB memory in use. Process 4056402 has 762.00 MiB memory in use. Process 4056410 has 744.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 550.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 604.00 MiB memory in use. Process 4057186 has 444.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 520.00 MiB memory in use. Process 4057300 has 606.00 MiB memory in use. Process 4057580 has 568.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 780.00 MiB memory in use. Process 4057586 has 768.00 MiB memory in use. Process 4057597 has 444.00 MiB memory in use. Of the allocated memory 339.61 MiB is allocated by PyTorch, and 90.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
89f940cb,"{'temperature_head': 0.9, 'latent_dim': 672, 'batch_size': 363, 'transform_funcs': (7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 73.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 508.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 520.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 870.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 744.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 692.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 598.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 488.00 MiB memory in use. Process 4057300 has 698.00 MiB memory in use. Process 4057580 has 568.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 464.00 MiB memory in use. Process 4057597 has 444.00 MiB memory in use. Of the allocated memory 117.78 MiB is allocated by PyTorch, and 32.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
36d2825c,"{'temperature_head': 0.30000000000000004, 'latent_dim': 346, 'batch_size': 325, 'transform_funcs': (5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 155.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 508.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 654.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 870.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 692.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 598.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 516.00 MiB memory in use. Process 4057300 has 698.00 MiB memory in use. Process 4057580 has 604.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 470.00 MiB memory in use. Process 4057597 has 460.00 MiB memory in use. Of the allocated memory 115.57 MiB is allocated by PyTorch, and 16.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
86039911,"{'temperature_head': 1.0, 'latent_dim': 499, 'batch_size': 411, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 470.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 654.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 870.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 534.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 692.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 598.00 MiB memory in use. Process 4057186 has 490.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 496.00 MiB memory in use. Process 4057300 has 698.00 MiB memory in use. Process 4057580 has 604.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 510.00 MiB memory in use. Process 4057597 has 460.00 MiB memory in use. Of the allocated memory 116.43 MiB is allocated by PyTorch, and 41.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
06cd4a7b,"{'temperature_head': 0.5, 'latent_dim': 282, 'batch_size': 371, 'transform_funcs': (0, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 63.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 442.00 MiB memory in use. Process 4053180 has 618.00 MiB memory in use. Process 4053182 has 654.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 870.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 534.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 692.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 598.00 MiB memory in use. Process 4057186 has 526.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 486.00 MiB memory in use. Process 4057300 has 698.00 MiB memory in use. Process 4057580 has 604.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 470.00 MiB memory in use. Of the allocated memory 115.07 MiB is allocated by PyTorch, and 16.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4855e750,"{'temperature_head': 0.5, 'latent_dim': 169, 'batch_size': 436, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 442.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 654.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 870.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 574.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 448.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 638.00 MiB memory in use. Process 4057186 has 526.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 490.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 774.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 510.00 MiB memory in use. Process 4057597 has 636.00 MiB memory in use. Of the allocated memory 67.85 MiB is allocated by PyTorch, and 40.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a4e81d51,"{'temperature_head': 0.8, 'latent_dim': 412, 'batch_size': 289, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 442.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 654.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 870.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 574.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 448.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 638.00 MiB memory in use. Process 4057186 has 526.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 490.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 774.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 510.00 MiB memory in use. Process 4057597 has 636.00 MiB memory in use. Of the allocated memory 115.75 MiB is allocated by PyTorch, and 36.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
81d1dfa8,"{'temperature_head': 0.6000000000000001, 'latent_dim': 260, 'batch_size': 509, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 57.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 460.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 654.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 870.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 574.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 482.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 638.00 MiB memory in use. Process 4057186 has 526.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 442.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 774.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 474.00 MiB memory in use. Process 4057597 has 636.00 MiB memory in use. Of the allocated memory 114.90 MiB is allocated by PyTorch, and 19.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b1afc5dd,"{'temperature_head': 0.9, 'latent_dim': 115, 'batch_size': 483, 'transform_funcs': (9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 7.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 462.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 870.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 744.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 490.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 638.00 MiB memory in use. Process 4057186 has 612.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 444.00 MiB memory in use. Process 4057300 has 422.00 MiB memory in use. Process 4057580 has 774.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 510.00 MiB memory in use. Process 4057597 has 636.00 MiB memory in use. Of the allocated memory 113.42 MiB is allocated by PyTorch, and 36.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8dae3c3b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 235, 'batch_size': 379, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 91.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 462.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 870.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 744.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 444.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 638.00 MiB memory in use. Process 4057186 has 612.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 444.00 MiB memory in use. Process 4057300 has 422.00 MiB memory in use. Process 4057580 has 774.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 636.00 MiB memory in use. Of the allocated memory 114.70 MiB is allocated by PyTorch, and 17.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
268fa26d,"{'temperature_head': 0.4, 'latent_dim': 190, 'batch_size': 245, 'transform_funcs': (6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 468.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 870.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 744.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 444.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 638.00 MiB memory in use. Process 4057186 has 612.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 490.00 MiB memory in use. Process 4057300 has 422.00 MiB memory in use. Process 4057580 has 774.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 508.00 MiB memory in use. Process 4057597 has 636.00 MiB memory in use. Of the allocated memory 114.01 MiB is allocated by PyTorch, and 37.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2436ae3d,"{'temperature_head': 0.6000000000000001, 'latent_dim': 59, 'batch_size': 358, 'transform_funcs': (2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 17.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 460.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 870.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 744.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 446.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 638.00 MiB memory in use. Process 4057186 has 614.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 444.00 MiB memory in use. Process 4057300 has 446.00 MiB memory in use. Process 4057580 has 776.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 518.00 MiB memory in use. Process 4057597 has 636.00 MiB memory in use. Of the allocated memory 141.68 MiB is allocated by PyTorch, and 36.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b2219039,"{'temperature_head': 0.1, 'latent_dim': 215, 'batch_size': 336, 'transform_funcs': (4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 460.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 446.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 870.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 744.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 448.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 638.00 MiB memory in use. Process 4057186 has 614.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 444.00 MiB memory in use. Process 4057300 has 446.00 MiB memory in use. Process 4057580 has 776.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 424.00 MiB memory in use. Process 4057597 has 676.00 MiB memory in use. Of the allocated memory 68.21 MiB is allocated by PyTorch, and 39.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dc5d7a30,"{'temperature_head': 0.7000000000000001, 'latent_dim': 30, 'batch_size': 405, 'transform_funcs': (0, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 460.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 446.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 870.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 744.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 484.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 638.00 MiB memory in use. Process 4057186 has 614.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 444.00 MiB memory in use. Process 4057300 has 442.00 MiB memory in use. Process 4057580 has 776.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 402.00 MiB memory in use. Process 4057597 has 676.00 MiB memory in use. Of the allocated memory 41.10 MiB is allocated by PyTorch, and 20.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9f9b7f94,"{'temperature_head': 0.9, 'latent_dim': 244, 'batch_size': 349, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 67.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 462.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 490.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 870.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 662.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 486.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 634.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 608.00 MiB memory in use. Process 4057300 has 442.00 MiB memory in use. Process 4057580 has 720.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 676.00 MiB memory in use. Of the allocated memory 114.77 MiB is allocated by PyTorch, and 17.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
747163b4,"{'temperature_head': 1.0, 'latent_dim': 357, 'batch_size': 260, 'transform_funcs': (3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 101.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 460.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 786.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 662.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 486.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 634.00 MiB memory in use. Process 4057186 has 486.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 608.00 MiB memory in use. Process 4057300 has 460.00 MiB memory in use. Process 4057580 has 720.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 510.00 MiB memory in use. Process 4057597 has 676.00 MiB memory in use. Of the allocated memory 286.31 MiB is allocated by PyTorch, and 159.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f443d905,"{'temperature_head': 0.4, 'latent_dim': 335, 'batch_size': 280, 'transform_funcs': (9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 460.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 822.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 662.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 738.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 404.00 MiB memory in use. Process 4057186 has 526.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 608.00 MiB memory in use. Process 4057300 has 460.00 MiB memory in use. Process 4057580 has 720.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 510.00 MiB memory in use. Process 4057597 has 676.00 MiB memory in use. Of the allocated memory 276.26 MiB is allocated by PyTorch, and 121.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
74ec0949,"{'temperature_head': 0.5, 'latent_dim': 436, 'batch_size': 418, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 105.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 460.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 822.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 662.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 752.00 MiB memory in use. Process 4056798 has 776.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 442.00 MiB memory in use. Process 4057186 has 444.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 608.00 MiB memory in use. Process 4057300 has 460.00 MiB memory in use. Process 4057580 has 720.00 MiB memory in use. Process 4057583 has 674.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 474.00 MiB memory in use. Process 4057597 has 634.00 MiB memory in use. Of the allocated memory 116.27 MiB is allocated by PyTorch, and 17.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cb2ce1d1,"{'temperature_head': 0.8, 'latent_dim': 93, 'batch_size': 213, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 5.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 462.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 486.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 662.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 752.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 536.00 MiB memory in use. Process 4057186 has 694.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 492.00 MiB memory in use. Process 4057300 has 442.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 686.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 510.00 MiB memory in use. Process 4057597 has 670.00 MiB memory in use. Of the allocated memory 113.25 MiB is allocated by PyTorch, and 38.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b577bda2,"{'temperature_head': 0.9, 'latent_dim': 271, 'batch_size': 475, 'transform_funcs': (0, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 462.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 472.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 662.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 752.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 536.00 MiB memory in use. Process 4057186 has 694.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 492.00 MiB memory in use. Process 4057300 has 442.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 686.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 510.00 MiB memory in use. Process 4057597 has 670.00 MiB memory in use. Of the allocated memory 114.98 MiB is allocated by PyTorch, and 17.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fcaafeec,"{'temperature_head': 0.6000000000000001, 'latent_dim': 145, 'batch_size': 189, 'transform_funcs': (3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 57.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 462.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 472.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 662.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 752.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 536.00 MiB memory in use. Process 4057186 has 694.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 492.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 686.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 470.00 MiB memory in use. Process 4057597 has 670.00 MiB memory in use. Of the allocated memory 114.00 MiB is allocated by PyTorch, and 16.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
66d8f713,"{'temperature_head': 0.4, 'latent_dim': 79, 'batch_size': 496, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 702.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 510.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 662.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 752.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 572.00 MiB memory in use. Process 4057186 has 694.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 446.00 MiB memory in use. Process 4057300 has 442.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 480.00 MiB memory in use. Process 4057597 has 670.00 MiB memory in use. Of the allocated memory 67.14 MiB is allocated by PyTorch, and 38.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
374b1262,"{'temperature_head': 0.6000000000000001, 'latent_dim': 456, 'batch_size': 429, 'transform_funcs': (2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 220.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 53.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 702.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 420.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 510.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 662.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 752.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 572.00 MiB memory in use. Process 4057186 has 694.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 446.00 MiB memory in use. Process 4057300 has 442.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 474.00 MiB memory in use. Process 4057597 has 670.00 MiB memory in use. Of the allocated memory 116.43 MiB is allocated by PyTorch, and 17.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
529ef800,"{'temperature_head': 0.7000000000000001, 'latent_dim': 407, 'batch_size': 298, 'transform_funcs': (8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 67.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 702.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 484.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 662.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 752.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 572.00 MiB memory in use. Process 4057186 has 694.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 486.00 MiB memory in use. Process 4057300 has 442.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 444.00 MiB memory in use. Process 4057597 has 670.00 MiB memory in use. Of the allocated memory 115.99 MiB is allocated by PyTorch, and 28.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
53766ce2,"{'temperature_head': 0.8, 'latent_dim': 224, 'batch_size': 327, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 702.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 518.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 664.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 722.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 572.00 MiB memory in use. Process 4057186 has 730.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 458.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 470.00 MiB memory in use. Process 4057597 has 672.00 MiB memory in use. Of the allocated memory 114.62 MiB is allocated by PyTorch, and 15.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a33f8221,"{'temperature_head': 0.5, 'latent_dim': 489, 'batch_size': 399, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 702.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 420.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 518.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 664.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 722.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 572.00 MiB memory in use. Process 4057186 has 730.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 456.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 462.00 MiB memory in use. Process 4057597 has 672.00 MiB memory in use. Of the allocated memory 70.35 MiB is allocated by PyTorch, and 45.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
294f679b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 311, 'batch_size': 372, 'transform_funcs': (0, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 105.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 742.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 518.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 616.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 722.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 662.00 MiB memory in use. Process 4057186 has 730.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 446.00 MiB memory in use. Process 4057300 has 482.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 480.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 470.00 MiB memory in use. Process 4057597 has 444.00 MiB memory in use. Of the allocated memory 115.30 MiB is allocated by PyTorch, and 14.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b41486dc,"{'temperature_head': 0.30000000000000004, 'latent_dim': 288, 'batch_size': 151, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 140.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 73.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 742.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 480.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 616.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 722.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 662.00 MiB memory in use. Process 4057186 has 760.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 446.00 MiB memory in use. Process 4057300 has 484.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 480.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 508.00 MiB memory in use. Process 4057597 has 444.00 MiB memory in use. Of the allocated memory 115.06 MiB is allocated by PyTorch, and 24.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2ea4bf74,"{'temperature_head': 0.2, 'latent_dim': 190, 'batch_size': 489, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 742.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 518.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 616.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 722.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 662.00 MiB memory in use. Process 4057186 has 760.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 488.00 MiB memory in use. Process 4057300 has 484.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 444.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 508.00 MiB memory in use. Process 4057597 has 462.00 MiB memory in use. Of the allocated memory 114.01 MiB is allocated by PyTorch, and 33.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
678ded39,"{'temperature_head': 0.5, 'latent_dim': 108, 'batch_size': 423, 'transform_funcs': (0, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 742.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 518.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 616.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 744.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 662.00 MiB memory in use. Process 4057186 has 760.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 488.00 MiB memory in use. Process 4057300 has 490.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 444.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 462.00 MiB memory in use. Of the allocated memory 113.71 MiB is allocated by PyTorch, and 18.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
de5250ae,"{'temperature_head': 0.9, 'latent_dim': 161, 'batch_size': 342, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 73.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 742.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 654.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 478.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 616.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 422.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 662.00 MiB memory in use. Process 4057186 has 760.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 522.00 MiB memory in use. Process 4057300 has 460.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 480.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 508.00 MiB memory in use. Process 4057597 has 462.00 MiB memory in use. Of the allocated memory 114.06 MiB is allocated by PyTorch, and 23.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
980c95a1,"{'temperature_head': 0.7000000000000001, 'latent_dim': 208, 'batch_size': 411, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 742.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 654.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 518.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 658.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 422.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 662.00 MiB memory in use. Process 4057186 has 760.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 524.00 MiB memory in use. Process 4057300 has 462.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 480.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 474.00 MiB memory in use. Process 4057597 has 442.00 MiB memory in use. Of the allocated memory 114.49 MiB is allocated by PyTorch, and 19.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b698670c,"{'temperature_head': 0.6000000000000001, 'latent_dim': 663, 'batch_size': 467, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 320.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 275.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 742.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 656.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 482.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 658.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 422.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 662.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 524.00 MiB memory in use. Process 4057300 has 438.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 446.00 MiB memory in use. Process 4057597 has 442.00 MiB memory in use. Of the allocated memory 117.99 MiB is allocated by PyTorch, and 24.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
90f46968,"{'temperature_head': 0.4, 'latent_dim': 568, 'batch_size': 438, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 742.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 656.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 482.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 658.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 422.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 662.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 758.00 MiB memory in use. Process 4057300 has 438.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 446.00 MiB memory in use. Process 4057597 has 442.00 MiB memory in use. Of the allocated memory 391.27 MiB is allocated by PyTorch, and 26.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e0291816,"{'temperature_head': 0.5, 'latent_dim': 148, 'batch_size': 510, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 742.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 656.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 518.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 658.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 422.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 662.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 512.00 MiB memory in use. Process 4057300 has 488.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 426.00 MiB memory in use. Process 4057597 has 624.00 MiB memory in use. Of the allocated memory 68.02 MiB is allocated by PyTorch, and 17.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
feaa5817,"{'temperature_head': 0.9, 'latent_dim': 247, 'batch_size': 363, 'transform_funcs': (3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 742.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 656.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 484.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 658.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 422.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 662.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 512.00 MiB memory in use. Process 4057300 has 524.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 424.00 MiB memory in use. Process 4057597 has 624.00 MiB memory in use. Of the allocated memory 114.73 MiB is allocated by PyTorch, and 29.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2a1becdd,"{'temperature_head': 0.4, 'latent_dim': 57, 'batch_size': 311, 'transform_funcs': (3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 744.00 MiB memory in use. Process 4053180 has 698.00 MiB memory in use. Process 4053182 has 616.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 518.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 422.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 662.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 492.00 MiB memory in use. Process 4057300 has 524.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 426.00 MiB memory in use. Process 4057597 has 624.00 MiB memory in use. Of the allocated memory 67.31 MiB is allocated by PyTorch, and 18.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
218f94b1,"{'temperature_head': 0.8, 'latent_dim': 335, 'batch_size': 292, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 87.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 744.00 MiB memory in use. Process 4053180 has 698.00 MiB memory in use. Process 4053182 has 616.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 478.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 458.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 662.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 492.00 MiB memory in use. Process 4057300 has 446.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 444.00 MiB memory in use. Process 4057597 has 624.00 MiB memory in use. Of the allocated memory 115.42 MiB is allocated by PyTorch, and 22.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5d7ab1fa,"{'temperature_head': 0.30000000000000004, 'latent_dim': 597, 'batch_size': 390, 'transform_funcs': (7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 183.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 828.00 MiB memory in use. Process 4053180 has 694.00 MiB memory in use. Process 4053182 has 616.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 516.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 422.00 MiB memory in use. Process 4056798 has 862.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 662.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 494.00 MiB memory in use. Process 4057300 has 446.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 444.00 MiB memory in use. Process 4057597 has 444.00 MiB memory in use. Of the allocated memory 117.33 MiB is allocated by PyTorch, and 36.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9d9323b8,"{'temperature_head': 0.5, 'latent_dim': 100, 'batch_size': 458, 'transform_funcs': (2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 828.00 MiB memory in use. Process 4053180 has 694.00 MiB memory in use. Process 4053182 has 616.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 480.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 422.00 MiB memory in use. Process 4056798 has 884.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 674.00 MiB memory in use. Process 4057186 has 440.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 530.00 MiB memory in use. Process 4057300 has 446.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 562.00 MiB memory in use. Process 4057597 has 444.00 MiB memory in use. Of the allocated memory 113.58 MiB is allocated by PyTorch, and 26.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8423172d,"{'temperature_head': 0.8, 'latent_dim': 80, 'batch_size': 480, 'transform_funcs': (5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 828.00 MiB memory in use. Process 4053180 has 694.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 426.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 442.00 MiB memory in use. Process 4056798 has 884.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 674.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 540.00 MiB memory in use. Process 4057300 has 530.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 562.00 MiB memory in use. Process 4057597 has 550.00 MiB memory in use. Of the allocated memory 67.49 MiB is allocated by PyTorch, and 18.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d72deda5,"{'temperature_head': 0.6000000000000001, 'latent_dim': 131, 'batch_size': 405, 'transform_funcs': (5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 442.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 470.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 506.00 MiB memory in use. Process 4056798 has 884.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 674.00 MiB memory in use. Process 4057186 has 480.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 576.00 MiB memory in use. Process 4057300 has 446.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 602.00 MiB memory in use. Process 4057597 has 636.00 MiB memory in use. Of the allocated memory 113.89 MiB is allocated by PyTorch, and 16.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4c9af285,"{'temperature_head': 0.4, 'latent_dim': 176, 'batch_size': 420, 'transform_funcs': (0, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 59.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 442.00 MiB memory in use. Process 4053182 has 644.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 508.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 514.00 MiB memory in use. Process 4056798 has 884.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 442.00 MiB memory in use. Process 4057186 has 480.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 576.00 MiB memory in use. Process 4057300 has 446.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 556.00 MiB memory in use. Process 4057597 has 638.00 MiB memory in use. Of the allocated memory 198.83 MiB is allocated by PyTorch, and 17.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3533e2c5,"{'temperature_head': 0.8, 'latent_dim': 112, 'batch_size': 432, 'transform_funcs': (0, 1)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 576.00 MiB memory in use. Process 4053182 has 644.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 640.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 514.00 MiB memory in use. Process 4056798 has 444.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 480.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 538.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 638.00 MiB memory in use. Of the allocated memory 113.74 MiB is allocated by PyTorch, and 18.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6040a3d3,"{'temperature_head': 0.9, 'latent_dim': 71, 'batch_size': 349, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 576.00 MiB memory in use. Process 4053182 has 644.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 640.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 540.00 MiB memory in use. Process 4056798 has 444.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 480.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 538.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 638.00 MiB memory in use. Of the allocated memory 147.21 MiB is allocated by PyTorch, and 50.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cb980382,"{'temperature_head': 0.5, 'latent_dim': 20, 'batch_size': 415, 'transform_funcs': (6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 576.00 MiB memory in use. Process 4053182 has 644.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 640.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 540.00 MiB memory in use. Process 4056798 has 442.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 480.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 462.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 508.00 MiB memory in use. Process 4057597 has 662.00 MiB memory in use. Of the allocated memory 66.68 MiB is allocated by PyTorch, and 35.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2f0ea17a,"{'temperature_head': 0.9, 'latent_dim': 268, 'batch_size': 458, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 614.00 MiB memory in use. Process 4053182 has 644.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 640.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 540.00 MiB memory in use. Process 4056798 has 446.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 488.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 510.00 MiB memory in use. Process 4057597 has 662.00 MiB memory in use. Of the allocated memory 114.62 MiB is allocated by PyTorch, and 33.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
18de5d88,"{'temperature_head': 0.7000000000000001, 'latent_dim': 230, 'batch_size': 367, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 614.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 640.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 540.00 MiB memory in use. Process 4056798 has 446.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 446.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 510.00 MiB memory in use. Process 4057597 has 662.00 MiB memory in use. Of the allocated memory 68.32 MiB is allocated by PyTorch, and 37.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
22858046,"{'temperature_head': 0.4, 'latent_dim': 256, 'batch_size': 383, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 614.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 640.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 422.00 MiB memory in use. Process 4056798 has 492.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 480.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 488.00 MiB memory in use. Process 4057300 has 436.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 510.00 MiB memory in use. Process 4057597 has 662.00 MiB memory in use. Of the allocated memory 114.53 MiB is allocated by PyTorch, and 33.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
044db40b,"{'temperature_head': 0.30000000000000004, 'latent_dim': 165, 'batch_size': 357, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 69.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 614.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 614.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 422.00 MiB memory in use. Process 4056798 has 492.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 480.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 524.00 MiB memory in use. Process 4057300 has 410.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 662.00 MiB memory in use. Of the allocated memory 114.15 MiB is allocated by PyTorch, and 17.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
49fea6b2,"{'temperature_head': 0.6000000000000001, 'latent_dim': 390, 'batch_size': 377, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 81.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 614.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 614.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 422.00 MiB memory in use. Process 4056798 has 492.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 480.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 524.00 MiB memory in use. Process 4057300 has 448.00 MiB memory in use. Process 4057580 has 754.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 422.00 MiB memory in use. Process 4057597 has 662.00 MiB memory in use. Of the allocated memory 115.58 MiB is allocated by PyTorch, and 36.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ab0887c9,"{'temperature_head': 0.9, 'latent_dim': 43, 'batch_size': 403, 'transform_funcs': (2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 614.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 614.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 422.00 MiB memory in use. Process 4056798 has 528.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 480.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 524.00 MiB memory in use. Process 4057300 has 412.00 MiB memory in use. Process 4057580 has 756.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 426.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 67.20 MiB is allocated by PyTorch, and 18.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
105fe968,"{'temperature_head': 0.6000000000000001, 'latent_dim': 63, 'batch_size': 336, 'transform_funcs': (2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 614.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 614.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 436.00 MiB memory in use. Process 4056798 has 490.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 480.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 524.00 MiB memory in use. Process 4057300 has 416.00 MiB memory in use. Process 4057580 has 756.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 444.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 113.02 MiB is allocated by PyTorch, and 36.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
57a968b8,"{'temperature_head': 0.8, 'latent_dim': 214, 'batch_size': 482, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 614.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 582.00 MiB memory in use. Process 4056798 has 444.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 528.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 622.00 MiB memory in use. Process 4057300 has 424.00 MiB memory in use. Process 4057580 has 444.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 114.54 MiB is allocated by PyTorch, and 17.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0dd567b7,"{'temperature_head': 0.7000000000000001, 'latent_dim': 132, 'batch_size': 321, 'transform_funcs': (5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 614.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 582.00 MiB memory in use. Process 4056798 has 494.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 528.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 622.00 MiB memory in use. Process 4057300 has 424.00 MiB memory in use. Process 4057580 has 444.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 446.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 113.56 MiB is allocated by PyTorch, and 40.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6f405f52,"{'temperature_head': 0.30000000000000004, 'latent_dim': 184, 'batch_size': 466, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 444.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 582.00 MiB memory in use. Process 4056798 has 532.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 634.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 622.00 MiB memory in use. Process 4057300 has 436.00 MiB memory in use. Process 4057580 has 444.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 426.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 68.30 MiB is allocated by PyTorch, and 17.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
722a801b,"{'temperature_head': 0.4, 'latent_dim': 153, 'batch_size': 511, 'transform_funcs': (7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 472.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 532.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 634.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 444.00 MiB memory in use. Process 4057300 has 424.00 MiB memory in use. Process 4057580 has 554.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 444.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 114.06 MiB is allocated by PyTorch, and 17.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
392f2b73,"{'temperature_head': 0.5, 'latent_dim': 320, 'batch_size': 303, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 217.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 472.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 492.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 634.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 444.00 MiB memory in use. Process 4057300 has 424.00 MiB memory in use. Process 4057580 has 420.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 444.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 115.03 MiB is allocated by PyTorch, and 36.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7131de59,"{'temperature_head': 0.7000000000000001, 'latent_dim': 104, 'batch_size': 439, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 508.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 530.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 634.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 444.00 MiB memory in use. Process 4057300 has 424.00 MiB memory in use. Process 4057580 has 442.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 522.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 163.68 MiB is allocated by PyTorch, and 18.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d55275fa,"{'temperature_head': 0.9, 'latent_dim': 55, 'batch_size': 424, 'transform_funcs': (9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 508.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 530.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 634.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 420.00 MiB memory in use. Process 4057300 has 424.00 MiB memory in use. Process 4057580 has 442.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 558.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 40.95 MiB is allocated by PyTorch, and 39.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4d34184f,"{'temperature_head': 0.6000000000000001, 'latent_dim': 544, 'batch_size': 411, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 508.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 530.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 634.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 438.00 MiB memory in use. Process 4057300 has 424.00 MiB memory in use. Process 4057580 has 442.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 558.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 90.76 MiB is allocated by PyTorch, and 7.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
ae5c450e,"{'temperature_head': 0.5, 'latent_dim': 125, 'batch_size': 346, 'transform_funcs': (4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 526.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 530.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 634.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 418.00 MiB memory in use. Process 4057300 has 434.00 MiB memory in use. Process 4057580 has 442.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 558.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 50.44 MiB is allocated by PyTorch, and 27.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/dataset_simcrl.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
365f9882,"{'temperature_head': 0.4, 'latent_dim': 280, 'batch_size': 399, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 526.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 492.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 634.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 422.00 MiB memory in use. Process 4057300 has 424.00 MiB memory in use. Process 4057580 has 442.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 558.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 114.71 MiB is allocated by PyTorch, and 37.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ac7716aa,"{'temperature_head': 0.30000000000000004, 'latent_dim': 27, 'batch_size': 386, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 490.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 446.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 444.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 440.00 MiB memory in use. Process 4057300 has 474.00 MiB memory in use. Process 4057580 has 506.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 720.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 67.20 MiB is allocated by PyTorch, and 32.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
94b245b4,"{'temperature_head': 0.6000000000000001, 'latent_dim': 166, 'batch_size': 369, 'transform_funcs': (2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 680.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 490.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 446.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 444.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 440.00 MiB memory in use. Process 4057300 has 474.00 MiB memory in use. Process 4057580 has 506.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 720.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 67.82 MiB is allocated by PyTorch, and 38.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f1e04c41,"{'temperature_head': 0.8, 'latent_dim': 238, 'batch_size': 454, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 682.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 462.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 444.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 444.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 488.00 MiB memory in use. Process 4057300 has 484.00 MiB memory in use. Process 4057580 has 478.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 720.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 114.39 MiB is allocated by PyTorch, and 33.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3ce703e6,"{'temperature_head': 0.9, 'latent_dim': 90, 'batch_size': 430, 'transform_funcs': (4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 682.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 462.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 490.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 444.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 488.00 MiB memory in use. Process 4057300 has 424.00 MiB memory in use. Process 4057580 has 478.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 720.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 113.23 MiB is allocated by PyTorch, and 36.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
eecf8e82,"{'temperature_head': 0.2, 'latent_dim': 506, 'batch_size': 330, 'transform_funcs': (3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 682.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 474.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 444.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 468.00 MiB memory in use. Process 4057300 has 436.00 MiB memory in use. Process 4057580 has 516.00 MiB memory in use. Process 4057583 has 650.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 720.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 116.82 MiB is allocated by PyTorch, and 17.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fa4c6e0d,"{'temperature_head': 0.7000000000000001, 'latent_dim': 357, 'batch_size': 356, 'transform_funcs': (3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 682.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 508.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 446.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 492.00 MiB memory in use. Process 4057300 has 448.00 MiB memory in use. Process 4057580 has 516.00 MiB memory in use. Process 4057583 has 596.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 720.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 115.32 MiB is allocated by PyTorch, and 36.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2ad8a826,"{'temperature_head': 0.4, 'latent_dim': 114, 'batch_size': 505, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 53.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 764.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 480.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 568.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 530.00 MiB memory in use. Process 4057300 has 440.00 MiB memory in use. Process 4057580 has 514.00 MiB memory in use. Process 4057583 has 596.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 488.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 113.69 MiB is allocated by PyTorch, and 26.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4a8129e1,"{'temperature_head': 0.6000000000000001, 'latent_dim': 304, 'batch_size': 418, 'transform_funcs': (1, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 89.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 764.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 480.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 568.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 494.00 MiB memory in use. Process 4057300 has 440.00 MiB memory in use. Process 4057580 has 514.00 MiB memory in use. Process 4057583 has 596.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 488.00 MiB memory in use. Process 4057597 has 700.00 MiB memory in use. Of the allocated memory 114.90 MiB is allocated by PyTorch, and 39.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
273d9d66,"{'temperature_head': 0.8, 'latent_dim': 143, 'batch_size': 315, 'transform_funcs': (2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 17.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 764.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 602.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 568.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 446.00 MiB memory in use. Process 4057300 has 552.00 MiB memory in use. Process 4057580 has 524.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 516.00 MiB memory in use. Process 4057597 has 702.00 MiB memory in use. Of the allocated memory 67.64 MiB is allocated by PyTorch, and 38.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
84f7801a,"{'temperature_head': 0.1, 'latent_dim': 447, 'batch_size': 439, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 764.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 602.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 694.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 568.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 446.00 MiB memory in use. Process 4057300 has 552.00 MiB memory in use. Process 4057580 has 524.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 478.00 MiB memory in use. Process 4057597 has 702.00 MiB memory in use. Of the allocated memory 116.36 MiB is allocated by PyTorch, and 21.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
997e0b6a,"{'temperature_head': 0.7000000000000001, 'latent_dim': 253, 'batch_size': 495, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 73.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 764.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 602.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 656.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 444.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 480.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 482.00 MiB memory in use. Process 4057300 has 588.00 MiB memory in use. Process 4057580 has 444.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 510.00 MiB memory in use. Process 4057597 has 784.00 MiB memory in use. Of the allocated memory 114.97 MiB is allocated by PyTorch, and 27.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
76891b7a,"{'temperature_head': 0.4, 'latent_dim': 100, 'batch_size': 386, 'transform_funcs': (0, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 592.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 656.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 492.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 480.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 520.00 MiB memory in use. Process 4057300 has 600.00 MiB memory in use. Process 4057580 has 444.00 MiB memory in use. Process 4057583 has 440.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 818.00 MiB memory in use. Process 4057597 has 784.00 MiB memory in use. Of the allocated memory 113.31 MiB is allocated by PyTorch, and 38.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
efaafbf5,"{'temperature_head': 0.8, 'latent_dim': 156, 'batch_size': 375, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 592.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 656.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 466.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 534.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 484.00 MiB memory in use. Process 4057300 has 600.00 MiB memory in use. Process 4057580 has 446.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 818.00 MiB memory in use. Process 4057597 has 784.00 MiB memory in use. Of the allocated memory 114.21 MiB is allocated by PyTorch, and 29.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6eeeab4e,"{'temperature_head': 0.30000000000000004, 'latent_dim': 377, 'batch_size': 410, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 592.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 656.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 450.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 572.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 436.00 MiB memory in use. Process 4057300 has 600.00 MiB memory in use. Process 4057580 has 460.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 818.00 MiB memory in use. Process 4057597 has 784.00 MiB memory in use. Of the allocated memory 69.47 MiB is allocated by PyTorch, and 40.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
228cd6b8,"{'temperature_head': 1.0, 'latent_dim': 39, 'batch_size': 471, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 592.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 656.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 484.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 572.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 410.00 MiB memory in use. Process 4057300 has 600.00 MiB memory in use. Process 4057580 has 460.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 818.00 MiB memory in use. Process 4057597 has 784.00 MiB memory in use. Of the allocated memory 41.29 MiB is allocated by PyTorch, and 28.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7193fbc6,"{'temperature_head': 0.7000000000000001, 'latent_dim': 329, 'batch_size': 392, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 650.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 592.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 492.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 572.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 518.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 562.00 MiB memory in use. Process 4057583 has 608.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 818.00 MiB memory in use. Process 4057597 has 784.00 MiB memory in use. Of the allocated memory 115.10 MiB is allocated by PyTorch, and 36.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5d56c275,"{'temperature_head': 0.2, 'latent_dim': 720, 'batch_size': 426, 'transform_funcs': (3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 628.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 522.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 528.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 622.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 514.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 562.00 MiB memory in use. Process 4057583 has 608.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 818.00 MiB memory in use. Process 4057597 has 784.00 MiB memory in use. Of the allocated memory 118.63 MiB is allocated by PyTorch, and 55.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
dd12c85b,"{'temperature_head': 0.5, 'latent_dim': 121, 'batch_size': 336, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 57.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 628.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 522.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 552.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 622.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 458.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 562.00 MiB memory in use. Process 4057583 has 608.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 818.00 MiB memory in use. Process 4057597 has 784.00 MiB memory in use. Of the allocated memory 171.63 MiB is allocated by PyTorch, and 40.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
196cbf32,"{'temperature_head': 1.0, 'latent_dim': 211, 'batch_size': 482, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 664.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 522.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 526.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 444.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 622.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 590.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 818.00 MiB memory in use. Process 4057597 has 784.00 MiB memory in use. Of the allocated memory 216.17 MiB is allocated by PyTorch, and 33.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ba7189a8,"{'temperature_head': 0.4, 'latent_dim': 680, 'batch_size': 162, 'transform_funcs': (4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 328.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 93.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 664.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 472.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 526.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 444.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 622.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 590.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 818.00 MiB memory in use. Process 4057597 has 784.00 MiB memory in use. Of the allocated memory 118.30 MiB is allocated by PyTorch, and 13.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
232214d9,"{'temperature_head': 0.8, 'latent_dim': 195, 'batch_size': 355, 'transform_funcs': (8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 664.00 MiB memory in use. Process 4053182 has 434.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 514.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 488.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 446.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 622.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 628.00 MiB memory in use. Process 4057300 has 446.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 818.00 MiB memory in use. Process 4057597 has 784.00 MiB memory in use. Of the allocated memory 68.05 MiB is allocated by PyTorch, and 37.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
be01ccea,"{'temperature_head': 0.30000000000000004, 'latent_dim': 633, 'batch_size': 294, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 664.00 MiB memory in use. Process 4053182 has 530.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 492.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 422.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 484.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 760.00 MiB memory in use. Process 4057300 has 436.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 480.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 818.00 MiB memory in use. Process 4057597 has 784.00 MiB memory in use. Of the allocated memory 117.75 MiB is allocated by PyTorch, and 34.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3820067d,"{'temperature_head': 0.8, 'latent_dim': 402, 'batch_size': 183, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 664.00 MiB memory in use. Process 4053182 has 530.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 462.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 422.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 746.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 496.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 760.00 MiB memory in use. Process 4057300 has 414.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 480.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 818.00 MiB memory in use. Process 4057597 has 784.00 MiB memory in use. Of the allocated memory 115.67 MiB is allocated by PyTorch, and 40.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e85216a0,"{'temperature_head': 0.9, 'latent_dim': 295, 'batch_size': 345, 'transform_funcs': (0, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 864.00 MiB memory in use. Process 4053180 has 664.00 MiB memory in use. Process 4053182 has 530.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 428.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 608.00 MiB memory in use. Process 4056803 has 618.00 MiB memory in use. Process 4056798 has 528.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 524.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 760.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 526.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 784.00 MiB memory in use. Process 4057597 has 784.00 MiB memory in use. Of the allocated memory 69.17 MiB is allocated by PyTorch, and 18.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
421b3af8,"{'temperature_head': 0.4, 'latent_dim': 139, 'batch_size': 220, 'transform_funcs': (1, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 664.00 MiB memory in use. Process 4053182 has 566.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 448.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 422.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 608.00 MiB memory in use. Process 4056803 has 614.00 MiB memory in use. Process 4056798 has 562.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 526.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 760.00 MiB memory in use. Process 4057300 has 484.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 784.00 MiB memory in use. Process 4057597 has 766.00 MiB memory in use. Of the allocated memory 180.42 MiB is allocated by PyTorch, and 41.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
84335f4e,"{'temperature_head': 0.30000000000000004, 'latent_dim': 343, 'batch_size': 268, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 566.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 472.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 400.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 614.00 MiB memory in use. Process 4056798 has 444.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 526.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 796.00 MiB memory in use. Process 4057300 has 484.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 784.00 MiB memory in use. Process 4057597 has 766.00 MiB memory in use. Of the allocated memory 115.55 MiB is allocated by PyTorch, and 16.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
82083b5e,"{'temperature_head': 1.0, 'latent_dim': 102, 'batch_size': 506, 'transform_funcs': (7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 566.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 508.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 410.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 614.00 MiB memory in use. Process 4056798 has 422.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 488.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 796.00 MiB memory in use. Process 4057300 has 514.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 442.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 784.00 MiB memory in use. Process 4057597 has 766.00 MiB memory in use. Of the allocated memory 41.32 MiB is allocated by PyTorch, and 40.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e2d2d780,"{'temperature_head': 0.8, 'latent_dim': 14, 'batch_size': 475, 'transform_funcs': (5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 596.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 436.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 650.00 MiB memory in use. Process 4056798 has 444.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 796.00 MiB memory in use. Process 4057300 has 550.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 434.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 784.00 MiB memory in use. Process 4057597 has 766.00 MiB memory in use. Of the allocated memory 66.63 MiB is allocated by PyTorch, and 37.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c5006290,"{'temperature_head': 0.5, 'latent_dim': 253, 'batch_size': 463, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 95.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 696.00 MiB memory in use. Process 4053182 has 446.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 634.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 472.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 620.00 MiB memory in use. Process 4056798 has 614.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 428.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 796.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 518.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 486.00 MiB memory in use. Process 4057597 has 790.00 MiB memory in use. Of the allocated memory 236.50 MiB is allocated by PyTorch, and 37.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6458d6d9,"{'temperature_head': 0.5, 'latent_dim': 429, 'batch_size': 452, 'transform_funcs': (5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 63.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 446.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 634.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 658.00 MiB memory in use. Process 4056798 has 462.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 414.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 798.00 MiB memory in use. Process 4057300 has 530.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 782.00 MiB memory in use. Of the allocated memory 116.22 MiB is allocated by PyTorch, and 15.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1171c904,"{'temperature_head': 0.4, 'latent_dim': 277, 'batch_size': 275, 'transform_funcs': (3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 134.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 446.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 648.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 658.00 MiB memory in use. Process 4056798 has 462.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 452.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 798.00 MiB memory in use. Process 4057300 has 530.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 782.00 MiB memory in use. Of the allocated memory 248.09 MiB is allocated by PyTorch, and 59.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bf6d1ad3,"{'temperature_head': 0.4, 'latent_dim': 317, 'batch_size': 237, 'transform_funcs': (3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 472.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 684.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 442.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 658.00 MiB memory in use. Process 4056798 has 488.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 454.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 798.00 MiB memory in use. Process 4057300 has 424.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 462.00 MiB memory in use. Process 4057597 has 782.00 MiB memory in use. Of the allocated memory 115.00 MiB is allocated by PyTorch, and 33.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d79774bb,"{'temperature_head': 0.5, 'latent_dim': 365, 'batch_size': 337, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 97.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 472.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 684.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 480.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 658.00 MiB memory in use. Process 4056798 has 468.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 454.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 720.00 MiB memory in use. Process 4057300 has 424.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 462.00 MiB memory in use. Process 4057597 has 782.00 MiB memory in use. Of the allocated memory 290.50 MiB is allocated by PyTorch, and 89.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7f367f3a,"{'temperature_head': 0.5, 'latent_dim': 263, 'batch_size': 359, 'transform_funcs': (3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 472.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 728.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 480.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 658.00 MiB memory in use. Process 4056798 has 468.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 750.00 MiB memory in use. Process 4057186 has 454.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 758.00 MiB memory in use. Process 4057300 has 424.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 462.00 MiB memory in use. Process 4057597 has 782.00 MiB memory in use. Of the allocated memory 240.39 MiB is allocated by PyTorch, and 147.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
96628bc3,"{'temperature_head': 0.2, 'latent_dim': 307, 'batch_size': 401, 'transform_funcs': (0, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 69.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 472.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 764.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 480.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 658.00 MiB memory in use. Process 4056798 has 468.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 650.00 MiB memory in use. Process 4057186 has 454.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 758.00 MiB memory in use. Process 4057300 has 424.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 782.00 MiB memory in use. Of the allocated memory 115.27 MiB is allocated by PyTorch, and 16.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
66847059,"{'temperature_head': 0.4, 'latent_dim': 346, 'batch_size': 326, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 472.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 766.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 480.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 658.00 MiB memory in use. Process 4056798 has 448.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 650.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 758.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 514.00 MiB memory in use. Process 4057597 has 782.00 MiB memory in use. Of the allocated memory 69.23 MiB is allocated by PyTorch, and 38.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4e37e596,"{'temperature_head': 0.5, 'latent_dim': 292, 'batch_size': 385, 'transform_funcs': (2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 77.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 432.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 766.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 480.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 658.00 MiB memory in use. Process 4056798 has 482.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 650.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 724.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 514.00 MiB memory in use. Process 4057597 has 782.00 MiB memory in use. Of the allocated memory 254.28 MiB is allocated by PyTorch, and 129.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cec84181,"{'temperature_head': 0.4, 'latent_dim': 586, 'batch_size': 348, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 282.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 195.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 472.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 596.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 606.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 484.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 442.00 MiB memory in use. Process 4057186 has 526.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 490.00 MiB memory in use. Process 4057300 has 528.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 540.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 116.17 MiB is allocated by PyTorch, and 139.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9a60569d,"{'temperature_head': 0.5, 'latent_dim': 509, 'batch_size': 254, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 151.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 472.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 632.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 606.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 484.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 442.00 MiB memory in use. Process 4057186 has 526.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 498.00 MiB memory in use. Process 4057300 has 528.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 540.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 116.51 MiB is allocated by PyTorch, and 41.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
82640335,"{'temperature_head': 0.30000000000000004, 'latent_dim': 527, 'batch_size': 315, 'transform_funcs': (6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 568.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 632.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 606.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 490.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 442.00 MiB memory in use. Process 4057186 has 526.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 532.00 MiB memory in use. Process 4057300 has 528.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 540.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 117.10 MiB is allocated by PyTorch, and 32.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
42de83ed,"{'temperature_head': 0.30000000000000004, 'latent_dim': 614, 'batch_size': 299, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 81.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 568.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 632.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 606.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 490.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 442.00 MiB memory in use. Process 4057186 has 526.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 532.00 MiB memory in use. Process 4057300 has 528.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 474.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 117.85 MiB is allocated by PyTorch, and 16.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
615cfc26,"{'temperature_head': 0.4, 'latent_dim': 416, 'batch_size': 370, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 568.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 596.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 446.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 466.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 442.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 532.00 MiB memory in use. Process 4057300 has 574.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 510.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 115.17 MiB is allocated by PyTorch, and 140.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a6fdcbb2,"{'temperature_head': 0.5, 'latent_dim': 452, 'batch_size': 408, 'transform_funcs': (6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 67.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 568.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 620.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 446.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 466.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 442.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 496.00 MiB memory in use. Process 4057300 has 574.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 510.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 116.06 MiB is allocated by PyTorch, and 39.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
01578e3f,"{'temperature_head': 0.30000000000000004, 'latent_dim': 244, 'batch_size': 283, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 634.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 446.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 494.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 460.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 530.00 MiB memory in use. Process 4057300 has 574.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 590.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 232.77 MiB is allocated by PyTorch, and 17.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ac3156ee,"{'temperature_head': 0.2, 'latent_dim': 391, 'batch_size': 378, 'transform_funcs': (5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 634.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 446.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 494.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 460.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 530.00 MiB memory in use. Process 4057300 has 574.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 590.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 115.58 MiB is allocated by PyTorch, and 38.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
91916fc1,"{'temperature_head': 0.6000000000000001, 'latent_dim': 279, 'batch_size': 416, 'transform_funcs': (7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 85.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 634.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 484.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 528.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 488.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 492.00 MiB memory in use. Process 4057300 has 574.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 462.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 114.71 MiB is allocated by PyTorch, and 37.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a8f91c8d,"{'temperature_head': 0.1, 'latent_dim': 470, 'batch_size': 395, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 75.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 594.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 484.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 530.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 624.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 532.00 MiB memory in use. Process 4057300 has 446.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 462.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 115.60 MiB is allocated by PyTorch, and 138.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b6c7c4d9,"{'temperature_head': 0.6000000000000001, 'latent_dim': 228, 'batch_size': 333, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 594.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 448.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 602.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 624.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 532.00 MiB memory in use. Process 4057300 has 446.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 462.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 224.31 MiB is allocated by PyTorch, and 37.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2f32789d,"{'temperature_head': 0.5, 'latent_dim': 358, 'batch_size': 289, 'transform_funcs': (0, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 630.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 448.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 644.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 602.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 624.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 492.00 MiB memory in use. Process 4057300 has 446.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 462.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 115.32 MiB is allocated by PyTorch, and 36.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b8cd71fd,"{'temperature_head': 0.4, 'latent_dim': 328, 'batch_size': 136, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 416.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 630.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 640.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 624.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 446.00 MiB memory in use. Process 4057300 has 446.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 426.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 69.43 MiB is allocated by PyTorch, and 16.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e73d8bca,"{'temperature_head': 1.0, 'latent_dim': 156, 'batch_size': 352, 'transform_funcs': (4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 630.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 632.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 624.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 446.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 598.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 446.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 187.84 MiB is allocated by PyTorch, and 104.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
28c86b61,"{'temperature_head': 0.4, 'latent_dim': 200, 'batch_size': 343, 'transform_funcs': (6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 71.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 594.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 632.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 624.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 446.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 586.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 446.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 113.48 MiB is allocated by PyTorch, and 140.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cd7b4edf,"{'temperature_head': 0.7000000000000001, 'latent_dim': 171, 'batch_size': 443, 'transform_funcs': (3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 444.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 670.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 624.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 446.00 MiB memory in use. Process 4057300 has 490.00 MiB memory in use. Process 4057580 has 586.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 558.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 196.39 MiB is allocated by PyTorch, and 21.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c7a0e525,"{'temperature_head': 0.30000000000000004, 'latent_dim': 235, 'batch_size': 309, 'transform_funcs': (4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 422.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 444.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 670.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 624.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 446.00 MiB memory in use. Process 4057300 has 490.00 MiB memory in use. Process 4057580 has 586.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 558.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 68.36 MiB is allocated by PyTorch, and 37.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
66456665,"{'temperature_head': 0.4, 'latent_dim': 216, 'batch_size': 428, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 410.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 472.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 670.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 624.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 460.00 MiB memory in use. Process 4057300 has 424.00 MiB memory in use. Process 4057580 has 586.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 596.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 114.55 MiB is allocated by PyTorch, and 17.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9e6228dd,"{'temperature_head': 0.6000000000000001, 'latent_dim': 442, 'batch_size': 394, 'transform_funcs': (1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 446.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 510.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 782.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 434.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 460.00 MiB memory in use. Process 4057300 has 472.00 MiB memory in use. Process 4057580 has 420.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 726.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 327.89 MiB is allocated by PyTorch, and 58.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5108a844,"{'temperature_head': 0.5, 'latent_dim': 483, 'batch_size': 369, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 446.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 510.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 782.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 434.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 456.00 MiB memory in use. Process 4057300 has 474.00 MiB memory in use. Process 4057580 has 422.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 726.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 70.30 MiB is allocated by PyTorch, and 45.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b3185aa2,"{'temperature_head': 0.8, 'latent_dim': 302, 'batch_size': 229, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 125.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 446.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 480.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 630.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 782.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 422.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 494.00 MiB memory in use. Process 4057300 has 474.00 MiB memory in use. Process 4057580 has 422.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 434.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 115.17 MiB is allocated by PyTorch, and 24.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3d01e87b,"{'temperature_head': 0.9, 'latent_dim': 371, 'batch_size': 384, 'transform_funcs': (0, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 482.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 516.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 630.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 782.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 434.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 494.00 MiB memory in use. Process 4057300 has 474.00 MiB memory in use. Process 4057580 has 422.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 428.00 MiB memory in use. Process 4057597 has 818.00 MiB memory in use. Of the allocated memory 69.77 MiB is allocated by PyTorch, and 18.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
55f9d4cf,"{'temperature_head': 0.4, 'latent_dim': 400, 'batch_size': 404, 'transform_funcs': (3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 518.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 516.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 630.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 782.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 434.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 504.00 MiB memory in use. Process 4057300 has 474.00 MiB memory in use. Process 4057580 has 422.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 424.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 115.65 MiB is allocated by PyTorch, and 48.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
45aa035a,"{'temperature_head': 0.7000000000000001, 'latent_dim': 73, 'batch_size': 436, 'transform_funcs': (2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 518.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 528.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 630.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 782.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 410.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 504.00 MiB memory in use. Process 4057300 has 474.00 MiB memory in use. Process 4057580 has 420.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 438.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 148.46 MiB is allocated by PyTorch, and 39.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c68dd1fd,"{'temperature_head': 0.8, 'latent_dim': 50, 'batch_size': 489, 'transform_funcs': (9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 518.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 444.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 630.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 782.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 446.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 444.00 MiB memory in use. Process 4057300 has 520.00 MiB memory in use. Process 4057580 has 422.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 470.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 113.25 MiB is allocated by PyTorch, and 16.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ac0ffc09,"{'temperature_head': 0.7000000000000001, 'latent_dim': 130, 'batch_size': 459, 'transform_funcs': (0, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 5.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 484.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 470.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 436.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 820.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 458.00 MiB memory in use. Process 4057186 has 690.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 582.00 MiB memory in use. Process 4057300 has 522.00 MiB memory in use. Process 4057580 has 422.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 508.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 113.88 MiB is allocated by PyTorch, and 16.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0670d929,"{'temperature_head': 0.5, 'latent_dim': 112, 'batch_size': 511, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 53.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 518.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 424.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 436.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 820.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 422.00 MiB memory in use. Process 4057186 has 614.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 582.00 MiB memory in use. Process 4057300 has 634.00 MiB memory in use. Process 4057580 has 422.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 113.74 MiB is allocated by PyTorch, and 18.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f97f6012,"{'temperature_head': 0.5, 'latent_dim': 38, 'batch_size': 413, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 518.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 424.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 474.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 820.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 434.00 MiB memory in use. Process 4057186 has 614.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 582.00 MiB memory in use. Process 4057300 has 636.00 MiB memory in use. Process 4057580 has 422.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 444.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 67.16 MiB is allocated by PyTorch, and 16.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
53bfc9e9,"{'temperature_head': 0.8, 'latent_dim': 202, 'batch_size': 469, 'transform_funcs': (3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 518.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 462.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 474.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 820.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 422.00 MiB memory in use. Process 4057186 has 614.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 582.00 MiB memory in use. Process 4057300 has 636.00 MiB memory in use. Process 4057580 has 422.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 410.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 41.98 MiB is allocated by PyTorch, and 28.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d30655c3,"{'temperature_head': 0.9, 'latent_dim': 83, 'batch_size': 389, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 654.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 520.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 820.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 518.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 620.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 468.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 424.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 67.51 MiB is allocated by PyTorch, and 16.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e15f7af2,"{'temperature_head': 0.4, 'latent_dim': 289, 'batch_size': 360, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 654.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 520.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 820.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 518.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 620.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 506.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 428.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 71.55 MiB is allocated by PyTorch, and 16.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 46, in calculate_loss
    logits = torch.cat([torch.cat([logits_ab, logits_aa], dim=1), torch.cat([logits_ba, logits_bb], dim=1)], dim=0)
"
8377759d,"{'temperature_head': 0.30000000000000004, 'latent_dim': 320, 'batch_size': 441, 'transform_funcs': (2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 654.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 520.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 820.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 518.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 620.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 506.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 428.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 74.91 MiB is allocated by PyTorch, and 13.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 46, in calculate_loss
    logits = torch.cat([torch.cat([logits_ab, logits_aa], dim=1), torch.cat([logits_ba, logits_bb], dim=1)], dim=0)
"
934c6a16,"{'temperature_head': 0.7000000000000001, 'latent_dim': 106, 'batch_size': 399, 'transform_funcs': (0, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 52.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 526.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 654.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 820.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 518.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 540.00 MiB memory in use. Process 4057300 has 490.00 MiB memory in use. Process 4057580 has 506.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 446.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 164.30 MiB is allocated by PyTorch, and 35.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4953cd2f,"{'temperature_head': 0.5, 'latent_dim': 245, 'batch_size': 494, 'transform_funcs': (8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 654.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 446.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 820.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 604.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 436.00 MiB memory in use. Process 4057300 has 528.00 MiB memory in use. Process 4057580 has 506.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 114.78 MiB is allocated by PyTorch, and 17.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
532f7be9,"{'temperature_head': 0.9, 'latent_dim': 58, 'batch_size': 379, 'transform_funcs': (4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 442.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 654.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 446.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 820.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 604.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 438.00 MiB memory in use. Process 4057300 has 528.00 MiB memory in use. Process 4057580 has 506.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 67.44 MiB is allocated by PyTorch, and 30.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d891960f,"{'temperature_head': 1.0, 'latent_dim': 133, 'batch_size': 418, 'transform_funcs': (1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 480.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 654.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 800.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 604.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 476.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 560.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 113.90 MiB is allocated by PyTorch, and 18.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
318138a2,"{'temperature_head': 0.5, 'latent_dim': 263, 'batch_size': 405, 'transform_funcs': (2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 480.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 464.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 800.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 604.00 MiB memory in use. Process 4057186 has 600.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 484.00 MiB memory in use. Process 4057300 has 446.00 MiB memory in use. Process 4057580 has 560.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 492.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 115.05 MiB is allocated by PyTorch, and 28.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f14250f8,"{'temperature_head': 0.4, 'latent_dim': 22, 'batch_size': 463, 'transform_funcs': (0, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 480.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 466.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 444.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 800.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 642.00 MiB memory in use. Process 4057186 has 600.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 446.00 MiB memory in use. Process 4057300 has 446.00 MiB memory in use. Process 4057580 has 560.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 470.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 113.04 MiB is allocated by PyTorch, and 16.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7f6c9164,"{'temperature_head': 0.6000000000000001, 'latent_dim': 342, 'batch_size': 372, 'transform_funcs': (3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 480.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 474.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 446.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 800.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 642.00 MiB memory in use. Process 4057186 has 600.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 446.00 MiB memory in use. Process 4057300 has 446.00 MiB memory in use. Process 4057580 has 560.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 470.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 115.54 MiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a530ec6c,"{'temperature_head': 0.30000000000000004, 'latent_dim': 171, 'batch_size': 435, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 480.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 444.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 482.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 800.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 642.00 MiB memory in use. Process 4057186 has 600.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 446.00 MiB memory in use. Process 4057300 has 446.00 MiB memory in use. Process 4057580 has 560.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 462.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 67.86 MiB is allocated by PyTorch, and 38.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
38a9484a,"{'temperature_head': 0.9, 'latent_dim': 119, 'batch_size': 449, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 480.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 530.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 482.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 800.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 642.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 482.00 MiB memory in use. Process 4057300 has 484.00 MiB memory in use. Process 4057580 has 560.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 462.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 171.79 MiB is allocated by PyTorch, and 18.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
25e4b1c5,"{'temperature_head': 0.8, 'latent_dim': 274, 'batch_size': 329, 'transform_funcs': (8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 9.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 480.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 542.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 482.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 800.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 642.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 482.00 MiB memory in use. Process 4057300 has 484.00 MiB memory in use. Process 4057580 has 560.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 474.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 115.01 MiB is allocated by PyTorch, and 18.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0b609233,"{'temperature_head': 0.5, 'latent_dim': 92, 'batch_size': 355, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 564.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 444.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 424.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 800.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 642.00 MiB memory in use. Process 4057186 has 442.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 490.00 MiB memory in use. Process 4057300 has 484.00 MiB memory in use. Process 4057580 has 560.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 508.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 113.24 MiB is allocated by PyTorch, and 36.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
85a1b174,"{'temperature_head': 0.6000000000000001, 'latent_dim': 145, 'batch_size': 471, 'transform_funcs': (5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 71.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 564.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 444.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 436.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 838.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 642.00 MiB memory in use. Process 4057186 has 480.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 446.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 560.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 114.00 MiB is allocated by PyTorch, and 18.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f3a3d0e9,"{'temperature_head': 0.4, 'latent_dim': 209, 'batch_size': 364, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 564.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 472.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 436.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 838.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 642.00 MiB memory in use. Process 4057186 has 480.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 446.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 560.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 472.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 114.50 MiB is allocated by PyTorch, and 17.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
32d48415,"{'temperature_head': 0.7000000000000001, 'latent_dim': 179, 'batch_size': 414, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.56 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4021085 has 1.26 GiB memory in use. Process 4024297 has 992.00 MiB memory in use. Process 4024689 has 1.03 GiB memory in use. Process 4025083 has 1.15 GiB memory in use. Process 4025510 has 1.10 GiB memory in use. Process 4053142 has 866.00 MiB memory in use. Process 4053180 has 734.00 MiB memory in use. Process 4053182 has 564.00 MiB memory in use. Process 4053184 has 1.32 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 940.00 MiB memory in use. Process 4056414 has 726.00 MiB memory in use. Process 4056409 has 424.00 MiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 482.00 MiB memory in use. Process 4056793 has 946.00 MiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 754.00 MiB memory in use. Process 4056798 has 838.00 MiB memory in use. Process 4056804 has 1.05 GiB memory in use. Process 4057192 has 642.00 MiB memory in use. Process 4057186 has 480.00 MiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 418.00 MiB memory in use. Process 4057300 has 444.00 MiB memory in use. Process 4057580 has 560.00 MiB memory in use. Process 4057583 has 604.00 MiB memory in use. Process 4057577 has 782.00 MiB memory in use. Process 4057586 has 508.00 MiB memory in use. Process 4057597 has 820.00 MiB memory in use. Of the allocated memory 41.92 MiB is allocated by PyTorch, and 36.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bab11155,"{'temperature_head': 0.9, 'latent_dim': 511, 'batch_size': 403, 'transform_funcs': (4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 148.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4053142 has 646.00 MiB memory in use. Process 4053180 has 864.00 MiB memory in use. Process 4053182 has 840.00 MiB memory in use. Process 4053184 has 1.12 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 1.08 GiB memory in use. Process 4056414 has 816.00 MiB memory in use. Process 4056409 has 1.28 GiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 838.00 MiB memory in use. Process 4056793 has 1.10 GiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 668.00 MiB memory in use. Process 4056798 has 1.29 GiB memory in use. Process 4056804 has 1.07 GiB memory in use. Process 4057192 has 656.00 MiB memory in use. Process 4057186 has 1.15 GiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 936.00 MiB memory in use. Process 4057300 has 944.00 MiB memory in use. Process 4057580 has 924.00 MiB memory in use. Process 4057583 has 844.00 MiB memory in use. Process 4057577 has 914.00 MiB memory in use. Process 4057586 has 1.16 GiB memory in use. Process 4057597 has 1.11 GiB memory in use. Of the allocated memory 361.53 MiB is allocated by PyTorch, and 442.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ce97a3c5,"{'temperature_head': 0.8, 'latent_dim': 412, 'batch_size': 324, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 188.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4053142 has 790.00 MiB memory in use. Process 4053180 has 804.00 MiB memory in use. Process 4053182 has 840.00 MiB memory in use. Process 4053184 has 1.15 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 1.08 GiB memory in use. Process 4056414 has 816.00 MiB memory in use. Process 4056409 has 1.31 GiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 838.00 MiB memory in use. Process 4056793 has 1.10 GiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 1.29 GiB memory in use. Process 4056804 has 1.07 GiB memory in use. Process 4057192 has 656.00 MiB memory in use. Process 4057186 has 1.15 GiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 1.10 GiB memory in use. Process 4057300 has 998.00 MiB memory in use. Process 4057580 has 924.00 MiB memory in use. Process 4057583 has 844.00 MiB memory in use. Process 4057577 has 914.00 MiB memory in use. Process 4057586 has 674.00 MiB memory in use. Process 4057597 has 1.11 GiB memory in use. Of the allocated memory 314.12 MiB is allocated by PyTorch, and 19.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
80df10e7,"{'temperature_head': 0.6000000000000001, 'latent_dim': 346, 'batch_size': 327, 'transform_funcs': (2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 170.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4053142 has 800.00 MiB memory in use. Process 4053180 has 804.00 MiB memory in use. Process 4053182 has 840.00 MiB memory in use. Process 4053184 has 1.15 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 1.08 GiB memory in use. Process 4056414 has 816.00 MiB memory in use. Process 4056409 has 1.34 GiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 838.00 MiB memory in use. Process 4056793 has 1.10 GiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 1.29 GiB memory in use. Process 4056804 has 1.07 GiB memory in use. Process 4057192 has 680.00 MiB memory in use. Process 4057186 has 1.15 GiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 1.24 GiB memory in use. Process 4057300 has 1000.00 MiB memory in use. Process 4057580 has 924.00 MiB memory in use. Process 4057583 has 844.00 MiB memory in use. Process 4057577 has 914.00 MiB memory in use. Process 4057586 has 476.00 MiB memory in use. Process 4057597 has 1.11 GiB memory in use. Of the allocated memory 115.57 MiB is allocated by PyTorch, and 20.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c6324aa7,"{'temperature_head': 1.0, 'latent_dim': 150, 'batch_size': 347, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4053142 has 800.00 MiB memory in use. Process 4053180 has 804.00 MiB memory in use. Process 4053182 has 840.00 MiB memory in use. Process 4053184 has 1.15 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 1.08 GiB memory in use. Process 4056414 has 816.00 MiB memory in use. Process 4056409 has 1.34 GiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 838.00 MiB memory in use. Process 4056793 has 1.10 GiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 750.00 MiB memory in use. Process 4056798 has 1.29 GiB memory in use. Process 4056804 has 1.07 GiB memory in use. Process 4057192 has 718.00 MiB memory in use. Process 4057186 has 1.15 GiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 1.24 GiB memory in use. Process 4057300 has 1000.00 MiB memory in use. Process 4057580 has 924.00 MiB memory in use. Process 4057583 has 844.00 MiB memory in use. Process 4057577 has 914.00 MiB memory in use. Process 4057586 has 546.00 MiB memory in use. Process 4057597 has 1.11 GiB memory in use. Of the allocated memory 186.14 MiB is allocated by PyTorch, and 19.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6e353b99,"{'temperature_head': 1.0, 'latent_dim': 330, 'batch_size': 360, 'transform_funcs': (4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 130.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4053142 has 744.00 MiB memory in use. Process 4053180 has 806.00 MiB memory in use. Process 4053182 has 840.00 MiB memory in use. Process 4053184 has 1.15 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 1.08 GiB memory in use. Process 4056414 has 816.00 MiB memory in use. Process 4056409 has 1.38 GiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 852.00 MiB memory in use. Process 4056793 has 1.10 GiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 552.00 MiB memory in use. Process 4056798 has 1.29 GiB memory in use. Process 4056804 has 1.07 GiB memory in use. Process 4057192 has 718.00 MiB memory in use. Process 4057186 has 1.15 GiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 1.24 GiB memory in use. Process 4057300 has 1000.00 MiB memory in use. Process 4057580 has 926.00 MiB memory in use. Process 4057583 has 844.00 MiB memory in use. Process 4057577 has 914.00 MiB memory in use. Process 4057586 has 672.00 MiB memory in use. Process 4057597 has 1.11 GiB memory in use. Of the allocated memory 273.18 MiB is allocated by PyTorch, and 58.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2588b59c,"{'temperature_head': 0.7000000000000001, 'latent_dim': 285, 'batch_size': 425, 'transform_funcs': (0, 1)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 78.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4053142 has 744.00 MiB memory in use. Process 4053180 has 806.00 MiB memory in use. Process 4053182 has 840.00 MiB memory in use. Process 4053184 has 1.15 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 1.08 GiB memory in use. Process 4056414 has 816.00 MiB memory in use. Process 4056409 has 1.38 GiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 852.00 MiB memory in use. Process 4056793 has 1.10 GiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 552.00 MiB memory in use. Process 4056798 has 1.29 GiB memory in use. Process 4056804 has 1.07 GiB memory in use. Process 4057192 has 718.00 MiB memory in use. Process 4057186 has 1.15 GiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 1.24 GiB memory in use. Process 4057300 has 1000.00 MiB memory in use. Process 4057580 has 926.00 MiB memory in use. Process 4057583 has 844.00 MiB memory in use. Process 4057577 has 914.00 MiB memory in use. Process 4057586 has 724.00 MiB memory in use. Process 4057597 has 1.11 GiB memory in use. Of the allocated memory 251.20 MiB is allocated by PyTorch, and 132.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
848d9eb0,"{'temperature_head': 0.9, 'latent_dim': 720, 'batch_size': 406, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 348.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 152.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4053142 has 744.00 MiB memory in use. Process 4053180 has 806.00 MiB memory in use. Process 4053182 has 840.00 MiB memory in use. Process 4053184 has 1.15 GiB memory in use. Process 4053199 has 654.00 MiB memory in use. Process 4056411 has 1.08 GiB memory in use. Process 4056414 has 816.00 MiB memory in use. Process 4056409 has 1.38 GiB memory in use. Process 4056402 has 882.00 MiB memory in use. Process 4056410 has 778.00 MiB memory in use. Process 4056793 has 1.10 GiB memory in use. Process 4056795 has 722.00 MiB memory in use. Process 4056803 has 552.00 MiB memory in use. Process 4056798 has 1.29 GiB memory in use. Process 4056804 has 1.07 GiB memory in use. Process 4057192 has 718.00 MiB memory in use. Process 4057186 has 1.15 GiB memory in use. Process 4057191 has 672.00 MiB memory in use. Process 4057198 has 1.24 GiB memory in use. Process 4057300 has 1000.00 MiB memory in use. Process 4057580 has 926.00 MiB memory in use. Process 4057583 has 844.00 MiB memory in use. Process 4057577 has 914.00 MiB memory in use. Process 4057586 has 724.00 MiB memory in use. Process 4057597 has 1.11 GiB memory in use. Of the allocated memory 117.55 MiB is allocated by PyTorch, and 266.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
