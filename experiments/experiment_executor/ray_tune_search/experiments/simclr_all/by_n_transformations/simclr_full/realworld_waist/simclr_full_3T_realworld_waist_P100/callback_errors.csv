trial_id,config,error_type,error_message,error_traceback
86dd5a02,"{'temperature_head': 0.4, 'latent_dim': 259, 'batch_size': 317, 'transform_funcs': (7, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.10 GiB memory in use. Process 71994 has 1.33 GiB memory in use. Process 71966 has 972.00 MiB memory in use. Process 72010 has 768.00 MiB memory in use. Process 72025 has 858.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 924.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 898.00 MiB memory in use. Process 75230 has 996.00 MiB memory in use. Process 75625 has 908.00 MiB memory in use. Process 75627 has 782.00 MiB memory in use. Process 75626 has 450.00 MiB memory in use. Process 75618 has 1.47 GiB memory in use. Process 75630 has 896.00 MiB memory in use. Process 76014 has 778.00 MiB memory in use. Process 76020 has 882.00 MiB memory in use. Process 76017 has 1.51 GiB memory in use. Process 76010 has 1.10 GiB memory in use. Process 76013 has 706.00 MiB memory in use. Process 76400 has 708.00 MiB memory in use. Process 76406 has 512.00 MiB memory in use. Process 76409 has 968.00 MiB memory in use. Process 76410 has 636.00 MiB memory in use. Process 76403 has 868.00 MiB memory in use. Of the allocated memory 288.49 MiB is allocated by PyTorch, and 255.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1654eaf7,"{'temperature_head': 0.30000000000000004, 'latent_dim': 259, 'batch_size': 180, 'transform_funcs': (0, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 148.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.10 GiB memory in use. Process 71994 has 450.00 MiB memory in use. Process 71966 has 972.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 700.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 924.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.10 GiB memory in use. Process 75230 has 660.00 MiB memory in use. Process 75625 has 952.00 MiB memory in use. Process 75627 has 782.00 MiB memory in use. Process 75626 has 800.00 MiB memory in use. Process 75618 has 1.47 GiB memory in use. Process 75630 has 988.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 932.00 MiB memory in use. Process 76017 has 1.51 GiB memory in use. Process 76010 has 872.00 MiB memory in use. Process 76013 has 706.00 MiB memory in use. Process 76400 has 654.00 MiB memory in use. Process 76406 has 764.00 MiB memory in use. Process 76409 has 968.00 MiB memory in use. Process 76410 has 778.00 MiB memory in use. Process 76403 has 1.19 GiB memory in use. Of the allocated memory 289.87 MiB is allocated by PyTorch, and 32.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
227e889a,"{'temperature_head': 0.4, 'latent_dim': 255, 'batch_size': 217, 'transform_funcs': (4, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.10 GiB memory in use. Process 71994 has 976.00 MiB memory in use. Process 71966 has 972.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 748.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 866.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.10 GiB memory in use. Process 75230 has 910.00 MiB memory in use. Process 75625 has 952.00 MiB memory in use. Process 75627 has 782.00 MiB memory in use. Process 75626 has 836.00 MiB memory in use. Process 75618 has 1.47 GiB memory in use. Process 75630 has 790.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 454.00 MiB memory in use. Process 76017 has 1.34 GiB memory in use. Process 76010 has 872.00 MiB memory in use. Process 76013 has 706.00 MiB memory in use. Process 76400 has 768.00 MiB memory in use. Process 76406 has 744.00 MiB memory in use. Process 76409 has 968.00 MiB memory in use. Process 76410 has 778.00 MiB memory in use. Process 76403 has 1.24 GiB memory in use. Of the allocated memory 79.84 MiB is allocated by PyTorch, and 36.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
08067593,"{'temperature_head': 0.5, 'latent_dim': 307, 'batch_size': 249, 'transform_funcs': (2, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 104.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.10 GiB memory in use. Process 71994 has 924.00 MiB memory in use. Process 71966 has 864.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 748.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 866.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.10 GiB memory in use. Process 75230 has 910.00 MiB memory in use. Process 75625 has 952.00 MiB memory in use. Process 75627 has 782.00 MiB memory in use. Process 75626 has 836.00 MiB memory in use. Process 75618 has 1.47 GiB memory in use. Process 75630 has 790.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 500.00 MiB memory in use. Process 76017 has 1.34 GiB memory in use. Process 76010 has 872.00 MiB memory in use. Process 76013 has 706.00 MiB memory in use. Process 76400 has 738.00 MiB memory in use. Process 76406 has 744.00 MiB memory in use. Process 76409 has 868.00 MiB memory in use. Process 76410 has 778.00 MiB memory in use. Process 76403 has 1.43 GiB memory in use. Of the allocated memory 317.24 MiB is allocated by PyTorch, and 212.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
762fc063,"{'temperature_head': 0.30000000000000004, 'latent_dim': 108, 'batch_size': 128, 'transform_funcs': (2, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.10 GiB memory in use. Process 71994 has 924.00 MiB memory in use. Process 71966 has 864.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 748.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 866.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.10 GiB memory in use. Process 75230 has 910.00 MiB memory in use. Process 75625 has 952.00 MiB memory in use. Process 75627 has 782.00 MiB memory in use. Process 75626 has 836.00 MiB memory in use. Process 75618 has 1.47 GiB memory in use. Process 75630 has 790.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 1.34 GiB memory in use. Process 76010 has 872.00 MiB memory in use. Process 76013 has 706.00 MiB memory in use. Process 76400 has 738.00 MiB memory in use. Process 76406 has 744.00 MiB memory in use. Process 76409 has 912.00 MiB memory in use. Process 76410 has 778.00 MiB memory in use. Process 76403 has 1.43 GiB memory in use. Of the allocated memory 134.69 MiB is allocated by PyTorch, and 35.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
dffb679a,"{'temperature_head': 0.8, 'latent_dim': 108, 'batch_size': 147, 'transform_funcs': (3, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.10 GiB memory in use. Process 71994 has 924.00 MiB memory in use. Process 71966 has 864.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 748.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 866.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.11 GiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 952.00 MiB memory in use. Process 75627 has 782.00 MiB memory in use. Process 75626 has 836.00 MiB memory in use. Process 75618 has 1.47 GiB memory in use. Process 75630 has 760.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 762.00 MiB memory in use. Process 76017 has 1.34 GiB memory in use. Process 76010 has 1.01 GiB memory in use. Process 76013 has 706.00 MiB memory in use. Process 76400 has 784.00 MiB memory in use. Process 76406 has 744.00 MiB memory in use. Process 76409 has 912.00 MiB memory in use. Process 76410 has 778.00 MiB memory in use. Process 76403 has 1.43 GiB memory in use. Of the allocated memory 134.69 MiB is allocated by PyTorch, and 37.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
afc3f1e3,"{'temperature_head': 0.6000000000000001, 'latent_dim': 279, 'batch_size': 284, 'transform_funcs': (1, 2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 146.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.10 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 910.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 776.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 868.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.11 GiB memory in use. Process 75230 has 706.00 MiB memory in use. Process 75625 has 952.00 MiB memory in use. Process 75627 has 782.00 MiB memory in use. Process 75626 has 802.00 MiB memory in use. Process 75618 has 1.47 GiB memory in use. Process 75630 has 946.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 676.00 MiB memory in use. Process 76017 has 496.00 MiB memory in use. Process 76010 has 1.01 GiB memory in use. Process 76013 has 700.00 MiB memory in use. Process 76400 has 808.00 MiB memory in use. Process 76406 has 744.00 MiB memory in use. Process 76409 has 912.00 MiB memory in use. Process 76410 has 778.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 300.97 MiB is allocated by PyTorch, and 37.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
dfe64d56,"{'temperature_head': 0.9, 'latent_dim': 221, 'batch_size': 232, 'transform_funcs': (7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 118.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.10 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 910.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 452.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 868.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.11 GiB memory in use. Process 75230 has 656.00 MiB memory in use. Process 75625 has 1002.00 MiB memory in use. Process 75627 has 782.00 MiB memory in use. Process 75626 has 850.00 MiB memory in use. Process 75618 has 1.47 GiB memory in use. Process 75630 has 860.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 798.00 MiB memory in use. Process 76017 has 558.00 MiB memory in use. Process 76010 has 1.01 GiB memory in use. Process 76013 has 746.00 MiB memory in use. Process 76400 has 1006.00 MiB memory in use. Process 76406 has 706.00 MiB memory in use. Process 76409 has 912.00 MiB memory in use. Process 76410 has 778.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 265.72 MiB is allocated by PyTorch, and 52.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
596a7212,"{'temperature_head': 0.30000000000000004, 'latent_dim': 150, 'batch_size': 154, 'transform_funcs': (2, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.10 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 910.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 838.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 868.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.11 GiB memory in use. Process 75230 has 672.00 MiB memory in use. Process 75625 has 498.00 MiB memory in use. Process 75627 has 782.00 MiB memory in use. Process 75626 has 850.00 MiB memory in use. Process 75618 has 1.33 GiB memory in use. Process 75630 has 966.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 798.00 MiB memory in use. Process 76017 has 744.00 MiB memory in use. Process 76010 has 888.00 MiB memory in use. Process 76013 has 746.00 MiB memory in use. Process 76400 has 1006.00 MiB memory in use. Process 76406 has 888.00 MiB memory in use. Process 76409 has 914.00 MiB memory in use. Process 76410 has 778.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 223.19 MiB is allocated by PyTorch, and 110.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
44cd937c,"{'temperature_head': 0.5, 'latent_dim': 9, 'batch_size': 209, 'transform_funcs': (4, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.10 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 910.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 838.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 868.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.11 GiB memory in use. Process 75230 has 502.00 MiB memory in use. Process 75625 has 500.00 MiB memory in use. Process 75627 has 782.00 MiB memory in use. Process 75626 has 850.00 MiB memory in use. Process 75618 has 1.33 GiB memory in use. Process 75630 has 966.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 970.00 MiB memory in use. Process 76017 has 744.00 MiB memory in use. Process 76010 has 888.00 MiB memory in use. Process 76013 has 746.00 MiB memory in use. Process 76400 has 1006.00 MiB memory in use. Process 76406 has 888.00 MiB memory in use. Process 76409 has 914.00 MiB memory in use. Process 76410 has 778.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 133.91 MiB is allocated by PyTorch, and 30.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f884c006,"{'temperature_head': 0.4, 'latent_dim': 219, 'batch_size': 221, 'transform_funcs': (0, 3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.10 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 910.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 920.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 868.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.11 GiB memory in use. Process 75230 has 554.00 MiB memory in use. Process 75625 has 500.00 MiB memory in use. Process 75627 has 782.00 MiB memory in use. Process 75626 has 850.00 MiB memory in use. Process 75618 has 1.33 GiB memory in use. Process 75630 has 640.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 970.00 MiB memory in use. Process 76017 has 744.00 MiB memory in use. Process 76010 has 888.00 MiB memory in use. Process 76013 has 746.00 MiB memory in use. Process 76400 has 1006.00 MiB memory in use. Process 76406 has 872.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 778.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 265.56 MiB is allocated by PyTorch, and 36.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a68526c8,"{'temperature_head': 0.30000000000000004, 'latent_dim': 250, 'batch_size': 136, 'transform_funcs': (0, 3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.10 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 910.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 920.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 868.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.11 GiB memory in use. Process 75230 has 654.00 MiB memory in use. Process 75625 has 500.00 MiB memory in use. Process 75627 has 782.00 MiB memory in use. Process 75626 has 850.00 MiB memory in use. Process 75618 has 1.33 GiB memory in use. Process 75630 has 452.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 970.00 MiB memory in use. Process 76017 has 788.00 MiB memory in use. Process 76010 has 888.00 MiB memory in use. Process 76013 has 746.00 MiB memory in use. Process 76400 has 1006.00 MiB memory in use. Process 76406 has 872.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 778.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 283.80 MiB is allocated by PyTorch, and 32.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
102bf1c3,"{'temperature_head': 0.30000000000000004, 'latent_dim': 180, 'batch_size': 167, 'transform_funcs': (3, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 86.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.10 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 910.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 920.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 868.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.11 GiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 556.00 MiB memory in use. Process 75627 has 782.00 MiB memory in use. Process 75626 has 850.00 MiB memory in use. Process 75618 has 1.38 GiB memory in use. Process 75630 has 454.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 970.00 MiB memory in use. Process 76017 has 788.00 MiB memory in use. Process 76010 has 888.00 MiB memory in use. Process 76013 has 746.00 MiB memory in use. Process 76400 has 1006.00 MiB memory in use. Process 76406 has 872.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 778.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 135.25 MiB is allocated by PyTorch, and 36.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
993d223e,"{'temperature_head': 0.2, 'latent_dim': 204, 'batch_size': 187, 'transform_funcs': (8, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.10 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 910.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 920.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 868.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.11 GiB memory in use. Process 75230 has 556.00 MiB memory in use. Process 75625 has 556.00 MiB memory in use. Process 75627 has 782.00 MiB memory in use. Process 75626 has 850.00 MiB memory in use. Process 75618 has 1.38 GiB memory in use. Process 75630 has 452.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 970.00 MiB memory in use. Process 76017 has 788.00 MiB memory in use. Process 76010 has 888.00 MiB memory in use. Process 76013 has 746.00 MiB memory in use. Process 76400 has 1006.00 MiB memory in use. Process 76406 has 872.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 778.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 79.44 MiB is allocated by PyTorch, and 34.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
16bde532,"{'temperature_head': 0.5, 'latent_dim': 244, 'batch_size': 221, 'transform_funcs': (2, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.10 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 910.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 920.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 868.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.11 GiB memory in use. Process 75230 has 744.00 MiB memory in use. Process 75625 has 772.00 MiB memory in use. Process 75627 has 782.00 MiB memory in use. Process 75626 has 850.00 MiB memory in use. Process 75618 has 1.38 GiB memory in use. Process 75630 has 454.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 970.00 MiB memory in use. Process 76017 has 790.00 MiB memory in use. Process 76010 has 888.00 MiB memory in use. Process 76013 has 746.00 MiB memory in use. Process 76400 has 1006.00 MiB memory in use. Process 76406 has 452.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 778.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 79.75 MiB is allocated by PyTorch, and 36.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
aa9b66a4,"{'temperature_head': 0.2, 'latent_dim': 269, 'batch_size': 183, 'transform_funcs': (4, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.10 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 910.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 920.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 868.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.11 GiB memory in use. Process 75230 has 744.00 MiB memory in use. Process 75625 has 774.00 MiB memory in use. Process 75627 has 782.00 MiB memory in use. Process 75626 has 850.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 670.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 970.00 MiB memory in use. Process 76017 has 454.00 MiB memory in use. Process 76010 has 888.00 MiB memory in use. Process 76013 has 746.00 MiB memory in use. Process 76400 has 1006.00 MiB memory in use. Process 76406 has 668.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 778.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 295.95 MiB is allocated by PyTorch, and 36.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cbc7003f,"{'temperature_head': 0.1, 'latent_dim': 104, 'batch_size': 358, 'transform_funcs': (2, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 756.00 MiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 992.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 700.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 660.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 452.00 MiB memory in use. Process 75625 has 1024.00 MiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 920.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 452.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.38 GiB memory in use. Process 76017 has 966.00 MiB memory in use. Process 76010 has 764.00 MiB memory in use. Process 76013 has 614.00 MiB memory in use. Process 76400 has 928.00 MiB memory in use. Process 76406 has 904.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 78.66 MiB is allocated by PyTorch, and 35.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
994437b2,"{'temperature_head': 0.7000000000000001, 'latent_dim': 94, 'batch_size': 130, 'transform_funcs': (3, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 756.00 MiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 992.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 700.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 660.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 422.00 MiB memory in use. Process 75625 has 1024.00 MiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 920.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 502.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.38 GiB memory in use. Process 76017 has 966.00 MiB memory in use. Process 76010 has 764.00 MiB memory in use. Process 76013 has 614.00 MiB memory in use. Process 76400 has 928.00 MiB memory in use. Process 76406 has 904.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 46.10 MiB is allocated by PyTorch, and 37.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
42ec6bbd,"{'temperature_head': 0.4, 'latent_dim': 292, 'batch_size': 203, 'transform_funcs': (2, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 756.00 MiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 992.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 700.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 660.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 452.00 MiB memory in use. Process 75625 has 1024.00 MiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 920.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 454.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.38 GiB memory in use. Process 76017 has 966.00 MiB memory in use. Process 76010 has 764.00 MiB memory in use. Process 76013 has 614.00 MiB memory in use. Process 76400 has 928.00 MiB memory in use. Process 76406 has 904.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 80.13 MiB is allocated by PyTorch, and 35.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
67beef61,"{'temperature_head': 0.5, 'latent_dim': 113, 'batch_size': 193, 'transform_funcs': (1, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 756.00 MiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 1.01 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 668.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 660.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 578.00 MiB memory in use. Process 75625 has 1024.00 MiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 922.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 464.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.38 GiB memory in use. Process 76017 has 966.00 MiB memory in use. Process 76010 has 764.00 MiB memory in use. Process 76013 has 614.00 MiB memory in use. Process 76400 has 928.00 MiB memory in use. Process 76406 has 790.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 201.53 MiB is allocated by PyTorch, and 38.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fdf8fa74,"{'temperature_head': 0.6000000000000001, 'latent_dim': 172, 'batch_size': 494, 'transform_funcs': (4, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 94.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 756.00 MiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 1.01 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 668.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 660.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 452.00 MiB memory in use. Process 75625 has 1024.00 MiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 922.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 510.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.38 GiB memory in use. Process 76017 has 966.00 MiB memory in use. Process 76010 has 764.00 MiB memory in use. Process 76013 has 614.00 MiB memory in use. Process 76400 has 928.00 MiB memory in use. Process 76406 has 790.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 135.19 MiB is allocated by PyTorch, and 36.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
630878df,"{'temperature_head': 0.30000000000000004, 'latent_dim': 340, 'batch_size': 293, 'transform_funcs': (0, 2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 202.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 802.00 MiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 1.01 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 668.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 672.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 452.00 MiB memory in use. Process 75625 has 1024.00 MiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 922.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 712.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.38 GiB memory in use. Process 76017 has 966.00 MiB memory in use. Process 76010 has 766.00 MiB memory in use. Process 76013 has 432.00 MiB memory in use. Process 76400 has 928.00 MiB memory in use. Process 76406 has 790.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 338.50 MiB is allocated by PyTorch, and 35.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
31b0fe6c,"{'temperature_head': 0.2, 'latent_dim': 197, 'batch_size': 176, 'transform_funcs': (1, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 802.00 MiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 1.01 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 452.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 672.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 422.00 MiB memory in use. Process 75625 has 1024.00 MiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 922.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 668.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.38 GiB memory in use. Process 76017 has 966.00 MiB memory in use. Process 76010 has 912.00 MiB memory in use. Process 76013 has 552.00 MiB memory in use. Process 76400 has 928.00 MiB memory in use. Process 76406 has 790.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 46.91 MiB is allocated by PyTorch, and 37.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ba4e85f0,"{'temperature_head': 0.5, 'latent_dim': 237, 'batch_size': 228, 'transform_funcs': (6, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 804.00 MiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 1014.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 714.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 720.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 422.00 MiB memory in use. Process 75625 has 1.00 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 922.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 668.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.38 GiB memory in use. Process 76017 has 966.00 MiB memory in use. Process 76010 has 912.00 MiB memory in use. Process 76013 has 606.00 MiB memory in use. Process 76400 has 928.00 MiB memory in use. Process 76406 has 452.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 47.22 MiB is allocated by PyTorch, and 36.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
09986f9c,"{'temperature_head': 0.30000000000000004, 'latent_dim': 312, 'batch_size': 189, 'transform_funcs': (0, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 186.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 138.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 736.00 MiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 1014.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 714.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 684.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 454.00 MiB memory in use. Process 75625 has 990.00 MiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 922.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 668.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.38 GiB memory in use. Process 76017 has 966.00 MiB memory in use. Process 76010 has 912.00 MiB memory in use. Process 76013 has 608.00 MiB memory in use. Process 76400 has 928.00 MiB memory in use. Process 76406 has 452.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 320.23 MiB is allocated by PyTorch, and 77.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
229841c7,"{'temperature_head': 0.5, 'latent_dim': 188, 'batch_size': 400, 'transform_funcs': (1, 3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 92.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 796.00 MiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 1014.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 714.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 684.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 454.00 MiB memory in use. Process 75625 has 990.00 MiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 922.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 718.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.00 GiB memory in use. Process 76017 has 966.00 MiB memory in use. Process 76010 has 912.00 MiB memory in use. Process 76013 has 608.00 MiB memory in use. Process 76400 has 928.00 MiB memory in use. Process 76406 has 772.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 247.48 MiB is allocated by PyTorch, and 210.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
27379770,"{'temperature_head': 0.4, 'latent_dim': 262, 'batch_size': 129, 'transform_funcs': (1, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 844.00 MiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 1014.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 714.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 684.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 454.00 MiB memory in use. Process 75625 has 990.00 MiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 922.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 718.00 MiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.00 GiB memory in use. Process 76017 has 966.00 MiB memory in use. Process 76010 has 912.00 MiB memory in use. Process 76013 has 608.00 MiB memory in use. Process 76400 has 928.00 MiB memory in use. Process 76406 has 772.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 79.89 MiB is allocated by PyTorch, and 36.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
249b6a5e,"{'temperature_head': 0.30000000000000004, 'latent_dim': 166, 'batch_size': 440, 'transform_funcs': (2, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 78.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 990.00 MiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 668.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 672.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 676.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 750.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 610.00 MiB memory in use. Process 76014 has 826.00 MiB memory in use. Process 76020 has 1.04 GiB memory in use. Process 76017 has 966.00 MiB memory in use. Process 76010 has 898.00 MiB memory in use. Process 76013 has 432.00 MiB memory in use. Process 76400 has 928.00 MiB memory in use. Process 76406 has 992.00 MiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 233.28 MiB is allocated by PyTorch, and 38.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
34789019,"{'temperature_head': 0.2, 'latent_dim': 212, 'batch_size': 182, 'transform_funcs': (0, 1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 992.00 MiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 678.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 760.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 686.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 752.00 MiB memory in use. Process 76014 has 452.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.22 GiB memory in use. Process 76010 has 898.00 MiB memory in use. Process 76013 has 432.00 MiB memory in use. Process 76400 has 928.00 MiB memory in use. Process 76406 has 1.09 GiB memory in use. Process 76409 has 1.14 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 135.50 MiB is allocated by PyTorch, and 36.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
73cc409f,"{'temperature_head': 0.1, 'latent_dim': 274, 'batch_size': 300, 'transform_funcs': (4, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.00 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 678.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 760.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 686.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 470.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 714.00 MiB memory in use. Process 76014 has 452.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.22 GiB memory in use. Process 76010 has 898.00 MiB memory in use. Process 76013 has 432.00 MiB memory in use. Process 76400 has 928.00 MiB memory in use. Process 76406 has 1.09 GiB memory in use. Process 76409 has 1.14 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 297.48 MiB is allocated by PyTorch, and 78.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
35b54173,"{'temperature_head': 0.8, 'latent_dim': 245, 'batch_size': 276, 'transform_funcs': (0, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.00 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 704.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 874.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 732.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 470.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 756.00 MiB memory in use. Process 76014 has 644.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.22 GiB memory in use. Process 76010 has 898.00 MiB memory in use. Process 76013 has 764.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 1.09 GiB memory in use. Process 76409 has 422.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 47.28 MiB is allocated by PyTorch, and 36.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a515e736,"{'temperature_head': 0.2, 'latent_dim': 205, 'batch_size': 255, 'transform_funcs': (1, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 96.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.00 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 724.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 874.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 732.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 470.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 662.00 MiB memory in use. Process 76014 has 644.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.22 GiB memory in use. Process 76010 has 898.00 MiB memory in use. Process 76013 has 764.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 1.09 GiB memory in use. Process 76409 has 440.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 135.61 MiB is allocated by PyTorch, and 188.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f55c4f24,"{'temperature_head': 0.7000000000000001, 'latent_dim': 266, 'batch_size': 263, 'transform_funcs': (3, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.00 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 724.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 874.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 732.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 470.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 710.00 MiB memory in use. Process 76014 has 644.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.22 GiB memory in use. Process 76010 has 898.00 MiB memory in use. Process 76013 has 764.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 1.09 GiB memory in use. Process 76409 has 456.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 79.92 MiB is allocated by PyTorch, and 38.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1bb266a8,"{'temperature_head': 0.1, 'latent_dim': 302, 'batch_size': 286, 'transform_funcs': (2, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.00 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 724.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 874.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 732.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 450.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 710.00 MiB memory in use. Process 76014 has 644.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.22 GiB memory in use. Process 76010 has 898.00 MiB memory in use. Process 76013 has 764.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 1.09 GiB memory in use. Process 76409 has 456.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 80.21 MiB is allocated by PyTorch, and 31.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
59da3241,"{'temperature_head': 0.6000000000000001, 'latent_dim': 234, 'batch_size': 317, 'transform_funcs': (3, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 140.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 138.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.00 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 724.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 874.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 732.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 710.00 MiB memory in use. Process 76014 has 452.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.22 GiB memory in use. Process 76010 has 898.00 MiB memory in use. Process 76013 has 764.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 1.09 GiB memory in use. Process 76409 has 502.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 135.67 MiB is allocated by PyTorch, and 36.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1347e220,"{'temperature_head': 1.0, 'latent_dim': 329, 'batch_size': 238, 'transform_funcs': (0, 2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 126.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.00 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 724.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 874.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 732.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 710.00 MiB memory in use. Process 76014 has 452.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.22 GiB memory in use. Process 76010 has 898.00 MiB memory in use. Process 76013 has 764.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 1.09 GiB memory in use. Process 76409 has 514.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 136.42 MiB is allocated by PyTorch, and 39.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
496e688d,"{'temperature_head': 0.1, 'latent_dim': 280, 'batch_size': 336, 'transform_funcs': (6, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 116.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.20 GiB memory in use. Process 71966 has 724.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 874.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 734.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 556.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 736.00 MiB memory in use. Process 76014 has 452.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.22 GiB memory in use. Process 76010 has 898.00 MiB memory in use. Process 76013 has 764.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 1.09 GiB memory in use. Process 76409 has 452.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 301.53 MiB is allocated by PyTorch, and 96.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e74aca2b,"{'temperature_head': 0.9, 'latent_dim': 256, 'batch_size': 211, 'transform_funcs': (1, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.24 GiB memory in use. Process 71966 has 792.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 874.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 728.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 564.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 780.00 MiB memory in use. Process 76014 has 454.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.17 GiB memory in use. Process 76010 has 898.00 MiB memory in use. Process 76013 has 764.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 1.09 GiB memory in use. Process 76409 has 422.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 47.37 MiB is allocated by PyTorch, and 36.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
839282cb,"{'temperature_head': 0.5, 'latent_dim': 41, 'batch_size': 152, 'transform_funcs': (4, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.25 GiB memory in use. Process 71966 has 792.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 874.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 728.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 612.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 780.00 MiB memory in use. Process 76014 has 720.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.17 GiB memory in use. Process 76010 has 898.00 MiB memory in use. Process 76013 has 764.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 742.00 MiB memory in use. Process 76409 has 506.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 134.16 MiB is allocated by PyTorch, and 33.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d2cb9599,"{'temperature_head': 0.4, 'latent_dim': 183, 'batch_size': 175, 'transform_funcs': (2, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.25 GiB memory in use. Process 71966 has 792.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 874.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 728.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 622.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 780.00 MiB memory in use. Process 76014 has 720.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.17 GiB memory in use. Process 76010 has 898.00 MiB memory in use. Process 76013 has 764.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 742.00 MiB memory in use. Process 76409 has 506.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 243.46 MiB is allocated by PyTorch, and 40.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8f427018,"{'temperature_head': 0.5, 'latent_dim': 89, 'batch_size': 246, 'transform_funcs': (1, 3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 54.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.25 GiB memory in use. Process 71966 has 792.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 874.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 728.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 566.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.32 GiB memory in use. Process 75630 has 780.00 MiB memory in use. Process 76014 has 720.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.17 GiB memory in use. Process 76010 has 898.00 MiB memory in use. Process 76013 has 764.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 742.00 MiB memory in use. Process 76409 has 552.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 187.16 MiB is allocated by PyTorch, and 40.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e3b84fad,"{'temperature_head': 0.4, 'latent_dim': 228, 'batch_size': 199, 'transform_funcs': (1, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 136.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.60 GiB memory in use. Process 71966 has 920.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 874.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 452.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 910.00 MiB memory in use. Process 76014 has 766.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.17 GiB memory in use. Process 76010 has 898.00 MiB memory in use. Process 76013 has 764.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 788.00 MiB memory in use. Process 76409 has 848.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 135.63 MiB is allocated by PyTorch, and 36.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
95da734a,"{'temperature_head': 0.6000000000000001, 'latent_dim': 107, 'batch_size': 231, 'transform_funcs': (1, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.60 GiB memory in use. Process 71966 has 920.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 874.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 452.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 574.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 910.00 MiB memory in use. Process 76014 has 804.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.17 GiB memory in use. Process 76010 has 906.00 MiB memory in use. Process 76013 has 764.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 798.00 MiB memory in use. Process 76409 has 848.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 198.68 MiB is allocated by PyTorch, and 37.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1aa6962a,"{'temperature_head': 0.5, 'latent_dim': 136, 'batch_size': 258, 'transform_funcs': (0, 2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 76.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.60 GiB memory in use. Process 71966 has 920.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 874.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 452.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 598.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 500.00 MiB memory in use. Process 75630 has 910.00 MiB memory in use. Process 76014 has 804.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.17 GiB memory in use. Process 76010 has 906.00 MiB memory in use. Process 76013 has 764.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 798.00 MiB memory in use. Process 76409 has 822.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 214.81 MiB is allocated by PyTorch, and 45.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
049d880a,"{'temperature_head': 0.6000000000000001, 'latent_dim': 129, 'batch_size': 175, 'transform_funcs': (0, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.60 GiB memory in use. Process 71966 has 780.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 722.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 452.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 614.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 558.00 MiB memory in use. Process 75630 has 910.00 MiB memory in use. Process 76014 has 848.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.17 GiB memory in use. Process 76010 has 938.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 888.00 MiB memory in use. Process 76409 has 822.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 210.61 MiB is allocated by PyTorch, and 65.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
47733856,"{'temperature_head': 0.5, 'latent_dim': 153, 'batch_size': 269, 'transform_funcs': (0, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.60 GiB memory in use. Process 71966 has 780.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 722.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 452.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 454.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 462.00 MiB memory in use. Process 75630 has 910.00 MiB memory in use. Process 76014 has 848.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.38 GiB memory in use. Process 76010 has 954.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 888.00 MiB memory in use. Process 76409 has 822.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 79.04 MiB is allocated by PyTorch, and 36.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
31be6e10,"{'temperature_head': 0.4, 'latent_dim': 186, 'batch_size': 189, 'transform_funcs': (0, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.64 GiB memory in use. Process 71966 has 738.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 768.00 MiB memory in use. Process 75233 has 1.60 GiB memory in use. Process 75240 has 700.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 454.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 524.00 MiB memory in use. Process 75630 has 912.00 MiB memory in use. Process 76014 has 848.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.38 GiB memory in use. Process 76010 has 954.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 888.00 MiB memory in use. Process 76409 has 452.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 79.30 MiB is allocated by PyTorch, and 36.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e9cb2b0b,"{'temperature_head': 0.4, 'latent_dim': 242, 'batch_size': 209, 'transform_funcs': (4, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.64 GiB memory in use. Process 71966 has 738.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 768.00 MiB memory in use. Process 75233 has 1.40 GiB memory in use. Process 75240 has 744.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 564.00 MiB memory in use. Process 75630 has 912.00 MiB memory in use. Process 76014 has 848.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.42 GiB memory in use. Process 76010 has 918.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 946.00 MiB memory in use. Process 76409 has 806.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.10 GiB memory in use. Of the allocated memory 135.74 MiB is allocated by PyTorch, and 36.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8b088314,"{'temperature_head': 0.2, 'latent_dim': 207, 'batch_size': 307, 'transform_funcs': (5, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.64 GiB memory in use. Process 71966 has 700.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 768.00 MiB memory in use. Process 75233 has 1.40 GiB memory in use. Process 75240 has 744.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 634.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 912.00 MiB memory in use. Process 76014 has 848.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.42 GiB memory in use. Process 76010 has 918.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 946.00 MiB memory in use. Process 76409 has 806.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.05 GiB memory in use. Of the allocated memory 257.84 MiB is allocated by PyTorch, and 38.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bbf5141d,"{'temperature_head': 0.4, 'latent_dim': 275, 'batch_size': 262, 'transform_funcs': (9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 156.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 924.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 798.00 MiB memory in use. Process 75233 has 552.00 MiB memory in use. Process 75240 has 870.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 454.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 630.00 MiB memory in use. Process 75630 has 1.07 GiB memory in use. Process 76014 has 810.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.42 GiB memory in use. Process 76010 has 1004.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 992.00 MiB memory in use. Process 76409 has 672.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.38 GiB memory in use. Of the allocated memory 298.58 MiB is allocated by PyTorch, and 35.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0b8c3fe0,"{'temperature_head': 0.30000000000000004, 'latent_dim': 223, 'batch_size': 325, 'transform_funcs': (0, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 80.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 924.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 798.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 870.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 454.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 628.00 MiB memory in use. Process 75630 has 1.07 GiB memory in use. Process 76014 has 810.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.42 GiB memory in use. Process 76010 has 1004.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 992.00 MiB memory in use. Process 76409 has 748.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.38 GiB memory in use. Of the allocated memory 267.08 MiB is allocated by PyTorch, and 142.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a531e055,"{'temperature_head': 0.2, 'latent_dim': 256, 'batch_size': 219, 'transform_funcs': (2, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 924.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 798.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 870.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 454.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 630.00 MiB memory in use. Process 75630 has 1.07 GiB memory in use. Process 76014 has 810.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.42 GiB memory in use. Process 76010 has 1004.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 992.00 MiB memory in use. Process 76409 has 790.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.38 GiB memory in use. Of the allocated memory 79.84 MiB is allocated by PyTorch, and 36.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
903ca8e7,"{'temperature_head': 0.4, 'latent_dim': 300, 'batch_size': 154, 'transform_funcs': (1, 3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 956.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 798.00 MiB memory in use. Process 75233 has 898.00 MiB memory in use. Process 75240 has 870.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 738.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.45 GiB memory in use. Process 75630 has 686.00 MiB memory in use. Process 76014 has 654.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 476.00 MiB memory in use. Process 76010 has 1006.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 994.00 MiB memory in use. Process 76409 has 792.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.38 GiB memory in use. Of the allocated memory 314.19 MiB is allocated by PyTorch, and 33.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
27f151cb,"{'temperature_head': 0.30000000000000004, 'latent_dim': 284, 'batch_size': 184, 'transform_funcs': (0, 2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 134.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 956.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 798.00 MiB memory in use. Process 75233 has 846.00 MiB memory in use. Process 75240 has 870.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 784.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.45 GiB memory in use. Process 75630 has 728.00 MiB memory in use. Process 76014 has 452.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 562.00 MiB memory in use. Process 76010 has 1006.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 948.00 MiB memory in use. Process 76409 has 754.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 303.56 MiB is allocated by PyTorch, and 112.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
be24dd69,"{'temperature_head': 0.4, 'latent_dim': 249, 'batch_size': 203, 'transform_funcs': (1, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 126.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 956.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 798.00 MiB memory in use. Process 75233 has 846.00 MiB memory in use. Process 75240 has 870.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 780.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.45 GiB memory in use. Process 75630 has 728.00 MiB memory in use. Process 76014 has 556.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 472.00 MiB memory in use. Process 76010 has 1006.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 948.00 MiB memory in use. Process 76409 has 752.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 282.49 MiB is allocated by PyTorch, and 131.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ad4efcb0,"{'temperature_head': 0.30000000000000004, 'latent_dim': 269, 'batch_size': 256, 'transform_funcs': (4, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 156.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 956.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 798.00 MiB memory in use. Process 75233 has 842.00 MiB memory in use. Process 75240 has 870.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 996.00 MiB memory in use. Process 75230 has 780.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.45 GiB memory in use. Process 75630 has 628.00 MiB memory in use. Process 76014 has 610.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 556.00 MiB memory in use. Process 76010 has 898.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 996.00 MiB memory in use. Process 76409 has 748.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.47 GiB memory in use. Of the allocated memory 135.44 MiB is allocated by PyTorch, and 154.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c54e00b4,"{'temperature_head': 0.8, 'latent_dim': 219, 'batch_size': 234, 'transform_funcs': (1, 2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 82.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 956.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 768.00 MiB memory in use. Process 75233 has 1.62 GiB memory in use. Process 75240 has 870.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 840.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.31 GiB memory in use. Process 75630 has 638.00 MiB memory in use. Process 76014 has 710.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 556.00 MiB memory in use. Process 76010 has 944.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 996.00 MiB memory in use. Process 76409 has 934.00 MiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 528.00 MiB memory in use. Of the allocated memory 265.56 MiB is allocated by PyTorch, and 34.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f704db68,"{'temperature_head': 0.5, 'latent_dim': 349, 'batch_size': 159, 'transform_funcs': (2, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 138.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 958.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 812.00 MiB memory in use. Process 75233 has 492.00 MiB memory in use. Process 75240 has 870.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 792.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1008.00 MiB memory in use. Process 75630 has 884.00 MiB memory in use. Process 76014 has 452.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.10 GiB memory in use. Process 76010 has 944.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 996.00 MiB memory in use. Process 76409 has 1.10 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.19 GiB memory in use. Of the allocated memory 342.40 MiB is allocated by PyTorch, and 111.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
99a79833,"{'temperature_head': 0.30000000000000004, 'latent_dim': 258, 'batch_size': 148, 'transform_funcs': (2, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 920.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 812.00 MiB memory in use. Process 75233 has 550.00 MiB memory in use. Process 75240 has 870.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 788.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1010.00 MiB memory in use. Process 75630 has 884.00 MiB memory in use. Process 76014 has 538.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.10 GiB memory in use. Process 76010 has 944.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 996.00 MiB memory in use. Process 76409 has 1.10 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.19 GiB memory in use. Of the allocated memory 287.89 MiB is allocated by PyTorch, and 162.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8076bbfe,"{'temperature_head': 0.30000000000000004, 'latent_dim': 293, 'batch_size': 479, 'transform_funcs': (1, 3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 88.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 920.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 812.00 MiB memory in use. Process 75233 has 492.00 MiB memory in use. Process 75240 has 870.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 790.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 830.00 MiB memory in use. Process 75630 has 884.00 MiB memory in use. Process 76014 has 718.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.10 GiB memory in use. Process 76010 has 944.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 998.00 MiB memory in use. Process 76409 has 1.10 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.19 GiB memory in use. Of the allocated memory 308.85 MiB is allocated by PyTorch, and 143.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
db23981c,"{'temperature_head': 0.6000000000000001, 'latent_dim': 160, 'batch_size': 172, 'transform_funcs': (0, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 932.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 812.00 MiB memory in use. Process 75233 has 552.00 MiB memory in use. Process 75240 has 870.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 1012.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 830.00 MiB memory in use. Process 75630 has 606.00 MiB memory in use. Process 76014 has 718.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.10 GiB memory in use. Process 76010 has 944.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 998.00 MiB memory in use. Process 76409 has 1.10 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.19 GiB memory in use. Of the allocated memory 229.69 MiB is allocated by PyTorch, and 38.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
afbbad4c,"{'temperature_head': 0.4, 'latent_dim': 175, 'batch_size': 228, 'transform_funcs': (2, 3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.05 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 964.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 812.00 MiB memory in use. Process 75233 has 804.00 MiB memory in use. Process 75240 has 870.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 1012.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 830.00 MiB memory in use. Process 75630 has 612.00 MiB memory in use. Process 76014 has 452.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.10 GiB memory in use. Process 76010 has 944.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 998.00 MiB memory in use. Process 76409 has 1.10 GiB memory in use. Process 76410 has 880.00 MiB memory in use. Process 76403 has 1.16 GiB memory in use. Of the allocated memory 239.21 MiB is allocated by PyTorch, and 34.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
eabbe5da,"{'temperature_head': 0.5, 'latent_dim': 277, 'batch_size': 318, 'transform_funcs': (6, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.06 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 984.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 814.00 MiB memory in use. Process 75233 has 746.00 MiB memory in use. Process 75240 has 872.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 1012.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 954.00 MiB memory in use. Process 75630 has 506.00 MiB memory in use. Process 76014 has 672.00 MiB memory in use. Process 76020 has 1.05 GiB memory in use. Process 76017 has 1.10 GiB memory in use. Process 76010 has 944.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 998.00 MiB memory in use. Process 76409 has 1.10 GiB memory in use. Process 76410 has 696.00 MiB memory in use. Process 76403 has 1.16 GiB memory in use. Of the allocated memory 136.01 MiB is allocated by PyTorch, and 31.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c41098f8,"{'temperature_head': 0.1, 'latent_dim': 348, 'batch_size': 291, 'transform_funcs': (2, 3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 154.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.06 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 984.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 814.00 MiB memory in use. Process 75233 has 748.00 MiB memory in use. Process 75240 has 872.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 1012.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 954.00 MiB memory in use. Process 75630 has 470.00 MiB memory in use. Process 76014 has 672.00 MiB memory in use. Process 76020 has 952.00 MiB memory in use. Process 76017 has 1.10 GiB memory in use. Process 76010 has 944.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 998.00 MiB memory in use. Process 76409 has 1.10 GiB memory in use. Process 76410 has 696.00 MiB memory in use. Process 76403 has 1.21 GiB memory in use. Of the allocated memory 341.80 MiB is allocated by PyTorch, and 272.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
eb5be0b4,"{'temperature_head': 0.1, 'latent_dim': 326, 'batch_size': 285, 'transform_funcs': (4, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.06 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 984.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 814.00 MiB memory in use. Process 75233 has 748.00 MiB memory in use. Process 75240 has 872.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 1012.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 954.00 MiB memory in use. Process 75630 has 450.00 MiB memory in use. Process 76014 has 720.00 MiB memory in use. Process 76020 has 996.00 MiB memory in use. Process 76017 has 1.10 GiB memory in use. Process 76010 has 944.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 998.00 MiB memory in use. Process 76409 has 1.10 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.21 GiB memory in use. Of the allocated memory 80.39 MiB is allocated by PyTorch, and 31.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b9299fa6,"{'temperature_head': 0.9, 'latent_dim': 337, 'batch_size': 302, 'transform_funcs': (5, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.06 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 1.00 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 814.00 MiB memory in use. Process 75233 has 746.00 MiB memory in use. Process 75240 has 872.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 1012.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 954.00 MiB memory in use. Process 75630 has 456.00 MiB memory in use. Process 76014 has 720.00 MiB memory in use. Process 76020 has 996.00 MiB memory in use. Process 76017 has 1.10 GiB memory in use. Process 76010 has 944.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 998.00 MiB memory in use. Process 76409 has 1.10 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.16 GiB memory in use. Of the allocated memory 80.48 MiB is allocated by PyTorch, and 37.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0ac95e8b,"{'temperature_head': 0.1, 'latent_dim': 127, 'batch_size': 297, 'transform_funcs': (2, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.02 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 1.00 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 814.00 MiB memory in use. Process 75233 has 750.00 MiB memory in use. Process 75240 has 872.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 1012.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 954.00 MiB memory in use. Process 75630 has 506.00 MiB memory in use. Process 76014 has 780.00 MiB memory in use. Process 76020 has 998.00 MiB memory in use. Process 76017 has 1.10 GiB memory in use. Process 76010 has 888.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 952.00 MiB memory in use. Process 76409 has 1.10 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.16 GiB memory in use. Of the allocated memory 134.84 MiB is allocated by PyTorch, and 33.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6e23d12c,"{'temperature_head': 0.1, 'latent_dim': 357, 'batch_size': 244, 'transform_funcs': (3, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.02 GiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 1.00 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 814.00 MiB memory in use. Process 75233 has 748.00 MiB memory in use. Process 75240 has 872.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 1012.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 954.00 MiB memory in use. Process 75630 has 556.00 MiB memory in use. Process 76014 has 780.00 MiB memory in use. Process 76020 has 952.00 MiB memory in use. Process 76017 has 1.10 GiB memory in use. Process 76010 has 888.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 952.00 MiB memory in use. Process 76409 has 1.10 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.16 GiB memory in use. Of the allocated memory 347.19 MiB is allocated by PyTorch, and 266.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
28026d02,"{'temperature_head': 0.7000000000000001, 'latent_dim': 115, 'batch_size': 368, 'transform_funcs': (0, 2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 510.00 MiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 1.01 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 814.00 MiB memory in use. Process 75233 has 1.39 GiB memory in use. Process 75240 has 872.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 1.03 GiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 558.00 MiB memory in use. Process 75630 has 1.03 GiB memory in use. Process 76014 has 878.00 MiB memory in use. Process 76020 has 998.00 MiB memory in use. Process 76017 has 1.56 GiB memory in use. Process 76010 has 1.07 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 556.00 MiB memory in use. Process 76409 has 1.10 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 500.00 MiB memory in use. Of the allocated memory 134.74 MiB is allocated by PyTorch, and 37.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9b4093bb,"{'temperature_head': 0.6000000000000001, 'latent_dim': 265, 'batch_size': 264, 'transform_funcs': (2, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 448.00 MiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 1.01 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 814.00 MiB memory in use. Process 75233 has 1.39 GiB memory in use. Process 75240 has 872.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 1.03 GiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.03 GiB memory in use. Process 76014 has 878.00 MiB memory in use. Process 76020 has 998.00 MiB memory in use. Process 76017 has 1.56 GiB memory in use. Process 76010 has 1.07 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 558.00 MiB memory in use. Process 76409 has 1.10 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 560.00 MiB memory in use. Of the allocated memory 79.92 MiB is allocated by PyTorch, and 30.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cba87a06,"{'temperature_head': 0.2, 'latent_dim': 252, 'batch_size': 391, 'transform_funcs': (4, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 506.00 MiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 1.01 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 814.00 MiB memory in use. Process 75233 has 1.39 GiB memory in use. Process 75240 has 872.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 1.03 GiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 884.00 MiB memory in use. Process 75630 has 1.03 GiB memory in use. Process 76014 has 878.00 MiB memory in use. Process 76020 has 1.23 GiB memory in use. Process 76017 has 610.00 MiB memory in use. Process 76010 has 1.07 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 978.00 MiB memory in use. Process 76409 has 1.10 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 498.00 MiB memory in use. Of the allocated memory 135.81 MiB is allocated by PyTorch, and 32.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2349a4f0,"{'temperature_head': 0.1, 'latent_dim': 221, 'batch_size': 224, 'transform_funcs': (1, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 112.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 512.00 MiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 1.01 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 814.00 MiB memory in use. Process 75233 has 1.44 GiB memory in use. Process 75240 has 872.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 452.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 884.00 MiB memory in use. Process 75630 has 1.03 GiB memory in use. Process 76014 has 792.00 MiB memory in use. Process 76020 has 1.23 GiB memory in use. Process 76017 has 928.00 MiB memory in use. Process 76010 has 1.07 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 978.00 MiB memory in use. Process 76409 has 1022.00 MiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 820.00 MiB memory in use. Of the allocated memory 135.57 MiB is allocated by PyTorch, and 38.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c0987e93,"{'temperature_head': 0.1, 'latent_dim': 237, 'batch_size': 234, 'transform_funcs': (3, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 684.00 MiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 1.01 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 814.00 MiB memory in use. Process 75233 has 1.44 GiB memory in use. Process 75240 has 794.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 512.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 886.00 MiB memory in use. Process 75630 has 1.03 GiB memory in use. Process 76014 has 840.00 MiB memory in use. Process 76020 has 1.23 GiB memory in use. Process 76017 has 880.00 MiB memory in use. Process 76010 has 1.07 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 978.00 MiB memory in use. Process 76409 has 1022.00 MiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 766.00 MiB memory in use. Of the allocated memory 135.70 MiB is allocated by PyTorch, and 38.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0102f781,"{'temperature_head': 0.6000000000000001, 'latent_dim': 154, 'batch_size': 204, 'transform_funcs': (5, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 732.00 MiB memory in use. Process 71994 has 1.66 GiB memory in use. Process 71966 has 1.01 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 814.00 MiB memory in use. Process 75233 has 1.44 GiB memory in use. Process 75240 has 794.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 998.00 MiB memory in use. Process 75230 has 602.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 830.00 MiB memory in use. Process 75630 has 1.03 GiB memory in use. Process 76014 has 876.00 MiB memory in use. Process 76020 has 1.23 GiB memory in use. Process 76017 has 878.00 MiB memory in use. Process 76010 has 1.07 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 930.00 MiB memory in use. Process 76406 has 978.00 MiB memory in use. Process 76409 has 1.04 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 558.00 MiB memory in use. Of the allocated memory 227.05 MiB is allocated by PyTorch, and 36.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
aa251976,"{'temperature_head': 0.6000000000000001, 'latent_dim': 165, 'batch_size': 260, 'transform_funcs': (2, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 510.00 MiB memory in use. Process 71994 has 1.64 GiB memory in use. Process 71966 has 1.01 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 814.00 MiB memory in use. Process 75233 has 1.44 GiB memory in use. Process 75240 has 812.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 958.00 MiB memory in use. Process 75625 has 1.01 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 882.00 MiB memory in use. Process 75630 has 1.03 GiB memory in use. Process 76014 has 922.00 MiB memory in use. Process 76020 has 1.23 GiB memory in use. Process 76017 has 522.00 MiB memory in use. Process 76010 has 1.07 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 452.00 MiB memory in use. Process 76406 has 978.00 MiB memory in use. Process 76409 has 1.04 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 942.00 MiB memory in use. Of the allocated memory 135.13 MiB is allocated by PyTorch, and 36.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6fc78fe4,"{'temperature_head': 0.30000000000000004, 'latent_dim': 187, 'batch_size': 233, 'transform_funcs': (2, 3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 456.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.01 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 814.00 MiB memory in use. Process 75233 has 494.00 MiB memory in use. Process 75240 has 500.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 996.00 MiB memory in use. Process 75625 has 994.00 MiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.43 GiB memory in use. Process 75630 has 1.01 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.23 GiB memory in use. Process 76017 has 558.00 MiB memory in use. Process 76010 has 1.07 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 822.00 MiB memory in use. Process 76406 has 1004.00 MiB memory in use. Process 76409 has 1.04 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.25 GiB memory in use. Of the allocated memory 79.31 MiB is allocated by PyTorch, and 36.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e334dfee,"{'temperature_head': 0.2, 'latent_dim': 316, 'batch_size': 302, 'transform_funcs': (1, 3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 108.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 864.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 996.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 934.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 928.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.21 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.23 GiB memory in use. Process 76017 has 516.00 MiB memory in use. Process 76010 has 1.07 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 970.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 560.00 MiB memory in use. Of the allocated memory 322.63 MiB is allocated by PyTorch, and 201.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
406d4de2,"{'temperature_head': 0.1, 'latent_dim': 328, 'batch_size': 188, 'transform_funcs': (1, 2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 454.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 676.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 934.00 MiB memory in use. Process 75233 has 546.00 MiB memory in use. Process 75240 has 928.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.21 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.23 GiB memory in use. Process 76017 has 792.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.12 GiB memory in use. Of the allocated memory 80.41 MiB is allocated by PyTorch, and 33.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e363ae90,"{'temperature_head': 0.2, 'latent_dim': 306, 'batch_size': 222, 'transform_funcs': (1, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 102.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 508.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 504.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 854.00 MiB memory in use. Process 75240 has 928.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.18 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.23 GiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.12 GiB memory in use. Of the allocated memory 136.24 MiB is allocated by PyTorch, and 31.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
44fa35bd,"{'temperature_head': 0.2, 'latent_dim': 360, 'batch_size': 175, 'transform_funcs': (1, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 208.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 510.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 454.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 798.00 MiB memory in use. Process 75240 has 928.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 558.00 MiB memory in use. Process 75630 has 1.18 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.23 GiB memory in use. Process 76017 has 558.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.12 GiB memory in use. Of the allocated memory 136.66 MiB is allocated by PyTorch, and 33.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b1082d28,"{'temperature_head': 0.1, 'latent_dim': 331, 'batch_size': 199, 'transform_funcs': (1, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 706.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 456.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 796.00 MiB memory in use. Process 75240 has 928.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.19 GiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.12 GiB memory in use. Of the allocated memory 332.43 MiB is allocated by PyTorch, and 33.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b76d7194,"{'temperature_head': 0.2, 'latent_dim': 287, 'batch_size': 162, 'transform_funcs': (3, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 508.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 714.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 400.00 MiB memory in use. Process 75240 has 928.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.19 GiB memory in use. Process 76017 has 836.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.12 GiB memory in use. Of the allocated memory 136.09 MiB is allocated by PyTorch, and 31.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4ff163fe,"{'temperature_head': 0.2, 'latent_dim': 308, 'batch_size': 224, 'transform_funcs': (2, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 510.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 714.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 470.00 MiB memory in use. Process 75240 has 928.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.17 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 470.00 MiB memory in use. Process 76017 has 882.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.12 GiB memory in use. Of the allocated memory 136.25 MiB is allocated by PyTorch, and 33.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
57fe71ef,"{'temperature_head': 0.1, 'latent_dim': 325, 'batch_size': 204, 'transform_funcs': (3, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 556.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 436.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 470.00 MiB memory in use. Process 75240 has 928.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.17 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 702.00 MiB memory in use. Process 76017 has 882.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.12 GiB memory in use. Of the allocated memory 328.53 MiB is allocated by PyTorch, and 35.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
89f242ca,"{'temperature_head': 0.2, 'latent_dim': 345, 'batch_size': 149, 'transform_funcs': (0, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 100.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 508.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 928.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.17 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 474.00 MiB memory in use. Process 76017 has 912.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.12 GiB memory in use. Of the allocated memory 136.54 MiB is allocated by PyTorch, and 31.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f916130e,"{'temperature_head': 0.1, 'latent_dim': 350, 'batch_size': 170, 'transform_funcs': (2, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 556.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 928.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.17 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 912.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.08 GiB memory in use. Of the allocated memory 136.58 MiB is allocated by PyTorch, and 35.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2b5bb6c6,"{'temperature_head': 0.1, 'latent_dim': 320, 'batch_size': 175, 'transform_funcs': (2, 3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 130.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 510.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 734.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 556.00 MiB memory in use. Process 75240 has 814.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.47 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 474.00 MiB memory in use. Process 76017 has 500.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.12 GiB memory in use. Of the allocated memory 136.35 MiB is allocated by PyTorch, and 33.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
eb672c18,"{'temperature_head': 0.1, 'latent_dim': 360, 'batch_size': 152, 'transform_funcs': (2, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 556.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 734.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 860.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.47 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 512.00 MiB memory in use. Process 76017 has 500.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.12 GiB memory in use. Of the allocated memory 136.66 MiB is allocated by PyTorch, and 37.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cbe9b8b2,"{'temperature_head': 0.1, 'latent_dim': 292, 'batch_size': 190, 'transform_funcs': (4, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 556.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.04 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 808.00 MiB memory in use. Process 75240 has 860.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.47 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 516.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 500.00 MiB memory in use. Of the allocated memory 136.13 MiB is allocated by PyTorch, and 35.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d098bc06,"{'temperature_head': 0.1, 'latent_dim': 351, 'batch_size': 162, 'transform_funcs': (0, 3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 78.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 510.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.04 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 808.00 MiB memory in use. Process 75240 has 860.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.47 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 538.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 500.00 MiB memory in use. Of the allocated memory 136.59 MiB is allocated by PyTorch, and 33.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9f65d81f,"{'temperature_head': 0.1, 'latent_dim': 323, 'batch_size': 198, 'transform_funcs': (3, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 88.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 474.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.04 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 748.00 MiB memory in use. Process 75240 has 860.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.47 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 514.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 560.00 MiB memory in use. Of the allocated memory 136.37 MiB is allocated by PyTorch, and 39.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d171a922,"{'temperature_head': 0.1, 'latent_dim': 342, 'batch_size': 135, 'transform_funcs': (1, 3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 510.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.04 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 748.00 MiB memory in use. Process 75240 has 860.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.47 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 558.00 MiB memory in use. Process 76017 has 562.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 560.00 MiB memory in use. Of the allocated memory 136.52 MiB is allocated by PyTorch, and 33.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
69399726,"{'temperature_head': 0.1, 'latent_dim': 280, 'batch_size': 218, 'transform_funcs': (0, 2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 474.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 914.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 750.00 MiB memory in use. Process 75240 has 860.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.47 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 678.00 MiB memory in use. Process 76017 has 562.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 560.00 MiB memory in use. Of the allocated memory 302.03 MiB is allocated by PyTorch, and 37.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5b893683,"{'temperature_head': 0.1, 'latent_dim': 354, 'batch_size': 145, 'transform_funcs': (1, 2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 456.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 914.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 750.00 MiB memory in use. Process 75240 has 860.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.11 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 1.06 GiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 558.00 MiB memory in use. Of the allocated memory 80.61 MiB is allocated by PyTorch, and 35.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
23449da9,"{'temperature_head': 0.1, 'latent_dim': 328, 'batch_size': 189, 'transform_funcs': (7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 190.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.04 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 454.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 706.00 MiB memory in use. Process 75240 has 860.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.02 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 472.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 1020.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.07 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.16 GiB memory in use. Of the allocated memory 136.41 MiB is allocated by PyTorch, and 35.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
526aca76,"{'temperature_head': 0.2, 'latent_dim': 322, 'batch_size': 217, 'transform_funcs': (2, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 130.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.04 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 456.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 750.00 MiB memory in use. Process 75240 has 860.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.02 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 512.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 698.00 MiB memory in use. Process 76017 has 758.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.16 GiB memory in use. Of the allocated memory 326.73 MiB is allocated by PyTorch, and 33.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
748016f1,"{'temperature_head': 0.2, 'latent_dim': 308, 'batch_size': 153, 'transform_funcs': (1, 2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 164.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.04 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 468.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 750.00 MiB memory in use. Process 75240 has 860.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 514.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 924.00 MiB memory in use. Process 76020 has 640.00 MiB memory in use. Process 76017 has 758.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.13 GiB memory in use. Of the allocated memory 135.75 MiB is allocated by PyTorch, and 166.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9373d464,"{'temperature_head': 0.1, 'latent_dim': 360, 'batch_size': 228, 'transform_funcs': (2, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 140.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.04 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 454.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 702.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 436.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 644.00 MiB memory in use. Process 76017 has 756.00 MiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.13 GiB memory in use. Of the allocated memory 136.15 MiB is allocated by PyTorch, and 169.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
88c4b677,"{'temperature_head': 0.1, 'latent_dim': 334, 'batch_size': 166, 'transform_funcs': (4, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.04 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 472.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 750.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 844.00 MiB memory in use. Process 76017 has 1.07 GiB memory in use. Process 76010 has 1.08 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 500.00 MiB memory in use. Of the allocated memory 333.95 MiB is allocated by PyTorch, and 172.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
97de8065,"{'temperature_head': 0.30000000000000004, 'latent_dim': 320, 'batch_size': 219, 'transform_funcs': (0, 1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 136.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.04 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 426.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 750.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 844.00 MiB memory in use. Process 76017 has 1.07 GiB memory in use. Process 76010 has 1.03 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 522.00 MiB memory in use. Of the allocated memory 325.02 MiB is allocated by PyTorch, and 180.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4ddd60cf,"{'temperature_head': 0.1, 'latent_dim': 266, 'batch_size': 175, 'transform_funcs': (0, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.04 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 472.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 750.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.10 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 842.00 MiB memory in use. Process 76017 has 1.07 GiB memory in use. Process 76010 has 456.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 558.00 MiB memory in use. Of the allocated memory 292.68 MiB is allocated by PyTorch, and 211.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e72445fa,"{'temperature_head': 0.2, 'latent_dim': 350, 'batch_size': 128, 'transform_funcs': (2, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1004.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 552.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 748.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.10 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 852.00 MiB memory in use. Process 76017 has 1.07 GiB memory in use. Process 76010 has 456.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 578.00 MiB memory in use. Of the allocated memory 343.00 MiB is allocated by PyTorch, and 171.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
81904461,"{'temperature_head': 0.1, 'latent_dim': 360, 'batch_size': 209, 'transform_funcs': (3, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 82.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1004.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 454.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 926.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.10 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 514.00 MiB memory in use. Process 76017 has 1.07 GiB memory in use. Process 76010 has 692.00 MiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 558.00 MiB memory in use. Of the allocated memory 136.66 MiB is allocated by PyTorch, and 39.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b0af33ec,"{'temperature_head': 0.30000000000000004, 'latent_dim': 294, 'batch_size': 199, 'transform_funcs': (1, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 88.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 472.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 454.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 930.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.14 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 512.00 MiB memory in use. Process 76017 has 1.07 GiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 654.00 MiB memory in use. Of the allocated memory 136.14 MiB is allocated by PyTorch, and 37.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
12db6cbb,"{'temperature_head': 0.2, 'latent_dim': 328, 'batch_size': 165, 'transform_funcs': (3, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 452.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 560.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 930.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.14 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 470.00 MiB memory in use. Process 76017 has 1.07 GiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 654.00 MiB memory in use. Of the allocated memory 80.41 MiB is allocated by PyTorch, and 31.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5b9c2a64,"{'temperature_head': 0.30000000000000004, 'latent_dim': 340, 'batch_size': 263, 'transform_funcs': (8, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 202.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 510.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 990.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 930.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.14 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 470.00 MiB memory in use. Process 76017 has 538.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 704.00 MiB memory in use. Of the allocated memory 136.50 MiB is allocated by PyTorch, and 33.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3d071226,"{'temperature_head': 0.1, 'latent_dim': 283, 'batch_size': 231, 'transform_funcs': (7, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 134.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 468.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 990.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 974.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.14 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 574.00 MiB memory in use. Of the allocated memory 136.06 MiB is allocated by PyTorch, and 35.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c672467d,"{'temperature_head': 0.1, 'latent_dim': 335, 'batch_size': 260, 'transform_funcs': (2, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 510.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 990.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 974.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.14 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 554.00 MiB memory in use. Process 76017 has 558.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 576.00 MiB memory in use. Of the allocated memory 136.46 MiB is allocated by PyTorch, and 33.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
15c9d898,"{'temperature_head': 0.2, 'latent_dim': 296, 'batch_size': 281, 'transform_funcs': (1, 2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 110.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 556.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 990.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 974.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.14 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 512.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 560.00 MiB memory in use. Of the allocated memory 136.16 MiB is allocated by PyTorch, and 33.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c358be78,"{'temperature_head': 0.1, 'latent_dim': 272, 'batch_size': 267, 'transform_funcs': (6, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 670.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 910.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 974.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.09 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 554.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 560.00 MiB memory in use. Of the allocated memory 296.78 MiB is allocated by PyTorch, and 33.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
61377fd2,"{'temperature_head': 0.1, 'latent_dim': 304, 'batch_size': 251, 'transform_funcs': (2, 3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 472.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 910.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 994.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.06 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.13 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 686.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 562.00 MiB memory in use. Of the allocated memory 316.22 MiB is allocated by PyTorch, and 31.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
47244956,"{'temperature_head': 0.1, 'latent_dim': 264, 'batch_size': 236, 'transform_funcs': (2, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 510.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 956.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 996.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.35 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 470.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 498.00 MiB memory in use. Of the allocated memory 135.91 MiB is allocated by PyTorch, and 34.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f0a942d1,"{'temperature_head': 0.1, 'latent_dim': 333, 'batch_size': 249, 'transform_funcs': (0, 3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 556.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 956.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 996.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.35 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 472.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 500.00 MiB memory in use. Of the allocated memory 136.45 MiB is allocated by PyTorch, and 33.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cd0c4161,"{'temperature_head': 0.1, 'latent_dim': 337, 'batch_size': 278, 'transform_funcs': (1, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 556.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 956.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 992.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.35 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 452.00 MiB memory in use. Process 76017 has 510.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 512.00 MiB memory in use. Of the allocated memory 80.48 MiB is allocated by PyTorch, and 33.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0c29145d,"{'temperature_head': 0.2, 'latent_dim': 326, 'batch_size': 214, 'transform_funcs': (5, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 888.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.03 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 540.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 514.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 1.03 GiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 786.00 MiB memory in use. Of the allocated memory 136.39 MiB is allocated by PyTorch, and 35.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bbc02615,"{'temperature_head': 0.1, 'latent_dim': 296, 'batch_size': 261, 'transform_funcs': (1, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 936.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.03 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 454.00 MiB memory in use. Process 76017 has 1.03 GiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 728.00 MiB memory in use. Of the allocated memory 80.16 MiB is allocated by PyTorch, and 35.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
78bfec06,"{'temperature_head': 0.2, 'latent_dim': 292, 'batch_size': 246, 'transform_funcs': (1, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 108.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 834.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.03 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 482.00 MiB memory in use. Process 76017 has 1.03 GiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 728.00 MiB memory in use. Of the allocated memory 308.25 MiB is allocated by PyTorch, and 185.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4c37c254,"{'temperature_head': 0.30000000000000004, 'latent_dim': 260, 'batch_size': 206, 'transform_funcs': (2, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 880.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 516.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 660.00 MiB memory in use. Process 76017 has 880.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 912.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 728.00 MiB memory in use. Of the allocated memory 289.88 MiB is allocated by PyTorch, and 32.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a6dfcaca,"{'temperature_head': 0.1, 'latent_dim': 306, 'batch_size': 268, 'transform_funcs': (0, 2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 92.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 832.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 470.00 MiB memory in use. Process 76017 has 880.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 730.00 MiB memory in use. Of the allocated memory 316.64 MiB is allocated by PyTorch, and 175.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a76864c1,"{'temperature_head': 0.30000000000000004, 'latent_dim': 329, 'batch_size': 284, 'transform_funcs': (3, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 880.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 552.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 824.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 730.00 MiB memory in use. Of the allocated memory 136.42 MiB is allocated by PyTorch, and 33.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8767074e,"{'temperature_head': 0.2, 'latent_dim': 312, 'batch_size': 295, 'transform_funcs': (1, 2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 186.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 116.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 830.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 514.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 554.00 MiB memory in use. Process 76017 has 822.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 730.00 MiB memory in use. Of the allocated memory 320.23 MiB is allocated by PyTorch, and 169.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7e369136,"{'temperature_head': 0.2, 'latent_dim': 351, 'batch_size': 276, 'transform_funcs': (2, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 880.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 552.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 506.00 MiB memory in use. Process 76017 has 824.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 730.00 MiB memory in use. Of the allocated memory 136.59 MiB is allocated by PyTorch, and 31.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
255580d4,"{'temperature_head': 0.1, 'latent_dim': 267, 'batch_size': 200, 'transform_funcs': (0, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 834.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 556.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 556.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 554.00 MiB memory in use. Process 76017 has 824.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 728.00 MiB memory in use. Of the allocated memory 293.28 MiB is allocated by PyTorch, and 200.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3ed465fa,"{'temperature_head': 0.30000000000000004, 'latent_dim': 250, 'batch_size': 181, 'transform_funcs': (6, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 114.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 880.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 556.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 558.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 506.00 MiB memory in use. Process 76017 has 778.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 728.00 MiB memory in use. Of the allocated memory 135.80 MiB is allocated by PyTorch, and 32.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
40e5c938,"{'temperature_head': 0.1, 'latent_dim': 277, 'batch_size': 245, 'transform_funcs': (0, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 92.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 832.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 552.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 538.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 554.00 MiB memory in use. Process 76017 has 822.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 730.00 MiB memory in use. Of the allocated memory 299.27 MiB is allocated by PyTorch, and 192.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1f872710,"{'temperature_head': 0.2, 'latent_dim': 321, 'batch_size': 216, 'transform_funcs': (5, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 88.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 880.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 552.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 538.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 824.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 730.00 MiB memory in use. Of the allocated memory 136.35 MiB is allocated by PyTorch, and 33.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
267aa6d4,"{'temperature_head': 0.2, 'latent_dim': 315, 'batch_size': 303, 'transform_funcs': (3, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 880.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 552.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 824.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 728.00 MiB memory in use. Of the allocated memory 136.31 MiB is allocated by PyTorch, and 33.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
77f6f8ba,"{'temperature_head': 0.1, 'latent_dim': 360, 'batch_size': 225, 'transform_funcs': (3, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 860.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 556.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 558.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 554.00 MiB memory in use. Process 76017 has 824.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 730.00 MiB memory in use. Of the allocated memory 348.99 MiB is allocated by PyTorch, and 171.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2abb4c44,"{'temperature_head': 0.1, 'latent_dim': 347, 'batch_size': 267, 'transform_funcs': (0, 2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 204.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 904.00 MiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 556.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 558.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 712.00 MiB memory in use. Process 76017 has 454.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 730.00 MiB memory in use. Of the allocated memory 342.56 MiB is allocated by PyTorch, and 31.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a656fb71,"{'temperature_head': 0.2, 'latent_dim': 247, 'batch_size': 188, 'transform_funcs': (2, 3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 124.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.01 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 658.00 MiB memory in use. Process 76017 has 454.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 730.00 MiB memory in use. Of the allocated memory 281.30 MiB is allocated by PyTorch, and 38.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
411ced88,"{'temperature_head': 0.2, 'latent_dim': 353, 'batch_size': 158, 'transform_funcs': (2, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.01 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 552.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 660.00 MiB memory in use. Process 76017 has 504.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 730.00 MiB memory in use. Of the allocated memory 136.10 MiB is allocated by PyTorch, and 183.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
232933e5,"{'temperature_head': 0.2, 'latent_dim': 283, 'batch_size': 275, 'transform_funcs': (0, 2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 88.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.08 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 556.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 506.00 MiB memory in use. Process 76017 has 570.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 730.00 MiB memory in use. Of the allocated memory 136.06 MiB is allocated by PyTorch, and 29.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
65a0eb14,"{'temperature_head': 0.1, 'latent_dim': 273, 'batch_size': 149, 'transform_funcs': (1, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 146.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.08 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 684.00 MiB memory in use. Of the allocated memory 135.98 MiB is allocated by PyTorch, and 32.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9df712ee,"{'temperature_head': 0.30000000000000004, 'latent_dim': 306, 'batch_size': 249, 'transform_funcs': (3, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 134.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.12 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 516.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 558.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 562.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 686.00 MiB memory in use. Of the allocated memory 136.24 MiB is allocated by PyTorch, and 33.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9229f2d2,"{'temperature_head': 0.1, 'latent_dim': 353, 'batch_size': 263, 'transform_funcs': (2, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 132.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.09 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 556.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 518.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 730.00 MiB memory in use. Of the allocated memory 136.60 MiB is allocated by PyTorch, and 33.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f02aec37,"{'temperature_head': 0.2, 'latent_dim': 340, 'batch_size': 221, 'transform_funcs': (3, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 202.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 124.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.13 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 506.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 558.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 528.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 732.00 MiB memory in use. Of the allocated memory 136.50 MiB is allocated by PyTorch, and 33.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
16893c28,"{'temperature_head': 0.2, 'latent_dim': 359, 'batch_size': 200, 'transform_funcs': (4, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 108.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.13 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 534.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 518.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 728.00 MiB memory in use. Of the allocated memory 136.65 MiB is allocated by PyTorch, and 33.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1fda51ec,"{'temperature_head': 0.2, 'latent_dim': 253, 'batch_size': 233, 'transform_funcs': (1, 3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.13 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 552.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 454.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 642.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 730.00 MiB memory in use. Of the allocated memory 135.82 MiB is allocated by PyTorch, and 34.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dc4478b4,"{'temperature_head': 0.2, 'latent_dim': 278, 'batch_size': 301, 'transform_funcs': (0, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.13 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 570.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 676.00 MiB memory in use. Process 76017 has 432.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 710.00 MiB memory in use. Of the allocated memory 300.37 MiB is allocated by PyTorch, and 35.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c61d8eaf,"{'temperature_head': 0.7000000000000001, 'latent_dim': 287, 'batch_size': 168, 'transform_funcs': (1, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 140.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.13 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 552.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 618.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 872.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 528.00 MiB memory in use. Of the allocated memory 135.58 MiB is allocated by PyTorch, and 142.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
148452e0,"{'temperature_head': 0.1, 'latent_dim': 314, 'batch_size': 164, 'transform_funcs': (2, 3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 186.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.13 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 552.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 796.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 620.00 MiB memory in use. Process 76017 has 556.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 670.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 570.00 MiB memory in use. Of the allocated memory 135.79 MiB is allocated by PyTorch, and 144.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
68fa56ca,"{'temperature_head': 0.2, 'latent_dim': 256, 'batch_size': 182, 'transform_funcs': (0, 1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 102.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.13 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 630.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 740.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 514.00 MiB memory in use. Process 76017 has 556.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 568.00 MiB memory in use. Of the allocated memory 135.84 MiB is allocated by PyTorch, and 38.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d4f91647,"{'temperature_head': 0.2, 'latent_dim': 318, 'batch_size': 141, 'transform_funcs': (1, 2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.13 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 670.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 742.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 514.00 MiB memory in use. Process 76017 has 556.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 568.00 MiB memory in use. Of the allocated memory 136.33 MiB is allocated by PyTorch, and 37.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7258c05a,"{'temperature_head': 0.30000000000000004, 'latent_dim': 273, 'batch_size': 187, 'transform_funcs': (0, 3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.13 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 490.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 742.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 514.00 MiB memory in use. Process 76017 has 556.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 758.00 MiB memory in use. Of the allocated memory 135.98 MiB is allocated by PyTorch, and 38.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
39cb55cc,"{'temperature_head': 0.6000000000000001, 'latent_dim': 320, 'batch_size': 136, 'transform_funcs': (2, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 110.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.13 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 488.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 740.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 514.00 MiB memory in use. Process 76017 has 556.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 702.00 MiB memory in use. Of the allocated memory 136.35 MiB is allocated by PyTorch, and 37.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0b9d44fe,"{'temperature_head': 0.7000000000000001, 'latent_dim': 299, 'batch_size': 179, 'transform_funcs': (2, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 108.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.13 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 492.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 740.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 512.00 MiB memory in use. Process 76017 has 556.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 702.00 MiB memory in use. Of the allocated memory 136.18 MiB is allocated by PyTorch, and 35.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6bc6ac4a,"{'temperature_head': 0.1, 'latent_dim': 262, 'batch_size': 159, 'transform_funcs': (0, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 156.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 130.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.13 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.08 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 470.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 740.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 512.00 MiB memory in use. Process 76017 has 556.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 702.00 MiB memory in use. Of the allocated memory 135.89 MiB is allocated by PyTorch, and 36.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6d907548,"{'temperature_head': 0.1, 'latent_dim': 276, 'batch_size': 137, 'transform_funcs': (1, 2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 128.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.13 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 1.04 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 740.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 514.00 MiB memory in use. Process 76017 has 510.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 702.00 MiB memory in use. Of the allocated memory 136.00 MiB is allocated by PyTorch, and 38.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0bf41169,"{'temperature_head': 0.2, 'latent_dim': 360, 'batch_size': 153, 'transform_funcs': (2, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 190.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.09 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 454.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 556.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 694.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 514.00 MiB memory in use. Process 76017 has 558.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 1.04 GiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.26 GiB memory in use. Of the allocated memory 136.66 MiB is allocated by PyTorch, and 37.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
97691aa9,"{'temperature_head': 0.1, 'latent_dim': 293, 'batch_size': 213, 'transform_funcs': (0, 1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 162.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.09 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 456.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 556.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 740.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 686.00 MiB memory in use. Process 76017 has 556.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 878.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.26 GiB memory in use. Of the allocated memory 310.14 MiB is allocated by PyTorch, and 35.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6b88c86f,"{'temperature_head': 0.2, 'latent_dim': 306, 'batch_size': 162, 'transform_funcs': (0, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 130.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.13 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 472.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 740.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 632.00 MiB memory in use. Process 76017 has 540.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.26 GiB memory in use. Of the allocated memory 135.73 MiB is allocated by PyTorch, and 156.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5cbcfe18,"{'temperature_head': 0.1, 'latent_dim': 346, 'batch_size': 195, 'transform_funcs': (0, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 76.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.13 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 556.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 506.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 740.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 632.00 MiB memory in use. Process 76017 has 558.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.26 GiB memory in use. Of the allocated memory 136.04 MiB is allocated by PyTorch, and 155.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
577c433e,"{'temperature_head': 0.2, 'latent_dim': 243, 'batch_size': 246, 'transform_funcs': (2, 3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 118.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.13 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 556.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 470.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 738.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 630.00 MiB memory in use. Process 76017 has 556.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.26 GiB memory in use. Of the allocated memory 135.24 MiB is allocated by PyTorch, and 154.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a500db50,"{'temperature_head': 0.1, 'latent_dim': 291, 'batch_size': 168, 'transform_funcs': (2, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 76.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.09 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 454.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 500.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 956.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 630.00 MiB memory in use. Process 76017 has 498.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.26 GiB memory in use. Of the allocated memory 135.61 MiB is allocated by PyTorch, and 154.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3e9d59c3,"{'temperature_head': 0.1, 'latent_dim': 345, 'batch_size': 225, 'transform_funcs': (1, 3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 456.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 504.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 930.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 632.00 MiB memory in use. Process 76017 has 482.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.26 GiB memory in use. Of the allocated memory 136.04 MiB is allocated by PyTorch, and 155.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9f7b71c0,"{'temperature_head': 0.1, 'latent_dim': 309, 'batch_size': 252, 'transform_funcs': (0, 2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 160.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 468.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 820.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 498.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 632.00 MiB memory in use. Process 76017 has 488.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.26 GiB memory in use. Of the allocated memory 135.75 MiB is allocated by PyTorch, and 156.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
139e1bc1,"{'temperature_head': 0.1, 'latent_dim': 300, 'batch_size': 255, 'transform_funcs': (2, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 502.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 810.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 526.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 810.00 MiB memory in use. Process 76017 has 562.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.05 GiB memory in use. Of the allocated memory 313.68 MiB is allocated by PyTorch, and 156.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6efc7b42,"{'temperature_head': 0.2, 'latent_dim': 360, 'batch_size': 232, 'transform_funcs': (4, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 114.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 472.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 778.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 510.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 846.00 MiB memory in use. Process 76017 has 562.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.05 GiB memory in use. Of the allocated memory 348.99 MiB is allocated by PyTorch, and 157.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
49521aaf,"{'temperature_head': 0.1, 'latent_dim': 296, 'batch_size': 297, 'transform_funcs': (6, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 108.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 828.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 810.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.02 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 516.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.05 GiB memory in use. Of the allocated memory 136.16 MiB is allocated by PyTorch, and 31.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1007c1dc,"{'temperature_head': 0.1, 'latent_dim': 337, 'batch_size': 203, 'transform_funcs': (5, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 468.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.02 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 506.00 MiB memory in use. Process 76017 has 908.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.06 GiB memory in use. Of the allocated memory 136.48 MiB is allocated by PyTorch, and 29.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7652b0f4,"{'temperature_head': 0.1, 'latent_dim': 287, 'batch_size': 262, 'transform_funcs': (6, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 560.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 810.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 476.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 558.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 678.00 MiB memory in use. Process 76017 has 908.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 306.09 MiB is allocated by PyTorch, and 31.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
78797b45,"{'temperature_head': 0.2, 'latent_dim': 348, 'batch_size': 183, 'transform_funcs': (2, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 190.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 560.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 810.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 512.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 558.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 470.00 MiB memory in use. Process 76017 has 910.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.56 MiB is allocated by PyTorch, and 35.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
aa2668dd,"{'temperature_head': 0.2, 'latent_dim': 306, 'batch_size': 230, 'transform_funcs': (4, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.09 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 560.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 810.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 704.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 910.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.24 MiB is allocated by PyTorch, and 33.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
463b6300,"{'temperature_head': 0.2, 'latent_dim': 273, 'batch_size': 196, 'transform_funcs': (1, 3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 104.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.09 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 542.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 704.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 472.00 MiB memory in use. Process 76017 has 910.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 135.98 MiB is allocated by PyTorch, and 34.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9fe1d0c1,"{'temperature_head': 0.1, 'latent_dim': 294, 'batch_size': 277, 'transform_funcs': (3, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.09 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 560.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 648.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 910.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.14 MiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
900250a7,"{'temperature_head': 0.2, 'latent_dim': 314, 'batch_size': 509, 'transform_funcs': (1, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 186.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 766.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 648.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 912.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.30 MiB is allocated by PyTorch, and 33.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2bf201e3,"{'temperature_head': 0.1, 'latent_dim': 303, 'batch_size': 250, 'transform_funcs': (4, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 86.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 560.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 650.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 478.00 MiB memory in use. Process 76017 has 912.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.21 MiB is allocated by PyTorch, and 33.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e9344035,"{'temperature_head': 0.6000000000000001, 'latent_dim': 332, 'batch_size': 261, 'transform_funcs': (7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 138.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 560.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 810.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 600.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 478.00 MiB memory in use. Process 76017 has 912.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.44 MiB is allocated by PyTorch, and 33.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
70c1233b,"{'temperature_head': 0.1, 'latent_dim': 351, 'batch_size': 155, 'transform_funcs': (1, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 112.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 810.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 648.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 514.00 MiB memory in use. Process 76017 has 808.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.59 MiB is allocated by PyTorch, and 37.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
97bb28aa,"{'temperature_head': 0.1, 'latent_dim': 316, 'batch_size': 163, 'transform_funcs': (4, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 648.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 514.00 MiB memory in use. Process 76017 has 854.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.31 MiB is allocated by PyTorch, and 37.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
02b3223c,"{'temperature_head': 0.2, 'latent_dim': 265, 'batch_size': 190, 'transform_funcs': (3, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 560.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 650.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 560.00 MiB memory in use. Process 76017 has 854.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 135.92 MiB is allocated by PyTorch, and 34.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a4bb366c,"{'temperature_head': 0.1, 'latent_dim': 284, 'batch_size': 493, 'transform_funcs': (0, 1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 648.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 512.00 MiB memory in use. Process 76017 has 856.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.06 MiB is allocated by PyTorch, and 35.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a7ef164b,"{'temperature_head': 0.2, 'latent_dim': 289, 'batch_size': 245, 'transform_funcs': (0, 1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 108.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 514.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 648.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 512.00 MiB memory in use. Process 76017 has 856.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.10 MiB is allocated by PyTorch, and 37.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0ac5878a,"{'temperature_head': 0.6000000000000001, 'latent_dim': 353, 'batch_size': 255, 'transform_funcs': (6, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 106.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 560.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 766.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 648.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 514.00 MiB memory in use. Process 76017 has 856.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.60 MiB is allocated by PyTorch, and 37.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a4b69f6e,"{'temperature_head': 0.2, 'latent_dim': 311, 'batch_size': 213, 'transform_funcs': (0, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 106.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 514.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 648.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 560.00 MiB memory in use. Process 76017 has 810.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.28 MiB is allocated by PyTorch, and 37.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
26f398df,"{'temperature_head': 0.7000000000000001, 'latent_dim': 320, 'batch_size': 172, 'transform_funcs': (1, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 810.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 648.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 512.00 MiB memory in use. Process 76017 has 856.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.35 MiB is allocated by PyTorch, and 35.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
fcff348c,"{'temperature_head': 0.30000000000000004, 'latent_dim': 265, 'batch_size': 295, 'transform_funcs': (2, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 512.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 650.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 560.00 MiB memory in use. Process 76017 has 856.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 135.92 MiB is allocated by PyTorch, and 36.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d6b136fc,"{'temperature_head': 0.30000000000000004, 'latent_dim': 301, 'batch_size': 326, 'transform_funcs': (3, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 110.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 762.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 650.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 514.00 MiB memory in use. Process 76017 has 856.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.20 MiB is allocated by PyTorch, and 37.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
59edae95,"{'temperature_head': 0.30000000000000004, 'latent_dim': 295, 'batch_size': 305, 'transform_funcs': (2, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 810.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 648.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 560.00 MiB memory in use. Process 76017 has 856.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.15 MiB is allocated by PyTorch, and 33.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
737fbdfe,"{'temperature_head': 0.30000000000000004, 'latent_dim': 302, 'batch_size': 317, 'transform_funcs': (5, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 810.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 648.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 514.00 MiB memory in use. Process 76017 has 856.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.21 MiB is allocated by PyTorch, and 37.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ee40744a,"{'temperature_head': 0.30000000000000004, 'latent_dim': 289, 'batch_size': 299, 'transform_funcs': (0, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 650.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 560.00 MiB memory in use. Process 76017 has 856.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.10 MiB is allocated by PyTorch, and 33.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
29133038,"{'temperature_head': 0.2, 'latent_dim': 256, 'batch_size': 273, 'transform_funcs': (2, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 650.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 512.00 MiB memory in use. Process 76017 has 856.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 135.84 MiB is allocated by PyTorch, and 36.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bb45ba04,"{'temperature_head': 0.30000000000000004, 'latent_dim': 278, 'batch_size': 271, 'transform_funcs': (7, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 512.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 650.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 560.00 MiB memory in use. Process 76017 has 856.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.02 MiB is allocated by PyTorch, and 35.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1325f5ee,"{'temperature_head': 0.30000000000000004, 'latent_dim': 309, 'batch_size': 267, 'transform_funcs': (2, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 650.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 854.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.26 MiB is allocated by PyTorch, and 33.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
da47c0c7,"{'temperature_head': 0.2, 'latent_dim': 297, 'batch_size': 311, 'transform_funcs': (3, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 514.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 650.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 560.00 MiB memory in use. Process 76017 has 854.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.17 MiB is allocated by PyTorch, and 37.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
45a602cf,"{'temperature_head': 0.30000000000000004, 'latent_dim': 291, 'batch_size': 282, 'transform_funcs': (2, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 110.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 602.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 514.00 MiB memory in use. Process 76017 has 854.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.12 MiB is allocated by PyTorch, and 37.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
fffb973c,"{'temperature_head': 0.2, 'latent_dim': 233, 'batch_size': 277, 'transform_funcs': (0, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 560.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 648.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 560.00 MiB memory in use. Process 76017 has 854.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 135.67 MiB is allocated by PyTorch, and 34.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
66ddf6ed,"{'temperature_head': 0.30000000000000004, 'latent_dim': 239, 'batch_size': 333, 'transform_funcs': (2, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 560.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 810.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 648.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 560.00 MiB memory in use. Process 76017 has 854.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 135.71 MiB is allocated by PyTorch, and 34.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6bc37e61,"{'temperature_head': 0.2, 'latent_dim': 250, 'batch_size': 258, 'transform_funcs': (0, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 560.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 648.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 854.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 135.80 MiB is allocated by PyTorch, and 34.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
139cb995,"{'temperature_head': 0.4, 'latent_dim': 319, 'batch_size': 182, 'transform_funcs': (0, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 648.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 560.00 MiB memory in use. Process 76017 has 858.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 136.34 MiB is allocated by PyTorch, and 33.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3eb92fcc,"{'temperature_head': 0.30000000000000004, 'latent_dim': 259, 'batch_size': 292, 'transform_funcs': (0, 2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 648.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 512.00 MiB memory in use. Process 76017 has 858.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 135.87 MiB is allocated by PyTorch, and 36.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4dd9c2c9,"{'temperature_head': 0.6000000000000001, 'latent_dim': 270, 'batch_size': 344, 'transform_funcs': (0, 3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 512.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 810.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 706.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 560.00 MiB memory in use. Process 76017 has 856.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 135.96 MiB is allocated by PyTorch, and 34.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c0a0564b,"{'temperature_head': 0.30000000000000004, 'latent_dim': 283, 'batch_size': 262, 'transform_funcs': (2, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.69 GiB memory in use. Process 71966 has 560.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 810.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 498.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 682.00 MiB memory in use. Process 76017 has 856.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.40 GiB memory in use. Of the allocated memory 304.06 MiB is allocated by PyTorch, and 37.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e4aa6b1b,"{'temperature_head': 0.2, 'latent_dim': 296, 'batch_size': 160, 'transform_funcs': (0, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.65 GiB memory in use. Process 71966 has 560.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 810.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 512.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 472.00 MiB memory in use. Process 76017 has 996.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.48 GiB memory in use. Of the allocated memory 136.16 MiB is allocated by PyTorch, and 35.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2c31bb89,"{'temperature_head': 0.1, 'latent_dim': 326, 'batch_size': 136, 'transform_funcs': (3, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.65 GiB memory in use. Process 71966 has 560.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 810.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 454.00 MiB memory in use. Process 76017 has 996.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.48 GiB memory in use. Of the allocated memory 80.39 MiB is allocated by PyTorch, and 33.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
975e2c94,"{'temperature_head': 0.30000000000000004, 'latent_dim': 305, 'batch_size': 276, 'transform_funcs': (0, 1, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.65 GiB memory in use. Process 71966 has 560.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 810.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 510.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 472.00 MiB memory in use. Process 76017 has 996.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.48 GiB memory in use. Of the allocated memory 136.23 MiB is allocated by PyTorch, and 33.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
aeb01927,"{'temperature_head': 0.6000000000000001, 'latent_dim': 276, 'batch_size': 246, 'transform_funcs': (1, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 116.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.65 GiB memory in use. Process 71966 has 430.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 810.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 558.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 558.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 996.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.48 GiB memory in use. Of the allocated memory 136.00 MiB is allocated by PyTorch, and 32.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8c66a711,"{'temperature_head': 0.1, 'latent_dim': 291, 'batch_size': 269, 'transform_funcs': (1, 3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.65 GiB memory in use. Process 71966 has 468.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 684.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 890.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 556.00 MiB memory in use. Process 76017 has 514.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.48 GiB memory in use. Of the allocated memory 308.16 MiB is allocated by PyTorch, and 35.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4f29f4b4,"{'temperature_head': 0.4, 'latent_dim': 246, 'batch_size': 151, 'transform_funcs': (6, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.65 GiB memory in use. Process 71966 has 468.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 812.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 732.00 MiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 890.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 514.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.48 GiB memory in use. Of the allocated memory 135.77 MiB is allocated by PyTorch, and 32.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
deb29227,"{'temperature_head': 0.1, 'latent_dim': 333, 'batch_size': 254, 'transform_funcs': (0, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 524.00 MiB memory in use. Process 71966 has 1.03 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 768.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.15 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 472.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.52 GiB memory in use. Of the allocated memory 136.45 MiB is allocated by PyTorch, and 33.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
86796b6a,"{'temperature_head': 0.2, 'latent_dim': 283, 'batch_size': 186, 'transform_funcs': (2, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 112.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1.03 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 558.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.15 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 556.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.52 GiB memory in use. Of the allocated memory 136.06 MiB is allocated by PyTorch, and 31.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d5cc5cee,"{'temperature_head': 0.6000000000000001, 'latent_dim': 318, 'batch_size': 214, 'transform_funcs': (1, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 110.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1.03 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 558.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.07 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.15 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 556.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.52 GiB memory in use. Of the allocated memory 136.33 MiB is allocated by PyTorch, and 33.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1bddfd8f,"{'temperature_head': 0.30000000000000004, 'latent_dim': 360, 'batch_size': 228, 'transform_funcs': (4, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 562.00 MiB memory in use. Process 71966 has 1.03 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 556.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.11 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.15 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 556.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.52 GiB memory in use. Of the allocated memory 136.66 MiB is allocated by PyTorch, and 31.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f19f8ed4,"{'temperature_head': 0.8, 'latent_dim': 306, 'batch_size': 280, 'transform_funcs': (5, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1.03 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 560.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.11 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.15 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 556.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.52 GiB memory in use. Of the allocated memory 136.24 MiB is allocated by PyTorch, and 31.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bcc138c6,"{'temperature_head': 0.1, 'latent_dim': 341, 'batch_size': 243, 'transform_funcs': (2, 3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 202.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1.03 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 558.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.15 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 554.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.52 GiB memory in use. Of the allocated memory 136.51 MiB is allocated by PyTorch, and 33.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ac9dbfa3,"{'temperature_head': 0.1, 'latent_dim': 323, 'batch_size': 142, 'transform_funcs': (4, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 102.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1.03 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 558.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.15 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 516.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.52 GiB memory in use. Of the allocated memory 136.37 MiB is allocated by PyTorch, and 31.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3e2a0c64,"{'temperature_head': 0.6000000000000001, 'latent_dim': 188, 'batch_size': 259, 'transform_funcs': (2, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 562.00 MiB memory in use. Process 71966 has 1.03 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 558.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.15 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 506.00 MiB memory in use. Process 76017 has 556.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.52 GiB memory in use. Of the allocated memory 135.31 MiB is allocated by PyTorch, and 30.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6dad2cc4,"{'temperature_head': 0.1, 'latent_dim': 252, 'batch_size': 252, 'transform_funcs': (3, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 82.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 562.00 MiB memory in use. Process 71966 has 1.03 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 556.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.12 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 558.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.52 GiB memory in use. Of the allocated memory 135.81 MiB is allocated by PyTorch, and 34.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
13b31186,"{'temperature_head': 0.1, 'latent_dim': 277, 'batch_size': 155, 'transform_funcs': (0, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 130.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1.03 GiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 558.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.12 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 508.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.01 MiB is allocated by PyTorch, and 33.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
688cc1ae,"{'temperature_head': 0.1, 'latent_dim': 268, 'batch_size': 336, 'transform_funcs': (1, 2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 96.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 926.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 512.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.12 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 668.00 MiB memory in use. Process 76017 has 556.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 294.38 MiB is allocated by PyTorch, and 33.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c9db1a0b,"{'temperature_head': 0.2, 'latent_dim': 324, 'batch_size': 232, 'transform_funcs': (2, 3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 640.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 560.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.12 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 512.00 MiB memory in use. Process 76017 has 1006.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.38 MiB is allocated by PyTorch, and 35.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
54ab646e,"{'temperature_head': 0.1, 'latent_dim': 236, 'batch_size': 287, 'transform_funcs': (1, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 640.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 558.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.12 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 456.00 MiB memory in use. Process 76017 has 1.03 GiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 79.69 MiB is allocated by PyTorch, and 36.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a903b52a,"{'temperature_head': 0.1, 'latent_dim': 355, 'batch_size': 223, 'transform_funcs': (4, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 558.00 MiB memory in use. Process 71966 has 642.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 514.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.12 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 512.00 MiB memory in use. Process 76017 has 1.03 GiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.62 MiB is allocated by PyTorch, and 35.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ae6a9b5b,"{'temperature_head': 0.2, 'latent_dim': 274, 'batch_size': 158, 'transform_funcs': (1, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 558.00 MiB memory in use. Process 71966 has 472.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 492.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.13 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 674.00 MiB memory in use. Process 76017 has 1.07 GiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 297.99 MiB is allocated by PyTorch, and 36.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e9d87002,"{'temperature_head': 0.7000000000000001, 'latent_dim': 303, 'batch_size': 196, 'transform_funcs': (2, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 556.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.13 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 1.09 GiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.21 MiB is allocated by PyTorch, and 31.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b7683576,"{'temperature_head': 0.5, 'latent_dim': 114, 'batch_size': 260, 'transform_funcs': (2, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 558.00 MiB memory in use. Process 71966 has 548.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.13 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 1.09 GiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 134.73 MiB is allocated by PyTorch, and 35.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
529d5589,"{'temperature_head': 0.1, 'latent_dim': 307, 'batch_size': 308, 'transform_funcs': (1, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 596.00 MiB memory in use. Process 71966 has 554.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.13 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 452.00 MiB memory in use. Process 76017 has 1.09 GiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 80.24 MiB is allocated by PyTorch, and 31.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5af8e639,"{'temperature_head': 0.1, 'latent_dim': 346, 'batch_size': 247, 'transform_funcs': (4, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 596.00 MiB memory in use. Process 71966 has 556.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.13 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 458.00 MiB memory in use. Process 76017 has 1.09 GiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 80.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
dd5ea411,"{'temperature_head': 0.6000000000000001, 'latent_dim': 319, 'batch_size': 283, 'transform_funcs': (5, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 932.00 MiB memory in use. Process 71966 has 814.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.13 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 458.00 MiB memory in use. Process 76017 has 502.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 80.34 MiB is allocated by PyTorch, and 37.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
02a83cef,"{'temperature_head': 0.4, 'latent_dim': 220, 'batch_size': 128, 'transform_funcs': (0, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 876.00 MiB memory in use. Process 71966 has 814.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.13 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 514.00 MiB memory in use. Process 76017 has 510.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 135.56 MiB is allocated by PyTorch, and 38.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ec764c49,"{'temperature_head': 0.5, 'latent_dim': 195, 'batch_size': 134, 'transform_funcs': (3, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 116.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 106.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 784.00 MiB memory in use. Process 71966 has 860.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 552.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.13 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 500.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 135.37 MiB is allocated by PyTorch, and 34.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
af37fc6b,"{'temperature_head': 0.5, 'latent_dim': 253, 'batch_size': 143, 'transform_funcs': (1, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 104.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 738.00 MiB memory in use. Process 71966 has 948.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 494.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.13 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 514.00 MiB memory in use. Process 76017 has 512.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 135.82 MiB is allocated by PyTorch, and 38.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8f4119ca,"{'temperature_head': 0.5, 'latent_dim': 246, 'batch_size': 159, 'transform_funcs': (1, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 782.00 MiB memory in use. Process 71966 has 948.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 494.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.12 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 512.00 MiB memory in use. Process 76017 has 514.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 135.77 MiB is allocated by PyTorch, and 36.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1f6a62ab,"{'temperature_head': 0.5, 'latent_dim': 186, 'batch_size': 135, 'transform_funcs': (0, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 784.00 MiB memory in use. Process 71966 has 454.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 552.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.48 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 512.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 135.30 MiB is allocated by PyTorch, and 36.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
269b49a3,"{'temperature_head': 0.6000000000000001, 'latent_dim': 180, 'batch_size': 142, 'transform_funcs': (1, 2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 782.00 MiB memory in use. Process 71966 has 454.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.48 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 620.00 MiB memory in use. Process 76017 has 512.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 241.67 MiB is allocated by PyTorch, and 38.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d846e5df,"{'temperature_head': 0.6000000000000001, 'latent_dim': 207, 'batch_size': 348, 'transform_funcs': (2, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 782.00 MiB memory in use. Process 71966 has 472.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.48 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 636.00 MiB memory in use. Process 76017 has 506.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 257.84 MiB is allocated by PyTorch, and 38.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bacbf892,"{'temperature_head': 0.4, 'latent_dim': 191, 'batch_size': 151, 'transform_funcs': (1, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 784.00 MiB memory in use. Process 71966 has 556.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.47 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 512.00 MiB memory in use. Process 76017 has 506.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 135.34 MiB is allocated by PyTorch, and 36.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
78db15a9,"{'temperature_head': 0.30000000000000004, 'latent_dim': 285, 'batch_size': 364, 'transform_funcs': (4, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 782.00 MiB memory in use. Process 71966 has 556.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 554.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.47 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 452.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 80.07 MiB is allocated by PyTorch, and 31.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5209b784,"{'temperature_head': 0.5, 'latent_dim': 274, 'batch_size': 149, 'transform_funcs': (1, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 782.00 MiB memory in use. Process 71966 has 1012.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 916.00 MiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 514.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 670.00 MiB memory in use. Process 76017 has 558.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 297.99 MiB is allocated by PyTorch, and 32.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c4c8c3ca,"{'temperature_head': 0.30000000000000004, 'latent_dim': 294, 'batch_size': 141, 'transform_funcs': (2, 3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1012.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.17 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 572.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 506.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.14 MiB is allocated by PyTorch, and 29.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9dba27f1,"{'temperature_head': 0.30000000000000004, 'latent_dim': 271, 'batch_size': 308, 'transform_funcs': (0, 3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1012.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.17 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 135.96 MiB is allocated by PyTorch, and 32.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bfead92e,"{'temperature_head': 0.4, 'latent_dim': 201, 'batch_size': 375, 'transform_funcs': (0, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1012.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.17 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 135.42 MiB is allocated by PyTorch, and 34.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6d358ac9,"{'temperature_head': 0.6000000000000001, 'latent_dim': 171, 'batch_size': 188, 'transform_funcs': (5, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1012.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.17 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 135.18 MiB is allocated by PyTorch, and 32.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0038763b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 298, 'batch_size': 333, 'transform_funcs': (0, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1012.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.17 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.17 MiB is allocated by PyTorch, and 31.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2cbfef51,"{'temperature_head': 0.30000000000000004, 'latent_dim': 178, 'batch_size': 168, 'transform_funcs': (1, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1012.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.17 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 135.24 MiB is allocated by PyTorch, and 32.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7c837925,"{'temperature_head': 0.1, 'latent_dim': 139, 'batch_size': 157, 'transform_funcs': (0, 1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 562.00 MiB memory in use. Process 71966 has 1012.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.17 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 134.93 MiB is allocated by PyTorch, and 33.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d67bb9d5,"{'temperature_head': 0.1, 'latent_dim': 288, 'batch_size': 177, 'transform_funcs': (4, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1012.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.17 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.10 MiB is allocated by PyTorch, and 33.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f0d3fff0,"{'temperature_head': 0.6000000000000001, 'latent_dim': 120, 'batch_size': 318, 'transform_funcs': (2, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1012.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.17 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 578.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 205.73 MiB is allocated by PyTorch, and 32.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7a528eb0,"{'temperature_head': 0.30000000000000004, 'latent_dim': 293, 'batch_size': 426, 'transform_funcs': (2, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1012.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.17 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.14 MiB is allocated by PyTorch, and 33.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8629b0ed,"{'temperature_head': 0.1, 'latent_dim': 281, 'batch_size': 129, 'transform_funcs': (2, 3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 120.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1012.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.17 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 512.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 506.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.04 MiB is allocated by PyTorch, and 29.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8f60a631,"{'temperature_head': 0.2, 'latent_dim': 186, 'batch_size': 169, 'transform_funcs': (2, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1012.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.17 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 562.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 922.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 135.30 MiB is allocated by PyTorch, and 32.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
975227d7,"{'temperature_head': 0.1, 'latent_dim': 303, 'batch_size': 298, 'transform_funcs': (2, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 108.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1012.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.17 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 518.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 562.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.21 MiB is allocated by PyTorch, and 33.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9bb2b568,"{'temperature_head': 0.4, 'latent_dim': 319, 'batch_size': 321, 'transform_funcs': (1, 2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 1012.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.17 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.34 MiB is allocated by PyTorch, and 31.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
784baed8,"{'temperature_head': 0.30000000000000004, 'latent_dim': 269, 'batch_size': 146, 'transform_funcs': (2, 3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 556.00 MiB memory in use. Process 71966 has 1012.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.17 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 562.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 135.95 MiB is allocated by PyTorch, and 34.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0e82fa38,"{'temperature_head': 0.1, 'latent_dim': 225, 'batch_size': 266, 'transform_funcs': (3, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 134.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 88.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 622.00 MiB memory in use. Process 71966 has 930.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.17 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 135.60 MiB is allocated by PyTorch, and 32.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8e6ba25f,"{'temperature_head': 0.30000000000000004, 'latent_dim': 339, 'batch_size': 279, 'transform_funcs': (6, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 202.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 622.00 MiB memory in use. Process 71966 has 454.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.48 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 714.00 MiB memory in use. Process 76017 has 558.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 336.91 MiB is allocated by PyTorch, and 37.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a602891f,"{'temperature_head': 0.2, 'latent_dim': 303, 'batch_size': 156, 'transform_funcs': (1, 2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 724.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.48 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 512.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.21 MiB is allocated by PyTorch, and 35.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0b89b602,"{'temperature_head': 0.1, 'latent_dim': 325, 'batch_size': 186, 'transform_funcs': (3, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 758.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.48 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 512.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 560.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.39 MiB is allocated by PyTorch, and 33.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4da04856,"{'temperature_head': 0.2, 'latent_dim': 330, 'batch_size': 161, 'transform_funcs': (1, 2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 156.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 558.00 MiB memory in use. Process 71966 has 652.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.48 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 510.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 562.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.42 MiB is allocated by PyTorch, and 33.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
017837fa,"{'temperature_head': 0.1, 'latent_dim': 306, 'batch_size': 180, 'transform_funcs': (0, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 142.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 528.00 MiB memory in use. Process 71966 has 740.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.48 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 514.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 514.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.24 MiB is allocated by PyTorch, and 33.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a7903c43,"{'temperature_head': 0.1, 'latent_dim': 297, 'batch_size': 201, 'transform_funcs': (4, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 488.00 MiB memory in use. Process 71966 has 862.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.48 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 562.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 474.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.17 MiB is allocated by PyTorch, and 33.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5122ae80,"{'temperature_head': 0.1, 'latent_dim': 320, 'batch_size': 210, 'transform_funcs': (2, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 102.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 572.00 MiB memory in use. Process 71966 has 468.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.48 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 736.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.35 MiB is allocated by PyTorch, and 31.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
37df1581,"{'temperature_head': 0.2, 'latent_dim': 314, 'batch_size': 143, 'transform_funcs': (0, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 186.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 102.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 558.00 MiB memory in use. Process 71966 has 560.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.48 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 528.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 688.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.30 MiB is allocated by PyTorch, and 33.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6ea7edcd,"{'temperature_head': 0.1, 'latent_dim': 298, 'batch_size': 151, 'transform_funcs': (1, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 558.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.48 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 530.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 734.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.17 MiB is allocated by PyTorch, and 33.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6d854ed6,"{'temperature_head': 0.30000000000000004, 'latent_dim': 324, 'batch_size': 404, 'transform_funcs': (3, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 128.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 454.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.48 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 560.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 510.00 MiB memory in use. Process 76017 has 734.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.38 MiB is allocated by PyTorch, and 33.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
214d184a,"{'temperature_head': 0.1, 'latent_dim': 359, 'batch_size': 206, 'transform_funcs': (0, 2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 558.00 MiB memory in use. Process 71966 has 512.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.48 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 558.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 508.00 MiB memory in use. Process 76017 has 736.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 136.65 MiB is allocated by PyTorch, and 31.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
19094f27,"{'temperature_head': 0.1, 'latent_dim': 335, 'batch_size': 169, 'transform_funcs': (2, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 514.00 MiB memory in use. Process 71966 has 456.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.48 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 496.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 456.00 MiB memory in use. Process 76017 has 970.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 80.46 MiB is allocated by PyTorch, and 35.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
868c3140,"{'temperature_head': 0.2, 'latent_dim': 320, 'batch_size': 135, 'transform_funcs': (4, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 454.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.48 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 502.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 426.00 MiB memory in use. Process 76017 has 970.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 47.87 MiB is allocated by PyTorch, and 38.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
08faa827,"{'temperature_head': 0.30000000000000004, 'latent_dim': 275, 'batch_size': 141, 'transform_funcs': (3, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 560.00 MiB memory in use. Process 71966 has 878.00 MiB memory in use. Process 72010 has 720.00 MiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.48 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75236 has 720.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75627 has 828.00 MiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 568.00 MiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 424.00 MiB memory in use. Process 76017 has 482.00 MiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76013 has 720.00 MiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76410 has 744.00 MiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 47.52 MiB is allocated by PyTorch, and 36.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
59eaa6e9,"{'temperature_head': 0.30000000000000004, 'latent_dim': 331, 'batch_size': 313, 'transform_funcs': (2, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 202.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.42 GiB memory in use. Process 71966 has 1.21 GiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.48 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.12 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.44 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 948.00 MiB memory in use. Process 76017 has 1.35 GiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 331.61 MiB is allocated by PyTorch, and 276.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
588512c6,"{'temperature_head': 0.2, 'latent_dim': 346, 'batch_size': 149, 'transform_funcs': (3, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 184.94 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 72008 has 1.14 GiB memory in use. Process 71994 has 1.42 GiB memory in use. Process 71966 has 1.21 GiB memory in use. Process 72025 has 936.00 MiB memory in use. Process 75233 has 1.48 GiB memory in use. Process 75240 has 862.00 MiB memory in use. Process 75237 has 1.19 GiB memory in use. Process 75230 has 1.13 GiB memory in use. Process 75625 has 1.02 GiB memory in use. Process 75626 has 924.00 MiB memory in use. Process 75618 has 1.44 GiB memory in use. Process 75630 has 1.22 GiB memory in use. Process 76014 has 1.06 GiB memory in use. Process 76020 has 948.00 MiB memory in use. Process 76017 has 1.35 GiB memory in use. Process 76010 has 1.04 GiB memory in use. Process 76400 has 924.00 MiB memory in use. Process 76406 has 1.03 GiB memory in use. Process 76409 has 1.12 GiB memory in use. Process 76403 has 1.53 GiB memory in use. Of the allocated memory 340.60 MiB is allocated by PyTorch, and 267.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
