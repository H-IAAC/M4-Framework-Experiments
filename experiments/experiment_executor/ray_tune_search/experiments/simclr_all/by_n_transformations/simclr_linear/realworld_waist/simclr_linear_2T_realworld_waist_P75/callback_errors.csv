trial_id,config,error_type,error_message,error_traceback
f4697235,"{'temperature_head': 0.5, 'latent_dim': 221, 'batch_size': 168, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 97.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.01 GiB memory in use. Process 805194 has 902.00 MiB memory in use. Process 805137 has 1.20 GiB memory in use. Process 805180 has 816.00 MiB memory in use. Process 805153 has 768.00 MiB memory in use. Process 808405 has 888.00 MiB memory in use. Process 808408 has 514.00 MiB memory in use. Process 808411 has 780.00 MiB memory in use. Process 808399 has 918.00 MiB memory in use. Process 808404 has 748.00 MiB memory in use. Process 808790 has 816.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 690.00 MiB memory in use. Process 808793 has 1.01 GiB memory in use. Process 808801 has 880.00 MiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 838.00 MiB memory in use. Process 809183 has 944.00 MiB memory in use. Process 809192 has 876.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.46 GiB memory in use. Process 809580 has 946.00 MiB memory in use. Process 809577 has 1.12 GiB memory in use. Process 809615 has 910.00 MiB memory in use. Process 809574 has 728.00 MiB memory in use. Of the allocated memory 137.08 MiB is allocated by PyTorch, and 38.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bf93a59b,"{'temperature_head': 0.2, 'latent_dim': 244, 'batch_size': 457, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.01 GiB memory in use. Process 805194 has 902.00 MiB memory in use. Process 805137 has 1.20 GiB memory in use. Process 805180 has 962.00 MiB memory in use. Process 805153 has 658.00 MiB memory in use. Process 808405 has 456.00 MiB memory in use. Process 808408 has 716.00 MiB memory in use. Process 808411 has 780.00 MiB memory in use. Process 808399 has 918.00 MiB memory in use. Process 808404 has 1.11 GiB memory in use. Process 808790 has 816.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 778.00 MiB memory in use. Process 808793 has 1.01 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 838.00 MiB memory in use. Process 809183 has 944.00 MiB memory in use. Process 809192 has 460.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.46 GiB memory in use. Process 809580 has 946.00 MiB memory in use. Process 809577 has 1.12 GiB memory in use. Process 809615 has 910.00 MiB memory in use. Process 809574 has 730.00 MiB memory in use. Of the allocated memory 79.76 MiB is allocated by PyTorch, and 42.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d5e7633f,"{'temperature_head': 0.30000000000000004, 'latent_dim': 247, 'batch_size': 156, 'transform_funcs': (0, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 5.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.01 GiB memory in use. Process 805194 has 902.00 MiB memory in use. Process 805137 has 1.20 GiB memory in use. Process 805180 has 962.00 MiB memory in use. Process 805153 has 554.00 MiB memory in use. Process 808405 has 512.00 MiB memory in use. Process 808408 has 716.00 MiB memory in use. Process 808411 has 780.00 MiB memory in use. Process 808399 has 814.00 MiB memory in use. Process 808404 has 1.11 GiB memory in use. Process 808790 has 850.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 778.00 MiB memory in use. Process 808793 has 1.01 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 838.00 MiB memory in use. Process 809183 has 944.00 MiB memory in use. Process 809192 has 666.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.46 GiB memory in use. Process 809580 has 946.00 MiB memory in use. Process 809577 has 1.12 GiB memory in use. Process 809615 has 718.00 MiB memory in use. Process 809574 has 850.00 MiB memory in use. Of the allocated memory 281.81 MiB is allocated by PyTorch, and 46.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5350bea7,"{'temperature_head': 0.30000000000000004, 'latent_dim': 36, 'batch_size': 368, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 986.00 MiB memory in use. Process 805194 has 816.00 MiB memory in use. Process 805137 has 1.16 GiB memory in use. Process 805180 has 514.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.31 GiB memory in use. Process 808408 has 882.00 MiB memory in use. Process 808411 has 664.00 MiB memory in use. Process 808399 has 856.00 MiB memory in use. Process 808404 has 1.11 GiB memory in use. Process 808790 has 890.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 690.00 MiB memory in use. Process 808793 has 1.26 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 882.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 856.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 560.00 MiB memory in use. Process 809580 has 1004.00 MiB memory in use. Process 809577 has 816.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 852.00 MiB memory in use. Of the allocated memory 136.03 MiB is allocated by PyTorch, and 39.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
374e790f,"{'temperature_head': 0.5, 'latent_dim': 264, 'batch_size': 487, 'transform_funcs': (5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 141.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 986.00 MiB memory in use. Process 805194 has 858.00 MiB memory in use. Process 805137 has 1.16 GiB memory in use. Process 805180 has 674.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.31 GiB memory in use. Process 808408 has 950.00 MiB memory in use. Process 808411 has 496.00 MiB memory in use. Process 808399 has 856.00 MiB memory in use. Process 808404 has 1.03 GiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 734.00 MiB memory in use. Process 808793 has 1.26 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 882.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 856.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 498.00 MiB memory in use. Process 809580 has 694.00 MiB memory in use. Process 809577 has 992.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 854.00 MiB memory in use. Of the allocated memory 293.40 MiB is allocated by PyTorch, and 42.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
37bc0919,"{'temperature_head': 0.2, 'latent_dim': 160, 'batch_size': 225, 'transform_funcs': (0, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 35.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 986.00 MiB memory in use. Process 805194 has 920.00 MiB memory in use. Process 805137 has 1.16 GiB memory in use. Process 805180 has 720.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.35 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 432.00 MiB memory in use. Process 808399 has 856.00 MiB memory in use. Process 808404 has 1.03 GiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 1.26 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 882.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 832.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 510.00 MiB memory in use. Process 809580 has 610.00 MiB memory in use. Process 809577 has 994.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 814.00 MiB memory in use. Of the allocated memory 229.69 MiB is allocated by PyTorch, and 42.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1a7faf28,"{'temperature_head': 0.7000000000000001, 'latent_dim': 72, 'batch_size': 369, 'transform_funcs': (3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 960.00 MiB memory in use. Process 805137 has 1.19 GiB memory in use. Process 805180 has 760.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.35 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 756.00 MiB memory in use. Process 808399 has 856.00 MiB memory in use. Process 808404 has 636.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 1.29 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 882.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 422.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 924.00 MiB memory in use. Process 809580 has 736.00 MiB memory in use. Process 809577 has 878.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 500.00 MiB memory in use. Of the allocated memory 45.93 MiB is allocated by PyTorch, and 38.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7b560495,"{'temperature_head': 0.8, 'latent_dim': 213, 'batch_size': 469, 'transform_funcs': (2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 111.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 960.00 MiB memory in use. Process 805137 has 1.19 GiB memory in use. Process 805180 has 662.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.35 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 756.00 MiB memory in use. Process 808399 has 856.00 MiB memory in use. Process 808404 has 636.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 1.29 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 882.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 454.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 924.00 MiB memory in use. Process 809580 has 736.00 MiB memory in use. Process 809577 has 878.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 498.00 MiB memory in use. Of the allocated memory 262.84 MiB is allocated by PyTorch, and 61.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
18511c57,"{'temperature_head': 0.4, 'latent_dim': 256, 'batch_size': 339, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 53.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 960.00 MiB memory in use. Process 805137 has 1.19 GiB memory in use. Process 805180 has 662.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.35 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 756.00 MiB memory in use. Process 808399 has 856.00 MiB memory in use. Process 808404 has 636.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 1.29 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 882.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 512.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 924.00 MiB memory in use. Process 809580 has 736.00 MiB memory in use. Process 809577 has 878.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 498.00 MiB memory in use. Of the allocated memory 135.85 MiB is allocated by PyTorch, and 38.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
07a70b95,"{'temperature_head': 0.30000000000000004, 'latent_dim': 111, 'batch_size': 128, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 67.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 960.00 MiB memory in use. Process 805137 has 1.19 GiB memory in use. Process 805180 has 664.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.35 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 674.00 MiB memory in use. Process 808399 has 856.00 MiB memory in use. Process 808404 has 636.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 1.29 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 882.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 512.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 924.00 MiB memory in use. Process 809580 has 736.00 MiB memory in use. Process 809577 has 878.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 564.00 MiB memory in use. Of the allocated memory 134.71 MiB is allocated by PyTorch, and 39.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ef5e4b0f,"{'temperature_head': 0.1, 'latent_dim': 185, 'batch_size': 358, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 105.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 960.00 MiB memory in use. Process 805137 has 1.19 GiB memory in use. Process 805180 has 664.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.35 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 674.00 MiB memory in use. Process 808399 has 856.00 MiB memory in use. Process 808404 has 680.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 1.29 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 882.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 512.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 924.00 MiB memory in use. Process 809580 has 736.00 MiB memory in use. Process 809577 has 796.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 564.00 MiB memory in use. Of the allocated memory 135.30 MiB is allocated by PyTorch, and 38.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0defc6f0,"{'temperature_head': 0.5, 'latent_dim': 93, 'batch_size': 215, 'transform_funcs': (9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 960.00 MiB memory in use. Process 805137 has 1.19 GiB memory in use. Process 805180 has 570.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.35 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 714.00 MiB memory in use. Process 808399 has 916.00 MiB memory in use. Process 808404 has 662.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 1.29 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 882.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 670.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 924.00 MiB memory in use. Process 809580 has 766.00 MiB memory in use. Process 809577 has 796.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 452.00 MiB memory in use. Of the allocated memory 191.46 MiB is allocated by PyTorch, and 40.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
db1b327a,"{'temperature_head': 0.6000000000000001, 'latent_dim': 65, 'batch_size': 301, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 960.00 MiB memory in use. Process 805137 has 1.19 GiB memory in use. Process 805180 has 454.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 674.00 MiB memory in use. Process 808404 has 752.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 822.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 890.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 732.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 924.00 MiB memory in use. Process 809580 has 922.00 MiB memory in use. Process 809577 has 914.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 886.00 MiB memory in use. Of the allocated memory 80.26 MiB is allocated by PyTorch, and 35.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5bfa3a43,"{'temperature_head': 0.1, 'latent_dim': 114, 'batch_size': 292, 'transform_funcs': (3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 960.00 MiB memory in use. Process 805137 has 1.19 GiB memory in use. Process 805180 has 460.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 674.00 MiB memory in use. Process 808404 has 752.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 906.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 890.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 452.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.14 GiB memory in use. Process 809580 has 922.00 MiB memory in use. Process 809577 has 914.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 804.00 MiB memory in use. Of the allocated memory 80.64 MiB is allocated by PyTorch, and 41.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
46014a9c,"{'temperature_head': 0.5, 'latent_dim': 80, 'batch_size': 343, 'transform_funcs': (0, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 960.00 MiB memory in use. Process 805137 has 1.15 GiB memory in use. Process 805180 has 500.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 674.00 MiB memory in use. Process 808404 has 752.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 906.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 890.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 460.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.14 GiB memory in use. Process 809580 has 922.00 MiB memory in use. Process 809577 has 914.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 804.00 MiB memory in use. Of the allocated memory 78.47 MiB is allocated by PyTorch, and 43.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
56a0edce,"{'temperature_head': 0.5, 'latent_dim': 200, 'batch_size': 254, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 5.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 960.00 MiB memory in use. Process 805137 has 672.00 MiB memory in use. Process 805180 has 930.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 450.00 MiB memory in use. Process 808404 has 1.07 GiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 948.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 890.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 664.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.14 GiB memory in use. Process 809580 has 636.00 MiB memory in use. Process 809577 has 916.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 842.00 MiB memory in use. Of the allocated memory 253.65 MiB is allocated by PyTorch, and 44.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b0661ef0,"{'temperature_head': 0.2, 'latent_dim': 143, 'batch_size': 267, 'transform_funcs': (0, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 960.00 MiB memory in use. Process 805137 has 838.00 MiB memory in use. Process 805180 has 930.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 680.00 MiB memory in use. Process 808404 has 1.07 GiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 672.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 428.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.02 GiB memory in use. Process 809580 has 840.00 MiB memory in use. Process 809577 has 916.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 836.00 MiB memory in use. Of the allocated memory 46.49 MiB is allocated by PyTorch, and 43.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
26ff837f,"{'temperature_head': 0.30000000000000004, 'latent_dim': 223, 'batch_size': 307, 'transform_funcs': (2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 960.00 MiB memory in use. Process 805137 has 838.00 MiB memory in use. Process 805180 has 930.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 680.00 MiB memory in use. Process 808404 has 1.07 GiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 672.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 428.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.02 GiB memory in use. Process 809580 has 840.00 MiB memory in use. Process 809577 has 916.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 836.00 MiB memory in use. Of the allocated memory 47.12 MiB is allocated by PyTorch, and 42.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
78b0442b,"{'temperature_head': 0.6000000000000001, 'latent_dim': 10, 'batch_size': 281, 'transform_funcs': (1, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 960.00 MiB memory in use. Process 805137 has 838.00 MiB memory in use. Process 805180 has 930.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 680.00 MiB memory in use. Process 808404 has 1.07 GiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 672.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 424.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.02 GiB memory in use. Process 809580 has 840.00 MiB memory in use. Process 809577 has 916.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 836.00 MiB memory in use. Of the allocated memory 45.44 MiB is allocated by PyTorch, and 40.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5e3be496,"{'temperature_head': 0.9, 'latent_dim': 127, 'batch_size': 181, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 960.00 MiB memory in use. Process 805137 has 838.00 MiB memory in use. Process 805180 has 930.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 680.00 MiB memory in use. Process 808404 has 1.07 GiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 672.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 428.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.02 GiB memory in use. Process 809580 has 840.00 MiB memory in use. Process 809577 has 916.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 836.00 MiB memory in use. Of the allocated memory 46.36 MiB is allocated by PyTorch, and 43.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f35288df,"{'temperature_head': 0.5, 'latent_dim': 108, 'batch_size': 376, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 45.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 960.00 MiB memory in use. Process 805137 has 838.00 MiB memory in use. Process 805180 has 930.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 640.00 MiB memory in use. Process 808404 has 1.07 GiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 672.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 508.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.02 GiB memory in use. Process 809580 has 830.00 MiB memory in use. Process 809577 has 886.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 836.00 MiB memory in use. Of the allocated memory 134.69 MiB is allocated by PyTorch, and 35.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
25235236,"{'temperature_head': 0.1, 'latent_dim': 197, 'batch_size': 218, 'transform_funcs': (8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 910.00 MiB memory in use. Process 805180 has 930.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 452.00 MiB memory in use. Process 808404 has 1.07 GiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 756.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 460.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.02 GiB memory in use. Process 809580 has 870.00 MiB memory in use. Process 809577 has 886.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 872.00 MiB memory in use. Of the allocated memory 79.39 MiB is allocated by PyTorch, and 42.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8056f78d,"{'temperature_head': 0.2, 'latent_dim': 238, 'batch_size': 313, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 37.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 454.00 MiB memory in use. Process 805180 has 930.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 612.00 MiB memory in use. Process 808404 has 1.07 GiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 944.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 516.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.02 GiB memory in use. Process 809580 has 872.00 MiB memory in use. Process 809577 has 908.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 910.00 MiB memory in use. Of the allocated memory 135.71 MiB is allocated by PyTorch, and 42.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b9ba40aa,"{'temperature_head': 0.30000000000000004, 'latent_dim': 164, 'batch_size': 255, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 61.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 454.00 MiB memory in use. Process 805180 has 930.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 754.00 MiB memory in use. Process 808404 has 930.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 944.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1.01 GiB memory in use. Process 809192 has 512.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.02 GiB memory in use. Process 809580 has 872.00 MiB memory in use. Process 809577 has 908.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 910.00 MiB memory in use. Of the allocated memory 135.13 MiB is allocated by PyTorch, and 38.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
620f7271,"{'temperature_head': 0.5, 'latent_dim': 155, 'batch_size': 204, 'transform_funcs': (8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 466.00 MiB memory in use. Process 805180 has 930.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 754.00 MiB memory in use. Process 808404 has 930.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 944.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1.06 GiB memory in use. Process 809192 has 428.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.04 GiB memory in use. Process 809580 has 914.00 MiB memory in use. Process 809577 has 908.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 910.00 MiB memory in use. Of the allocated memory 46.58 MiB is allocated by PyTorch, and 43.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a1eae0de,"{'temperature_head': 0.4, 'latent_dim': 215, 'batch_size': 361, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 514.00 MiB memory in use. Process 805180 has 932.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 754.00 MiB memory in use. Process 808404 has 930.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 946.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1.06 GiB memory in use. Process 809192 has 452.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 970.00 MiB memory in use. Process 809580 has 914.00 MiB memory in use. Process 809577 has 908.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 910.00 MiB memory in use. Of the allocated memory 79.53 MiB is allocated by PyTorch, and 34.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f1b084df,"{'temperature_head': 0.2, 'latent_dim': 65, 'batch_size': 286, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 17.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 504.00 MiB memory in use. Process 805180 has 890.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 784.00 MiB memory in use. Process 808404 has 930.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 982.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1.06 GiB memory in use. Process 809192 has 422.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 970.00 MiB memory in use. Process 809580 has 914.00 MiB memory in use. Process 809577 has 950.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 910.00 MiB memory in use. Of the allocated memory 45.88 MiB is allocated by PyTorch, and 38.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d286dbcd,"{'temperature_head': 1.0, 'latent_dim': 177, 'batch_size': 225, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 514.00 MiB memory in use. Process 805180 has 890.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 784.00 MiB memory in use. Process 808404 has 930.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 982.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1.06 GiB memory in use. Process 809192 has 410.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 970.00 MiB memory in use. Process 809580 has 914.00 MiB memory in use. Process 809577 has 950.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 910.00 MiB memory in use. Of the allocated memory 65.77 MiB is allocated by PyTorch, and 6.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
874df52f,"{'temperature_head': 0.4, 'latent_dim': 23, 'batch_size': 438, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 456.00 MiB memory in use. Process 805180 has 890.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 784.00 MiB memory in use. Process 808404 has 972.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 982.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1.06 GiB memory in use. Process 809192 has 418.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 970.00 MiB memory in use. Process 809580 has 914.00 MiB memory in use. Process 809577 has 950.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 910.00 MiB memory in use. Of the allocated memory 45.55 MiB is allocated by PyTorch, and 34.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8ca1bdb0,"{'temperature_head': 0.30000000000000004, 'latent_dim': 195, 'batch_size': 299, 'transform_funcs': (0, 1)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 7.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 484.00 MiB memory in use. Process 805180 has 890.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 784.00 MiB memory in use. Process 808404 has 972.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 982.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1.06 GiB memory in use. Process 809192 has 410.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 970.00 MiB memory in use. Process 809580 has 914.00 MiB memory in use. Process 809577 has 950.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 910.00 MiB memory in use. Of the allocated memory 68.27 MiB is allocated by PyTorch, and 3.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
1217e091,"{'temperature_head': 0.5, 'latent_dim': 119, 'batch_size': 250, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 936.00 MiB memory in use. Process 805180 has 890.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 784.00 MiB memory in use. Process 808404 has 972.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 982.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 452.00 MiB memory in use. Process 809192 has 458.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 970.00 MiB memory in use. Process 809580 has 914.00 MiB memory in use. Process 809577 has 950.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 998.00 MiB memory in use. Of the allocated memory 78.78 MiB is allocated by PyTorch, and 41.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
24969d74,"{'temperature_head': 0.4, 'latent_dim': 112, 'batch_size': 347, 'transform_funcs': (2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 936.00 MiB memory in use. Process 805180 has 890.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 784.00 MiB memory in use. Process 808404 has 972.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 982.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 430.00 MiB memory in use. Process 809192 has 516.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 970.00 MiB memory in use. Process 809580 has 914.00 MiB memory in use. Process 809577 has 950.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 998.00 MiB memory in use. Of the allocated memory 134.72 MiB is allocated by PyTorch, and 43.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e24251ac,"{'temperature_head': 0.1, 'latent_dim': 151, 'batch_size': 323, 'transform_funcs': (0, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 936.00 MiB memory in use. Process 805180 has 890.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 454.00 MiB memory in use. Process 808404 has 972.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 982.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 738.00 MiB memory in use. Process 809192 has 514.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 970.00 MiB memory in use. Process 809580 has 914.00 MiB memory in use. Process 809577 has 950.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 998.00 MiB memory in use. Of the allocated memory 135.03 MiB is allocated by PyTorch, and 40.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a509b105,"{'temperature_head': 0.30000000000000004, 'latent_dim': 99, 'batch_size': 363, 'transform_funcs': (5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 936.00 MiB memory in use. Process 805180 has 456.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 640.00 MiB memory in use. Process 808404 has 972.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 1.00 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 762.00 MiB memory in use. Process 809192 has 672.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1014.00 MiB memory in use. Process 809580 has 914.00 MiB memory in use. Process 809577 has 914.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 998.00 MiB memory in use. Of the allocated memory 80.52 MiB is allocated by PyTorch, and 37.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
44aac5d0,"{'temperature_head': 0.5, 'latent_dim': 269, 'batch_size': 259, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 936.00 MiB memory in use. Process 805180 has 510.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 992.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 836.00 MiB memory in use. Process 808404 has 972.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 754.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.53 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 802.00 MiB memory in use. Process 809192 has 674.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1014.00 MiB memory in use. Process 809580 has 914.00 MiB memory in use. Process 809577 has 914.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1000.00 MiB memory in use. Of the allocated memory 137.86 MiB is allocated by PyTorch, and 34.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
617966de,"{'temperature_head': 0.4, 'latent_dim': 210, 'batch_size': 337, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 95.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 858.00 MiB memory in use. Process 805180 has 638.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 994.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 836.00 MiB memory in use. Process 808404 has 876.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 556.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.40 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 762.00 MiB memory in use. Process 809192 has 786.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.30 GiB memory in use. Process 809580 has 914.00 MiB memory in use. Process 809577 has 954.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 886.00 MiB memory in use. Of the allocated memory 261.55 MiB is allocated by PyTorch, and 38.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
436dad70,"{'temperature_head': 0.9, 'latent_dim': 136, 'batch_size': 210, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 858.00 MiB memory in use. Process 805180 has 460.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 994.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 986.00 MiB memory in use. Process 808404 has 916.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 478.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.40 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 802.00 MiB memory in use. Process 809192 has 824.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.30 GiB memory in use. Process 809580 has 914.00 MiB memory in use. Process 809577 has 954.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 928.00 MiB memory in use. Of the allocated memory 80.82 MiB is allocated by PyTorch, and 41.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ff463925,"{'temperature_head': 0.6000000000000001, 'latent_dim': 73, 'batch_size': 220, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 23.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 762.00 MiB memory in use. Process 805180 has 510.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 994.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 986.00 MiB memory in use. Process 808404 has 916.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 560.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.40 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 802.00 MiB memory in use. Process 809192 has 824.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.30 GiB memory in use. Process 809580 has 914.00 MiB memory in use. Process 809577 has 956.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 908.00 MiB memory in use. Of the allocated memory 136.32 MiB is allocated by PyTorch, and 35.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7310668a,"{'temperature_head': 0.8, 'latent_dim': 222, 'batch_size': 420, 'transform_funcs': (7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 67.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 762.00 MiB memory in use. Process 805180 has 514.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 994.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 986.00 MiB memory in use. Process 808404 has 916.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 512.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.40 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 802.00 MiB memory in use. Process 809192 has 824.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.30 GiB memory in use. Process 809580 has 914.00 MiB memory in use. Process 809577 has 956.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 908.00 MiB memory in use. Of the allocated memory 137.49 MiB is allocated by PyTorch, and 38.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
27736956,"{'temperature_head': 0.4, 'latent_dim': 144, 'batch_size': 179, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 15.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 762.00 MiB memory in use. Process 805180 has 516.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 954.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 986.00 MiB memory in use. Process 808404 has 916.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 602.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.40 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 802.00 MiB memory in use. Process 809192 has 824.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.30 GiB memory in use. Process 809580 has 914.00 MiB memory in use. Process 809577 has 956.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 908.00 MiB memory in use. Of the allocated memory 136.88 MiB is allocated by PyTorch, and 41.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
67b124f8,"{'temperature_head': 0.4, 'latent_dim': 188, 'batch_size': 311, 'transform_funcs': (4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 67.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 762.00 MiB memory in use. Process 805180 has 516.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 954.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 986.00 MiB memory in use. Process 808404 has 916.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 470.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.43 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 802.00 MiB memory in use. Process 809192 has 824.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.30 GiB memory in use. Process 809580 has 956.00 MiB memory in use. Process 809577 has 956.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 908.00 MiB memory in use. Of the allocated memory 137.23 MiB is allocated by PyTorch, and 40.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
52c6c03f,"{'temperature_head': 0.2, 'latent_dim': 155, 'batch_size': 147, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 91.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 556.00 MiB memory in use. Process 805180 has 608.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 954.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 986.00 MiB memory in use. Process 808404 has 916.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 556.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.43 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 802.00 MiB memory in use. Process 809192 has 824.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.30 GiB memory in use. Process 809580 has 956.00 MiB memory in use. Process 809577 has 920.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 948.00 MiB memory in use. Of the allocated memory 228.97 MiB is allocated by PyTorch, and 41.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a61e7a90,"{'temperature_head': 0.2, 'latent_dim': 169, 'batch_size': 161, 'transform_funcs': (5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 87.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 554.00 MiB memory in use. Process 805180 has 650.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 996.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 988.00 MiB memory in use. Process 808404 has 916.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 842.00 MiB memory in use. Process 808793 has 470.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.44 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 802.00 MiB memory in use. Process 809192 has 826.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.30 GiB memory in use. Process 809580 has 956.00 MiB memory in use. Process 809577 has 920.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 948.00 MiB memory in use. Of the allocated memory 236.57 MiB is allocated by PyTorch, and 75.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
09e9b2d3,"{'temperature_head': 0.4, 'latent_dim': 160, 'batch_size': 188, 'transform_funcs': (1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 61.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 700.00 MiB memory in use. Process 805180 has 654.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 996.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 988.00 MiB memory in use. Process 808404 has 916.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 1.05 GiB memory in use. Process 808802 has 756.00 MiB memory in use. Process 808793 has 858.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.44 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 802.00 MiB memory in use. Process 809192 has 826.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.30 GiB memory in use. Process 809580 has 998.00 MiB memory in use. Process 809577 has 452.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 948.00 MiB memory in use. Of the allocated memory 231.09 MiB is allocated by PyTorch, and 84.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2404ae03,"{'temperature_head': 0.2, 'latent_dim': 173, 'batch_size': 129, 'transform_funcs': (7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 43.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 646.00 MiB memory in use. Process 805180 has 664.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 996.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 988.00 MiB memory in use. Process 808404 has 918.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 992.00 MiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 858.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.44 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 802.00 MiB memory in use. Process 809192 has 826.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.30 GiB memory in use. Process 809580 has 998.00 MiB memory in use. Process 809577 has 554.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 948.00 MiB memory in use. Of the allocated memory 238.88 MiB is allocated by PyTorch, and 87.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0c75467f,"{'temperature_head': 0.4, 'latent_dim': 192, 'batch_size': 277, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 27.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1014.00 MiB memory in use. Process 805180 has 456.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 996.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 988.00 MiB memory in use. Process 808404 has 672.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 856.00 MiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 816.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.44 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 802.00 MiB memory in use. Process 809192 has 924.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.30 GiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 568.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 81.26 MiB is allocated by PyTorch, and 36.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bdd08d1f,"{'temperature_head': 0.2, 'latent_dim': 135, 'batch_size': 216, 'transform_funcs': (3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 41.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1014.00 MiB memory in use. Process 805180 has 456.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 996.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 988.00 MiB memory in use. Process 808404 has 672.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 856.00 MiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 816.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.44 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 802.00 MiB memory in use. Process 809192 has 1.08 GiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.06 GiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 612.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 80.81 MiB is allocated by PyTorch, and 37.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
707ba4f7,"{'temperature_head': 0.2, 'latent_dim': 183, 'batch_size': 327, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 7.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1014.00 MiB memory in use. Process 805180 has 510.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 996.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 988.00 MiB memory in use. Process 808404 has 810.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 856.00 MiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 816.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.44 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 804.00 MiB memory in use. Process 809192 has 1.08 GiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.06 GiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 452.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 137.19 MiB is allocated by PyTorch, and 34.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
51af35cd,"{'temperature_head': 0.4, 'latent_dim': 82, 'batch_size': 153, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1014.00 MiB memory in use. Process 805180 has 422.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 996.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 988.00 MiB memory in use. Process 808404 has 810.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 858.00 MiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 462.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.44 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 860.00 MiB memory in use. Process 809192 has 1.08 GiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.06 GiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 794.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 47.91 MiB is allocated by PyTorch, and 36.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1460a07f,"{'temperature_head': 0.6000000000000001, 'latent_dim': 207, 'batch_size': 382, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 73.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1018.00 MiB memory in use. Process 805180 has 510.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 996.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 988.00 MiB memory in use. Process 808404 has 810.00 MiB memory in use. Process 808790 has 892.00 MiB memory in use. Process 808796 has 704.00 MiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 500.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 1.44 GiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 860.00 MiB memory in use. Process 809192 has 1.08 GiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.06 GiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 794.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 137.38 MiB is allocated by PyTorch, and 34.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6a99dc79,"{'temperature_head': 0.4, 'latent_dim': 126, 'batch_size': 305, 'transform_funcs': (1, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.34 GiB memory in use. Process 805180 has 996.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 996.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 828.00 MiB memory in use. Process 808404 has 914.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 874.00 MiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.01 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 658.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 872.00 MiB memory in use. Process 809192 has 458.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.06 GiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 616.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 78.83 MiB is allocated by PyTorch, and 41.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
10af8e4d,"{'temperature_head': 0.4, 'latent_dim': 8, 'batch_size': 238, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 57.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.34 GiB memory in use. Process 805180 has 996.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 996.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 828.00 MiB memory in use. Process 808404 has 914.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 874.00 MiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.01 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 658.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 872.00 MiB memory in use. Process 809192 has 514.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.06 GiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 558.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 133.90 MiB is allocated by PyTorch, and 42.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8651e39d,"{'temperature_head': 0.4, 'latent_dim': 58, 'batch_size': 347, 'transform_funcs': (3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 53.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.23 GiB memory in use. Process 805180 has 996.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 966.00 MiB memory in use. Process 808404 has 934.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 874.00 MiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.01 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 554.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 872.00 MiB memory in use. Process 809192 has 454.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.08 GiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 664.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 78.30 MiB is allocated by PyTorch, and 37.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
77383c8c,"{'temperature_head': 0.7000000000000001, 'latent_dim': 177, 'batch_size': 385, 'transform_funcs': (0, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.23 GiB memory in use. Process 805180 has 996.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 966.00 MiB memory in use. Process 808404 has 934.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 874.00 MiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.01 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 554.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 872.00 MiB memory in use. Process 809192 has 616.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.04 GiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 560.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 239.88 MiB is allocated by PyTorch, and 38.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0489e3bc,"{'temperature_head': 0.5, 'latent_dim': 131, 'batch_size': 285, 'transform_funcs': (1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.23 GiB memory in use. Process 805180 has 998.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 1.08 GiB memory in use. Process 808404 has 452.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.01 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.01 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 672.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 872.00 MiB memory in use. Process 809192 has 638.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 760.00 MiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 894.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 212.37 MiB is allocated by PyTorch, and 87.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7c9a6769,"{'temperature_head': 0.6000000000000001, 'latent_dim': 114, 'batch_size': 340, 'transform_funcs': (7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 61.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.26 GiB memory in use. Process 805180 has 998.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.36 GiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 1.08 GiB memory in use. Process 808404 has 556.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.01 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.01 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 718.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 874.00 MiB memory in use. Process 809192 has 638.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 556.00 MiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 894.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 201.63 MiB is allocated by PyTorch, and 98.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
19c5e970,"{'temperature_head': 0.5, 'latent_dim': 249, 'batch_size': 325, 'transform_funcs': (2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 79.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.21 GiB memory in use. Process 805180 has 998.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.37 GiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 1.08 GiB memory in use. Process 808404 has 556.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.01 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.01 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 432.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 874.00 MiB memory in use. Process 809192 has 710.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 796.00 MiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 894.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 283.29 MiB is allocated by PyTorch, and 88.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bb286255,"{'temperature_head': 0.4, 'latent_dim': 107, 'batch_size': 252, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.23 GiB memory in use. Process 805180 has 998.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.37 GiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 716.00 MiB memory in use. Process 808404 has 936.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1018.00 MiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.29 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 554.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 554.00 MiB memory in use. Process 809192 has 460.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 950.00 MiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 934.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 78.68 MiB is allocated by PyTorch, and 43.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d61e0993,"{'temperature_head': 0.4, 'latent_dim': 146, 'batch_size': 289, 'transform_funcs': (9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 69.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.23 GiB memory in use. Process 805180 has 998.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 870.00 MiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 756.00 MiB memory in use. Process 808404 has 936.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1018.00 MiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.29 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 818.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 512.00 MiB memory in use. Process 809192 has 514.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 950.00 MiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 1.10 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 134.99 MiB is allocated by PyTorch, and 41.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
72228a70,"{'temperature_head': 0.30000000000000004, 'latent_dim': 126, 'batch_size': 500, 'transform_funcs': (3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 71.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.23 GiB memory in use. Process 805180 has 998.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 870.00 MiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 756.00 MiB memory in use. Process 808404 has 936.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1018.00 MiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.29 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 818.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 512.00 MiB memory in use. Process 809192 has 512.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 950.00 MiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 1.10 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 134.83 MiB is allocated by PyTorch, and 39.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1388ddda,"{'temperature_head': 0.1, 'latent_dim': 119, 'batch_size': 277, 'transform_funcs': (5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 7.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.23 GiB memory in use. Process 805180 has 998.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 870.00 MiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 810.00 MiB memory in use. Process 808404 has 932.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1018.00 MiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.29 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 820.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 554.00 MiB memory in use. Process 809192 has 514.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 914.00 MiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 1.10 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 134.78 MiB is allocated by PyTorch, and 41.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
39a3463a,"{'temperature_head': 0.8, 'latent_dim': 175, 'batch_size': 351, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 25.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.23 GiB memory in use. Process 805180 has 998.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 974.00 MiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 810.00 MiB memory in use. Process 808404 has 932.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1018.00 MiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.34 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 752.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 554.00 MiB memory in use. Process 809192 has 518.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 914.00 MiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 1024.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 135.22 MiB is allocated by PyTorch, and 44.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
25679d56,"{'temperature_head': 0.30000000000000004, 'latent_dim': 151, 'batch_size': 378, 'transform_funcs': (1, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.23 GiB memory in use. Process 805180 has 998.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 974.00 MiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 850.00 MiB memory in use. Process 808404 has 932.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.03 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.34 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 652.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 554.00 MiB memory in use. Process 809192 has 516.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 914.00 MiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 1024.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 135.03 MiB is allocated by PyTorch, and 42.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
adba7cca,"{'temperature_head': 0.5, 'latent_dim': 105, 'batch_size': 269, 'transform_funcs': (6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 51.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.23 GiB memory in use. Process 805180 has 998.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 976.00 MiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 850.00 MiB memory in use. Process 808404 has 932.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.03 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.34 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 652.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 608.00 MiB memory in use. Process 809192 has 456.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 914.00 MiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 1024.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 78.67 MiB is allocated by PyTorch, and 39.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
34a9653f,"{'temperature_head': 0.1, 'latent_dim': 180, 'batch_size': 241, 'transform_funcs': (1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.23 GiB memory in use. Process 805180 has 998.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 976.00 MiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 850.00 MiB memory in use. Process 808404 has 932.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.03 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.34 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 682.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 650.00 MiB memory in use. Process 809192 has 416.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 914.00 MiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 1024.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 66.73 MiB is allocated by PyTorch, and 11.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
b72fd00d,"{'temperature_head': 0.4, 'latent_dim': 72, 'batch_size': 309, 'transform_funcs': (1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.23 GiB memory in use. Process 805180 has 998.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 976.00 MiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 850.00 MiB memory in use. Process 808404 has 932.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.03 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.34 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 696.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 650.00 MiB memory in use. Process 809192 has 418.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 914.00 MiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 1024.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 52.27 MiB is allocated by PyTorch, and 27.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
0d6a1eaa,"{'temperature_head': 0.2, 'latent_dim': 95, 'batch_size': 424, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.23 GiB memory in use. Process 805180 has 998.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 976.00 MiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 850.00 MiB memory in use. Process 808404 has 932.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.03 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.34 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 696.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 650.00 MiB memory in use. Process 809192 has 418.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 914.00 MiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 1024.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 52.40 MiB is allocated by PyTorch, and 27.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
2338bd34,"{'temperature_head': 0.30000000000000004, 'latent_dim': 169, 'batch_size': 282, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.23 GiB memory in use. Process 805180 has 998.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 976.00 MiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 850.00 MiB memory in use. Process 808404 has 932.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.03 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.34 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 696.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 650.00 MiB memory in use. Process 809192 has 410.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 914.00 MiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 1024.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 65.40 MiB is allocated by PyTorch, and 6.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
61b8a6f3,"{'temperature_head': 0.4, 'latent_dim': 193, 'batch_size': 393, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.23 GiB memory in use. Process 805180 has 998.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 976.00 MiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 850.00 MiB memory in use. Process 808404 has 932.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.03 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.34 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 696.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 650.00 MiB memory in use. Process 809192 has 410.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 914.00 MiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 1024.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 68.24 MiB is allocated by PyTorch, and 3.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
c70a9fde,"{'temperature_head': 0.7000000000000001, 'latent_dim': 187, 'batch_size': 232, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 7.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.20 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.23 GiB memory in use. Process 805180 has 998.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 976.00 MiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 850.00 MiB memory in use. Process 808404 has 936.00 MiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.03 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 1.34 GiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 696.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 650.00 MiB memory in use. Process 809192 has 410.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 914.00 MiB memory in use. Process 809580 has 1000.00 MiB memory in use. Process 809577 has 1024.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 68.13 MiB is allocated by PyTorch, and 3.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
e3d2f5f1,"{'temperature_head': 0.2, 'latent_dim': 182, 'batch_size': 141, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 97.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.15 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.08 GiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 624.00 MiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 876.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 722.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 968.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 622.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1004.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 946.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 243.27 MiB is allocated by PyTorch, and 40.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8e6b69a0,"{'temperature_head': 0.2, 'latent_dim': 142, 'batch_size': 164, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.15 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.08 GiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 664.00 MiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 918.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 624.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 968.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 648.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.02 GiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 946.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 218.45 MiB is allocated by PyTorch, and 91.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f17eddbd,"{'temperature_head': 0.2, 'latent_dim': 197, 'batch_size': 168, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 67.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.11 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.08 GiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 832.00 MiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 918.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 610.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 968.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 516.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.02 GiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 946.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 135.39 MiB is allocated by PyTorch, and 42.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ab70341a,"{'temperature_head': 0.1, 'latent_dim': 218, 'batch_size': 187, 'transform_funcs': (2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 103.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.15 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 1.08 GiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 504.00 MiB memory in use. Process 808408 has 998.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 922.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 698.00 MiB memory in use. Process 808801 has 1.06 GiB memory in use. Process 809186 has 912.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 732.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.02 GiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 946.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 263.93 MiB is allocated by PyTorch, and 130.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8879c278,"{'temperature_head': 0.30000000000000004, 'latent_dim': 110, 'batch_size': 243, 'transform_funcs': (1, 8)}",<class 'RuntimeError'>,"CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 82, in fit
    loss.backward()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 492, in backward
    torch.autograd.backward(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
17670d28,"{'temperature_head': 0.8, 'latent_dim': 108, 'batch_size': 162, 'transform_funcs': (8, 11)}",<class 'RuntimeError'>,"CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 82, in fit
    loss.backward()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 492, in backward
    torch.autograd.backward(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
639d94f5,"{'temperature_head': 0.30000000000000004, 'latent_dim': 128, 'batch_size': 162, 'transform_funcs': (2, 11)}",<class 'RuntimeError'>,"CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 82, in fit
    loss.backward()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 492, in backward
    torch.autograd.backward(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
4777551d,"{'temperature_head': 0.2, 'latent_dim': 162, 'batch_size': 230, 'transform_funcs': (7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 73.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.16 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 898.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.04 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 790.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 928.00 MiB memory in use. Process 808801 has 520.00 MiB memory in use. Process 809186 has 558.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.18 GiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 974.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 135.12 MiB is allocated by PyTorch, and 44.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2bf26f4e,"{'temperature_head': 0.2, 'latent_dim': 196, 'batch_size': 141, 'transform_funcs': (5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.16 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 842.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 798.00 MiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 902.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 972.00 MiB memory in use. Process 808801 has 460.00 MiB memory in use. Process 809186 has 814.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.18 GiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 974.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 79.38 MiB is allocated by PyTorch, and 40.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
23c605a0,"{'temperature_head': 0.2, 'latent_dim': 159, 'batch_size': 188, 'transform_funcs': (9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 39.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.16 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 842.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 798.00 MiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 902.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 972.00 MiB memory in use. Process 808801 has 462.00 MiB memory in use. Process 809186 has 812.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.18 GiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 974.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 79.09 MiB is allocated by PyTorch, and 42.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1107c507,"{'temperature_head': 0.30000000000000004, 'latent_dim': 238, 'batch_size': 200, 'transform_funcs': (3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 73.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.16 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 456.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 798.00 MiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 902.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 972.00 MiB memory in use. Process 808801 has 656.00 MiB memory in use. Process 809186 has 970.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.18 GiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 974.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 276.42 MiB is allocated by PyTorch, and 39.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e86bf98a,"{'temperature_head': 0.2, 'latent_dim': 170, 'batch_size': 257, 'transform_funcs': (9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 31.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.16 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 554.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 936.00 MiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 902.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 972.00 MiB memory in use. Process 808801 has 462.00 MiB memory in use. Process 809186 has 970.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.18 GiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 974.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 79.18 MiB is allocated by PyTorch, and 42.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d3ce4534,"{'temperature_head': 0.2, 'latent_dim': 147, 'batch_size': 267, 'transform_funcs': (6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.16 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 554.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 936.00 MiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 902.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 972.00 MiB memory in use. Process 808801 has 460.00 MiB memory in use. Process 809186 has 970.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.18 GiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 974.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 79.00 MiB is allocated by PyTorch, and 41.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8c2ddb4b,"{'temperature_head': 0.30000000000000004, 'latent_dim': 210, 'batch_size': 294, 'transform_funcs': (10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 29.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.16 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 554.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 936.00 MiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 902.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 972.00 MiB memory in use. Process 808801 has 464.00 MiB memory in use. Process 809186 has 970.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.18 GiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 974.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 79.49 MiB is allocated by PyTorch, and 44.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0e3fc889,"{'temperature_head': 0.2, 'latent_dim': 156, 'batch_size': 232, 'transform_funcs': (2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 11.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.16 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 676.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 882.00 MiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 802.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 972.00 MiB memory in use. Process 808801 has 514.00 MiB memory in use. Process 809186 has 970.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.18 GiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 974.00 MiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 135.07 MiB is allocated by PyTorch, and 38.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3f5249c5,"{'temperature_head': 0.1, 'latent_dim': 139, 'batch_size': 207, 'transform_funcs': (7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.16 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 454.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 840.00 MiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 828.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 972.00 MiB memory in use. Process 808801 has 516.00 MiB memory in use. Process 809186 has 970.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.18 GiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 134.93 MiB is allocated by PyTorch, and 41.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
42283613,"{'temperature_head': 0.1, 'latent_dim': 131, 'batch_size': 225, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 33.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.16 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 502.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 882.00 MiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 848.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 972.00 MiB memory in use. Process 808801 has 428.00 MiB memory in use. Process 809186 has 970.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 1.18 GiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 46.40 MiB is allocated by PyTorch, and 41.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
50c28361,"{'temperature_head': 0.7000000000000001, 'latent_dim': 174, 'batch_size': 168, 'transform_funcs': (2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 57.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.16 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 502.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.01 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 848.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 972.00 MiB memory in use. Process 808801 has 458.00 MiB memory in use. Process 809186 has 970.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 998.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 79.21 MiB is allocated by PyTorch, and 38.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5e94092d,"{'temperature_head': 0.4, 'latent_dim': 150, 'batch_size': 213, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 57.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.16 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 502.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.01 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 848.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 972.00 MiB memory in use. Process 808801 has 458.00 MiB memory in use. Process 809186 has 970.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 998.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 79.02 MiB is allocated by PyTorch, and 38.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0e3d4c56,"{'temperature_head': 0.2, 'latent_dim': 194, 'batch_size': 243, 'transform_funcs': (5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 55.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.17 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 502.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.01 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 848.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 972.00 MiB memory in use. Process 808801 has 458.00 MiB memory in use. Process 809186 has 970.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 998.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 79.37 MiB is allocated by PyTorch, and 38.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0033e166,"{'temperature_head': 0.30000000000000004, 'latent_dim': 160, 'batch_size': 176, 'transform_funcs': (1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 53.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.17 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 456.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.01 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 900.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 972.00 MiB memory in use. Process 808801 has 454.00 MiB memory in use. Process 809186 has 970.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 998.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 79.10 MiB is allocated by PyTorch, and 34.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
298c2cc3,"{'temperature_head': 0.2, 'latent_dim': 179, 'batch_size': 219, 'transform_funcs': (7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 49.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.17 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 938.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.05 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 900.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 972.00 MiB memory in use. Process 808801 has 456.00 MiB memory in use. Process 809186 has 972.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 472.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 46.77 MiB is allocated by PyTorch, and 69.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
09e30e91,"{'temperature_head': 0.30000000000000004, 'latent_dim': 197, 'batch_size': 184, 'transform_funcs': (5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.17 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 938.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.03 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 452.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 970.00 MiB memory in use. Process 808801 has 512.00 MiB memory in use. Process 809186 has 950.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 940.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 135.39 MiB is allocated by PyTorch, and 36.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
359cbe86,"{'temperature_head': 0.2, 'latent_dim': 206, 'batch_size': 237, 'transform_funcs': (2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 47.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.17 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 938.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.03 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 510.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 970.00 MiB memory in use. Process 808801 has 426.00 MiB memory in use. Process 809186 has 950.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 940.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 46.98 MiB is allocated by PyTorch, and 39.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 60, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bc5f9a77,"{'temperature_head': 0.2, 'latent_dim': 131, 'batch_size': 154, 'transform_funcs': (5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.17 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 938.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.03 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 552.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 970.00 MiB memory in use. Process 808801 has 428.00 MiB memory in use. Process 809186 has 950.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 940.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 58.94 MiB is allocated by PyTorch, and 29.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
478564ca,"{'temperature_head': 0.2, 'latent_dim': 125, 'batch_size': 261, 'transform_funcs': (4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.17 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 938.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.03 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 552.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 970.00 MiB memory in use. Process 808801 has 428.00 MiB memory in use. Process 809186 has 950.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 940.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 58.91 MiB is allocated by PyTorch, and 29.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
c3faa692,"{'temperature_head': 0.4, 'latent_dim': 164, 'batch_size': 191, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.17 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 938.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.03 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 552.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 970.00 MiB memory in use. Process 808801 has 428.00 MiB memory in use. Process 809186 has 950.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 940.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 58.79 MiB is allocated by PyTorch, and 29.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
1ca05845,"{'temperature_head': 0.1, 'latent_dim': 217, 'batch_size': 254, 'transform_funcs': (4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.17 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 938.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.03 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 552.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 970.00 MiB memory in use. Process 808801 has 428.00 MiB memory in use. Process 809186 has 950.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 940.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 59.10 MiB is allocated by PyTorch, and 28.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
53860605,"{'temperature_head': 0.30000000000000004, 'latent_dim': 137, 'batch_size': 207, 'transform_funcs': (4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.17 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 938.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.03 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 552.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 970.00 MiB memory in use. Process 808801 has 428.00 MiB memory in use. Process 809186 has 950.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 940.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 58.98 MiB is allocated by PyTorch, and 29.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
d061799a,"{'temperature_head': 0.2, 'latent_dim': 172, 'batch_size': 168, 'transform_funcs': (4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.17 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 938.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.03 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 552.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 970.00 MiB memory in use. Process 808801 has 412.00 MiB memory in use. Process 809186 has 950.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 940.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 65.53 MiB is allocated by PyTorch, and 6.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
da332837,"{'temperature_head': 0.30000000000000004, 'latent_dim': 151, 'batch_size': 177, 'transform_funcs': (6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.17 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 938.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.03 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 552.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 970.00 MiB memory in use. Process 808801 has 428.00 MiB memory in use. Process 809186 has 950.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 940.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 59.06 MiB is allocated by PyTorch, and 28.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
249803ae,"{'temperature_head': 0.1, 'latent_dim': 184, 'batch_size': 134, 'transform_funcs': (1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.17 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 938.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.03 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 552.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 970.00 MiB memory in use. Process 808801 has 410.00 MiB memory in use. Process 809186 has 950.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 940.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 67.03 MiB is allocated by PyTorch, and 2.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
32f95e5e,"{'temperature_head': 0.1, 'latent_dim': 247, 'batch_size': 128, 'transform_funcs': (1, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 21.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.17 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 938.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.03 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 552.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 970.00 MiB memory in use. Process 808801 has 410.00 MiB memory in use. Process 809186 has 950.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 940.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 65.59 MiB is allocated by PyTorch, and 4.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/simclr_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a8765600,"{'temperature_head': 0.30000000000000004, 'latent_dim': 178, 'batch_size': 142, 'transform_funcs': (2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 19.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.17 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 938.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.03 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 552.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 970.00 MiB memory in use. Process 808801 has 412.00 MiB memory in use. Process 809186 has 950.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 940.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 65.81 MiB is allocated by PyTorch, and 6.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
8ef51521,"{'temperature_head': 0.2, 'latent_dim': 145, 'batch_size': 219, 'transform_funcs': (1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.17 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 938.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.03 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 552.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 970.00 MiB memory in use. Process 808801 has 428.00 MiB memory in use. Process 809186 has 950.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 940.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 58.67 MiB is allocated by PyTorch, and 29.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
d1e3358a,"{'temperature_head': 0.1, 'latent_dim': 201, 'batch_size': 309, 'transform_funcs': (8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 3.31 MiB is free. Process 611821 has 462.00 MiB memory in use. Process 617737 has 256.00 MiB memory in use. Process 805196 has 1.17 GiB memory in use. Process 805194 has 962.00 MiB memory in use. Process 805137 has 938.00 MiB memory in use. Process 805180 has 1018.00 MiB memory in use. Process 805153 has 772.00 MiB memory in use. Process 808405 has 1.03 GiB memory in use. Process 808408 has 1014.00 MiB memory in use. Process 808411 has 716.00 MiB memory in use. Process 808399 has 552.00 MiB memory in use. Process 808404 has 1.08 GiB memory in use. Process 808790 has 1.03 GiB memory in use. Process 808796 has 1.08 GiB memory in use. Process 808802 has 798.00 MiB memory in use. Process 808793 has 970.00 MiB memory in use. Process 808801 has 428.00 MiB memory in use. Process 809186 has 950.00 MiB memory in use. Process 809180 has 892.00 MiB memory in use. Process 809183 has 1014.00 MiB memory in use. Process 809192 has 1012.00 MiB memory in use. Process 809189 has 784.00 MiB memory in use. Process 809571 has 940.00 MiB memory in use. Process 809580 has 1002.00 MiB memory in use. Process 809577 has 1.14 GiB memory in use. Process 809615 has 872.00 MiB memory in use. Process 809574 has 1.08 GiB memory in use. Of the allocated memory 59.35 MiB is allocated by PyTorch, and 28.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 56, in fit
    trained_simclr_model,epoch_wise_loss = self.simclr.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/dataset_simclr.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
bfc4b0fb,"{'temperature_head': 0.2, 'latent_dim': 83, 'batch_size': 162, 'transform_funcs': (3, 5)}",<class 'RuntimeError'>,"CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 82, in fit
    loss.backward()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 492, in backward
    torch.autograd.backward(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
f91d07c0,"{'temperature_head': 0.30000000000000004, 'latent_dim': 198, 'batch_size': 162, 'transform_funcs': (3, 8)}",<class 'RuntimeError'>,"CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simclr_linear.py"", line 51, in fit
    self.linear_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simclr/torch/simclr_linear_estimator.py"", line 82, in fit
    loss.backward()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 492, in backward
    torch.autograd.backward(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
