trial_id,config,error_type,error_message,error_traceback
ae655af0,"{'temperature_head': 0.8, 'latent_dim': 527, 'batch_size': 416, 'transform_funcs': (4, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 112.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 854.00 MiB memory in use. Process 4088273 has 1.07 GiB memory in use. Process 4088254 has 890.00 MiB memory in use. Process 4088240 has 762.00 MiB memory in use. Process 4088256 has 932.00 MiB memory in use. Process 4091487 has 946.00 MiB memory in use. Process 4091492 has 850.00 MiB memory in use. Process 4091488 has 792.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 1.06 GiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 728.00 MiB memory in use. Process 4091870 has 1.33 GiB memory in use. Process 4091875 has 810.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 1.05 GiB memory in use. Process 4092270 has 790.00 MiB memory in use. Process 4092267 has 866.00 MiB memory in use. Process 4092263 has 730.00 MiB memory in use. Process 4092652 has 750.00 MiB memory in use. Process 4092722 has 1.18 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 371.39 MiB is allocated by PyTorch, and 236.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e6a59bb9,"{'temperature_head': 0.1, 'latent_dim': 528, 'batch_size': 437, 'transform_funcs': (3, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 110.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 854.00 MiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 816.00 MiB memory in use. Process 4088240 has 762.00 MiB memory in use. Process 4088256 has 1.01 GiB memory in use. Process 4091487 has 950.00 MiB memory in use. Process 4091492 has 680.00 MiB memory in use. Process 4091488 has 792.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 1.06 GiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 728.00 MiB memory in use. Process 4091870 has 1.34 GiB memory in use. Process 4091875 has 762.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 1.05 GiB memory in use. Process 4092270 has 790.00 MiB memory in use. Process 4092267 has 906.00 MiB memory in use. Process 4092263 has 730.00 MiB memory in use. Process 4092652 has 750.00 MiB memory in use. Process 4092722 has 1.15 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 371.34 MiB is allocated by PyTorch, and 240.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
17778cd2,"{'temperature_head': 0.5, 'latent_dim': 446, 'batch_size': 470, 'transform_funcs': (1, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 892.00 MiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 816.00 MiB memory in use. Process 4088240 has 762.00 MiB memory in use. Process 4088256 has 1.01 GiB memory in use. Process 4091487 has 954.00 MiB memory in use. Process 4091492 has 716.00 MiB memory in use. Process 4091488 has 792.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 1.06 GiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 728.00 MiB memory in use. Process 4091870 has 1.34 GiB memory in use. Process 4091875 has 762.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 1.05 GiB memory in use. Process 4092270 has 790.00 MiB memory in use. Process 4092267 has 906.00 MiB memory in use. Process 4092263 has 730.00 MiB memory in use. Process 4092652 has 750.00 MiB memory in use. Process 4092722 has 1.15 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 331.81 MiB is allocated by PyTorch, and 284.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c441b468,"{'temperature_head': 0.2, 'latent_dim': 263, 'batch_size': 278, 'transform_funcs': (0, 2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 892.00 MiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 844.00 MiB memory in use. Process 4088240 has 762.00 MiB memory in use. Process 4088256 has 1.01 GiB memory in use. Process 4091487 has 442.00 MiB memory in use. Process 4091492 has 718.00 MiB memory in use. Process 4091488 has 792.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 1.21 GiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 728.00 MiB memory in use. Process 4091870 has 1.34 GiB memory in use. Process 4091875 has 764.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 1.05 GiB memory in use. Process 4092270 has 826.00 MiB memory in use. Process 4092267 has 1.18 GiB memory in use. Process 4092263 has 730.00 MiB memory in use. Process 4092652 has 750.00 MiB memory in use. Process 4092722 has 1.15 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 70.43 MiB is allocated by PyTorch, and 33.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8b1b4f78,"{'temperature_head': 0.2, 'latent_dim': 489, 'batch_size': 319, 'transform_funcs': (1, 3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 892.00 MiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 844.00 MiB memory in use. Process 4088240 has 762.00 MiB memory in use. Process 4088256 has 1.01 GiB memory in use. Process 4091487 has 464.00 MiB memory in use. Process 4091492 has 718.00 MiB memory in use. Process 4091488 has 792.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 1.21 GiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 728.00 MiB memory in use. Process 4091870 has 1.34 GiB memory in use. Process 4091875 has 764.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 1.05 GiB memory in use. Process 4092270 has 826.00 MiB memory in use. Process 4092267 has 1.18 GiB memory in use. Process 4092263 has 730.00 MiB memory in use. Process 4092652 has 750.00 MiB memory in use. Process 4092722 has 1.15 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 90.42 MiB is allocated by PyTorch, and 35.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 46, in calculate_loss
    logits = torch.cat([torch.cat([logits_ab, logits_aa], dim=1), torch.cat([logits_ba, logits_bb], dim=1)], dim=0)
"
9ed92c65,"{'temperature_head': 0.5, 'latent_dim': 587, 'batch_size': 437, 'transform_funcs': (2, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 892.00 MiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 844.00 MiB memory in use. Process 4088240 has 762.00 MiB memory in use. Process 4088256 has 1.01 GiB memory in use. Process 4091487 has 770.00 MiB memory in use. Process 4091492 has 718.00 MiB memory in use. Process 4091488 has 792.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 1.21 GiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 728.00 MiB memory in use. Process 4091870 has 1.34 GiB memory in use. Process 4091875 has 444.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 1.05 GiB memory in use. Process 4092270 has 826.00 MiB memory in use. Process 4092267 has 1.18 GiB memory in use. Process 4092263 has 730.00 MiB memory in use. Process 4092652 has 750.00 MiB memory in use. Process 4092722 has 1.15 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 401.11 MiB is allocated by PyTorch, and 30.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4b8ab6d5,"{'temperature_head': 0.1, 'latent_dim': 256, 'batch_size': 292, 'transform_funcs': (0, 3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 892.00 MiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 844.00 MiB memory in use. Process 4088240 has 588.00 MiB memory in use. Process 4088256 has 1.01 GiB memory in use. Process 4091487 has 604.00 MiB memory in use. Process 4091492 has 718.00 MiB memory in use. Process 4091488 has 792.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 1.21 GiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 728.00 MiB memory in use. Process 4091870 has 1.34 GiB memory in use. Process 4091875 has 762.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 1.05 GiB memory in use. Process 4092270 has 828.00 MiB memory in use. Process 4092267 has 1.18 GiB memory in use. Process 4092263 has 730.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.15 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 240.84 MiB is allocated by PyTorch, and 25.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3c0bd63d,"{'temperature_head': 0.7000000000000001, 'latent_dim': 404, 'batch_size': 370, 'transform_funcs': (1, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 892.00 MiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 844.00 MiB memory in use. Process 4088240 has 626.00 MiB memory in use. Process 4088256 has 1.01 GiB memory in use. Process 4091487 has 492.00 MiB memory in use. Process 4091492 has 718.00 MiB memory in use. Process 4091488 has 792.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 1.21 GiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 728.00 MiB memory in use. Process 4091870 has 1.34 GiB memory in use. Process 4091875 has 762.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 1.05 GiB memory in use. Process 4092270 has 828.00 MiB memory in use. Process 4092267 has 1.18 GiB memory in use. Process 4092263 has 730.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.19 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.53 MiB is allocated by PyTorch, and 36.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6216cb68,"{'temperature_head': 0.30000000000000004, 'latent_dim': 344, 'batch_size': 469, 'transform_funcs': (0, 1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 136.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 892.00 MiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 880.00 MiB memory in use. Process 4088240 has 698.00 MiB memory in use. Process 4088256 has 1.01 GiB memory in use. Process 4091487 has 660.00 MiB memory in use. Process 4091492 has 718.00 MiB memory in use. Process 4091488 has 792.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 784.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 728.00 MiB memory in use. Process 4091870 has 1.34 GiB memory in use. Process 4091875 has 762.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 1.05 GiB memory in use. Process 4092270 has 828.00 MiB memory in use. Process 4092267 has 1.18 GiB memory in use. Process 4092263 has 840.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.19 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 283.06 MiB is allocated by PyTorch, and 38.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
544e4c3c,"{'temperature_head': 0.2, 'latent_dim': 614, 'batch_size': 248, 'transform_funcs': (3, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 208.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 892.00 MiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 880.00 MiB memory in use. Process 4088240 has 698.00 MiB memory in use. Process 4088256 has 1.01 GiB memory in use. Process 4091487 has 684.00 MiB memory in use. Process 4091492 has 718.00 MiB memory in use. Process 4091488 has 792.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 784.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 728.00 MiB memory in use. Process 4091870 has 1.34 GiB memory in use. Process 4091875 has 762.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 1.05 GiB memory in use. Process 4092270 has 828.00 MiB memory in use. Process 4092267 has 1.18 GiB memory in use. Process 4092263 has 840.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.09 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 412.27 MiB is allocated by PyTorch, and 369.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6332e386,"{'temperature_head': 0.8, 'latent_dim': 718, 'batch_size': 335, 'transform_funcs': (1, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 346.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 892.00 MiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 956.00 MiB memory in use. Process 4088240 has 698.00 MiB memory in use. Process 4088256 has 1.01 GiB memory in use. Process 4091487 has 696.00 MiB memory in use. Process 4091492 has 718.00 MiB memory in use. Process 4091488 has 874.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 784.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 728.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 800.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 1.05 GiB memory in use. Process 4092270 has 828.00 MiB memory in use. Process 4092267 has 1.21 GiB memory in use. Process 4092263 has 840.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 463.94 MiB is allocated by PyTorch, and 154.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f3a40ba5,"{'temperature_head': 0.6000000000000001, 'latent_dim': 320, 'batch_size': 138, 'transform_funcs': (2, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 892.00 MiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 472.00 MiB memory in use. Process 4088240 has 630.00 MiB memory in use. Process 4088256 has 1.01 GiB memory in use. Process 4091487 has 1.19 GiB memory in use. Process 4091492 has 718.00 MiB memory in use. Process 4091488 has 874.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 810.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 728.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 838.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 1.05 GiB memory in use. Process 4092270 has 780.00 MiB memory in use. Process 4092267 has 1.21 GiB memory in use. Process 4092263 has 840.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 115.70 MiB is allocated by PyTorch, and 18.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
27f2cfdf,"{'temperature_head': 1.0, 'latent_dim': 556, 'batch_size': 304, 'transform_funcs': (0, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 246.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 472.00 MiB memory in use. Process 4088240 has 666.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.19 GiB memory in use. Process 4091492 has 718.00 MiB memory in use. Process 4091488 has 590.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 776.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 730.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 566.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 1.05 GiB memory in use. Process 4092270 has 780.00 MiB memory in use. Process 4092267 has 1.21 GiB memory in use. Process 4092263 has 840.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 118.50 MiB is allocated by PyTorch, and 15.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cc1ce810,"{'temperature_head': 0.30000000000000004, 'latent_dim': 282, 'batch_size': 346, 'transform_funcs': (2, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 112.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 916.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 700.00 MiB memory in use. Process 4091488 has 722.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 830.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 840.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 914.00 MiB memory in use. Process 4092270 has 782.00 MiB memory in use. Process 4092267 has 470.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 115.07 MiB is allocated by PyTorch, and 16.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dde06dda,"{'temperature_head': 0.1, 'latent_dim': 589, 'batch_size': 508, 'transform_funcs': (0, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 916.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 700.00 MiB memory in use. Process 4091488 has 722.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 830.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 840.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 914.00 MiB memory in use. Process 4092270 has 888.00 MiB memory in use. Process 4092267 has 456.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 97.02 MiB is allocated by PyTorch, and 20.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
374a9d32,"{'temperature_head': 0.6000000000000001, 'latent_dim': 550, 'batch_size': 263, 'transform_funcs': (4, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 916.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 700.00 MiB memory in use. Process 4091488 has 722.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 866.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 840.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 916.00 MiB memory in use. Process 4092270 has 888.00 MiB memory in use. Process 4092267 has 410.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 44.70 MiB is allocated by PyTorch, and 27.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d1e04069,"{'temperature_head': 0.9, 'latent_dim': 469, 'batch_size': 326, 'transform_funcs': (1, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 916.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 700.00 MiB memory in use. Process 4091488 has 722.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 868.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 840.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 916.00 MiB memory in use. Process 4092270 has 888.00 MiB memory in use. Process 4092267 has 430.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 82.56 MiB is allocated by PyTorch, and 9.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
495982d8,"{'temperature_head': 0.7000000000000001, 'latent_dim': 511, 'batch_size': 426, 'transform_funcs': (1, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 916.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 700.00 MiB memory in use. Process 4091488 has 722.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 868.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 840.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 916.00 MiB memory in use. Process 4092270 has 888.00 MiB memory in use. Process 4092267 has 428.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 74.84 MiB is allocated by PyTorch, and 15.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/simcrl_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
84a604a7,"{'temperature_head': 0.8, 'latent_dim': 399, 'batch_size': 235, 'transform_funcs': (1, 2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 84.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 834.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 608.00 MiB memory in use. Process 4091488 has 808.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 868.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 764.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 406.00 MiB memory in use. Process 4092267 has 860.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 307.16 MiB is allocated by PyTorch, and 188.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
29f60705,"{'temperature_head': 0.7000000000000001, 'latent_dim': 128, 'batch_size': 392, 'transform_funcs': (5, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 532.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 648.00 MiB memory in use. Process 4091488 has 808.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 868.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 1.01 GiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 442.00 MiB memory in use. Process 4092267 has 860.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 176.20 MiB is allocated by PyTorch, and 17.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
050bda78,"{'temperature_head': 0.6000000000000001, 'latent_dim': 178, 'batch_size': 475, 'transform_funcs': (2, 3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 426.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 702.00 MiB memory in use. Process 4091488 has 808.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 868.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 1.01 GiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 456.00 MiB memory in use. Process 4092267 has 894.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 68.59 MiB is allocated by PyTorch, and 19.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2c2e8a5f,"{'temperature_head': 1.0, 'latent_dim': 268, 'batch_size': 408, 'transform_funcs': (0, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 468.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 702.00 MiB memory in use. Process 4091488 has 808.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 868.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 1.01 GiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 732.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 442.00 MiB memory in use. Process 4092267 has 894.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 115.30 MiB is allocated by PyTorch, and 14.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7b404855,"{'temperature_head': 0.7000000000000001, 'latent_dim': 309, 'batch_size': 143, 'transform_funcs': (0, 2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 470.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 702.00 MiB memory in use. Process 4091488 has 808.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 834.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 1.01 GiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 422.00 MiB memory in use. Process 4092267 has 894.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 115.62 MiB is allocated by PyTorch, and 16.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0079ae26,"{'temperature_head': 0.8, 'latent_dim': 167, 'batch_size': 285, 'transform_funcs': (0, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 558.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 442.00 MiB memory in use. Process 4091488 has 808.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 834.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 1.01 GiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 606.00 MiB memory in use. Process 4092267 has 896.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 194.72 MiB is allocated by PyTorch, and 25.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1acc2eb1,"{'temperature_head': 0.4, 'latent_dim': 375, 'batch_size': 355, 'transform_funcs': (0, 1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 182.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 134.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 558.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 442.00 MiB memory in use. Process 4091488 has 808.00 MiB memory in use. Process 4091482 has 1.05 GiB memory in use. Process 4091491 has 834.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 1.01 GiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 606.00 MiB memory in use. Process 4092267 has 812.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 295.16 MiB is allocated by PyTorch, and 178.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
03c43b1d,"{'temperature_head': 0.4, 'latent_dim': 194, 'batch_size': 373, 'transform_funcs': (0, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 88.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 514.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 468.00 MiB memory in use. Process 4091488 has 808.00 MiB memory in use. Process 4091482 has 1006.00 MiB memory in use. Process 4091491 has 834.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 1.01 GiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 606.00 MiB memory in use. Process 4092267 has 948.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 113.78 MiB is allocated by PyTorch, and 62.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
38a96312,"{'temperature_head': 0.8, 'latent_dim': 359, 'batch_size': 464, 'transform_funcs': (3, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 84.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 470.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 754.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 642.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 808.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 874.00 MiB memory in use. Process 4092267 has 988.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 116.01 MiB is allocated by PyTorch, and 15.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0b25be01,"{'temperature_head': 0.5, 'latent_dim': 555, 'batch_size': 405, 'transform_funcs': (2, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 88.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 508.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 754.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 642.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 808.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 874.00 MiB memory in use. Process 4092267 has 988.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.09 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 383.64 MiB is allocated by PyTorch, and 396.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c4fb7819,"{'temperature_head': 0.30000000000000004, 'latent_dim': 504, 'batch_size': 478, 'transform_funcs': (3, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 234.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 482.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 754.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 442.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 808.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 874.00 MiB memory in use. Process 4092267 has 1.00 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.08 MiB is allocated by PyTorch, and 26.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b88cbdbd,"{'temperature_head': 0.7000000000000001, 'latent_dim': 539, 'batch_size': 206, 'transform_funcs': (2, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 224.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 514.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 754.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 456.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 808.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 874.00 MiB memory in use. Process 4092267 has 1.00 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.10 GiB memory in use. Process 4092697 has 876.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 375.21 MiB is allocated by PyTorch, and 408.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
523e4dad,"{'temperature_head': 0.9, 'latent_dim': 574, 'batch_size': 282, 'transform_funcs': (0, 2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 146.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 478.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.27 GiB memory in use. Process 4091492 has 698.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 458.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 808.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 874.00 MiB memory in use. Process 4092267 has 1.00 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.63 MiB is allocated by PyTorch, and 22.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0b351bb3,"{'temperature_head': 0.8, 'latent_dim': 434, 'batch_size': 427, 'transform_funcs': (0, 1, 2)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 154.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 472.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.29 GiB memory in use. Process 4091492 has 698.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 632.00 MiB memory in use. Process 4091876 has 1.01 GiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 460.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.00 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 116.60 MiB is allocated by PyTorch, and 17.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
454f8316,"{'temperature_head': 0.5, 'latent_dim': 686, 'batch_size': 188, 'transform_funcs': (9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 330.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 86.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 508.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.29 GiB memory in use. Process 4091492 has 698.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 726.00 MiB memory in use. Process 4091876 has 692.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 704.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.04 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 118.51 MiB is allocated by PyTorch, and 51.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e47b9ed7,"{'temperature_head': 0.9, 'latent_dim': 612, 'batch_size': 297, 'transform_funcs': (0, 3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 222.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 544.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.29 GiB memory in use. Process 4091492 has 734.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 726.00 MiB memory in use. Process 4091876 has 692.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 704.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 856.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 411.21 MiB is allocated by PyTorch, and 106.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
839440a0,"{'temperature_head': 0.30000000000000004, 'latent_dim': 387, 'batch_size': 254, 'transform_funcs': (3, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 124.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 480.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.29 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 726.00 MiB memory in use. Process 4091876 has 692.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 704.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 894.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 116.17 MiB is allocated by PyTorch, and 25.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b5a929a6,"{'temperature_head': 1.0, 'latent_dim': 343, 'batch_size': 393, 'transform_funcs': (0, 1, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 110.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 480.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.29 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 726.00 MiB memory in use. Process 4091876 has 706.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 704.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 894.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 115.82 MiB is allocated by PyTorch, and 26.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8aa86e05,"{'temperature_head': 0.2, 'latent_dim': 235, 'batch_size': 335, 'transform_funcs': (1, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 106.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 628.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.05 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 528.00 MiB memory in use. Process 4091876 has 798.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 896.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 227.05 MiB is allocated by PyTorch, and 62.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
95ae3689,"{'temperature_head': 0.30000000000000004, 'latent_dim': 699, 'batch_size': 349, 'transform_funcs': (3, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 336.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 122.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 644.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.06 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 442.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 860.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.05 MiB is allocated by PyTorch, and 402.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e9385cbe,"{'temperature_head': 0.30000000000000004, 'latent_dim': 641, 'batch_size': 303, 'transform_funcs': (5, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 256.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 472.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.06 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 442.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 898.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 118.80 MiB is allocated by PyTorch, and 13.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d62e84c1,"{'temperature_head': 0.1, 'latent_dim': 598, 'batch_size': 409, 'transform_funcs': (1, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 162.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 588.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 968.00 MiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 572.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 860.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 404.48 MiB is allocated by PyTorch, and 115.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
11cb28fa,"{'temperature_head': 0.2, 'latent_dim': 717, 'batch_size': 387, 'transform_funcs': (3, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 346.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 268.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 482.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 968.00 MiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 572.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 860.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 118.75 MiB is allocated by PyTorch, and 23.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dfdd4e5a,"{'temperature_head': 1.0, 'latent_dim': 523, 'batch_size': 269, 'transform_funcs': (0, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 234.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 518.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 968.00 MiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 572.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 858.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.13 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 367.64 MiB is allocated by PyTorch, and 150.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
84f8499c,"{'temperature_head': 0.30000000000000004, 'latent_dim': 183, 'batch_size': 329, 'transform_funcs': (3, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 902.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 968.00 MiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 572.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 472.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.32 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 114.29 MiB is allocated by PyTorch, and 17.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b2fc5df5,"{'temperature_head': 0.7000000000000001, 'latent_dim': 42, 'batch_size': 160, 'transform_funcs': (7, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 902.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 968.00 MiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 572.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 472.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.32 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 113.19 MiB is allocated by PyTorch, and 18.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
05ddac6f,"{'temperature_head': 0.9, 'latent_dim': 204, 'batch_size': 370, 'transform_funcs': (3, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 902.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1006.00 MiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 572.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 472.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.32 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 114.46 MiB is allocated by PyTorch, and 17.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9f50526d,"{'temperature_head': 0.4, 'latent_dim': 566, 'batch_size': 314, 'transform_funcs': (0, 1, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 92.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 902.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 946.00 MiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 572.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 444.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.32 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 389.97 MiB is allocated by PyTorch, and 218.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7e7d1aab,"{'temperature_head': 0.8, 'latent_dim': 543, 'batch_size': 275, 'transform_funcs': (2, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 902.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 984.00 MiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 572.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 474.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.32 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.11 MiB is allocated by PyTorch, and 16.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2b48fd13,"{'temperature_head': 0.2, 'latent_dim': 626, 'batch_size': 245, 'transform_funcs': (6, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 302.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 118.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 824.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.15 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 572.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.10 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 488.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 418.92 MiB is allocated by PyTorch, and 65.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4b5fc373,"{'temperature_head': 0.1, 'latent_dim': 505, 'batch_size': 179, 'transform_funcs': (2, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 938.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.15 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 572.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 1.19 GiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.10 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 474.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 116.81 MiB is allocated by PyTorch, and 17.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
50ec8a1f,"{'temperature_head': 0.1, 'latent_dim': 489, 'batch_size': 210, 'transform_funcs': (1, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 236.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 128.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 938.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.19 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 490.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.23 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 916.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.10 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 710.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 352.69 MiB is allocated by PyTorch, and 17.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4c9e5cd0,"{'temperature_head': 0.2, 'latent_dim': 603, 'batch_size': 220, 'transform_funcs': (2, 3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 290.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 100.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 972.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.19 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 526.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.15 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 916.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.10 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 746.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 406.99 MiB is allocated by PyTorch, and 437.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d453dc98,"{'temperature_head': 0.30000000000000004, 'latent_dim': 536, 'batch_size': 243, 'transform_funcs': (0, 3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 972.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.19 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 578.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 916.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.10 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 664.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 116.17 MiB is allocated by PyTorch, and 207.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
49451165,"{'temperature_head': 0.1, 'latent_dim': 582, 'batch_size': 147, 'transform_funcs': (1, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 936.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.19 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 578.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 916.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.10 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 700.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 397.51 MiB is allocated by PyTorch, and 198.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7023b6fd,"{'temperature_head': 0.2, 'latent_dim': 638, 'batch_size': 290, 'transform_funcs': (3, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 308.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 974.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.19 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 616.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 916.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.10 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 662.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.08 MiB is allocated by PyTorch, and 204.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
05a1d7de,"{'temperature_head': 1.0, 'latent_dim': 676, 'batch_size': 262, 'transform_funcs': (2, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 326.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 286.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 888.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1000.00 MiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 616.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.10 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 700.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 443.70 MiB is allocated by PyTorch, and 218.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0578b8cd,"{'temperature_head': 0.30000000000000004, 'latent_dim': 563, 'batch_size': 251, 'transform_funcs': (4, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 888.00 MiB memory in use. Process 4088240 has 668.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.24 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 616.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.10 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 662.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 116.39 MiB is allocated by PyTorch, and 205.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
483aeda1,"{'temperature_head': 0.4, 'latent_dim': 425, 'batch_size': 379, 'transform_funcs': (8, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 118.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 624.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.24 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 612.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.00 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 870.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 319.58 MiB is allocated by PyTorch, and 210.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
eb5076e8,"{'temperature_head': 0.5, 'latent_dim': 379, 'batch_size': 302, 'transform_funcs': (6, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 118.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 588.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.24 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 612.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.00 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 906.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 115.22 MiB is allocated by PyTorch, and 132.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
39e27ecc,"{'temperature_head': 0.2, 'latent_dim': 351, 'batch_size': 359, 'transform_funcs': (5, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 84.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 624.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.24 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 648.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.00 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 868.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 283.44 MiB is allocated by PyTorch, and 244.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1c19ab6b,"{'temperature_head': 0.30000000000000004, 'latent_dim': 403, 'batch_size': 295, 'transform_funcs': (1, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 80.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 588.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.24 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 648.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.00 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 908.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 115.41 MiB is allocated by PyTorch, and 132.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
895f521d,"{'temperature_head': 0.7000000000000001, 'latent_dim': 444, 'batch_size': 241, 'transform_funcs': (1, 3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 82.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 624.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.24 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 648.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.00 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 870.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 328.86 MiB is allocated by PyTorch, and 201.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
933d6df0,"{'temperature_head': 0.6000000000000001, 'latent_dim': 299, 'batch_size': 342, 'transform_funcs': (3, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 84.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 586.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.24 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 648.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.00 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 906.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 114.60 MiB is allocated by PyTorch, and 131.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
df4278e2,"{'temperature_head': 0.8, 'latent_dim': 360, 'batch_size': 276, 'transform_funcs': (0, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 588.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.28 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 648.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 446.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.43 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 115.07 MiB is allocated by PyTorch, and 132.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
947d3fb5,"{'temperature_head': 0.4, 'latent_dim': 246, 'batch_size': 234, 'transform_funcs': (1, 3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 622.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.28 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 648.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 474.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.43 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 114.79 MiB is allocated by PyTorch, and 19.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
efb5917c,"{'temperature_head': 0.2, 'latent_dim': 146, 'batch_size': 436, 'transform_funcs': (2, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 586.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.28 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 638.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 464.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.43 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 113.40 MiB is allocated by PyTorch, and 132.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
22bc2c9e,"{'temperature_head': 0.30000000000000004, 'latent_dim': 268, 'batch_size': 323, 'transform_funcs': (1, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 624.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.28 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 638.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 472.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.43 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 114.96 MiB is allocated by PyTorch, and 17.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9aad239f,"{'temperature_head': 0.5, 'latent_dim': 228, 'batch_size': 266, 'transform_funcs': (3, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 86.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 586.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.28 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 638.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 444.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.43 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 114.04 MiB is allocated by PyTorch, and 131.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
af77f495,"{'temperature_head': 0.6000000000000001, 'latent_dim': 101, 'batch_size': 286, 'transform_funcs': (0, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 626.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.28 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 638.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 474.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.43 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 113.65 MiB is allocated by PyTorch, and 20.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fad0feb9,"{'temperature_head': 0.4, 'latent_dim': 464, 'batch_size': 174, 'transform_funcs': (5, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 814.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.28 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 442.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 466.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.43 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 339.89 MiB is allocated by PyTorch, and 134.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
657f436d,"{'temperature_head': 0.7000000000000001, 'latent_dim': 392, 'batch_size': 329, 'transform_funcs': (0, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 144.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 502.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.28 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 442.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 666.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.43 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 304.35 MiB is allocated by PyTorch, and 21.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9502afa6,"{'temperature_head': 0.30000000000000004, 'latent_dim': 593, 'batch_size': 367, 'transform_funcs': (0, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 286.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 122.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 486.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.28 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 444.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 702.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.43 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 118.30 MiB is allocated by PyTorch, and 27.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ef264e65,"{'temperature_head': 0.1, 'latent_dim': 420, 'batch_size': 391, 'transform_funcs': (5, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 202.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 86.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 522.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.28 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 528.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 618.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.43 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 115.27 MiB is allocated by PyTorch, and 162.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2a552bb0,"{'temperature_head': 0.6000000000000001, 'latent_dim': 529, 'batch_size': 224, 'transform_funcs': (2, 3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 128.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 480.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.28 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 528.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 618.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.43 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.28 MiB is allocated by PyTorch, and 22.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a24cffee,"{'temperature_head': 0.5, 'latent_dim': 552, 'batch_size': 259, 'transform_funcs': (1, 2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 518.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.28 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 574.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 616.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.43 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 116.62 MiB is allocated by PyTorch, and 159.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
816f1aa9,"{'temperature_head': 0.8, 'latent_dim': 621, 'batch_size': 253, 'transform_funcs': (2, 3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 482.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.28 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 574.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 638.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.43 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 118.00 MiB is allocated by PyTorch, and 24.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d71186cb,"{'temperature_head': 0.1, 'latent_dim': 486, 'batch_size': 311, 'transform_funcs': (4, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 168.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 484.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.29 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 444.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.19 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 654.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.43 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 116.94 MiB is allocated by PyTorch, and 27.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ff790e5b,"{'temperature_head': 0.30000000000000004, 'latent_dim': 514, 'batch_size': 200, 'transform_funcs': (4, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 248.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 168.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 518.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.29 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 444.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 618.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.43 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 116.05 MiB is allocated by PyTorch, and 161.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
be452159,"{'temperature_head': 0.4, 'latent_dim': 580, 'batch_size': 504, 'transform_funcs': (0, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 520.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.29 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 538.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 654.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.43 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.74 MiB is allocated by PyTorch, and 62.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2eddaa70,"{'temperature_head': 0.30000000000000004, 'latent_dim': 527, 'batch_size': 152, 'transform_funcs': (1, 2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 180.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 508.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.29 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 538.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 616.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.33 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 116.10 MiB is allocated by PyTorch, and 159.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
62e67f72,"{'temperature_head': 0.4, 'latent_dim': 571, 'batch_size': 298, 'transform_funcs': (1, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 142.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 472.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.29 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 574.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 654.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.33 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.74 MiB is allocated by PyTorch, and 14.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
fb4af2c3,"{'temperature_head': 0.5, 'latent_dim': 609, 'batch_size': 270, 'transform_funcs': (0, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 512.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.29 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 658.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 616.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.33 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.42 MiB is allocated by PyTorch, and 158.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
052eaf8d,"{'temperature_head': 1.0, 'latent_dim': 494, 'batch_size': 205, 'transform_funcs': (1, 3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 482.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 1.29 GiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 658.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 654.00 MiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.33 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.00 MiB is allocated by PyTorch, and 25.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7fa93565,"{'temperature_head': 0.5, 'latent_dim': 647, 'batch_size': 130, 'transform_funcs': (1, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 312.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 106.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 792.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 486.00 MiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 658.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 952.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.09 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.33 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 429.59 MiB is allocated by PyTorch, and 22.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
530700c9,"{'temperature_head': 0.2, 'latent_dim': 410, 'batch_size': 285, 'transform_funcs': (6, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 142.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 830.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 494.00 MiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 658.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 870.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.09 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.33 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.58 MiB is allocated by PyTorch, and 38.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
49fed0ad,"{'temperature_head': 0.4, 'latent_dim': 445, 'batch_size': 238, 'transform_funcs': (1, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 930.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 490.00 MiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 658.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 870.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.09 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.33 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.85 MiB is allocated by PyTorch, and 34.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
02862275,"{'temperature_head': 0.7000000000000001, 'latent_dim': 675, 'batch_size': 334, 'transform_funcs': (2, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 930.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 490.00 MiB memory in use. Process 4091492 has 858.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 658.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 870.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.09 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 1.33 GiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 119.65 MiB is allocated by PyTorch, and 30.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7f9b7c69,"{'temperature_head': 0.2, 'latent_dim': 501, 'batch_size': 215, 'transform_funcs': (0, 1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 182.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 968.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 494.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 718.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.09 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 958.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 118.29 MiB is allocated by PyTorch, and 35.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6490e2a6,"{'temperature_head': 1.0, 'latent_dim': 430, 'batch_size': 497, 'transform_funcs': (2, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 150.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 884.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 492.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 718.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1022.00 MiB memory in use. Process 4092267 has 1.21 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 958.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.74 MiB is allocated by PyTorch, and 34.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d6078028,"{'temperature_head': 0.9, 'latent_dim': 349, 'batch_size': 444, 'transform_funcs': (2, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 148.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 884.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 492.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 718.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.21 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 958.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.10 MiB is allocated by PyTorch, and 34.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f19443b9,"{'temperature_head': 0.9, 'latent_dim': 286, 'batch_size': 508, 'transform_funcs': (0, 2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 884.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 632.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 718.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.21 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 958.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 254.61 MiB is allocated by PyTorch, and 37.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a233d95c,"{'temperature_head': 1.0, 'latent_dim': 337, 'batch_size': 419, 'transform_funcs': (1, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 148.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 884.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 492.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 718.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.21 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 958.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.01 MiB is allocated by PyTorch, and 34.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5033979d,"{'temperature_head': 0.8, 'latent_dim': 392, 'batch_size': 451, 'transform_funcs': (5, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 146.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 884.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 494.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 718.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.21 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 958.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.44 MiB is allocated by PyTorch, and 36.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
42bb091b,"{'temperature_head': 0.9, 'latent_dim': 215, 'batch_size': 486, 'transform_funcs': (6, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 884.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 492.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.21 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 958.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 116.05 MiB is allocated by PyTorch, and 35.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
aa42c8f9,"{'temperature_head': 0.8, 'latent_dim': 406, 'batch_size': 432, 'transform_funcs': (1, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 888.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 494.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.21 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 996.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.55 MiB is allocated by PyTorch, and 36.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
72668a57,"{'temperature_head': 0.9, 'latent_dim': 469, 'batch_size': 462, 'transform_funcs': (0, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 156.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 700.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 530.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.21 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 996.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 342.87 MiB is allocated by PyTorch, and 17.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
858d8f2d,"{'temperature_head': 1.0, 'latent_dim': 424, 'batch_size': 405, 'transform_funcs': (0, 1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 192.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 700.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 494.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.21 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 996.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 117.69 MiB is allocated by PyTorch, and 36.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
98211de2,"{'temperature_head': 0.8, 'latent_dim': 302, 'batch_size': 493, 'transform_funcs': (6, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 120.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 734.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 492.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 996.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 116.73 MiB is allocated by PyTorch, and 35.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
db4c7254,"{'temperature_head': 0.9, 'latent_dim': 561, 'batch_size': 438, 'transform_funcs': (2, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 270.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 120.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 734.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 492.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 996.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 119.42 MiB is allocated by PyTorch, and 32.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4b94bc59,"{'temperature_head': 0.7000000000000001, 'latent_dim': 630, 'batch_size': 510, 'transform_funcs': (0, 1, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 120.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 734.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 492.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 996.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 119.30 MiB is allocated by PyTorch, and 32.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dfed446a,"{'temperature_head': 1.0, 'latent_dim': 381, 'batch_size': 350, 'transform_funcs': (0, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 164.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 736.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 528.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 914.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 298.09 MiB is allocated by PyTorch, and 275.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2c802825,"{'temperature_head': 0.9, 'latent_dim': 157, 'batch_size': 272, 'transform_funcs': (4, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 992.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 604.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 672.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 190.72 MiB is allocated by PyTorch, and 73.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4c434be5,"{'temperature_head': 1.0, 'latent_dim': 185, 'batch_size': 296, 'transform_funcs': (1, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 992.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 580.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 718.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 204.74 MiB is allocated by PyTorch, and 35.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
60ec2727,"{'temperature_head': 1.0, 'latent_dim': 298, 'batch_size': 314, 'transform_funcs': (1, 3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1024.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 492.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 756.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 116.70 MiB is allocated by PyTorch, and 35.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f76cb398,"{'temperature_head': 0.7000000000000001, 'latent_dim': 76, 'batch_size': 358, 'transform_funcs': (0, 2, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1024.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 534.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 756.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 151.50 MiB is allocated by PyTorch, and 42.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
44340d7b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 122, 'batch_size': 410, 'transform_funcs': (4, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1024.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 552.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 756.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 173.96 MiB is allocated by PyTorch, and 38.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
83c16c7c,"{'temperature_head': 0.8, 'latent_dim': 142, 'batch_size': 364, 'transform_funcs': (1, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1024.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 492.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 756.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 115.48 MiB is allocated by PyTorch, and 36.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1ed1541d,"{'temperature_head': 0.8, 'latent_dim': 343, 'batch_size': 311, 'transform_funcs': (3, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1.00 GiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 846.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 428.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 69.55 MiB is allocated by PyTorch, and 18.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e307a314,"{'temperature_head': 0.7000000000000001, 'latent_dim': 21, 'batch_size': 321, 'transform_funcs': (1, 3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1008.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 846.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 470.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 113.03 MiB is allocated by PyTorch, and 16.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
31a316b3,"{'temperature_head': 0.7000000000000001, 'latent_dim': 59, 'batch_size': 282, 'transform_funcs': (5, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1008.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 846.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 472.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 113.32 MiB is allocated by PyTorch, and 18.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fff83a38,"{'temperature_head': 0.6000000000000001, 'latent_dim': 108, 'batch_size': 301, 'transform_funcs': (0, 2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1008.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 846.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 470.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 113.71 MiB is allocated by PyTorch, and 16.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3918950b,"{'temperature_head': 0.8, 'latent_dim': 67, 'batch_size': 321, 'transform_funcs': (3, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1008.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 846.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 470.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 113.39 MiB is allocated by PyTorch, and 16.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b76e75a7,"{'temperature_head': 0.7000000000000001, 'latent_dim': 4, 'batch_size': 357, 'transform_funcs': (3, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1008.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 846.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 470.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 112.90 MiB is allocated by PyTorch, and 17.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1d9aeb04,"{'temperature_head': 0.8, 'latent_dim': 50, 'batch_size': 377, 'transform_funcs': (3, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1008.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 846.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 470.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 113.25 MiB is allocated by PyTorch, and 16.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
03e0d8c3,"{'temperature_head': 0.6000000000000001, 'latent_dim': 34, 'batch_size': 332, 'transform_funcs': (2, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1008.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 846.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 818.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 842.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 470.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 113.13 MiB is allocated by PyTorch, and 16.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
98efc005,"{'temperature_head': 0.6000000000000001, 'latent_dim': 268, 'batch_size': 381, 'transform_funcs': (0, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 88.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1.02 GiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 858.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 764.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 646.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 602.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 243.78 MiB is allocated by PyTorch, and 18.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
be1434de,"{'temperature_head': 0.6000000000000001, 'latent_dim': 223, 'batch_size': 397, 'transform_funcs': (5, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 96.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1.02 GiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 898.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 764.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 646.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 554.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 113.72 MiB is allocated by PyTorch, and 100.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d652ae6a,"{'temperature_head': 0.8, 'latent_dim': 98, 'batch_size': 388, 'transform_funcs': (5, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1.02 GiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 898.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 764.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 646.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 604.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 160.75 MiB is allocated by PyTorch, and 103.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fce5ed52,"{'temperature_head': 0.30000000000000004, 'latent_dim': 204, 'batch_size': 327, 'transform_funcs': (7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1.02 GiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 898.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 642.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 740.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1024.00 MiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 570.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 660.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 950.00 MiB memory in use. Of the allocated memory 211.63 MiB is allocated by PyTorch, and 108.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ce480d60,"{'temperature_head': 0.6000000000000001, 'latent_dim': 136, 'batch_size': 313, 'transform_funcs': (0, 2, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1.02 GiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 898.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 782.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 906.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 698.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 540.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 814.00 MiB memory in use. Of the allocated memory 179.93 MiB is allocated by PyTorch, and 20.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fccbf870,"{'temperature_head': 0.30000000000000004, 'latent_dim': 703, 'batch_size': 393, 'transform_funcs': (4, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 338.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 316.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 896.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 898.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 782.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 698.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 444.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 744.00 MiB memory in use. Of the allocated memory 455.76 MiB is allocated by PyTorch, and 100.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c01226c5,"{'temperature_head': 0.5, 'latent_dim': 198, 'batch_size': 403, 'transform_funcs': (0, 3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 84.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 936.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 898.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 782.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.24 GiB memory in use. Process 4092263 has 714.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 586.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 778.00 MiB memory in use. Of the allocated memory 209.53 MiB is allocated by PyTorch, and 36.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
edf7fc4b,"{'temperature_head': 0.30000000000000004, 'latent_dim': 652, 'batch_size': 205, 'transform_funcs': (2, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 214.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 698.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 898.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 792.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.25 GiB memory in use. Process 4092263 has 716.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 522.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 117.21 MiB is allocated by PyTorch, and 64.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8c563593,"{'temperature_head': 0.4, 'latent_dim': 333, 'batch_size': 234, 'transform_funcs': (4, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 144.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 684.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 898.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 792.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 652.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 634.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 274.92 MiB is allocated by PyTorch, and 69.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b43904b0,"{'temperature_head': 0.30000000000000004, 'latent_dim': 277, 'batch_size': 240, 'transform_funcs': (2, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 134.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 114.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 606.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 898.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 792.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 652.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 740.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 249.37 MiB is allocated by PyTorch, and 16.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
89afbac3,"{'temperature_head': 0.4, 'latent_dim': 77, 'batch_size': 226, 'transform_funcs': (4, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1024.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 538.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 792.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.20 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 908.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 700.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 740.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 151.98 MiB is allocated by PyTorch, and 46.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2760fcf2,"{'temperature_head': 0.30000000000000004, 'latent_dim': 608, 'batch_size': 303, 'transform_funcs': (2, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 140.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1024.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 690.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 762.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.10 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 642.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 640.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 410.40 MiB is allocated by PyTorch, and 375.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
251e0041,"{'temperature_head': 0.1, 'latent_dim': 545, 'batch_size': 345, 'transform_funcs': (1, 2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 262.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 184.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1024.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 790.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 572.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 490.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 379.69 MiB is allocated by PyTorch, and 70.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
59e2a91b,"{'temperature_head': 0.6000000000000001, 'latent_dim': 633, 'batch_size': 361, 'transform_funcs': (2, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 306.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 186.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1024.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 824.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.10 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 572.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 492.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 421.23 MiB is allocated by PyTorch, and 362.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
36b63ca0,"{'temperature_head': 0.4, 'latent_dim': 516, 'batch_size': 261, 'transform_funcs': (7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 122.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1024.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 824.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 618.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 474.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 116.97 MiB is allocated by PyTorch, and 17.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
360876b8,"{'temperature_head': 0.5, 'latent_dim': 717, 'batch_size': 384, 'transform_funcs': (6, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 346.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 340.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1024.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 486.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 618.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 594.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 121.30 MiB is allocated by PyTorch, and 24.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9120494a,"{'temperature_head': 0.30000000000000004, 'latent_dim': 302, 'batch_size': 419, 'transform_funcs': (5, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 108.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 1.00 GiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 630.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 702.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 596.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 263.20 MiB is allocated by PyTorch, and 26.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
56b60f65,"{'temperature_head': 0.7000000000000001, 'latent_dim': 371, 'batch_size': 337, 'transform_funcs': (1, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 110.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 930.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 666.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 702.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 654.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 294.09 MiB is allocated by PyTorch, and 19.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6de7386b,"{'temperature_head': 0.4, 'latent_dim': 671, 'batch_size': 295, 'transform_funcs': (1, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 302.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 668.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 666.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 672.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 754.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 118.02 MiB is allocated by PyTorch, and 209.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8b74b800,"{'temperature_head': 0.6000000000000001, 'latent_dim': 156, 'batch_size': 311, 'transform_funcs': (0, 1, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 668.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 770.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 754.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 188.46 MiB is allocated by PyTorch, and 139.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a0bcc75b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 245, 'batch_size': 327, 'transform_funcs': (0, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 110.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 704.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 688.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 754.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 233.63 MiB is allocated by PyTorch, and 114.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
254c0370,"{'temperature_head': 0.7000000000000001, 'latent_dim': 481, 'batch_size': 253, 'transform_funcs': (0, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 232.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 704.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 726.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 772.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 347.74 MiB is allocated by PyTorch, and 84.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
00b3dfd9,"{'temperature_head': 0.30000000000000004, 'latent_dim': 285, 'batch_size': 349, 'transform_funcs': (4, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 804.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 930.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 474.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 115.09 MiB is allocated by PyTorch, and 18.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
347e3460,"{'temperature_head': 0.9, 'latent_dim': 84, 'batch_size': 401, 'transform_funcs': (6, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 804.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 930.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 516.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 153.90 MiB is allocated by PyTorch, and 22.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5eb58043,"{'temperature_head': 0.5, 'latent_dim': 68, 'batch_size': 203, 'transform_funcs': (0, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 806.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 966.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 470.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 113.40 MiB is allocated by PyTorch, and 16.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6a7d0cd4,"{'temperature_head': 0.7000000000000001, 'latent_dim': 49, 'batch_size': 322, 'transform_funcs': (4, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 806.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 966.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 470.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 113.25 MiB is allocated by PyTorch, and 16.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ee9e8c00,"{'temperature_head': 0.30000000000000004, 'latent_dim': 129, 'batch_size': 417, 'transform_funcs': (2, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 806.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 966.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 472.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 113.87 MiB is allocated by PyTorch, and 18.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e85738a0,"{'temperature_head': 0.5, 'latent_dim': 40, 'batch_size': 288, 'transform_funcs': (1, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 806.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 966.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 470.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 113.18 MiB is allocated by PyTorch, and 16.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3fcac141,"{'temperature_head': 0.7000000000000001, 'latent_dim': 75, 'batch_size': 377, 'transform_funcs': (5, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 806.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 966.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 470.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 113.45 MiB is allocated by PyTorch, and 16.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2af54a23,"{'temperature_head': 0.5, 'latent_dim': 55, 'batch_size': 392, 'transform_funcs': (1, 2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 806.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 966.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 470.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 113.29 MiB is allocated by PyTorch, and 16.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
45100ff9,"{'temperature_head': 0.4, 'latent_dim': 39, 'batch_size': 271, 'transform_funcs': (0, 1, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 806.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 970.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 472.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 113.17 MiB is allocated by PyTorch, and 18.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a1cd6218,"{'temperature_head': 0.7000000000000001, 'latent_dim': 502, 'batch_size': 387, 'transform_funcs': (0, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 112.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 808.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 888.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 446.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 359.17 MiB is allocated by PyTorch, and 188.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f245c6eb,"{'temperature_head': 0.5, 'latent_dim': 160, 'batch_size': 249, 'transform_funcs': (2, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 808.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 920.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 470.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 114.12 MiB is allocated by PyTorch, and 15.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0e423653,"{'temperature_head': 0.6000000000000001, 'latent_dim': 468, 'batch_size': 370, 'transform_funcs': (1, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 794.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 920.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 508.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 340.86 MiB is allocated by PyTorch, and 113.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9e9387fd,"{'temperature_head': 0.30000000000000004, 'latent_dim': 267, 'batch_size': 218, 'transform_funcs': (0, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 126.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 606.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 920.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 602.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 243.29 MiB is allocated by PyTorch, and 18.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8d449f5d,"{'temperature_head': 0.5, 'latent_dim': 200, 'batch_size': 129, 'transform_funcs': (1, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 96.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 600.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 920.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 638.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 209.95 MiB is allocated by PyTorch, and 50.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
49006cb2,"{'temperature_head': 0.7000000000000001, 'latent_dim': 340, 'batch_size': 166, 'transform_funcs': (0, 1, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 140.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 636.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 920.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 558.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 114.64 MiB is allocated by PyTorch, and 103.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4c3aba12,"{'temperature_head': 0.7000000000000001, 'latent_dim': 315, 'batch_size': 378, 'transform_funcs': (3, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 638.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 920.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 624.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 267.33 MiB is allocated by PyTorch, and 16.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b06abc4b,"{'temperature_head': 0.1, 'latent_dim': 131, 'batch_size': 352, 'transform_funcs': (2, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 616.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 922.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 660.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 176.25 MiB is allocated by PyTorch, and 99.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2a6a3d62,"{'temperature_head': 0.8, 'latent_dim': 559, 'batch_size': 312, 'transform_funcs': (2, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 270.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 654.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 908.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 804.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 674.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 386.49 MiB is allocated by PyTorch, and 181.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7d0bca98,"{'temperature_head': 0.5, 'latent_dim': 33, 'batch_size': 294, 'transform_funcs': (3, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 424.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 840.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 812.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 67.46 MiB is allocated by PyTorch, and 16.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d41836b4,"{'temperature_head': 0.30000000000000004, 'latent_dim': 28, 'batch_size': 381, 'transform_funcs': (0, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 426.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 840.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 800.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 812.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 67.42 MiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7887e4e8,"{'temperature_head': 0.6000000000000001, 'latent_dim': 87, 'batch_size': 315, 'transform_funcs': (2, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 424.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 840.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 802.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 812.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 67.88 MiB is allocated by PyTorch, and 16.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4477e5ea,"{'temperature_head': 0.5, 'latent_dim': 108, 'batch_size': 196, 'transform_funcs': (0, 2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 470.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 840.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 768.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 812.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 114.05 MiB is allocated by PyTorch, and 15.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
65a3d436,"{'temperature_head': 0.30000000000000004, 'latent_dim': 43, 'batch_size': 287, 'transform_funcs': (7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 426.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 840.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 804.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 814.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 67.54 MiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c10a8620,"{'temperature_head': 0.4, 'latent_dim': 534, 'batch_size': 370, 'transform_funcs': (4, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 444.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 840.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 804.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 778.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 373.62 MiB is allocated by PyTorch, and 64.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7d4cfcd2,"{'temperature_head': 0.6000000000000001, 'latent_dim': 121, 'batch_size': 306, 'transform_funcs': (5, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 424.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 840.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 804.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 68.15 MiB is allocated by PyTorch, and 15.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
73f90ae6,"{'temperature_head': 0.30000000000000004, 'latent_dim': 36, 'batch_size': 377, 'transform_funcs': (1, 3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 424.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 840.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 804.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 67.48 MiB is allocated by PyTorch, and 16.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7ce91b62,"{'temperature_head': 0.4, 'latent_dim': 435, 'batch_size': 358, 'transform_funcs': (0, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 440.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 840.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 804.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 82.34 MiB is allocated by PyTorch, and 17.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
0bddf8ab,"{'temperature_head': 0.7000000000000001, 'latent_dim': 70, 'batch_size': 318, 'transform_funcs': (2, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 422.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 840.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 804.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 67.75 MiB is allocated by PyTorch, and 14.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
16065880,"{'temperature_head': 0.6000000000000001, 'latent_dim': 132, 'batch_size': 243, 'transform_funcs': (0, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 472.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 840.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 770.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 114.23 MiB is allocated by PyTorch, and 17.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
75949997,"{'temperature_head': 0.6000000000000001, 'latent_dim': 62, 'batch_size': 351, 'transform_funcs': (1, 3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 468.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 840.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 770.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 113.69 MiB is allocated by PyTorch, and 14.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8de250b6,"{'temperature_head': 0.5, 'latent_dim': 622, 'batch_size': 309, 'transform_funcs': (4, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 472.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 840.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 770.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 118.37 MiB is allocated by PyTorch, and 13.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1a8f0805,"{'temperature_head': 0.4, 'latent_dim': 35, 'batch_size': 232, 'transform_funcs': (0, 1, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 424.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 840.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 806.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 67.48 MiB is allocated by PyTorch, and 16.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8f43fa87,"{'temperature_head': 0.6000000000000001, 'latent_dim': 699, 'batch_size': 395, 'transform_funcs': (5, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 446.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 840.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 806.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 101.42 MiB is allocated by PyTorch, and 4.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
8a6eefcd,"{'temperature_head': 0.30000000000000004, 'latent_dim': 2, 'batch_size': 338, 'transform_funcs': (2, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 424.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 840.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 806.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 67.22 MiB is allocated by PyTorch, and 16.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
92f69850,"{'temperature_head': 0.5, 'latent_dim': 120, 'batch_size': 354, 'transform_funcs': (2, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 424.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 844.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 806.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 68.14 MiB is allocated by PyTorch, and 15.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1d2a5cd8,"{'temperature_head': 0.6000000000000001, 'latent_dim': 14, 'batch_size': 258, 'transform_funcs': (0, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 426.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 852.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 806.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 67.31 MiB is allocated by PyTorch, and 18.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
35acd780,"{'temperature_head': 0.7000000000000001, 'latent_dim': 147, 'batch_size': 189, 'transform_funcs': (1, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 426.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 852.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 806.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 68.35 MiB is allocated by PyTorch, and 17.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
eae37cca,"{'temperature_head': 0.4, 'latent_dim': 30, 'batch_size': 328, 'transform_funcs': (4, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 426.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 852.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 806.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 67.44 MiB is allocated by PyTorch, and 18.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b448cc4a,"{'temperature_head': 0.6000000000000001, 'latent_dim': 3, 'batch_size': 346, 'transform_funcs': (0, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 424.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 852.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 806.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 67.23 MiB is allocated by PyTorch, and 16.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3c764b37,"{'temperature_head': 0.30000000000000004, 'latent_dim': 19, 'batch_size': 414, 'transform_funcs': (0, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 426.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 852.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 806.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 67.35 MiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c33a527a,"{'temperature_head': 0.5, 'latent_dim': 92, 'batch_size': 339, 'transform_funcs': (0, 1, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 414.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 880.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 806.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 47.06 MiB is allocated by PyTorch, and 26.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/dataset_simcrl.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
2d667743,"{'temperature_head': 0.8, 'latent_dim': 362, 'batch_size': 403, 'transform_funcs': (6, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 628.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 658.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 806.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 291.67 MiB is allocated by PyTorch, and 26.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
46632fc0,"{'temperature_head': 0.4, 'latent_dim': 300, 'batch_size': 324, 'transform_funcs': (0, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 88.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 668.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 574.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 806.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 780.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 258.52 MiB is allocated by PyTorch, and 181.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6d36d997,"{'temperature_head': 0.6000000000000001, 'latent_dim': 407, 'batch_size': 372, 'transform_funcs': (0, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 176.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 544.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 574.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 806.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 115.44 MiB is allocated by PyTorch, and 88.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d0f6292c,"{'temperature_head': 0.6000000000000001, 'latent_dim': 659, 'batch_size': 433, 'transform_funcs': (3, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 318.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 206.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 514.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 574.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 806.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 119.03 MiB is allocated by PyTorch, and 54.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d155f4cf,"{'temperature_head': 0.8, 'latent_dim': 154, 'batch_size': 424, 'transform_funcs': (2, 3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 4088258 has 1.09 GiB memory in use. Process 4088273 has 1.24 GiB memory in use. Process 4088254 has 678.00 MiB memory in use. Process 4088240 has 758.00 MiB memory in use. Process 4088256 has 1.14 GiB memory in use. Process 4091487 has 568.00 MiB memory in use. Process 4091492 has 990.00 MiB memory in use. Process 4091488 has 644.00 MiB memory in use. Process 4091482 has 1.02 GiB memory in use. Process 4091491 has 806.00 MiB memory in use. Process 4091876 has 886.00 MiB memory in use. Process 4091881 has 820.00 MiB memory in use. Process 4091870 has 1.13 GiB memory in use. Process 4091875 has 908.00 MiB memory in use. Process 4091882 has 910.00 MiB memory in use. Process 4092264 has 734.00 MiB memory in use. Process 4092273 has 1.03 GiB memory in use. Process 4092270 has 1.17 GiB memory in use. Process 4092267 has 1.29 GiB memory in use. Process 4092263 has 938.00 MiB memory in use. Process 4092652 has 752.00 MiB memory in use. Process 4092722 has 816.00 MiB memory in use. Process 4092697 has 1006.00 MiB memory in use. Process 4092696 has 1.04 GiB memory in use. Process 4092655 has 932.00 MiB memory in use. Of the allocated memory 189.60 MiB is allocated by PyTorch, and 38.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
