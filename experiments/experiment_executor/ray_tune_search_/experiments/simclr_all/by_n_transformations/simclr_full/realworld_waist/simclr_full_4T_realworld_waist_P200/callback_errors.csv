trial_id,config,error_type,error_message,error_traceback
7304c705,"{'temperature_head': 0.8, 'latent_dim': 683, 'batch_size': 459, 'transform_funcs': (2, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 404.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 156.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.14 GiB memory in use. Process 110622 has 1.01 GiB memory in use. Process 110650 has 960.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 768.00 MiB memory in use. Process 113906 has 776.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 912.00 MiB memory in use. Process 113909 has 672.00 MiB memory in use. Process 114323 has 1.00 GiB memory in use. Process 114327 has 766.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 684.00 MiB memory in use. Process 114324 has 1.47 GiB memory in use. Process 114709 has 880.00 MiB memory in use. Process 114710 has 926.00 MiB memory in use. Process 114711 has 768.00 MiB memory in use. Process 114717 has 1.07 GiB memory in use. Process 114714 has 686.00 MiB memory in use. Process 115104 has 970.00 MiB memory in use. Process 115097 has 960.00 MiB memory in use. Process 115103 has 884.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 672.00 MiB memory in use. Of the allocated memory 543.39 MiB is allocated by PyTorch, and 30.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5905de5c,"{'temperature_head': 0.8, 'latent_dim': 659, 'batch_size': 487, 'transform_funcs': (0, 1, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 390.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 306.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 954.00 MiB memory in use. Process 110650 has 800.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 676.00 MiB memory in use. Process 113906 has 748.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 856.00 MiB memory in use. Process 113909 has 672.00 MiB memory in use. Process 114323 has 1.00 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 684.00 MiB memory in use. Process 114324 has 1.47 GiB memory in use. Process 114709 has 880.00 MiB memory in use. Process 114710 has 926.00 MiB memory in use. Process 114711 has 768.00 MiB memory in use. Process 114717 has 900.00 MiB memory in use. Process 114714 has 686.00 MiB memory in use. Process 115104 has 970.00 MiB memory in use. Process 115097 has 960.00 MiB memory in use. Process 115103 has 884.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 766.00 MiB memory in use. Of the allocated memory 138.75 MiB is allocated by PyTorch, and 379.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ad6b3182,"{'temperature_head': 0.8, 'latent_dim': 663, 'batch_size': 354, 'transform_funcs': (0, 1, 3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 306.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 954.00 MiB memory in use. Process 110650 has 800.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 676.00 MiB memory in use. Process 113906 has 748.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 856.00 MiB memory in use. Process 113909 has 672.00 MiB memory in use. Process 114323 has 1.00 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 684.00 MiB memory in use. Process 114324 has 1.47 GiB memory in use. Process 114709 has 880.00 MiB memory in use. Process 114710 has 926.00 MiB memory in use. Process 114711 has 768.00 MiB memory in use. Process 114717 has 900.00 MiB memory in use. Process 114714 has 686.00 MiB memory in use. Process 115104 has 970.00 MiB memory in use. Process 115097 has 960.00 MiB memory in use. Process 115103 has 884.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 766.00 MiB memory in use. Of the allocated memory 531.76 MiB is allocated by PyTorch, and 30.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0b4d3ce7,"{'temperature_head': 0.2, 'latent_dim': 573, 'batch_size': 158, 'transform_funcs': (1, 2, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.07 GiB memory in use. Process 110650 has 844.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 926.00 MiB memory in use. Process 113906 has 794.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 902.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 928.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 796.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 886.00 MiB memory in use. Process 114710 has 926.00 MiB memory in use. Process 114711 has 668.00 MiB memory in use. Process 114717 has 1.06 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 964.00 MiB memory in use. Process 115097 has 960.00 MiB memory in use. Process 115103 has 632.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 714.00 MiB memory in use. Of the allocated memory 477.00 MiB is allocated by PyTorch, and 149.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
295f9972,"{'temperature_head': 0.1, 'latent_dim': 483, 'batch_size': 329, 'transform_funcs': (1, 4, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 286.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 124.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 872.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 928.00 MiB memory in use. Process 113906 has 794.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 902.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 850.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 796.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 978.00 MiB memory in use. Process 114710 has 452.00 MiB memory in use. Process 114711 has 698.00 MiB memory in use. Process 114717 has 1.11 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 798.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 732.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 423.62 MiB is allocated by PyTorch, and 36.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7e95a5d3,"{'temperature_head': 0.1, 'latent_dim': 410, 'batch_size': 418, 'transform_funcs': (0, 1, 3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 110.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 918.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1002.00 MiB memory in use. Process 113906 has 794.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 902.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 850.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 796.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 978.00 MiB memory in use. Process 114710 has 754.00 MiB memory in use. Process 114711 has 560.00 MiB memory in use. Process 114717 has 1.11 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 510.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 746.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 137.05 MiB is allocated by PyTorch, and 34.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
48efbc80,"{'temperature_head': 0.4, 'latent_dim': 400, 'batch_size': 254, 'transform_funcs': (0, 6, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 152.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 744.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1002.00 MiB memory in use. Process 113906 has 794.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.01 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 850.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 796.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 978.00 MiB memory in use. Process 114710 has 754.00 MiB memory in use. Process 114711 has 560.00 MiB memory in use. Process 114717 has 1.06 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 746.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 372.95 MiB is allocated by PyTorch, and 379.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a607c9b2,"{'temperature_head': 0.30000000000000004, 'latent_dim': 479, 'batch_size': 201, 'transform_funcs': (0, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 276.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 890.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 794.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.01 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.05 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 796.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 1022.00 MiB memory in use. Process 114710 has 754.00 MiB memory in use. Process 114711 has 606.00 MiB memory in use. Process 114717 has 452.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 792.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 137.59 MiB is allocated by PyTorch, and 36.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
74afae4b,"{'temperature_head': 0.1, 'latent_dim': 166, 'batch_size': 317, 'transform_funcs': (2, 4, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 890.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 794.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.01 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.05 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 796.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 1022.00 MiB memory in use. Process 114710 has 800.00 MiB memory in use. Process 114711 has 606.00 MiB memory in use. Process 114717 has 608.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 792.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 233.28 MiB is allocated by PyTorch, and 36.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f1fbf79c,"{'temperature_head': 0.6000000000000001, 'latent_dim': 249, 'batch_size': 264, 'transform_funcs': (0, 1, 2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 890.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 794.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.01 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.05 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 796.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 1022.00 MiB memory in use. Process 114710 has 800.00 MiB memory in use. Process 114711 has 606.00 MiB memory in use. Process 114717 has 470.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 658.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 792.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 283.79 MiB is allocated by PyTorch, and 36.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c8afd649,"{'temperature_head': 0.4, 'latent_dim': 303, 'batch_size': 438, 'transform_funcs': (5, 6, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 890.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 794.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.01 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.05 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 796.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 1022.00 MiB memory in use. Process 114710 has 800.00 MiB memory in use. Process 114711 has 606.00 MiB memory in use. Process 114717 has 456.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 704.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 792.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 80.21 MiB is allocated by PyTorch, and 37.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
66c7396a,"{'temperature_head': 0.7000000000000001, 'latent_dim': 27, 'batch_size': 312, 'transform_funcs': (0, 1, 3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 934.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 806.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 496.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.05 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 1.00 GiB memory in use. Process 114710 has 960.00 MiB memory in use. Process 114711 has 608.00 MiB memory in use. Process 114717 has 506.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 704.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 134.05 MiB is allocated by PyTorch, and 33.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
79ae445c,"{'temperature_head': 0.30000000000000004, 'latent_dim': 198, 'batch_size': 205, 'transform_funcs': (1, 5, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 116.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 936.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 806.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 498.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.05 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 1.00 GiB memory in use. Process 114710 has 960.00 MiB memory in use. Process 114711 has 608.00 MiB memory in use. Process 114717 has 498.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 602.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 134.89 MiB is allocated by PyTorch, and 129.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9d293274,"{'temperature_head': 0.2, 'latent_dim': 404, 'batch_size': 505, 'transform_funcs': (2, 4, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 190.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 936.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 806.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.05 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 1.01 GiB memory in use. Process 114710 has 960.00 MiB memory in use. Process 114711 has 608.00 MiB memory in use. Process 114717 has 534.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 470.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 137.00 MiB is allocated by PyTorch, and 39.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e7b33a80,"{'temperature_head': 0.4, 'latent_dim': 458, 'batch_size': 451, 'transform_funcs': (2, 5, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 210.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 936.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 806.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.05 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 1.01 GiB memory in use. Process 114710 has 960.00 MiB memory in use. Process 114711 has 608.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 470.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 137.43 MiB is allocated by PyTorch, and 38.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3c9d089f,"{'temperature_head': 0.30000000000000004, 'latent_dim': 309, 'batch_size': 385, 'transform_funcs': (5, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 950.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 854.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 558.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.05 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 1.01 GiB memory in use. Process 114710 has 960.00 MiB memory in use. Process 114711 has 608.00 MiB memory in use. Process 114717 has 556.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 506.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 136.26 MiB is allocated by PyTorch, and 31.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
068bed10,"{'temperature_head': 0.6000000000000001, 'latent_dim': 74, 'batch_size': 348, 'transform_funcs': (0, 1, 3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 950.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 854.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 558.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.05 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 1.01 GiB memory in use. Process 114710 has 960.00 MiB memory in use. Process 114711 has 608.00 MiB memory in use. Process 114717 has 564.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 506.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 178.17 MiB is allocated by PyTorch, and 47.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fe504b30,"{'temperature_head': 0.2, 'latent_dim': 169, 'batch_size': 222, 'transform_funcs': (1, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 950.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 854.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 508.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.05 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 1.01 GiB memory in use. Process 114710 has 960.00 MiB memory in use. Process 114711 has 616.00 MiB memory in use. Process 114717 has 614.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 452.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 135.17 MiB is allocated by PyTorch, and 34.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a5012e91,"{'temperature_head': 0.4, 'latent_dim': 281, 'batch_size': 190, 'transform_funcs': (1, 2, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 120.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 950.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 854.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 554.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.05 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 1.01 GiB memory in use. Process 114710 has 960.00 MiB memory in use. Process 114711 has 616.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 452.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 136.04 MiB is allocated by PyTorch, and 37.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2c9c39e4,"{'temperature_head': 0.1, 'latent_dim': 221, 'batch_size': 284, 'transform_funcs': (1, 5, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 950.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 854.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 554.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.05 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 1.01 GiB memory in use. Process 114710 has 960.00 MiB memory in use. Process 114711 has 616.00 MiB memory in use. Process 114717 has 556.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 510.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 135.57 MiB is allocated by PyTorch, and 36.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a817ff5b,"{'temperature_head': 0.7000000000000001, 'latent_dim': 238, 'batch_size': 267, 'transform_funcs': (4, 7, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 84.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 950.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 854.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 596.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.05 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 1.01 GiB memory in use. Process 114710 has 960.00 MiB memory in use. Process 114711 has 450.00 MiB memory in use. Process 114717 has 650.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 474.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 276.41 MiB is allocated by PyTorch, and 35.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b960d6ea,"{'temperature_head': 0.2, 'latent_dim': 335, 'batch_size': 303, 'transform_funcs': (1, 4, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 994.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 854.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 610.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 990.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 452.00 MiB memory in use. Process 114710 has 960.00 MiB memory in use. Process 114711 has 848.00 MiB memory in use. Process 114717 has 700.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 712.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 334.52 MiB is allocated by PyTorch, and 39.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a8a759db,"{'temperature_head': 1.0, 'latent_dim': 373, 'batch_size': 462, 'transform_funcs': (5, 6, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.41 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 994.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 854.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 990.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 470.00 MiB memory in use. Process 114710 has 960.00 MiB memory in use. Process 114711 has 848.00 MiB memory in use. Process 114717 has 700.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 756.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.24 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 136.76 MiB is allocated by PyTorch, and 37.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
24d47cff,"{'temperature_head': 0.1, 'latent_dim': 557, 'batch_size': 135, 'transform_funcs': (1, 2, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 330.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 228.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.06 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 994.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 854.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 476.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 990.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 730.00 MiB memory in use. Process 114710 has 960.00 MiB memory in use. Process 114711 has 850.00 MiB memory in use. Process 114717 has 926.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 756.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 996.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 467.69 MiB is allocated by PyTorch, and 120.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
52dcaef0,"{'temperature_head': 0.2, 'latent_dim': 528, 'batch_size': 419, 'transform_funcs': (1, 2, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.06 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 994.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 854.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 476.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 990.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 730.00 MiB memory in use. Process 114710 has 960.00 MiB memory in use. Process 114711 has 850.00 MiB memory in use. Process 114717 has 926.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 968.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 996.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 449.64 MiB is allocated by PyTorch, and 180.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1f55958f,"{'temperature_head': 0.7000000000000001, 'latent_dim': 511, 'batch_size': 364, 'transform_funcs': (3, 5, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 78.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.06 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 994.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 854.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 476.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 990.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.35 GiB memory in use. Process 114709 has 730.00 MiB memory in use. Process 114710 has 960.00 MiB memory in use. Process 114711 has 850.00 MiB memory in use. Process 114717 has 816.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1016.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 996.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 439.94 MiB is allocated by PyTorch, and 38.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c2488daa,"{'temperature_head': 0.8, 'latent_dim': 607, 'batch_size': 444, 'transform_funcs': (3, 6, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 360.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 182.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.06 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 994.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 764.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 854.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 476.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 990.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.25 GiB memory in use. Process 114709 has 730.00 MiB memory in use. Process 114710 has 960.00 MiB memory in use. Process 114711 has 850.00 MiB memory in use. Process 114717 has 816.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1016.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 996.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 497.49 MiB is allocated by PyTorch, and 444.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
610949ff,"{'temperature_head': 0.1, 'latent_dim': 356, 'batch_size': 147, 'transform_funcs': (2, 5, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.06 GiB memory in use. Process 110622 has 1.12 GiB memory in use. Process 110650 has 994.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 656.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 854.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 452.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.01 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 732.00 MiB memory in use. Process 114710 has 960.00 MiB memory in use. Process 114711 has 850.00 MiB memory in use. Process 114717 has 982.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1016.00 MiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 996.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 80.63 MiB is allocated by PyTorch, and 33.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ffdc9a43,"{'temperature_head': 0.2, 'latent_dim': 653, 'batch_size': 490, 'transform_funcs': (4, 8, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.06 GiB memory in use. Process 110622 has 1.14 GiB memory in use. Process 110650 has 994.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 700.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 854.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 444.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.01 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 728.00 MiB memory in use. Process 114710 has 962.00 MiB memory in use. Process 114711 has 850.00 MiB memory in use. Process 114717 has 982.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.49 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 438.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 51.42 MiB is allocated by PyTorch, and 54.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cd3d09df,"{'temperature_head': 1.0, 'latent_dim': 426, 'batch_size': 160, 'transform_funcs': (1, 4, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 112.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.14 GiB memory in use. Process 110650 has 994.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 702.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 854.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 490.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.01 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 728.00 MiB memory in use. Process 114710 has 954.00 MiB memory in use. Process 114711 has 850.00 MiB memory in use. Process 114717 has 982.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.49 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 910.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 137.18 MiB is allocated by PyTorch, and 36.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
329bdf7b,"{'temperature_head': 0.1, 'latent_dim': 332, 'batch_size': 335, 'transform_funcs': (2, 6, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 556.00 MiB memory in use. Process 110622 has 1.14 GiB memory in use. Process 110650 has 994.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 702.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 854.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 456.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.01 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 728.00 MiB memory in use. Process 114710 has 954.00 MiB memory in use. Process 114711 has 850.00 MiB memory in use. Process 114717 has 1.00 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.49 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 910.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 80.44 MiB is allocated by PyTorch, and 37.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6ba7f45d,"{'temperature_head': 0.2, 'latent_dim': 711, 'batch_size': 404, 'transform_funcs': (3, 6, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 422.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 208.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 508.00 MiB memory in use. Process 110622 has 1.14 GiB memory in use. Process 110650 has 950.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 702.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 854.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 500.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.01 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 776.00 MiB memory in use. Process 114710 has 954.00 MiB memory in use. Process 114711 has 742.00 MiB memory in use. Process 114717 has 984.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.49 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 910.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 139.41 MiB is allocated by PyTorch, and 30.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2f1009b7,"{'temperature_head': 0.30000000000000004, 'latent_dim': 328, 'batch_size': 247, 'transform_funcs': (1, 2, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1014.00 MiB memory in use. Process 110622 has 648.00 MiB memory in use. Process 110650 has 996.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 786.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 730.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.01 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 1.15 GiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 744.00 MiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 982.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 954.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 329.82 MiB is allocated by PyTorch, and 314.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f70cb12b,"{'temperature_head': 0.6000000000000001, 'latent_dim': 83, 'batch_size': 275, 'transform_funcs': (0, 4, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 786.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 732.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.01 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 992.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 792.00 MiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 452.00 MiB memory in use. Process 114717 has 510.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 956.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 134.49 MiB is allocated by PyTorch, and 35.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c3f77bc5,"{'temperature_head': 0.1, 'latent_dim': 233, 'batch_size': 190, 'transform_funcs': (1, 5, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 138.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 112.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 786.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 650.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.01 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 992.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 792.00 MiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 452.00 MiB memory in use. Process 114717 has 454.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1014.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 273.16 MiB is allocated by PyTorch, and 38.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6a9731e5,"{'temperature_head': 0.4, 'latent_dim': 184, 'batch_size': 196, 'transform_funcs': (1, 2, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 786.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 702.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.01 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 992.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 452.00 MiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 554.00 MiB memory in use. Process 114717 has 748.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1014.00 MiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 243.56 MiB is allocated by PyTorch, and 120.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f9492793,"{'temperature_head': 0.2, 'latent_dim': 150, 'batch_size': 152, 'transform_funcs': (0, 2, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 696.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 598.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.01 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 748.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 223.70 MiB is allocated by PyTorch, and 36.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b53fa0e2,"{'temperature_head': 0.1, 'latent_dim': 41, 'batch_size': 138, 'transform_funcs': (0, 6, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 696.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 810.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.01 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 562.00 MiB memory in use. Process 114717 has 432.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 61.93 MiB is allocated by PyTorch, and 30.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/dataset_simcrl.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
87f71519,"{'temperature_head': 0.30000000000000004, 'latent_dim': 492, 'batch_size': 128, 'transform_funcs': (1, 7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 742.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 810.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 826.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 544.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 656.00 MiB memory in use. Process 114717 has 460.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 81.69 MiB is allocated by PyTorch, and 38.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e3fb6c0a,"{'temperature_head': 0.6000000000000001, 'latent_dim': 213, 'batch_size': 278, 'transform_funcs': (0, 4, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 742.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 810.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 826.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 656.00 MiB memory in use. Process 114717 has 456.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 79.51 MiB is allocated by PyTorch, and 36.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
906b72d0,"{'temperature_head': 0.1, 'latent_dim': 538, 'batch_size': 211, 'transform_funcs': (1, 3, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 320.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 104.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 856.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 770.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 556.00 MiB memory in use. Process 114717 has 510.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 138.05 MiB is allocated by PyTorch, and 31.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
167ef713,"{'temperature_head': 0.5, 'latent_dim': 288, 'batch_size': 169, 'transform_funcs': (0, 3, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 156.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 856.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 816.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 452.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 136.10 MiB is allocated by PyTorch, and 37.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7672fa2b,"{'temperature_head': 0.9, 'latent_dim': 309, 'batch_size': 437, 'transform_funcs': (2, 3, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 76.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 788.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 816.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 554.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 318.44 MiB is allocated by PyTorch, and 131.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
03bb75a9,"{'temperature_head': 0.8, 'latent_dim': 448, 'batch_size': 461, 'transform_funcs': (3, 5, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 124.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 788.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 816.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 554.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 137.35 MiB is allocated by PyTorch, and 34.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5b9a04a9,"{'temperature_head': 0.7000000000000001, 'latent_dim': 364, 'batch_size': 509, 'transform_funcs': (3, 7, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 896.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 806.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 556.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 136.69 MiB is allocated by PyTorch, and 39.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7ebdc6ce,"{'temperature_head': 0.6000000000000001, 'latent_dim': 383, 'batch_size': 358, 'transform_funcs': (0, 2, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 896.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 806.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 556.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 136.84 MiB is allocated by PyTorch, and 35.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ddb647c1,"{'temperature_head': 0.8, 'latent_dim': 411, 'batch_size': 376, 'transform_funcs': (6, 8, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 558.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 896.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 806.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 610.00 MiB memory in use. Process 114717 has 440.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 48.58 MiB is allocated by PyTorch, and 51.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a9222a79,"{'temperature_head': 0.5, 'latent_dim': 397, 'batch_size': 477, 'transform_funcs': (1, 5, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 236.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 80.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 516.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 896.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 806.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 610.00 MiB memory in use. Process 114717 has 440.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 946.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 136.95 MiB is allocated by PyTorch, and 41.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
024caf7d,"{'temperature_head': 0.4, 'latent_dim': 315, 'batch_size': 415, 'transform_funcs': (0, 2, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.20 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 556.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 896.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 806.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 666.00 MiB memory in use. Process 114717 has 518.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 834.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 136.31 MiB is allocated by PyTorch, and 41.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9930a710,"{'temperature_head': 0.5, 'latent_dim': 500, 'batch_size': 199, 'transform_funcs': (3, 8, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 510.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 996.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.12 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 854.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 666.00 MiB memory in use. Process 114717 has 508.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 834.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 137.75 MiB is allocated by PyTorch, and 34.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2184c88c,"{'temperature_head': 0.2, 'latent_dim': 638, 'batch_size': 259, 'transform_funcs': (2, 3, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 378.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 112.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 508.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 996.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.12 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 750.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 666.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 834.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 139.79 MiB is allocated by PyTorch, and 32.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c554c0b9,"{'temperature_head': 0.2, 'latent_dim': 565, 'batch_size': 406, 'transform_funcs': (0, 4, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 516.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 996.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.12 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 750.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 654.00 MiB memory in use. Process 114717 has 562.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 880.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 138.95 MiB is allocated by PyTorch, and 39.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bc534711,"{'temperature_head': 0.30000000000000004, 'latent_dim': 463, 'batch_size': 291, 'transform_funcs': (0, 4, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 86.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 496.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 996.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.12 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 750.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 654.00 MiB memory in use. Process 114717 has 516.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 880.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 137.46 MiB is allocated by PyTorch, and 38.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9ca6912b,"{'temperature_head': 0.4, 'latent_dim': 416, 'batch_size': 154, 'transform_funcs': (0, 1, 2, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1000.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.12 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 750.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 654.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 880.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 137.10 MiB is allocated by PyTorch, and 36.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c2128f46,"{'temperature_head': 0.6000000000000001, 'latent_dim': 435, 'batch_size': 161, 'transform_funcs': (1, 2, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 232.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 770.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.12 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 750.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 674.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 880.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 395.25 MiB is allocated by PyTorch, and 34.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f71d5fd2,"{'temperature_head': 0.2, 'latent_dim': 527, 'batch_size': 144, 'transform_funcs': (1, 2, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 312.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 116.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 556.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 818.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.12 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 794.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.25 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 880.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 449.02 MiB is allocated by PyTorch, and 492.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4dbf2e7e,"{'temperature_head': 0.4, 'latent_dim': 427, 'batch_size': 181, 'transform_funcs': (0, 6, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 148.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 558.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 818.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.12 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 794.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.26 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 880.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 137.18 MiB is allocated by PyTorch, and 34.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
eebedc9c,"{'temperature_head': 0.30000000000000004, 'latent_dim': 471, 'batch_size': 205, 'transform_funcs': (0, 3, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 166.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 558.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 716.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.12 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 794.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 880.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 137.02 MiB is allocated by PyTorch, and 238.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3b3e5ead,"{'temperature_head': 0.5, 'latent_dim': 326, 'batch_size': 326, 'transform_funcs': (3, 7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 168.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 558.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 760.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.12 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 794.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 880.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 136.39 MiB is allocated by PyTorch, and 37.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f337298e,"{'temperature_head': 0.30000000000000004, 'latent_dim': 583, 'batch_size': 129, 'transform_funcs': (0, 8, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 346.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 172.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 510.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 760.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.12 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 794.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 880.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 138.40 MiB is allocated by PyTorch, and 33.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f3e470c6,"{'temperature_head': 0.1, 'latent_dim': 134, 'batch_size': 351, 'transform_funcs': (0, 1, 2, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 826.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.12 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 796.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 594.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 880.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 214.89 MiB is allocated by PyTorch, and 39.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
eadfdfdb,"{'temperature_head': 0.1, 'latent_dim': 446, 'batch_size': 138, 'transform_funcs': (0, 1, 2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 158.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 514.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 826.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.12 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 796.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 500.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 880.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 716.00 MiB memory in use. Of the allocated memory 137.33 MiB is allocated by PyTorch, and 38.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4c862c80,"{'temperature_head': 0.30000000000000004, 'latent_dim': 509, 'batch_size': 243, 'transform_funcs': (0, 4, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 302.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 100.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 558.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 874.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.12 GiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 796.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 510.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 880.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 672.00 MiB memory in use. Of the allocated memory 137.82 MiB is allocated by PyTorch, and 32.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
46cf7fb4,"{'temperature_head': 0.4, 'latent_dim': 344, 'batch_size': 216, 'transform_funcs': (1, 4, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 174.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 510.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 874.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 972.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 796.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 880.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 672.00 MiB memory in use. Of the allocated memory 136.53 MiB is allocated by PyTorch, and 35.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
10f3ab2c,"{'temperature_head': 0.6000000000000001, 'latent_dim': 358, 'batch_size': 190, 'transform_funcs': (0, 3, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 174.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 556.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 874.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 972.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 796.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 880.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 672.00 MiB memory in use. Of the allocated memory 136.64 MiB is allocated by PyTorch, and 37.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7390c78f,"{'temperature_head': 0.30000000000000004, 'latent_dim': 395, 'batch_size': 286, 'transform_funcs': (0, 9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 176.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 556.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 826.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 972.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 796.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 880.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 672.00 MiB memory in use. Of the allocated memory 369.95 MiB is allocated by PyTorch, and 116.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
473d872b,"{'temperature_head': 0.2, 'latent_dim': 214, 'batch_size': 445, 'transform_funcs': (1, 6, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 636.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 874.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 972.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 796.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 880.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 718.00 MiB memory in use. Of the allocated memory 262.03 MiB is allocated by PyTorch, and 35.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c47c1074,"{'temperature_head': 0.2, 'latent_dim': 266, 'batch_size': 432, 'transform_funcs': (2, 4, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 506.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.01 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 972.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 796.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 714.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 718.00 MiB memory in use. Of the allocated memory 135.92 MiB is allocated by PyTorch, and 32.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2c5c0a02,"{'temperature_head': 0.4, 'latent_dim': 161, 'batch_size': 385, 'transform_funcs': (1, 4, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 658.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 724.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 918.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 672.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.10 MiB is allocated by PyTorch, and 38.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6ed4724c,"{'temperature_head': 0.30000000000000004, 'latent_dim': 713, 'batch_size': 360, 'transform_funcs': (0, 5, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 422.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 76.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 658.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 724.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 918.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 672.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 140.03 MiB is allocated by PyTorch, and 31.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
978aefc5,"{'temperature_head': 0.30000000000000004, 'latent_dim': 245, 'batch_size': 318, 'transform_funcs': (5, 6, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 142.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 660.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 656.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 918.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 672.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.76 MiB is allocated by PyTorch, and 36.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ef510d9b,"{'temperature_head': 0.4, 'latent_dim': 286, 'batch_size': 497, 'transform_funcs': (1, 2, 3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 678.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 560.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 702.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 918.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 672.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.53 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 306.08 MiB is allocated by PyTorch, and 31.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
572fab87,"{'temperature_head': 0.5, 'latent_dim': 328, 'batch_size': 371, 'transform_funcs': (0, 1, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 96.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 454.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 708.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 702.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 918.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 672.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.54 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 330.41 MiB is allocated by PyTorch, and 37.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ca4e645f,"{'temperature_head': 0.1, 'latent_dim': 418, 'batch_size': 184, 'transform_funcs': (6, 8, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 248.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 106.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 772.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 654.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 452.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 918.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 700.00 MiB memory in use. Process 114717 has 1022.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.54 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.61 MiB is allocated by PyTorch, and 177.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b543a5f0,"{'temperature_head': 0.2, 'latent_dim': 443, 'batch_size': 156, 'transform_funcs': (3, 4, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 262.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 828.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 654.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 452.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 918.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 700.00 MiB memory in use. Process 114717 has 1022.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.54 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 398.80 MiB is allocated by PyTorch, and 89.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
45f73c08,"{'temperature_head': 0.2, 'latent_dim': 343, 'batch_size': 297, 'transform_funcs': (6, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 454.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 698.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 694.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 918.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 1.04 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 80.53 MiB is allocated by PyTorch, and 33.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
805a5700,"{'temperature_head': 0.2, 'latent_dim': 393, 'batch_size': 218, 'transform_funcs': (0, 3, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 146.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 472.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 698.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 694.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 918.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 682.00 MiB memory in use. Process 114717 has 966.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 368.75 MiB is allocated by PyTorch, and 257.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7e96bc52,"{'temperature_head': 0.1, 'latent_dim': 318, 'batch_size': 132, 'transform_funcs': (1, 2, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 148.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 472.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 652.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 694.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 918.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 682.00 MiB memory in use. Process 114717 has 1010.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.82 MiB is allocated by PyTorch, and 176.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
424b97b1,"{'temperature_head': 0.1, 'latent_dim': 266, 'batch_size': 138, 'transform_funcs': (0, 5, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 510.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 700.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 694.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 920.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 682.00 MiB memory in use. Process 114717 has 1012.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.92 MiB is allocated by PyTorch, and 34.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c1e4d3a3,"{'temperature_head': 0.30000000000000004, 'latent_dim': 379, 'batch_size': 252, 'transform_funcs': (2, 3, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 84.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 736.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 700.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 694.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 920.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 1012.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 360.87 MiB is allocated by PyTorch, and 35.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fa5e3966,"{'temperature_head': 0.2, 'latent_dim': 544, 'batch_size': 240, 'transform_funcs': (1, 3, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 322.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 82.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 736.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 700.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 694.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 920.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.11 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 1014.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 459.59 MiB is allocated by PyTorch, and 214.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9b2292fe,"{'temperature_head': 0.1, 'latent_dim': 470, 'batch_size': 391, 'transform_funcs': (2, 6, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 278.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 80.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 780.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 930.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 694.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 920.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 472.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 415.01 MiB is allocated by PyTorch, and 174.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b496d11a,"{'temperature_head': 0.1, 'latent_dim': 288, 'batch_size': 508, 'transform_funcs': (1, 4, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 780.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 976.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 452.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 920.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 682.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 306.36 MiB is allocated by PyTorch, and 35.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7dff846c,"{'temperature_head': 0.4, 'latent_dim': 406, 'batch_size': 194, 'transform_funcs': (3, 4, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 780.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 932.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 452.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 920.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 458.00 MiB memory in use. Process 114717 has 728.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 376.54 MiB is allocated by PyTorch, and 215.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
be666aed,"{'temperature_head': 0.2, 'latent_dim': 596, 'batch_size': 208, 'transform_funcs': (3, 6, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 780.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 456.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 870.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 920.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 498.00 MiB memory in use. Process 114717 has 728.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 83.25 MiB is allocated by PyTorch, and 32.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
af65d973,"{'temperature_head': 0.1, 'latent_dim': 581, 'batch_size': 161, 'transform_funcs': (1, 2, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 112.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 782.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 498.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 870.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 920.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 500.00 MiB memory in use. Process 114717 has 624.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.54 MiB is allocated by PyTorch, and 145.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b7d92006,"{'temperature_head': 0.2, 'latent_dim': 650, 'batch_size': 234, 'transform_funcs': (6, 9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 782.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 456.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 880.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 936.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 698.00 MiB memory in use. Process 114717 has 500.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 83.20 MiB is allocated by PyTorch, and 32.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
549af6d2,"{'temperature_head': 0.30000000000000004, 'latent_dim': 567, 'batch_size': 224, 'transform_funcs': (2, 6, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 782.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 456.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 880.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 936.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 698.00 MiB memory in use. Process 114717 has 510.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.28 MiB is allocated by PyTorch, and 31.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
de7bf821,"{'temperature_head': 0.1, 'latent_dim': 517, 'batch_size': 309, 'transform_funcs': (0, 2, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 306.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 116.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 678.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 500.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 880.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 936.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.30 GiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 698.00 MiB memory in use. Process 114717 has 498.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.38 MiB is allocated by PyTorch, and 200.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
217367c5,"{'temperature_head': 0.1, 'latent_dim': 532, 'batch_size': 251, 'transform_funcs': (4, 7, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 316.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 116.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 726.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 500.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 880.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 936.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.25 GiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 698.00 MiB memory in use. Process 114717 has 498.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 452.02 MiB is allocated by PyTorch, and 491.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c5354d4d,"{'temperature_head': 0.5, 'latent_dim': 455, 'batch_size': 266, 'transform_funcs': (1, 3, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 270.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 100.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 726.00 MiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 500.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 880.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 936.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 1.25 GiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 698.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.40 MiB is allocated by PyTorch, and 36.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7070ba15,"{'temperature_head': 0.2, 'latent_dim': 504, 'batch_size': 284, 'transform_funcs': (1, 2, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 280.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 880.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 936.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 498.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 450.00 MiB memory in use. Process 114717 has 508.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.79 MiB is allocated by PyTorch, and 36.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
031a9e6c,"{'temperature_head': 0.8, 'latent_dim': 476, 'batch_size': 186, 'transform_funcs': (4, 5, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 560.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 880.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 936.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 460.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 682.00 MiB memory in use. Process 114717 has 508.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 81.57 MiB is allocated by PyTorch, and 38.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
261b77f9,"{'temperature_head': 0.6000000000000001, 'latent_dim': 516, 'batch_size': 426, 'transform_funcs': (0, 6, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 306.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 212.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 818.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 880.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 682.00 MiB memory in use. Process 114717 has 508.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 444.41 MiB is allocated by PyTorch, and 33.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
57c526a1,"{'temperature_head': 0.30000000000000004, 'latent_dim': 693, 'batch_size': 443, 'transform_funcs': (1, 6, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 410.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 114.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 864.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 926.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 520.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 682.00 MiB memory in use. Process 114717 has 508.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.26 MiB is allocated by PyTorch, and 40.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
51ec2f02,"{'temperature_head': 0.1, 'latent_dim': 557, 'batch_size': 152, 'transform_funcs': (2, 3, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 330.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 864.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 926.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 566.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 682.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.19 MiB is allocated by PyTorch, and 32.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4342bc50,"{'temperature_head': 0.4, 'latent_dim': 361, 'batch_size': 472, 'transform_funcs': (2, 4, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 864.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 568.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 730.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.67 MiB is allocated by PyTorch, and 37.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
314437cc,"{'temperature_head': 0.1, 'latent_dim': 227, 'batch_size': 291, 'transform_funcs': (1, 2, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 864.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 508.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 746.00 MiB memory in use. Process 114717 has 562.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.62 MiB is allocated by PyTorch, and 32.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3886cb1e,"{'temperature_head': 0.2, 'latent_dim': 439, 'batch_size': 381, 'transform_funcs': (0, 5, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 864.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 746.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.28 MiB is allocated by PyTorch, and 34.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3b19253b,"{'temperature_head': 0.9, 'latent_dim': 461, 'batch_size': 316, 'transform_funcs': (7, 9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 114.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 864.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 510.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 746.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.45 MiB is allocated by PyTorch, and 32.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
896b201d,"{'temperature_head': 0.5, 'latent_dim': 630, 'batch_size': 213, 'transform_funcs': (0, 2, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 374.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 360.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 866.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 450.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.77 MiB is allocated by PyTorch, and 35.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4ccb2925,"{'temperature_head': 0.1, 'latent_dim': 593, 'batch_size': 145, 'transform_funcs': (3, 4, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 352.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 94.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 420.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 508.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 450.00 MiB memory in use. Process 114717 has 562.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.36 MiB is allocated by PyTorch, and 28.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3a550083,"{'temperature_head': 0.2, 'latent_dim': 492, 'batch_size': 257, 'transform_funcs': (1, 2, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 292.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 130.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 468.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 472.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 450.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.69 MiB is allocated by PyTorch, and 36.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
116cef85,"{'temperature_head': 0.30000000000000004, 'latent_dim': 318, 'batch_size': 202, 'transform_funcs': (3, 5, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 468.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.33 MiB is allocated by PyTorch, and 35.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
25f87f64,"{'temperature_head': 0.2, 'latent_dim': 336, 'batch_size': 130, 'transform_funcs': (1, 7, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 448.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 452.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.47 MiB is allocated by PyTorch, and 37.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
259ebb5a,"{'temperature_head': 0.30000000000000004, 'latent_dim': 525, 'batch_size': 244, 'transform_funcs': (2, 4, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 496.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.95 MiB is allocated by PyTorch, and 34.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6b2a93d1,"{'temperature_head': 0.1, 'latent_dim': 248, 'batch_size': 222, 'transform_funcs': (1, 5, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 92.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 822.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 552.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 508.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 450.00 MiB memory in use. Process 114717 has 476.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.78 MiB is allocated by PyTorch, and 32.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
18b8e8ec,"{'temperature_head': 0.1, 'latent_dim': 350, 'batch_size': 157, 'transform_funcs': (1, 4, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 552.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 456.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 80.58 MiB is allocated by PyTorch, and 35.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b8ed74f5,"{'temperature_head': 0.30000000000000004, 'latent_dim': 424, 'batch_size': 333, 'transform_funcs': (1, 3, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 122.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 560.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 508.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 412.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.16 MiB is allocated by PyTorch, and 30.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f9f4fefb,"{'temperature_head': 0.7000000000000001, 'latent_dim': 259, 'batch_size': 321, 'transform_funcs': (5, 6, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 560.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 554.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 456.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 79.87 MiB is allocated by PyTorch, and 36.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0c22dff9,"{'temperature_head': 0.8, 'latent_dim': 574, 'batch_size': 139, 'transform_funcs': (2, 7, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 560.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 508.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 478.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.33 MiB is allocated by PyTorch, and 29.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
78a405c6,"{'temperature_head': 0.4, 'latent_dim': 399, 'batch_size': 129, 'transform_funcs': (2, 6, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 608.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 494.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 458.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 80.96 MiB is allocated by PyTorch, and 37.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c6a27b32,"{'temperature_head': 0.5, 'latent_dim': 454, 'batch_size': 140, 'transform_funcs': (0, 1, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 270.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 820.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 550.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 496.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 450.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.39 MiB is allocated by PyTorch, and 36.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3c797795,"{'temperature_head': 0.30000000000000004, 'latent_dim': 93, 'batch_size': 276, 'transform_funcs': (0, 4, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 820.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 926.00 MiB memory in use. Process 114324 has 496.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 646.00 MiB memory in use. Process 114717 has 452.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.57 MiB is allocated by PyTorch, and 33.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
69206621,"{'temperature_head': 0.1, 'latent_dim': 483, 'batch_size': 172, 'transform_funcs': (7, 8, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 286.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 94.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 778.00 MiB memory in use. Process 114324 has 510.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 646.00 MiB memory in use. Process 114717 has 476.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.62 MiB is allocated by PyTorch, and 32.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3ac0065e,"{'temperature_head': 0.6000000000000001, 'latent_dim': 375, 'batch_size': 148, 'transform_funcs': (1, 6, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.14 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 778.00 MiB memory in use. Process 114324 has 510.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 646.00 MiB memory in use. Process 114717 has 516.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.78 MiB is allocated by PyTorch, and 39.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7304dd98,"{'temperature_head': 0.2, 'latent_dim': 671, 'batch_size': 462, 'transform_funcs': (1, 2, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 398.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 82.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.12 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 778.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 646.00 MiB memory in use. Process 114717 has 454.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 536.41 MiB is allocated by PyTorch, and 275.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5bfed012,"{'temperature_head': 0.30000000000000004, 'latent_dim': 206, 'batch_size': 266, 'transform_funcs': (3, 4, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 512.00 MiB memory in use. Process 114325 has 778.00 MiB memory in use. Process 114324 has 558.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 418.00 MiB memory in use. Process 114717 has 634.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 257.45 MiB is allocated by PyTorch, and 36.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fc08daa4,"{'temperature_head': 0.4, 'latent_dim': 501, 'batch_size': 229, 'transform_funcs': (4, 7, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 120.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 998.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 868.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 430.00 MiB memory in use. Process 114324 has 808.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 680.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 433.95 MiB is allocated by PyTorch, and 34.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
40c483c8,"{'temperature_head': 0.9, 'latent_dim': 433, 'batch_size': 164, 'transform_funcs': (0, 3, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 952.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 950.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 454.00 MiB memory in use. Process 114324 has 516.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 670.00 MiB memory in use. Process 114717 has 732.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.23 MiB is allocated by PyTorch, and 38.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5e81342a,"{'temperature_head': 0.30000000000000004, 'latent_dim': 369, 'batch_size': 149, 'transform_funcs': (0, 5, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 220.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 78.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 952.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 950.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 454.00 MiB memory in use. Process 114325 has 432.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 672.00 MiB memory in use. Process 114717 has 732.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.73 MiB is allocated by PyTorch, and 37.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
05744f75,"{'temperature_head': 0.7000000000000001, 'latent_dim': 535, 'batch_size': 373, 'transform_funcs': (0, 2, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 318.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 452.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 472.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 656.00 MiB memory in use. Process 114717 has 852.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 453.82 MiB is allocated by PyTorch, and 58.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
51928e2a,"{'temperature_head': 0.4, 'latent_dim': 4, 'batch_size': 387, 'transform_funcs': (3, 4, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 472.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 420.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.40 MiB is allocated by PyTorch, and 34.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
63291ace,"{'temperature_head': 0.1, 'latent_dim': 597, 'batch_size': 510, 'transform_funcs': (1, 2, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 472.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 442.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 84.72 MiB is allocated by PyTorch, and 17.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/simcrl_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
42179fe0,"{'temperature_head': 0.1, 'latent_dim': 334, 'batch_size': 189, 'transform_funcs': (0, 4, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 452.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 442.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 80.46 MiB is allocated by PyTorch, and 31.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8ac1090a,"{'temperature_head': 0.2, 'latent_dim': 472, 'batch_size': 440, 'transform_funcs': (1, 6, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 506.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 408.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 462.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 53.24 MiB is allocated by PyTorch, and 14.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 22, in forward
    hidden_features_transform_1 = model(samples_transform_1)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/simcrl_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c6696aef,"{'temperature_head': 0.6000000000000001, 'latent_dim': 412, 'batch_size': 311, 'transform_funcs': (4, 5, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 506.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 408.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 446.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 85.94 MiB is allocated by PyTorch, and 20.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
f5ed6263,"{'temperature_head': 0.5, 'latent_dim': 561, 'batch_size': 248, 'transform_funcs': (2, 7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 450.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 454.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 98.01 MiB is allocated by PyTorch, and 11.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
323c0114,"{'temperature_head': 0.4, 'latent_dim': 390, 'batch_size': 328, 'transform_funcs': (3, 4, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 440.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 456.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 82.27 MiB is allocated by PyTorch, and 17.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
7191f534,"{'temperature_head': 0.1, 'latent_dim': 614, 'batch_size': 199, 'transform_funcs': (0, 6, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 442.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 456.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 97.43 MiB is allocated by PyTorch, and 4.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/simcrl_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 33, in forward
    x = self.global_max_pooling(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/pooling.py"", line 1031, in forward
    return F.adaptive_max_pool1d(input, self.output_size, self.return_indices)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/_jit_internal.py"", line 488, in fn
    return if_false(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1096, in _adaptive_max_pool1d
    return adaptive_max_pool1d_with_indices(input, output_size)[0]

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1088, in adaptive_max_pool1d_with_indices
    return torch.adaptive_max_pool1d(input, output_size)
"
685eb523,"{'temperature_head': 0.30000000000000004, 'latent_dim': 314, 'batch_size': 350, 'transform_funcs': (6, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 476.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 428.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 47.82 MiB is allocated by PyTorch, and 40.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1458fddb,"{'temperature_head': 0.30000000000000004, 'latent_dim': 348, 'batch_size': 176, 'transform_funcs': (3, 4, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 478.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 410.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 64.98 MiB is allocated by PyTorch, and 5.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/simcrl_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7007605f,"{'temperature_head': 0.2, 'latent_dim': 404, 'batch_size': 136, 'transform_funcs': (1, 2, 3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 478.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 410.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 66.71 MiB is allocated by PyTorch, and 3.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/simcrl_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4cd9a9d2,"{'temperature_head': 0.1, 'latent_dim': 259, 'batch_size': 395, 'transform_funcs': (4, 6, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 478.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 428.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 73.90 MiB is allocated by PyTorch, and 14.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 48, in calculate_loss
    loss = entropy_function(logits, targets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py"", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
"
369ddf96,"{'temperature_head': 0.4, 'latent_dim': 444, 'batch_size': 262, 'transform_funcs': (2, 4, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 478.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 422.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 75.17 MiB is allocated by PyTorch, and 6.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/simcrl_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bb3ca615,"{'temperature_head': 0.2, 'latent_dim': 512, 'batch_size': 501, 'transform_funcs': (3, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 470.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 702.00 MiB memory in use. Process 114717 has 402.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 81.85 MiB is allocated by PyTorch, and 48.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
76f35bc5,"{'temperature_head': 0.6000000000000001, 'latent_dim': 115, 'batch_size': 422, 'transform_funcs': (1, 3, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 16.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 480.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 726.00 MiB memory in use. Process 114717 has 388.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 17.89 MiB is allocated by PyTorch, and 30.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 56, in transform
    test_data = torch.tensor(X, dtype=torch.float32).to(self.device)
"
72837474,"{'temperature_head': 0.1, 'latent_dim': 468, 'batch_size': 454, 'transform_funcs': (0, 1, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 480.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 726.00 MiB memory in use. Process 114717 has 402.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 35.50 MiB is allocated by PyTorch, and 26.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/dataset_simcrl.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
bc922646,"{'temperature_head': 0.30000000000000004, 'latent_dim': 162, 'batch_size': 241, 'transform_funcs': (3, 6, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 480.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 726.00 MiB memory in use. Process 114717 has 402.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 35.65 MiB is allocated by PyTorch, and 26.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/dataset_simcrl.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
5f177771,"{'temperature_head': 0.2, 'latent_dim': 220, 'batch_size': 158, 'transform_funcs': (0, 2, 3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 480.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 726.00 MiB memory in use. Process 114717 has 402.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 35.82 MiB is allocated by PyTorch, and 26.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/dataset_simcrl.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
e6063ae5,"{'temperature_head': 0.1, 'latent_dim': 704, 'batch_size': 406, 'transform_funcs': (0, 2, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 424.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 504.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 726.00 MiB memory in use. Process 114717 has 424.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.95 MiB is allocated by PyTorch, and 5.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/simcrl_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
274cf8ed,"{'temperature_head': 0.7000000000000001, 'latent_dim': 327, 'batch_size': 182, 'transform_funcs': (0, 2, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 424.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 504.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 726.00 MiB memory in use. Process 114717 has 424.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 76.50 MiB is allocated by PyTorch, and 7.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/simcrl_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 33, in forward
    x = self.global_max_pooling(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/pooling.py"", line 1031, in forward
    return F.adaptive_max_pool1d(input, self.output_size, self.return_indices)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/_jit_internal.py"", line 488, in fn
    return if_false(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1096, in _adaptive_max_pool1d
    return adaptive_max_pool1d_with_indices(input, output_size)[0]

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1088, in adaptive_max_pool1d_with_indices
    return torch.adaptive_max_pool1d(input, output_size)
"
b55ed4ee,"{'temperature_head': 0.4, 'latent_dim': 582, 'batch_size': 378, 'transform_funcs': (1, 5, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 850.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 408.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 504.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 726.00 MiB memory in use. Process 114717 has 424.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 74.49 MiB is allocated by PyTorch, and 9.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/simcrl_head.py"", line 19, in forward
    base_model_output = self.base_model(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
fd16d5db,"{'temperature_head': 0.5, 'latent_dim': 492, 'batch_size': 298, 'transform_funcs': (2, 5, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 292.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 154.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 396.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.17 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 424.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 806.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 726.00 MiB memory in use. Process 114717 has 424.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 428.56 MiB is allocated by PyTorch, and 37.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c5feffc6,"{'temperature_head': 0.2, 'latent_dim': 358, 'batch_size': 269, 'transform_funcs': (1, 4, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 212.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 470.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.49 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 444.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 454.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 452.00 MiB memory in use. Process 114717 has 722.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 348.64 MiB is allocated by PyTorch, and 33.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
77886967,"{'temperature_head': 0.30000000000000004, 'latent_dim': 141, 'batch_size': 363, 'transform_funcs': (1, 5, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 470.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.49 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 418.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 456.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 452.00 MiB memory in use. Process 114717 has 768.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.95 MiB is allocated by PyTorch, and 37.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
261b346a,"{'temperature_head': 0.4, 'latent_dim': 277, 'batch_size': 168, 'transform_funcs': (2, 3, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 470.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.49 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 464.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 424.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 770.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 47.53 MiB is allocated by PyTorch, and 36.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
731dff64,"{'temperature_head': 0.2, 'latent_dim': 545, 'batch_size': 340, 'transform_funcs': (0, 3, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 470.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.49 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 464.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 448.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 770.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 92.97 MiB is allocated by PyTorch, and 15.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
fd644b31,"{'temperature_head': 0.30000000000000004, 'latent_dim': 521, 'batch_size': 491, 'transform_funcs': (3, 4, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 118.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 452.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.49 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 464.00 MiB memory in use. Process 114325 has 856.00 MiB memory in use. Process 114324 has 470.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 668.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.41 MiB is allocated by PyTorch, and 190.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a3fd68c7,"{'temperature_head': 0.30000000000000004, 'latent_dim': 181, 'batch_size': 193, 'transform_funcs': (1, 5, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 452.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.53 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 592.00 MiB memory in use. Process 114325 has 754.00 MiB memory in use. Process 114324 has 454.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 710.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 79.26 MiB is allocated by PyTorch, and 34.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d34209a1,"{'temperature_head': 0.1, 'latent_dim': 446, 'batch_size': 203, 'transform_funcs': (2, 7, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 452.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.53 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 592.00 MiB memory in use. Process 114325 has 754.00 MiB memory in use. Process 114324 has 476.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 710.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 84.93 MiB is allocated by PyTorch, and 51.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/simcrl_head.py"", line 20, in forward
    projection_1 = self.projection_1(base_model_output)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
"
a73e7dcf,"{'temperature_head': 0.8, 'latent_dim': 300, 'batch_size': 284, 'transform_funcs': (1, 4, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 452.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.53 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 592.00 MiB memory in use. Process 114325 has 754.00 MiB memory in use. Process 114324 has 452.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 710.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 80.19 MiB is allocated by PyTorch, and 31.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4bf012d4,"{'temperature_head': 0.2, 'latent_dim': 226, 'batch_size': 435, 'transform_funcs': (0, 2, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 556.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.53 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 432.00 MiB memory in use. Process 114325 has 754.00 MiB memory in use. Process 114324 has 508.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 418.00 MiB memory in use. Process 114717 has 714.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.61 MiB is allocated by PyTorch, and 32.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f65b8c05,"{'temperature_head': 0.1, 'latent_dim': 385, 'batch_size': 128, 'transform_funcs': (2, 6, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 556.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 432.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 494.00 MiB memory in use. Process 114717 has 896.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 364.35 MiB is allocated by PyTorch, and 191.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bbcdcd66,"{'temperature_head': 0.1, 'latent_dim': 321, 'batch_size': 162, 'transform_funcs': (1, 2, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 190.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 556.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 672.00 MiB memory in use. Process 114324 has 698.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 494.00 MiB memory in use. Process 114717 has 470.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 326.35 MiB is allocated by PyTorch, and 31.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
051bbcc0,"{'temperature_head': 0.1, 'latent_dim': 336, 'batch_size': 133, 'transform_funcs': (6, 7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 642.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 444.00 MiB memory in use. Process 114325 has 672.00 MiB memory in use. Process 114324 has 746.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 452.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 80.47 MiB is allocated by PyTorch, and 31.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
77caa54b,"{'temperature_head': 0.2, 'latent_dim': 396, 'batch_size': 189, 'transform_funcs': (1, 2, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 236.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 126.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 644.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 444.00 MiB memory in use. Process 114325 has 672.00 MiB memory in use. Process 114324 has 644.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 452.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.44 MiB is allocated by PyTorch, and 167.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
844237c3,"{'temperature_head': 0.1, 'latent_dim': 480, 'batch_size': 154, 'transform_funcs': (1, 4, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 96.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 452.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 456.00 MiB memory in use. Process 114325 has 654.00 MiB memory in use. Process 114324 has 646.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 606.00 MiB memory in use. Process 114717 has 502.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.09 MiB is allocated by PyTorch, and 168.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6672d682,"{'temperature_head': 0.1, 'latent_dim': 429, 'batch_size': 144, 'transform_funcs': (1, 7, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 452.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 456.00 MiB memory in use. Process 114325 has 654.00 MiB memory in use. Process 114324 has 646.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 606.00 MiB memory in use. Process 114717 has 508.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.20 MiB is allocated by PyTorch, and 30.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8092b096,"{'temperature_head': 0.1, 'latent_dim': 343, 'batch_size': 150, 'transform_funcs': (0, 1, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 556.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 550.00 MiB memory in use. Process 114325 has 700.00 MiB memory in use. Process 114324 has 690.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 454.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 80.53 MiB is allocated by PyTorch, and 33.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
dc84b2ce,"{'temperature_head': 0.1, 'latent_dim': 370, 'batch_size': 135, 'transform_funcs': (0, 8, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 220.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 136.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 452.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 552.00 MiB memory in use. Process 114325 has 662.00 MiB memory in use. Process 114324 has 644.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 464.00 MiB memory in use. Process 114717 has 502.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.23 MiB is allocated by PyTorch, and 167.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6c514d49,"{'temperature_head': 0.2, 'latent_dim': 264, 'batch_size': 175, 'transform_funcs': (1, 4, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 452.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 618.00 MiB memory in use. Process 114325 has 662.00 MiB memory in use. Process 114324 has 690.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 416.00 MiB memory in use. Process 114717 has 510.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.91 MiB is allocated by PyTorch, and 34.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
509d0657,"{'temperature_head': 0.1, 'latent_dim': 313, 'batch_size': 236, 'transform_funcs': (2, 5, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 186.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 136.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 470.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 618.00 MiB memory in use. Process 114325 has 430.00 MiB memory in use. Process 114324 has 826.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 498.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 321.79 MiB is allocated by PyTorch, and 164.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6955e156,"{'temperature_head': 0.2, 'latent_dim': 439, 'batch_size': 128, 'transform_funcs': (0, 5, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 198.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 452.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 444.00 MiB memory in use. Process 114325 has 432.00 MiB memory in use. Process 114324 has 876.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 494.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.28 MiB is allocated by PyTorch, and 36.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
af2c36ae,"{'temperature_head': 0.30000000000000004, 'latent_dim': 404, 'batch_size': 162, 'transform_funcs': (0, 4, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 454.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 448.00 MiB memory in use. Process 114325 has 418.00 MiB memory in use. Process 114324 has 880.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 618.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 375.34 MiB is allocated by PyTorch, and 164.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1d634450,"{'temperature_head': 0.2, 'latent_dim': 80, 'batch_size': 198, 'transform_funcs': (0, 3, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 808.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 866.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 464.00 MiB memory in use. Process 114324 has 508.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 618.00 MiB memory in use. Process 114717 has 510.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.47 MiB is allocated by PyTorch, and 35.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9a898f4c,"{'temperature_head': 0.30000000000000004, 'latent_dim': 556, 'batch_size': 186, 'transform_funcs': (3, 5, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 808.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 468.00 MiB memory in use. Process 114325 has 464.00 MiB memory in use. Process 114324 has 524.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.04 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.96 MiB is allocated by PyTorch, and 45.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
73dd0940,"{'temperature_head': 0.2, 'latent_dim': 534, 'batch_size': 208, 'transform_funcs': (0, 3, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 316.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 80.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 470.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 468.00 MiB memory in use. Process 114325 has 432.00 MiB memory in use. Process 114324 has 572.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 720.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.08 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.02 MiB is allocated by PyTorch, and 35.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9bc16ad2,"{'temperature_head': 0.1, 'latent_dim': 278, 'batch_size': 448, 'transform_funcs': (1, 7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 500.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 468.00 MiB memory in use. Process 114325 has 432.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 720.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.08 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.02 MiB is allocated by PyTorch, and 37.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ea4d9434,"{'temperature_head': 0.1, 'latent_dim': 295, 'batch_size': 308, 'transform_funcs': (0, 3, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 500.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 448.00 MiB memory in use. Process 114325 has 444.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 720.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.08 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.15 MiB is allocated by PyTorch, and 35.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dcdecf49,"{'temperature_head': 0.4, 'latent_dim': 368, 'batch_size': 352, 'transform_funcs': (1, 2, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 118.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 500.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 448.00 MiB memory in use. Process 114325 has 444.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 720.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.08 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.72 MiB is allocated by PyTorch, and 37.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6540b528,"{'temperature_head': 0.5, 'latent_dim': 491, 'batch_size': 158, 'transform_funcs': (0, 3, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 508.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 494.00 MiB memory in use. Process 114325 has 418.00 MiB memory in use. Process 114324 has 504.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 764.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.08 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.68 MiB is allocated by PyTorch, and 36.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c01a94e0,"{'temperature_head': 0.2, 'latent_dim': 517, 'batch_size': 192, 'transform_funcs': (3, 4, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 764.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 610.00 MiB memory in use. Process 114325 has 464.00 MiB memory in use. Process 114324 has 454.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 764.00 MiB memory in use. Process 114717 has 510.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 746.00 MiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 81.91 MiB is allocated by PyTorch, and 32.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
21915c49,"{'temperature_head': 0.30000000000000004, 'latent_dim': 578, 'batch_size': 170, 'transform_funcs': (0, 3, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.03 GiB memory in use. Process 110650 has 764.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 506.00 MiB memory in use. Process 114325 has 558.00 MiB memory in use. Process 114324 has 504.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 764.00 MiB memory in use. Process 114717 has 470.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 746.00 MiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 83.10 MiB is allocated by PyTorch, and 46.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b11982df,"{'temperature_head': 0.2, 'latent_dim': 506, 'batch_size': 272, 'transform_funcs': (1, 2, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.01 GiB memory in use. Process 110650 has 764.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 456.00 MiB memory in use. Process 114325 has 628.00 MiB memory in use. Process 114324 has 506.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 764.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 688.00 MiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.80 MiB is allocated by PyTorch, and 36.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6fc7ba13,"{'temperature_head': 0.1, 'latent_dim': 478, 'batch_size': 242, 'transform_funcs': (0, 2, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 92.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.01 GiB memory in use. Process 110650 has 692.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 468.00 MiB memory in use. Process 114325 has 628.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 744.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 688.00 MiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.58 MiB is allocated by PyTorch, and 34.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ac8dd982,"{'temperature_head': 0.9, 'latent_dim': 449, 'batch_size': 295, 'transform_funcs': (4, 6, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 106.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.01 GiB memory in use. Process 110650 has 692.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 456.00 MiB memory in use. Process 114325 has 628.00 MiB memory in use. Process 114324 has 558.00 MiB memory in use. Process 114709 has 1.37 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 744.00 MiB memory in use. Process 114717 has 510.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 690.00 MiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.36 MiB is allocated by PyTorch, and 32.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9654ac4f,"{'temperature_head': 0.2, 'latent_dim': 589, 'batch_size': 143, 'transform_funcs': (1, 2, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 350.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 472.00 MiB memory in use. Process 110650 has 472.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 564.00 MiB memory in use. Process 114325 has 676.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.09 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 790.00 MiB memory in use. Process 114717 has 1.04 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.06 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.60 MiB is allocated by PyTorch, and 35.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a02aec2d,"{'temperature_head': 0.1, 'latent_dim': 645, 'batch_size': 334, 'transform_funcs': (4, 6, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 188.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 492.00 MiB memory in use. Process 110650 has 866.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 998.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 558.00 MiB memory in use. Process 114325 has 670.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 790.00 MiB memory in use. Process 114717 has 498.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.06 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.46 MiB is allocated by PyTorch, and 32.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
967da228,"{'temperature_head': 0.4, 'latent_dim': 488, 'batch_size': 167, 'transform_funcs': (2, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 290.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 140.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 722.00 MiB memory in use. Process 110650 has 866.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 558.00 MiB memory in use. Process 114325 has 452.00 MiB memory in use. Process 114324 has 516.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 790.00 MiB memory in use. Process 114717 has 500.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.09 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.66 MiB is allocated by PyTorch, and 38.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3c680c40,"{'temperature_head': 0.2, 'latent_dim': 435, 'batch_size': 176, 'transform_funcs': (0, 7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 100.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 722.00 MiB memory in use. Process 110650 has 866.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 558.00 MiB memory in use. Process 114325 has 430.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 790.00 MiB memory in use. Process 114717 has 518.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.09 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.25 MiB is allocated by PyTorch, and 40.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f17a3fcb,"{'temperature_head': 0.1, 'latent_dim': 503, 'batch_size': 384, 'transform_funcs': (2, 3, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 96.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 434.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 558.00 MiB memory in use. Process 114325 has 450.00 MiB memory in use. Process 114324 has 562.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 790.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.78 MiB is allocated by PyTorch, and 34.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
03f35edf,"{'temperature_head': 0.2, 'latent_dim': 468, 'batch_size': 481, 'transform_funcs': (0, 5, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 278.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 218.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 434.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 512.00 MiB memory in use. Process 114325 has 432.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 792.00 MiB memory in use. Process 114717 has 500.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.50 MiB is allocated by PyTorch, and 36.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1052ee7e,"{'temperature_head': 0.1, 'latent_dim': 513, 'batch_size': 470, 'transform_funcs': (4, 6, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 560.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 430.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 766.00 MiB memory in use. Process 114717 has 518.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.81 MiB is allocated by PyTorch, and 39.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8026dd5d,"{'temperature_head': 0.30000000000000004, 'latent_dim': 326, 'batch_size': 129, 'transform_funcs': (0, 4, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 102.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 560.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 508.00 MiB memory in use. Process 114325 has 432.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 766.00 MiB memory in use. Process 114717 has 522.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.39 MiB is allocated by PyTorch, and 35.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
be80ebcc,"{'temperature_head': 0.2, 'latent_dim': 626, 'batch_size': 245, 'transform_funcs': (4, 5, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 372.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 454.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 602.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 428.00 MiB memory in use. Process 114717 has 884.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 508.83 MiB is allocated by PyTorch, and 35.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c084cb0d,"{'temperature_head': 0.7000000000000001, 'latent_dim': 384, 'batch_size': 148, 'transform_funcs': (1, 2, 3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 208.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 454.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 602.00 MiB memory in use. Process 114324 has 740.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 498.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 364.85 MiB is allocated by PyTorch, and 35.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
aba36965,"{'temperature_head': 0.4, 'latent_dim': 451, 'batch_size': 303, 'transform_funcs': (2, 3, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 124.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 556.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 538.00 MiB memory in use. Process 114325 has 452.00 MiB memory in use. Process 114324 has 788.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.37 MiB is allocated by PyTorch, and 34.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
839d749d,"{'temperature_head': 0.2, 'latent_dim': 479, 'batch_size': 316, 'transform_funcs': (2, 3, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 152.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 510.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 512.00 MiB memory in use. Process 114324 has 686.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.08 MiB is allocated by PyTorch, and 208.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6741f88b,"{'temperature_head': 0.1, 'latent_dim': 172, 'batch_size': 398, 'transform_funcs': (5, 7, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 80.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 558.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 552.00 MiB memory in use. Process 114325 has 554.00 MiB memory in use. Process 114324 has 730.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 418.00 MiB memory in use. Process 114717 has 510.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.19 MiB is allocated by PyTorch, and 34.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
979486c1,"{'temperature_head': 0.30000000000000004, 'latent_dim': 546, 'batch_size': 207, 'transform_funcs': (0, 3, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 558.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 552.00 MiB memory in use. Process 114325 has 594.00 MiB memory in use. Process 114324 has 684.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 510.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.61 MiB is allocated by PyTorch, and 206.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9ca5311e,"{'temperature_head': 0.2, 'latent_dim': 529, 'batch_size': 190, 'transform_funcs': (2, 4, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 558.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 552.00 MiB memory in use. Process 114325 has 594.00 MiB memory in use. Process 114324 has 734.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 518.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.98 MiB is allocated by PyTorch, and 40.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e1045856,"{'temperature_head': 0.4, 'latent_dim': 495, 'batch_size': 497, 'transform_funcs': (5, 8, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 80.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 558.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 552.00 MiB memory in use. Process 114325 has 630.00 MiB memory in use. Process 114324 has 686.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 398.00 MiB memory in use. Process 114717 has 498.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.21 MiB is allocated by PyTorch, and 208.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
28556f5b,"{'temperature_head': 0.5, 'latent_dim': 461, 'batch_size': 278, 'transform_funcs': (6, 7, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 250.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 558.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 552.00 MiB memory in use. Process 114325 has 640.00 MiB memory in use. Process 114324 has 454.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 516.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.45 MiB is allocated by PyTorch, and 38.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c7aaa7b6,"{'temperature_head': 0.30000000000000004, 'latent_dim': 111, 'batch_size': 358, 'transform_funcs': (1, 2, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 558.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 696.00 MiB memory in use. Process 114324 has 576.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 200.71 MiB is allocated by PyTorch, and 35.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e0eed94b,"{'temperature_head': 0.2, 'latent_dim': 405, 'batch_size': 153, 'transform_funcs': (0, 3, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 452.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.54 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 698.00 MiB memory in use. Process 114324 has 498.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 618.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.01 MiB is allocated by PyTorch, and 36.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7b1203d0,"{'temperature_head': 1.0, 'latent_dim': 338, 'batch_size': 145, 'transform_funcs': (0, 5, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 166.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 558.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.52 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 698.00 MiB memory in use. Process 114324 has 498.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 510.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.49 MiB is allocated by PyTorch, and 33.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
634f761c,"{'temperature_head': 0.2, 'latent_dim': 374, 'batch_size': 183, 'transform_funcs': (3, 6, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 100.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 688.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.52 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 504.00 MiB memory in use. Process 114325 has 658.00 MiB memory in use. Process 114324 has 498.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 454.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.77 MiB is allocated by PyTorch, and 35.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
39f34ad5,"{'temperature_head': 0.1, 'latent_dim': 431, 'batch_size': 128, 'transform_funcs': (3, 9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 786.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.52 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 658.00 MiB memory in use. Process 114324 has 456.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 452.00 MiB memory in use. Process 114717 has 556.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 81.21 MiB is allocated by PyTorch, and 34.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
752d1062,"{'temperature_head': 0.1, 'latent_dim': 554, 'batch_size': 237, 'transform_funcs': (0, 3, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 786.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.52 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 452.00 MiB memory in use. Process 114325 has 702.00 MiB memory in use. Process 114324 has 454.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 452.00 MiB memory in use. Process 114717 has 556.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 97.25 MiB is allocated by PyTorch, and 16.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
8de9b6d7,"{'temperature_head': 0.2, 'latent_dim': 252, 'batch_size': 457, 'transform_funcs': (1, 4, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 786.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.52 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 456.00 MiB memory in use. Process 114325 has 690.00 MiB memory in use. Process 114324 has 454.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 566.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 79.81 MiB is allocated by PyTorch, and 34.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e12a43e9,"{'temperature_head': 0.30000000000000004, 'latent_dim': 718, 'batch_size': 219, 'transform_funcs': (4, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 786.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.52 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 690.00 MiB memory in use. Process 114324 has 460.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 566.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 107.66 MiB is allocated by PyTorch, and 12.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
98d85de1,"{'temperature_head': 0.1, 'latent_dim': 460, 'batch_size': 346, 'transform_funcs': (2, 3, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 810.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 500.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 818.00 MiB memory in use. Process 114325 has 738.00 MiB memory in use. Process 114324 has 910.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 672.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.44 MiB is allocated by PyTorch, and 34.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3d598050,"{'temperature_head': 0.2, 'latent_dim': 486, 'batch_size': 329, 'transform_funcs': (0, 6, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 810.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 818.00 MiB memory in use. Process 114325 has 740.00 MiB memory in use. Process 114324 has 910.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 672.00 MiB memory in use. Process 114717 has 476.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.64 MiB is allocated by PyTorch, and 36.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8d61bf1f,"{'temperature_head': 0.4, 'latent_dim': 612, 'batch_size': 195, 'transform_funcs': (1, 4, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 810.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 818.00 MiB memory in use. Process 114325 has 740.00 MiB memory in use. Process 114324 has 910.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 676.00 MiB memory in use. Process 114717 has 476.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.08 MiB is allocated by PyTorch, and 32.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8e21956f,"{'temperature_head': 0.2, 'latent_dim': 383, 'batch_size': 130, 'transform_funcs': (1, 2, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 810.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 818.00 MiB memory in use. Process 114325 has 740.00 MiB memory in use. Process 114324 has 910.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 676.00 MiB memory in use. Process 114717 has 458.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 80.84 MiB is allocated by PyTorch, and 37.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
70768d49,"{'temperature_head': 0.30000000000000004, 'latent_dim': 426, 'batch_size': 161, 'transform_funcs': (1, 6, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 160.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 454.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 766.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 740.00 MiB memory in use. Process 114324 has 910.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 676.00 MiB memory in use. Process 114717 has 798.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 389.18 MiB is allocated by PyTorch, and 36.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6f16b8f9,"{'temperature_head': 0.1, 'latent_dim': 520, 'batch_size': 428, 'transform_funcs': (1, 3, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 308.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 104.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 474.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 856.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 810.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 740.00 MiB memory in use. Process 114324 has 818.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 676.00 MiB memory in use. Process 114717 has 798.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 445.91 MiB is allocated by PyTorch, and 32.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9eb1afb6,"{'temperature_head': 0.5, 'latent_dim': 310, 'batch_size': 152, 'transform_funcs': (0, 3, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 512.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 820.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 966.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 900.00 MiB memory in use. Process 114325 has 450.00 MiB memory in use. Process 114324 has 862.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 814.00 MiB memory in use. Process 114717 has 452.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 80.27 MiB is allocated by PyTorch, and 31.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
22a4bd1a,"{'temperature_head': 0.4, 'latent_dim': 598, 'batch_size': 416, 'transform_funcs': (1, 6, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 354.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 454.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 866.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 966.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 902.00 MiB memory in use. Process 114325 has 502.00 MiB memory in use. Process 114324 has 864.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 814.00 MiB memory in use. Process 114717 has 454.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 492.39 MiB is allocated by PyTorch, and 133.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4f55a6d3,"{'temperature_head': 0.1, 'latent_dim': 217, 'batch_size': 231, 'transform_funcs': (0, 1, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 454.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 432.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 902.00 MiB memory in use. Process 114325 has 502.00 MiB memory in use. Process 114324 has 1.13 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 814.00 MiB memory in use. Process 114717 has 640.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 263.83 MiB is allocated by PyTorch, and 36.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
568aa91f,"{'temperature_head': 0.30000000000000004, 'latent_dim': 11, 'batch_size': 347, 'transform_funcs': (1, 3, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 514.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 418.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 904.00 MiB memory in use. Process 114325 has 452.00 MiB memory in use. Process 114324 has 1.13 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 814.00 MiB memory in use. Process 114717 has 690.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.45 MiB is allocated by PyTorch, and 32.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
be32c0eb,"{'temperature_head': 0.2, 'latent_dim': 656, 'batch_size': 165, 'transform_funcs': (0, 1, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 454.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 472.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 904.00 MiB memory in use. Process 114325 has 452.00 MiB memory in use. Process 114324 has 1.13 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 814.00 MiB memory in use. Process 114717 has 690.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 106.12 MiB is allocated by PyTorch, and 25.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
344ea2b3,"{'temperature_head': 0.30000000000000004, 'latent_dim': 637, 'batch_size': 399, 'transform_funcs': (1, 5, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 378.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 156.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 454.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 496.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 846.00 MiB memory in use. Process 114325 has 454.00 MiB memory in use. Process 114324 has 1.13 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 814.00 MiB memory in use. Process 114717 has 586.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.32 MiB is allocated by PyTorch, and 107.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
190fa3e3,"{'temperature_head': 0.1, 'latent_dim': 566, 'batch_size': 177, 'transform_funcs': (5, 7, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 336.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 470.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 518.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 848.00 MiB memory in use. Process 114325 has 452.00 MiB memory in use. Process 114324 has 1.13 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 814.00 MiB memory in use. Process 114717 has 634.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.19 MiB is allocated by PyTorch, and 38.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
960d994d,"{'temperature_head': 0.1, 'latent_dim': 694, 'batch_size': 166, 'transform_funcs': (2, 4, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 412.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 120.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 462.00 MiB memory in use. Process 110650 has 1004.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 510.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 846.00 MiB memory in use. Process 114325 has 614.00 MiB memory in use. Process 114324 has 1.13 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 756.00 MiB memory in use. Process 114717 has 588.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.77 MiB is allocated by PyTorch, and 109.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f03344c2,"{'temperature_head': 0.2, 'latent_dim': 505, 'batch_size': 390, 'transform_funcs': (5, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 174.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 464.00 MiB memory in use. Process 110650 has 1004.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 510.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 846.00 MiB memory in use. Process 114325 has 614.00 MiB memory in use. Process 114324 has 1.03 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 756.00 MiB memory in use. Process 114717 has 634.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 435.84 MiB is allocated by PyTorch, and 280.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
674da73e,"{'temperature_head': 0.1, 'latent_dim': 550, 'batch_size': 202, 'transform_funcs': (0, 1, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 326.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 556.00 MiB memory in use. Process 110650 has 1008.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 852.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 846.00 MiB memory in use. Process 114325 has 614.00 MiB memory in use. Process 114324 has 1.07 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 634.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 464.61 MiB is allocated by PyTorch, and 47.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bde2833b,"{'temperature_head': 0.2, 'latent_dim': 616, 'batch_size': 144, 'transform_funcs': (0, 1, 2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 556.00 MiB memory in use. Process 110650 has 472.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 896.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.00 GiB memory in use. Process 114325 has 614.00 MiB memory in use. Process 114324 has 1.07 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 952.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 503.12 MiB is allocated by PyTorch, and 108.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ea91547c,"{'temperature_head': 0.9, 'latent_dim': 576, 'batch_size': 192, 'transform_funcs': (0, 2, 3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 342.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 132.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 990.00 MiB memory in use. Process 110650 has 472.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 782.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.00 GiB memory in use. Process 114325 has 614.00 MiB memory in use. Process 114324 has 1.07 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.26 MiB is allocated by PyTorch, and 303.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7a936680,"{'temperature_head': 0.2, 'latent_dim': 587, 'batch_size': 170, 'transform_funcs': (0, 2, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 348.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 990.00 MiB memory in use. Process 110650 has 472.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 832.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.00 GiB memory in use. Process 114325 has 658.00 MiB memory in use. Process 114324 has 1.07 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 485.93 MiB is allocated by PyTorch, and 266.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
68a20c83,"{'temperature_head': 0.1, 'latent_dim': 495, 'batch_size': 128, 'transform_funcs': (4, 5, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 110.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 990.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 786.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.01 GiB memory in use. Process 114325 has 658.00 MiB memory in use. Process 114324 has 500.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 426.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.21 MiB is allocated by PyTorch, and 308.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5b8e1fd1,"{'temperature_head': 0.2, 'latent_dim': 525, 'batch_size': 207, 'transform_funcs': (2, 9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 312.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 110.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 990.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 802.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1012.00 MiB memory in use. Process 114325 has 658.00 MiB memory in use. Process 114324 has 500.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.95 MiB is allocated by PyTorch, and 34.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9763afc8,"{'temperature_head': 0.2, 'latent_dim': 469, 'batch_size': 186, 'transform_funcs': (1, 3, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 990.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 828.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1012.00 MiB memory in use. Process 114325 has 664.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.51 MiB is allocated by PyTorch, and 36.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1d7a2b35,"{'temperature_head': 0.1, 'latent_dim': 437, 'batch_size': 448, 'transform_funcs': (4, 5, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 100.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 944.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 828.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1012.00 MiB memory in use. Process 114325 has 664.00 MiB memory in use. Process 114324 has 500.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 452.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.26 MiB is allocated by PyTorch, and 36.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
aa8a0c9e,"{'temperature_head': 0.2, 'latent_dim': 484, 'batch_size': 147, 'transform_funcs': (0, 4, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 944.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 828.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1012.00 MiB memory in use. Process 114325 has 664.00 MiB memory in use. Process 114324 has 456.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 500.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 81.63 MiB is allocated by PyTorch, and 34.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3550b0c8,"{'temperature_head': 0.2, 'latent_dim': 607, 'batch_size': 422, 'transform_funcs': (0, 7, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 360.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 944.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 484.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1012.00 MiB memory in use. Process 114325 has 664.00 MiB memory in use. Process 114324 has 504.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 500.00 MiB memory in use. Process 114717 has 872.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 498.23 MiB is allocated by PyTorch, and 33.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
86d5ac14,"{'temperature_head': 0.1, 'latent_dim': 557, 'batch_size': 161, 'transform_funcs': (4, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 330.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 116.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 944.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 540.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 454.00 MiB memory in use. Process 114325 has 712.00 MiB memory in use. Process 114324 has 506.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 824.00 MiB memory in use. Process 114717 has 918.00 MiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 1.15 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.17 MiB is allocated by PyTorch, and 60.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0abf2a0e,"{'temperature_head': 0.2, 'latent_dim': 538, 'batch_size': 199, 'transform_funcs': (0, 5, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 320.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 118.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 888.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 588.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 454.00 MiB memory in use. Process 114325 has 782.00 MiB memory in use. Process 114324 has 506.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 824.00 MiB memory in use. Process 114717 has 1.11 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 894.00 MiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 455.61 MiB is allocated by PyTorch, and 340.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7c6db2c7,"{'temperature_head': 1.0, 'latent_dim': 672, 'batch_size': 136, 'transform_funcs': (2, 7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 398.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 932.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 548.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 454.00 MiB memory in use. Process 114325 has 782.00 MiB memory in use. Process 114324 has 506.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 824.00 MiB memory in use. Process 114717 has 1.15 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 894.00 MiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.40 MiB is allocated by PyTorch, and 68.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f7c9af53,"{'temperature_head': 0.1, 'latent_dim': 448, 'batch_size': 176, 'transform_funcs': (5, 7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 932.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 504.00 MiB memory in use. Process 114325 has 782.00 MiB memory in use. Process 114324 has 516.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 824.00 MiB memory in use. Process 114717 has 1.16 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 894.00 MiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.35 MiB is allocated by PyTorch, and 38.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e100d5a2,"{'temperature_head': 0.2, 'latent_dim': 641, 'batch_size': 219, 'transform_funcs': (3, 4, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 380.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 176.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 888.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 512.00 MiB memory in use. Process 114325 has 782.00 MiB memory in use. Process 114324 has 562.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 708.00 MiB memory in use. Process 114717 has 1.13 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 894.00 MiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 517.31 MiB is allocated by PyTorch, and 298.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
75c7afcb,"{'temperature_head': 0.30000000000000004, 'latent_dim': 460, 'batch_size': 169, 'transform_funcs': (0, 7, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 102.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 888.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 558.00 MiB memory in use. Process 114325 has 756.00 MiB memory in use. Process 114324 has 518.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 708.00 MiB memory in use. Process 114717 has 1.18 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 942.00 MiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.44 MiB is allocated by PyTorch, and 40.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ea0ef274,"{'temperature_head': 0.2, 'latent_dim': 572, 'batch_size': 157, 'transform_funcs': (0, 3, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 102.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 888.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 558.00 MiB memory in use. Process 114325 has 756.00 MiB memory in use. Process 114324 has 518.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 708.00 MiB memory in use. Process 114717 has 1.18 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 942.00 MiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.20 MiB is allocated by PyTorch, and 32.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f3deb986,"{'temperature_head': 0.2, 'latent_dim': 424, 'batch_size': 211, 'transform_funcs': (3, 6, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 192.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 934.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 560.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 434.00 MiB memory in use. Process 114325 has 756.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 756.00 MiB memory in use. Process 114717 has 1.18 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 838.00 MiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.16 MiB is allocated by PyTorch, and 36.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
333ca488,"{'temperature_head': 0.1, 'latent_dim': 545, 'batch_size': 128, 'transform_funcs': (1, 3, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 92.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 934.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 420.00 MiB memory in use. Process 114325 has 802.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 826.00 MiB memory in use. Process 114717 has 1.18 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 838.00 MiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.15 MiB is allocated by PyTorch, and 32.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cbaa40b4,"{'temperature_head': 0.1, 'latent_dim': 501, 'batch_size': 183, 'transform_funcs': (2, 3, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 84.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 934.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 502.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 486.00 MiB memory in use. Process 114325 has 802.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 826.00 MiB memory in use. Process 114717 has 1.13 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 838.00 MiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 433.45 MiB is allocated by PyTorch, and 384.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
59ce3b01,"{'temperature_head': 0.30000000000000004, 'latent_dim': 593, 'batch_size': 144, 'transform_funcs': (4, 5, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 352.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 82.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 934.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 504.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 488.00 MiB memory in use. Process 114325 has 802.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 826.00 MiB memory in use. Process 114717 has 1.18 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.59 GiB memory in use. Process 115097 has 838.00 MiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.26 MiB is allocated by PyTorch, and 32.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
fe2e2933,"{'temperature_head': 0.2, 'latent_dim': 533, 'batch_size': 195, 'transform_funcs': (0, 1, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 316.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 934.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 532.00 MiB memory in use. Process 114325 has 802.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 946.00 MiB memory in use. Process 114717 has 1.39 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.55 GiB memory in use. Process 115097 has 452.00 MiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.74 MiB is allocated by PyTorch, and 33.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d90a9ca0,"{'temperature_head': 0.1, 'latent_dim': 412, 'batch_size': 462, 'transform_funcs': (0, 3, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 136.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 934.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 510.00 MiB memory in use. Process 114325 has 802.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 946.00 MiB memory in use. Process 114717 has 1.39 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.55 GiB memory in use. Process 115097 has 452.00 MiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.07 MiB is allocated by PyTorch, and 36.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a8e8fc8a,"{'temperature_head': 0.2, 'latent_dim': 519, 'batch_size': 180, 'transform_funcs': (4, 6, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 308.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 932.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 434.00 MiB memory in use. Process 114325 has 802.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 946.00 MiB memory in use. Process 114717 has 1.39 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.55 GiB memory in use. Process 115097 has 556.00 MiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.10 MiB is allocated by PyTorch, and 34.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8664d1af,"{'temperature_head': 0.1, 'latent_dim': 563, 'batch_size': 388, 'transform_funcs': (1, 2, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 334.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 932.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 562.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 434.00 MiB memory in use. Process 114325 has 802.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 946.00 MiB memory in use. Process 114717 has 1.39 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.55 GiB memory in use. Process 115097 has 556.00 MiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.25 MiB is allocated by PyTorch, and 35.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
17107961,"{'temperature_head': 0.1, 'latent_dim': 494, 'batch_size': 338, 'transform_funcs': (0, 3, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 104.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 932.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 516.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 432.00 MiB memory in use. Process 114325 has 802.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 946.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.55 GiB memory in use. Process 115097 has 470.00 MiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.71 MiB is allocated by PyTorch, and 38.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e58e79c8,"{'temperature_head': 0.8, 'latent_dim': 621, 'batch_size': 254, 'transform_funcs': (2, 4, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 368.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 152.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 932.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 516.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 432.00 MiB memory in use. Process 114325 has 802.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 946.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 1.55 GiB memory in use. Process 115097 has 470.00 MiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.70 MiB is allocated by PyTorch, and 33.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
867c819e,"{'temperature_head': 0.2, 'latent_dim': 652, 'batch_size': 325, 'transform_funcs': (2, 3, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 386.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 306.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 932.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 688.00 MiB memory in use. Process 114325 has 802.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 946.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 550.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.21 MiB is allocated by PyTorch, and 34.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
78a0ae2c,"{'temperature_head': 0.30000000000000004, 'latent_dim': 585, 'batch_size': 353, 'transform_funcs': (3, 4, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 346.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 344.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 932.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 688.00 MiB memory in use. Process 114325 has 802.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 946.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.42 MiB is allocated by PyTorch, and 33.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
49d0ebcd,"{'temperature_head': 0.4, 'latent_dim': 525, 'batch_size': 316, 'transform_funcs': (2, 4, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 312.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 102.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 934.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 558.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 886.00 MiB memory in use. Process 114325 has 802.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 946.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 510.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.98 MiB is allocated by PyTorch, and 32.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8444729a,"{'temperature_head': 0.1, 'latent_dim': 433, 'batch_size': 128, 'transform_funcs': (1, 4, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 906.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 608.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 886.00 MiB memory in use. Process 114325 has 802.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 946.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 562.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.23 MiB is allocated by PyTorch, and 36.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c08403f9,"{'temperature_head': 0.2, 'latent_dim': 484, 'batch_size': 303, 'transform_funcs': (0, 2, 3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 934.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 608.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 886.00 MiB memory in use. Process 114325 has 802.00 MiB memory in use. Process 114324 has 558.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 946.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.63 MiB is allocated by PyTorch, and 34.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f27fe878,"{'temperature_head': 0.5, 'latent_dim': 548, 'batch_size': 271, 'transform_funcs': (0, 1, 3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 164.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 434.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 846.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 886.00 MiB memory in use. Process 114325 has 802.00 MiB memory in use. Process 114324 has 662.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 946.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 462.60 MiB is allocated by PyTorch, and 43.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
346c385f,"{'temperature_head': 0.1, 'latent_dim': 101, 'batch_size': 343, 'transform_funcs': (3, 8, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 540.00 MiB memory in use. Process 110650 has 1.02 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 890.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.08 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 770.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 670.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 452.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.63 MiB is allocated by PyTorch, and 33.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
dc65f1a2,"{'temperature_head': 0.2, 'latent_dim': 58, 'batch_size': 412, 'transform_funcs': (0, 2, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 662.00 MiB memory in use. Process 110650 has 932.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 890.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.04 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 740.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 714.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 510.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.30 MiB is allocated by PyTorch, and 35.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
36f23bac,"{'temperature_head': 0.2, 'latent_dim': 3, 'batch_size': 371, 'transform_funcs': (0, 5, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 6.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 664.00 MiB memory in use. Process 110650 has 932.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 890.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.04 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 740.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 716.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 510.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 133.87 MiB is allocated by PyTorch, and 36.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4bc06a01,"{'temperature_head': 0.30000000000000004, 'latent_dim': 125, 'batch_size': 435, 'transform_funcs': (5, 7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 494.00 MiB memory in use. Process 110650 has 980.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 890.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.04 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 786.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 716.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 584.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 208.82 MiB is allocated by PyTorch, and 35.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ee9b3e1b,"{'temperature_head': 0.1, 'latent_dim': 95, 'batch_size': 362, 'transform_funcs': (0, 1, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 510.00 MiB memory in use. Process 110650 has 980.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 890.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 768.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 728.00 MiB memory in use. Process 114717 has 1.44 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 510.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.59 MiB is allocated by PyTorch, and 35.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7b88ec1a,"{'temperature_head': 0.2, 'latent_dim': 575, 'batch_size': 393, 'transform_funcs': (4, 5, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 76.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 556.00 MiB memory in use. Process 110650 has 980.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 890.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 516.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 740.00 MiB memory in use. Process 114717 has 1.43 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 662.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.34 MiB is allocated by PyTorch, and 37.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3adba325,"{'temperature_head': 0.30000000000000004, 'latent_dim': 164, 'batch_size': 377, 'transform_funcs': (1, 3, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 86.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 554.00 MiB memory in use. Process 110650 has 980.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 890.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 562.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 740.00 MiB memory in use. Process 114717 has 1.43 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 608.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 232.08 MiB is allocated by PyTorch, and 35.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0bef51ca,"{'temperature_head': 0.1, 'latent_dim': 634, 'batch_size': 347, 'transform_funcs': (2, 3, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 376.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 124.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 754.00 MiB memory in use. Process 110650 has 980.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 890.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 664.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 454.00 MiB memory in use. Process 114717 has 1.43 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 554.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.56 MiB is allocated by PyTorch, and 75.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f26f1738,"{'temperature_head': 0.2, 'latent_dim': 599, 'batch_size': 448, 'transform_funcs': (3, 5, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 356.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 130.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 754.00 MiB memory in use. Process 110650 has 980.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 868.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 788.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 974.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 738.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 450.00 MiB memory in use. Process 114717 has 1.47 GiB memory in use. Process 114714 has 714.00 MiB memory in use. Process 115104 has 532.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.38 MiB is allocated by PyTorch, and 308.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3b97de2c,"{'temperature_head': 0.1, 'latent_dim': 677, 'batch_size': 339, 'transform_funcs': (0, 2, 3, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 402.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 338.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 754.00 MiB memory in use. Process 110650 has 980.00 MiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 834.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 674.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 738.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 556.00 MiB memory in use. Process 114717 has 1.47 GiB memory in use. Process 114714 has 670.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.40 MiB is allocated by PyTorch, and 34.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8255d2f9,"{'temperature_head': 0.2, 'latent_dim': 661, 'batch_size': 355, 'transform_funcs': (4, 5, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 124.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 806.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 836.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 674.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 454.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 836.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 716.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.70 MiB is allocated by PyTorch, and 34.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
88ba6460,"{'temperature_head': 0.1, 'latent_dim': 93, 'batch_size': 417, 'transform_funcs': (2, 3, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 806.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 836.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 452.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 836.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 716.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.57 MiB is allocated by PyTorch, and 33.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6c9e9253,"{'temperature_head': 0.1, 'latent_dim': 719, 'batch_size': 380, 'transform_funcs': (2, 5, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 426.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 806.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 786.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 486.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 836.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 716.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.22 MiB is allocated by PyTorch, and 306.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
268cec3b,"{'temperature_head': 0.2, 'latent_dim': 517, 'batch_size': 441, 'transform_funcs': (1, 3, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 806.00 MiB memory in use. Process 110650 has 1.07 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 834.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 486.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 836.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 716.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.95 MiB is allocated by PyTorch, and 36.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
13e27db1,"{'temperature_head': 0.30000000000000004, 'latent_dim': 587, 'batch_size': 306, 'transform_funcs': (1, 6, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 348.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 130.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 852.00 MiB memory in use. Process 110650 has 1.11 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 834.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 486.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 670.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 716.00 MiB memory in use. Process 115104 has 508.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.44 MiB is allocated by PyTorch, and 29.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7a4d8466,"{'temperature_head': 0.1, 'latent_dim': 63, 'batch_size': 340, 'transform_funcs': (0, 1, 2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 854.00 MiB memory in use. Process 110650 has 1.11 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 834.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 718.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 716.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.34 MiB is allocated by PyTorch, and 37.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d82f759e,"{'temperature_head': 0.1, 'latent_dim': 571, 'batch_size': 329, 'transform_funcs': (0, 1, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 854.00 MiB memory in use. Process 110650 has 1.11 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 834.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 718.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 716.00 MiB memory in use. Process 115104 has 540.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.31 MiB is allocated by PyTorch, and 33.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
915db9ca,"{'temperature_head': 0.4, 'latent_dim': 184, 'batch_size': 410, 'transform_funcs': (3, 5, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 108.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 854.00 MiB memory in use. Process 110650 has 1.11 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 790.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 434.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 732.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 716.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 243.56 MiB is allocated by PyTorch, and 206.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
11bddb25,"{'temperature_head': 0.30000000000000004, 'latent_dim': 80, 'batch_size': 456, 'transform_funcs': (5, 6, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 932.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 568.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 674.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 732.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 716.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 181.76 MiB is allocated by PyTorch, and 46.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d2787a24,"{'temperature_head': 0.2, 'latent_dim': 554, 'batch_size': 425, 'transform_funcs': (7, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 328.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 78.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 932.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 500.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 674.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 780.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 716.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.18 MiB is allocated by PyTorch, and 33.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3a17d6d6,"{'temperature_head': 0.2, 'latent_dim': 477, 'batch_size': 398, 'transform_funcs': (0, 5, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 932.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 674.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 782.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 670.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.57 MiB is allocated by PyTorch, and 36.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
07f80ebc,"{'temperature_head': 0.2, 'latent_dim': 96, 'batch_size': 322, 'transform_funcs': (0, 1, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 978.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 456.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 674.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 816.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 670.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.59 MiB is allocated by PyTorch, and 37.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
73de1e8f,"{'temperature_head': 0.1, 'latent_dim': 526, 'batch_size': 384, 'transform_funcs': (2, 3, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 312.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 82.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 978.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.06 GiB memory in use. Process 113903 has 456.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 674.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 816.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 670.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.99 MiB is allocated by PyTorch, and 36.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2247a892,"{'temperature_head': 0.30000000000000004, 'latent_dim': 512, 'batch_size': 311, 'transform_funcs': (0, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 978.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.22 GiB memory in use. Process 113903 has 556.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 674.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 816.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 432.00 MiB memory in use. Process 115104 has 516.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.85 MiB is allocated by PyTorch, and 38.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7db2ef48,"{'temperature_head': 0.7000000000000001, 'latent_dim': 641, 'batch_size': 364, 'transform_funcs': (3, 4, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 380.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 184.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 978.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.22 GiB memory in use. Process 113903 has 556.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 888.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 432.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 518.22 MiB is allocated by PyTorch, and 29.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
edb4dcb2,"{'temperature_head': 0.1, 'latent_dim': 618, 'batch_size': 335, 'transform_funcs': (1, 3, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 228.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 978.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.22 GiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 888.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 432.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.47 MiB is allocated by PyTorch, and 32.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4f04fb3e,"{'temperature_head': 0.4, 'latent_dim': 536, 'batch_size': 352, 'transform_funcs': (2, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 318.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 110.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 978.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.22 GiB memory in use. Process 113903 has 560.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 834.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 452.00 MiB memory in use. Process 115104 has 662.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 454.42 MiB is allocated by PyTorch, and 39.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
21f06b43,"{'temperature_head': 0.1, 'latent_dim': 167, 'batch_size': 417, 'transform_funcs': (0, 6, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 978.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.22 GiB memory in use. Process 113903 has 614.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 880.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 430.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 452.00 MiB memory in use. Process 115104 has 642.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 233.88 MiB is allocated by PyTorch, and 40.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
035e6ef9,"{'temperature_head': 0.1, 'latent_dim': 599, 'batch_size': 387, 'transform_funcs': (0, 3, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 356.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 978.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 870.00 MiB memory in use. Process 113907 has 1.22 GiB memory in use. Process 113903 has 454.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 834.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 432.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 622.00 MiB memory in use. Process 115104 has 642.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.02 MiB is allocated by PyTorch, and 355.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
92de7d93,"{'temperature_head': 0.4, 'latent_dim': 500, 'batch_size': 343, 'transform_funcs': (2, 3, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 164.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 978.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 830.00 MiB memory in use. Process 113907 has 776.00 MiB memory in use. Process 113903 has 454.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 878.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 668.00 MiB memory in use. Process 115104 has 542.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.25 MiB is allocated by PyTorch, and 64.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c32d3501,"{'temperature_head': 0.2, 'latent_dim': 120, 'batch_size': 361, 'transform_funcs': (1, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 978.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 830.00 MiB memory in use. Process 113907 has 776.00 MiB memory in use. Process 113903 has 582.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 878.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 668.00 MiB memory in use. Process 115104 has 542.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 205.73 MiB is allocated by PyTorch, and 36.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
757ca058,"{'temperature_head': 0.2, 'latent_dim': 568, 'batch_size': 375, 'transform_funcs': (2, 4, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 336.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 110.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 978.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 830.00 MiB memory in use. Process 113907 has 776.00 MiB memory in use. Process 113903 has 508.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 832.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 668.00 MiB memory in use. Process 115104 has 588.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.78 MiB is allocated by PyTorch, and 354.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1d35ce25,"{'temperature_head': 0.1, 'latent_dim': 423, 'batch_size': 425, 'transform_funcs': (0, 2, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 92.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 978.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 776.00 MiB memory in use. Process 113903 has 510.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 880.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 668.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.15 MiB is allocated by PyTorch, and 34.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d0dd7111,"{'temperature_head': 0.2, 'latent_dim': 549, 'batch_size': 297, 'transform_funcs': (3, 4, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 980.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 776.00 MiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 880.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 666.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.45 MiB is allocated by PyTorch, and 32.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1853a51e,"{'temperature_head': 0.30000000000000004, 'latent_dim': 687, 'batch_size': 410, 'transform_funcs': (5, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 408.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 88.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 980.00 MiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 776.00 MiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 832.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 666.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.71 MiB is allocated by PyTorch, and 353.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c0de3672,"{'temperature_head': 0.1, 'latent_dim': 198, 'batch_size': 282, 'transform_funcs': (1, 5, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 94.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 822.00 MiB memory in use. Process 113903 has 560.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 434.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 666.00 MiB memory in use. Process 115104 has 630.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 253.39 MiB is allocated by PyTorch, and 36.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0b3109d5,"{'temperature_head': 0.2, 'latent_dim': 399, 'batch_size': 373, 'transform_funcs': (5, 8, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 236.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 822.00 MiB memory in use. Process 113903 has 750.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 434.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 432.00 MiB memory in use. Process 115104 has 678.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 372.96 MiB is allocated by PyTorch, and 37.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6599ecf7,"{'temperature_head': 0.2, 'latent_dim': 516, 'batch_size': 454, 'transform_funcs': (0, 4, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 306.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 108.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 862.00 MiB memory in use. Process 113903 has 796.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 434.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 432.00 MiB memory in use. Process 115104 has 574.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.44 MiB is allocated by PyTorch, and 96.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
30e20d55,"{'temperature_head': 0.1, 'latent_dim': 24, 'batch_size': 381, 'transform_funcs': (2, 5, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 862.00 MiB memory in use. Process 113903 has 796.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 506.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 432.00 MiB memory in use. Process 115104 has 574.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.03 MiB is allocated by PyTorch, and 31.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c64cc583,"{'temperature_head': 0.9, 'latent_dim': 628, 'batch_size': 401, 'transform_funcs': (1, 3, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 372.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 140.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 862.00 MiB memory in use. Process 113903 has 692.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 506.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 432.00 MiB memory in use. Process 115104 has 574.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.56 MiB is allocated by PyTorch, and 213.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
efae4e29,"{'temperature_head': 0.30000000000000004, 'latent_dim': 580, 'batch_size': 392, 'transform_funcs': (2, 3, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 136.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 862.00 MiB memory in use. Process 113903 has 434.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 506.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 646.00 MiB memory in use. Process 115104 has 622.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.38 MiB is allocated by PyTorch, and 27.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5116c074,"{'temperature_head': 0.2, 'latent_dim': 38, 'batch_size': 301, 'transform_funcs': (4, 6, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 862.00 MiB memory in use. Process 113903 has 506.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 554.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 646.00 MiB memory in use. Process 115104 has 624.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.14 MiB is allocated by PyTorch, and 31.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
7f21aeda,"{'temperature_head': 0.1, 'latent_dim': 456, 'batch_size': 348, 'transform_funcs': (0, 5, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 270.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 118.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 862.00 MiB memory in use. Process 113903 has 452.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 882.00 MiB memory in use. Process 114324 has 554.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 646.00 MiB memory in use. Process 115104 has 574.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.90 MiB is allocated by PyTorch, and 97.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3e1bfde3,"{'temperature_head': 0.8, 'latent_dim': 500, 'batch_size': 367, 'transform_funcs': (2, 8, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 120.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 498.00 MiB memory in use. Process 113903 has 454.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 900.00 MiB memory in use. Process 114324 has 554.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 692.00 MiB memory in use. Process 115104 has 870.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 433.25 MiB is allocated by PyTorch, and 96.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bec6f80d,"{'temperature_head': 0.2, 'latent_dim': 127, 'batch_size': 353, 'transform_funcs': (4, 8, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 558.00 MiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 900.00 MiB memory in use. Process 114324 has 554.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 636.00 MiB memory in use. Process 115104 has 916.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.84 MiB is allocated by PyTorch, and 37.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
27a7a5b7,"{'temperature_head': 0.1, 'latent_dim': 102, 'batch_size': 419, 'transform_funcs': (1, 4, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 558.00 MiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 900.00 MiB memory in use. Process 114324 has 508.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 636.00 MiB memory in use. Process 115104 has 916.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.64 MiB is allocated by PyTorch, and 33.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bf5dd102,"{'temperature_head': 0.2, 'latent_dim': 654, 'batch_size': 437, 'transform_funcs': (1, 6, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 388.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 140.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 726.00 MiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 452.00 MiB memory in use. Process 114324 has 658.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 682.00 MiB memory in use. Process 115104 has 918.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 882.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.23 MiB is allocated by PyTorch, and 32.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
64937c25,"{'temperature_head': 0.30000000000000004, 'latent_dim': 412, 'batch_size': 386, 'transform_funcs': (3, 7, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 728.00 MiB memory in use. Process 113903 has 562.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 452.00 MiB memory in use. Process 114324 has 658.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 744.00 MiB memory in use. Process 115104 has 874.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 896.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 380.14 MiB is allocated by PyTorch, and 153.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9d72bd83,"{'temperature_head': 0.6000000000000001, 'latent_dim': 490, 'batch_size': 318, 'transform_funcs': (1, 4, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 290.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 106.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 728.00 MiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 452.00 MiB memory in use. Process 114324 has 658.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 744.00 MiB memory in use. Process 115104 has 874.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 896.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.68 MiB is allocated by PyTorch, and 34.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
259407d9,"{'temperature_head': 0.2, 'latent_dim': 597, 'batch_size': 172, 'transform_funcs': (0, 4, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 354.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 728.00 MiB memory in use. Process 113903 has 530.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 460.00 MiB memory in use. Process 114324 has 658.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 744.00 MiB memory in use. Process 115104 has 930.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 896.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 490.96 MiB is allocated by PyTorch, and 99.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e006078b,"{'temperature_head': 0.1, 'latent_dim': 466, 'batch_size': 374, 'transform_funcs': (1, 3, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 158.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 728.00 MiB memory in use. Process 113903 has 790.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 450.00 MiB memory in use. Process 114324 has 658.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 792.00 MiB memory in use. Process 115104 has 454.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 413.49 MiB is allocated by PyTorch, and 36.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
96f2444d,"{'temperature_head': 0.4, 'latent_dim': 437, 'batch_size': 290, 'transform_funcs': (1, 2, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 230.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 728.00 MiB memory in use. Process 113903 has 732.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 430.00 MiB memory in use. Process 114324 has 660.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 456.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.76 MiB is allocated by PyTorch, and 255.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
527b8d7d,"{'temperature_head': 0.2, 'latent_dim': 230, 'batch_size': 365, 'transform_funcs': (1, 2, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 128.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 728.00 MiB memory in use. Process 113903 has 778.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 430.00 MiB memory in use. Process 114324 has 660.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.64 MiB is allocated by PyTorch, and 36.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5515bea8,"{'temperature_head': 0.1, 'latent_dim': 534, 'batch_size': 344, 'transform_funcs': (4, 9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 316.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 282.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 728.00 MiB memory in use. Process 113903 has 778.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 430.00 MiB memory in use. Process 114324 has 506.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.02 MiB is allocated by PyTorch, and 27.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5e760e2e,"{'temperature_head': 0.1, 'latent_dim': 549, 'batch_size': 405, 'transform_funcs': (0, 2, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 326.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 178.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 452.00 MiB memory in use. Process 113903 has 734.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 686.00 MiB memory in use. Process 114324 has 510.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 676.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.10 MiB is allocated by PyTorch, and 255.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7c102e22,"{'temperature_head': 0.2, 'latent_dim': 521, 'batch_size': 142, 'transform_funcs': (1, 5, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 208.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 618.00 MiB memory in use. Process 113903 has 530.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.09 GiB memory in use. Process 114325 has 686.00 MiB memory in use. Process 114324 has 518.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 676.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.92 MiB is allocated by PyTorch, and 40.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c009b82c,"{'temperature_head': 0.30000000000000004, 'latent_dim': 49, 'batch_size': 149, 'transform_funcs': (0, 2, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 662.00 MiB memory in use. Process 113903 has 504.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.10 GiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 572.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 722.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 163.20 MiB is allocated by PyTorch, and 68.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
494efc8c,"{'temperature_head': 0.1, 'latent_dim': 581, 'batch_size': 416, 'transform_funcs': (1, 4, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 238.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 662.00 MiB memory in use. Process 113903 has 504.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.10 GiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 572.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.19 MiB is allocated by PyTorch, and 32.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8acdd102,"{'temperature_head': 0.1, 'latent_dim': 667, 'batch_size': 382, 'transform_funcs': (1, 2, 3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 396.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 190.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 662.00 MiB memory in use. Process 113903 has 518.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.10 GiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 602.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 516.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.76 MiB is allocated by PyTorch, and 38.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e5ccdc5a,"{'temperature_head': 0.5, 'latent_dim': 711, 'batch_size': 262, 'transform_funcs': (2, 4, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 422.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 144.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 706.00 MiB memory in use. Process 113903 has 562.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.10 GiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 518.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.41 MiB is allocated by PyTorch, and 38.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4bfd6905,"{'temperature_head': 0.2, 'latent_dim': 369, 'batch_size': 400, 'transform_funcs': (3, 6, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 220.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 706.00 MiB memory in use. Process 113903 has 642.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.10 GiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 520.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.73 MiB is allocated by PyTorch, and 43.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b5602b05,"{'temperature_head': 0.1, 'latent_dim': 540, 'batch_size': 206, 'transform_funcs': (0, 1, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 320.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 162.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 498.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 508.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 518.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 764.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.07 MiB is allocated by PyTorch, and 39.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
526f14d2,"{'temperature_head': 0.30000000000000004, 'latent_dim': 448, 'batch_size': 193, 'transform_funcs': (0, 1, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 516.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 432.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 670.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 764.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.35 MiB is allocated by PyTorch, and 38.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b762fb75,"{'temperature_head': 0.1, 'latent_dim': 565, 'batch_size': 178, 'transform_funcs': (3, 5, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 336.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 136.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 676.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 670.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 454.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.19 MiB is allocated by PyTorch, and 34.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6cdbbe70,"{'temperature_head': 0.2, 'latent_dim': 35, 'batch_size': 164, 'transform_funcs': (1, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 560.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 676.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 720.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 456.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.12 MiB is allocated by PyTorch, and 37.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8c8910ff,"{'temperature_head': 0.2, 'latent_dim': 157, 'batch_size': 377, 'transform_funcs': (0, 2, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 676.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 720.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 484.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.07 MiB is allocated by PyTorch, and 36.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2605ee8c,"{'temperature_head': 0.1, 'latent_dim': 422, 'batch_size': 367, 'transform_funcs': (2, 4, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 454.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 676.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 816.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 496.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 386.64 MiB is allocated by PyTorch, and 89.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ede652a2,"{'temperature_head': 0.1, 'latent_dim': 394, 'batch_size': 424, 'transform_funcs': (1, 5, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.18 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 724.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 678.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 498.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 510.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.93 MiB is allocated by PyTorch, and 33.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1ee72935,"{'temperature_head': 0.1, 'latent_dim': 458, 'batch_size': 407, 'transform_funcs': (1, 2, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 216.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.04 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 724.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 678.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 518.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 456.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.43 MiB is allocated by PyTorch, and 40.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dc20f5cc,"{'temperature_head': 0.2, 'latent_dim': 244, 'batch_size': 436, 'transform_funcs': (1, 2, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 26.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.04 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 724.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 826.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 456.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 79.75 MiB is allocated by PyTorch, and 36.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
82991160,"{'temperature_head': 0.2, 'latent_dim': 526, 'batch_size': 186, 'transform_funcs': (0, 6, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.04 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 724.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 826.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 480.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 94.05 MiB is allocated by PyTorch, and 45.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 46, in calculate_loss
    logits = torch.cat([torch.cat([logits_ab, logits_aa], dim=1), torch.cat([logits_ba, logits_bb], dim=1)], dim=0)
"
0e738c52,"{'temperature_head': 0.1, 'latent_dim': 615, 'batch_size': 327, 'transform_funcs': (1, 2, 3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.04 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 724.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 826.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 480.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 100.42 MiB is allocated by PyTorch, and 39.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 46, in calculate_loss
    logits = torch.cat([torch.cat([logits_ab, logits_aa], dim=1), torch.cat([logits_ba, logits_bb], dim=1)], dim=0)
"
7e5750fb,"{'temperature_head': 0.1, 'latent_dim': 348, 'batch_size': 149, 'transform_funcs': (0, 2, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.04 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 454.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 826.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 718.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 342.56 MiB is allocated by PyTorch, and 35.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bdaf4040,"{'temperature_head': 0.30000000000000004, 'latent_dim': 74, 'batch_size': 136, 'transform_funcs': (2, 5, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 34.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.04 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 454.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 826.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 718.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.42 MiB is allocated by PyTorch, and 35.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b00b3dcf,"{'temperature_head': 0.2, 'latent_dim': 508, 'batch_size': 360, 'transform_funcs': (5, 6, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 302.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 116.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 528.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 826.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.82 MiB is allocated by PyTorch, and 36.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f8475068,"{'temperature_head': 0.1, 'latent_dim': 594, 'batch_size': 385, 'transform_funcs': (3, 6, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 352.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 132.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 516.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 826.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.43 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.87 MiB is allocated by PyTorch, and 37.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
452ce04e,"{'temperature_head': 0.1, 'latent_dim': 629, 'batch_size': 350, 'transform_funcs': (0, 1, 3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 372.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 154.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 540.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 826.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.43 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 1.03 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.67 MiB is allocated by PyTorch, and 34.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3df5500a,"{'temperature_head': 1.0, 'latent_dim': 328, 'batch_size': 449, 'transform_funcs': (0, 2, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 194.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 140.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 558.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 736.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 710.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.43 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 944.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 330.41 MiB is allocated by PyTorch, and 39.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bfab759b,"{'temperature_head': 0.4, 'latent_dim': 578, 'batch_size': 477, 'transform_funcs': (1, 4, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 342.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 292.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 736.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 500.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.43 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 662.00 MiB memory in use. Process 115097 has 944.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.77 MiB is allocated by PyTorch, and 33.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f71beb44,"{'temperature_head': 0.2, 'latent_dim': 472, 'batch_size': 398, 'transform_funcs': (1, 3, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 232.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 560.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 736.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.43 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 662.00 MiB memory in use. Process 115097 has 944.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.54 MiB is allocated by PyTorch, and 34.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
050d2318,"{'temperature_head': 0.1, 'latent_dim': 264, 'batch_size': 158, 'transform_funcs': (2, 5, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 84.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 512.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 780.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 662.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.43 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 664.00 MiB memory in use. Process 115097 has 944.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.91 MiB is allocated by PyTorch, and 36.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
959c3f0c,"{'temperature_head': 0.1, 'latent_dim': 649, 'batch_size': 372, 'transform_funcs': (2, 3, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 292.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 562.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 780.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 662.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.43 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 896.00 MiB memory in use. Process 115097 has 454.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 522.92 MiB is allocated by PyTorch, and 33.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d285c89c,"{'temperature_head': 0.30000000000000004, 'latent_dim': 494, 'batch_size': 332, 'transform_funcs': (3, 5, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 294.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 780.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 662.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.43 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 942.00 MiB memory in use. Process 115097 has 454.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.71 MiB is allocated by PyTorch, and 36.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ce3f6222,"{'temperature_head': 0.5, 'latent_dim': 365, 'batch_size': 238, 'transform_funcs': (2, 5, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 780.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 662.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 944.00 MiB memory in use. Process 115097 has 626.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.70 MiB is allocated by PyTorch, and 37.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f1bce5c3,"{'temperature_head': 0.1, 'latent_dim': 560, 'batch_size': 460, 'transform_funcs': (2, 5, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 332.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 140.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 498.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 780.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 666.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 840.00 MiB memory in use. Process 115097 has 676.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.58 MiB is allocated by PyTorch, and 361.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9b5df69e,"{'temperature_head': 0.2, 'latent_dim': 442, 'batch_size': 162, 'transform_funcs': (0, 1, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 262.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 170.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 498.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 780.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 888.00 MiB memory in use. Process 115097 has 750.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.30 MiB is allocated by PyTorch, and 36.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
83840f40,"{'temperature_head': 0.2, 'latent_dim': 429, 'batch_size': 152, 'transform_funcs': (1, 2, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 92.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 780.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 888.00 MiB memory in use. Process 115097 has 766.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.20 MiB is allocated by PyTorch, and 36.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7b7e0232,"{'temperature_head': 0.1, 'latent_dim': 463, 'batch_size': 180, 'transform_funcs': (0, 1, 3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 88.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 562.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 780.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 844.00 MiB memory in use. Process 115097 has 766.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.96 MiB is allocated by PyTorch, and 367.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7c05d81c,"{'temperature_head': 0.2, 'latent_dim': 388, 'batch_size': 131, 'transform_funcs': (0, 2, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 88.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 562.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 784.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 888.00 MiB memory in use. Process 115097 has 766.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.88 MiB is allocated by PyTorch, and 35.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
92e6c362,"{'temperature_head': 0.1, 'latent_dim': 479, 'batch_size': 174, 'transform_funcs': (1, 5, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 516.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 794.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 890.00 MiB memory in use. Process 115097 has 766.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.59 MiB is allocated by PyTorch, and 38.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8c6d416d,"{'temperature_head': 0.1, 'latent_dim': 451, 'batch_size': 157, 'transform_funcs': (2, 6, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 158.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 560.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 710.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 890.00 MiB memory in use. Process 115097 has 766.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.37 MiB is allocated by PyTorch, and 36.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9aab8795,"{'temperature_head': 0.2, 'latent_dim': 458, 'batch_size': 142, 'transform_funcs': (4, 8, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 160.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 560.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 710.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 842.00 MiB memory in use. Process 115097 has 766.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 407.69 MiB is allocated by PyTorch, and 94.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
07ffe5d7,"{'temperature_head': 0.2, 'latent_dim': 440, 'batch_size': 167, 'transform_funcs': (1, 2, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 262.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 708.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 562.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1002.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 890.00 MiB memory in use. Process 115097 has 856.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.29 MiB is allocated by PyTorch, and 36.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
23cb1fba,"{'temperature_head': 0.2, 'latent_dim': 501, 'batch_size': 172, 'transform_funcs': (3, 5, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 116.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 560.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 660.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 562.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 842.00 MiB memory in use. Process 115097 has 856.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.26 MiB is allocated by PyTorch, and 364.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
55da36d8,"{'temperature_head': 0.30000000000000004, 'latent_dim': 373, 'batch_size': 159, 'transform_funcs': (0, 4, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 162.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 660.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 562.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 842.00 MiB memory in use. Process 115097 has 856.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.76 MiB is allocated by PyTorch, and 37.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
396fb1a0,"{'temperature_head': 0.1, 'latent_dim': 489, 'batch_size': 135, 'transform_funcs': (2, 6, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 290.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 208.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 514.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 660.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 516.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 842.00 MiB memory in use. Process 115097 has 856.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.67 MiB is allocated by PyTorch, and 38.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
258557aa,"{'temperature_head': 0.2, 'latent_dim': 398, 'batch_size': 204, 'transform_funcs': (0, 1, 2, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 236.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 562.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 454.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 750.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 888.00 MiB memory in use. Process 115097 has 900.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 372.96 MiB is allocated by PyTorch, and 37.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d12ac09c,"{'temperature_head': 0.2, 'latent_dim': 471, 'batch_size': 150, 'transform_funcs': (1, 2, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 794.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 454.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 500.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 888.00 MiB memory in use. Process 115097 has 900.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 415.98 MiB is allocated by PyTorch, and 38.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fc7aeeff,"{'temperature_head': 0.1, 'latent_dim': 529, 'batch_size': 181, 'transform_funcs': (0, 2, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 78.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 820.00 MiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 454.00 MiB memory in use. Process 114325 has 730.00 MiB memory in use. Process 114324 has 500.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 842.00 MiB memory in use. Process 115097 has 900.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.49 MiB is allocated by PyTorch, and 364.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
620bd825,"{'temperature_head': 0.2, 'latent_dim': 513, 'batch_size': 189, 'transform_funcs': (1, 5, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 220.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.02 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 432.00 MiB memory in use. Process 114325 has 790.00 MiB memory in use. Process 114324 has 500.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 888.00 MiB memory in use. Process 115097 has 454.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 442.58 MiB is allocated by PyTorch, and 257.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9b3f6c21,"{'temperature_head': 0.30000000000000004, 'latent_dim': 443, 'batch_size': 168, 'transform_funcs': (1, 7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 262.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 212.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.06 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 434.00 MiB memory in use. Process 114325 has 792.00 MiB memory in use. Process 114324 has 500.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 844.00 MiB memory in use. Process 115097 has 456.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 398.71 MiB is allocated by PyTorch, and 105.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
01b774e2,"{'temperature_head': 0.1, 'latent_dim': 507, 'batch_size': 129, 'transform_funcs': (2, 4, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 198.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.06 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 434.00 MiB memory in use. Process 114325 has 792.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 844.00 MiB memory in use. Process 115097 has 456.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.81 MiB is allocated by PyTorch, and 36.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c48ae591,"{'temperature_head': 0.30000000000000004, 'latent_dim': 413, 'batch_size': 137, 'transform_funcs': (3, 4, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.04 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.06 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 434.00 MiB memory in use. Process 114325 has 792.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 840.00 MiB memory in use. Process 115097 has 594.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 380.73 MiB is allocated by PyTorch, and 119.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c1e02e0e,"{'temperature_head': 0.1, 'latent_dim': 539, 'batch_size': 164, 'transform_funcs': (0, 2, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 320.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.04 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.03 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 560.00 MiB memory in use. Process 114325 has 792.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 886.00 MiB memory in use. Process 115097 has 454.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 457.29 MiB is allocated by PyTorch, and 258.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
12773ba3,"{'temperature_head': 0.1, 'latent_dim': 434, 'batch_size': 226, 'transform_funcs': (0, 1, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.04 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.08 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 560.00 MiB memory in use. Process 114325 has 792.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 886.00 MiB memory in use. Process 115097 has 454.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.24 MiB is allocated by PyTorch, and 36.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2d562b0f,"{'temperature_head': 0.2, 'latent_dim': 522, 'batch_size': 178, 'transform_funcs': (1, 4, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.08 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 494.00 MiB memory in use. Process 114325 has 792.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 840.00 MiB memory in use. Process 115097 has 464.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.46 MiB is allocated by PyTorch, and 362.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
63cadb78,"{'temperature_head': 0.2, 'latent_dim': 353, 'batch_size': 145, 'transform_funcs': (0, 4, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.08 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 494.00 MiB memory in use. Process 114325 has 792.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 848.00 MiB memory in use. Process 115097 has 502.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.60 MiB is allocated by PyTorch, and 37.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
957e74c0,"{'temperature_head': 0.2, 'latent_dim': 505, 'batch_size': 212, 'transform_funcs': (6, 8, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 106.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.08 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 440.00 MiB memory in use. Process 114325 has 792.00 MiB memory in use. Process 114324 has 476.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 844.00 MiB memory in use. Process 115097 has 558.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.29 MiB is allocated by PyTorch, and 366.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
71c0aed4,"{'temperature_head': 0.1, 'latent_dim': 396, 'batch_size': 184, 'transform_funcs': (2, 4, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.08 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 500.00 MiB memory in use. Process 114325 has 792.00 MiB memory in use. Process 114324 has 432.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 888.00 MiB memory in use. Process 115097 has 558.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 48.46 MiB is allocated by PyTorch, and 43.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
eaa88aee,"{'temperature_head': 0.30000000000000004, 'latent_dim': 451, 'batch_size': 151, 'transform_funcs': (5, 6, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 508.00 MiB memory in use. Process 114325 has 792.00 MiB memory in use. Process 114324 has 476.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 558.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.37 MiB is allocated by PyTorch, and 36.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2bbff6ca,"{'temperature_head': 0.2, 'latent_dim': 341, 'batch_size': 158, 'transform_funcs': (0, 5, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 468.00 MiB memory in use. Process 114325 has 792.00 MiB memory in use. Process 114324 has 458.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 558.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 80.51 MiB is allocated by PyTorch, and 37.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
67e07d80,"{'temperature_head': 0.1, 'latent_dim': 429, 'batch_size': 362, 'transform_funcs': (0, 1, 2, 3)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 476.00 MiB memory in use. Process 114325 has 754.00 MiB memory in use. Process 114324 has 508.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 854.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 558.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.20 MiB is allocated by PyTorch, and 36.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7f5cdb0c,"{'temperature_head': 0.2, 'latent_dim': 553, 'batch_size': 174, 'transform_funcs': (0, 4, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 328.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 476.00 MiB memory in use. Process 114325 has 754.00 MiB memory in use. Process 114324 has 572.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 754.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 558.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.66 MiB is allocated by PyTorch, and 94.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
72fb7458,"{'temperature_head': 0.2, 'latent_dim': 486, 'batch_size': 368, 'transform_funcs': (0, 4, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 108.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 500.00 MiB memory in use. Process 114325 has 452.00 MiB memory in use. Process 114324 has 800.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 754.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 558.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 425.64 MiB is allocated by PyTorch, and 34.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2d03e9f6,"{'temperature_head': 0.1, 'latent_dim': 522, 'batch_size': 134, 'transform_funcs': (3, 6, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 102.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 452.00 MiB memory in use. Process 114324 has 848.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 800.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 546.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.97 MiB is allocated by PyTorch, and 34.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b4be74df,"{'temperature_head': 0.2, 'latent_dim': 573, 'batch_size': 403, 'transform_funcs': (2, 4, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 106.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 508.00 MiB memory in use. Process 114325 has 452.00 MiB memory in use. Process 114324 has 744.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 560.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.82 MiB is allocated by PyTorch, and 266.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7fb0e6ae,"{'temperature_head': 0.30000000000000004, 'latent_dim': 377, 'batch_size': 194, 'transform_funcs': (0, 1, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 452.00 MiB memory in use. Process 114324 has 744.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 560.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.29 MiB is allocated by PyTorch, and 267.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a542bbf2,"{'temperature_head': 0.1, 'latent_dim': 361, 'batch_size': 165, 'transform_funcs': (3, 7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 556.00 MiB memory in use. Process 114324 has 790.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 454.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.67 MiB is allocated by PyTorch, and 37.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
59052a60,"{'temperature_head': 0.30000000000000004, 'latent_dim': 432, 'batch_size': 412, 'transform_funcs': (1, 3, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 556.00 MiB memory in use. Process 114324 has 790.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 456.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.22 MiB is allocated by PyTorch, and 34.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bf5b507d,"{'temperature_head': 0.1, 'latent_dim': 63, 'batch_size': 128, 'transform_funcs': (0, 9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 564.00 MiB memory in use. Process 114324 has 790.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 510.00 MiB memory in use. Process 115097 has 454.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.34 MiB is allocated by PyTorch, and 35.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ad621ed3,"{'temperature_head': 0.2, 'latent_dim': 602, 'batch_size': 375, 'transform_funcs': (0, 6, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 430.00 MiB memory in use. Process 114325 has 660.00 MiB memory in use. Process 114324 has 790.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 460.00 MiB memory in use. Process 115097 has 558.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 82.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c040ac90,"{'temperature_head': 0.1, 'latent_dim': 617, 'batch_size': 128, 'transform_funcs': (2, 5, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 432.00 MiB memory in use. Process 114325 has 660.00 MiB memory in use. Process 114324 has 790.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 486.00 MiB memory in use. Process 115097 has 560.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 103.83 MiB is allocated by PyTorch, and 42.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 46, in calculate_loss
    logits = torch.cat([torch.cat([logits_ab, logits_aa], dim=1), torch.cat([logits_ba, logits_bb], dim=1)], dim=0)
"
69994f15,"{'temperature_head': 0.2, 'latent_dim': 569, 'batch_size': 390, 'transform_funcs': (0, 4, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.41 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 432.00 MiB memory in use. Process 114325 has 660.00 MiB memory in use. Process 114324 has 790.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 486.00 MiB memory in use. Process 115097 has 560.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 98.86 MiB is allocated by PyTorch, and 47.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 48, in calculate_loss
    loss = entropy_function(logits, targets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py"", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
"
94978955,"{'temperature_head': 0.1, 'latent_dim': 587, 'batch_size': 361, 'transform_funcs': (0, 3, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.51 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 552.00 MiB memory in use. Process 114324 has 792.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.46 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 460.00 MiB memory in use. Process 115097 has 442.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 83.02 MiB is allocated by PyTorch, and 36.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
788dbb65,"{'temperature_head': 0.30000000000000004, 'latent_dim': 544, 'batch_size': 144, 'transform_funcs': (0, 8, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 322.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 192.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.51 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 510.00 MiB memory in use. Process 114325 has 430.00 MiB memory in use. Process 114324 has 742.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.46 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 524.00 MiB memory in use. Process 115097 has 454.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.59 MiB is allocated by PyTorch, and 264.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
16930dc7,"{'temperature_head': 0.4, 'latent_dim': 558, 'batch_size': 345, 'transform_funcs': (2, 7, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 330.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 108.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.51 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 430.00 MiB memory in use. Process 114324 has 792.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.46 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 454.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.89 MiB is allocated by PyTorch, and 33.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
973a455d,"{'temperature_head': 0.2, 'latent_dim': 625, 'batch_size': 421, 'transform_funcs': (0, 5, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 370.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 744.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.51 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 432.00 MiB memory in use. Process 114324 has 744.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.46 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 510.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.74 MiB is allocated by PyTorch, and 265.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f90c2205,"{'temperature_head': 0.2, 'latent_dim': 581, 'batch_size': 172, 'transform_funcs': (1, 3, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 136.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.54 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 700.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.51 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 558.00 MiB memory in use. Process 114324 has 530.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 558.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.39 MiB is allocated by PyTorch, and 33.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e2e580ee,"{'temperature_head': 0.2, 'latent_dim': 658, 'batch_size': 387, 'transform_funcs': (1, 3, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 390.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 234.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.55 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 450.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.55 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 608.00 MiB memory in use. Process 114324 has 518.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 560.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.99 MiB is allocated by PyTorch, and 39.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
484f4e4e,"{'temperature_head': 0.1, 'latent_dim': 614, 'batch_size': 409, 'transform_funcs': (6, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 364.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 134.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.55 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 450.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.55 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 564.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 560.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.65 MiB is allocated by PyTorch, and 33.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
57125e01,"{'temperature_head': 0.2, 'latent_dim': 545, 'batch_size': 183, 'transform_funcs': (1, 3, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 134.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.55 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 452.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.55 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 516.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 560.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.11 MiB is allocated by PyTorch, and 37.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b02ed431,"{'temperature_head': 0.1, 'latent_dim': 529, 'batch_size': 357, 'transform_funcs': (1, 2, 3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 64.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.55 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 674.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.55 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 516.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 454.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.00 MiB is allocated by PyTorch, and 36.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f416e23f,"{'temperature_head': 0.30000000000000004, 'latent_dim': 642, 'batch_size': 322, 'transform_funcs': (2, 3, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 380.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 306.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 536.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 674.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.55 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 986.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 516.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 892.00 MiB memory in use. Process 115097 has 456.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 519.41 MiB is allocated by PyTorch, and 32.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cb8fd923,"{'temperature_head': 0.6000000000000001, 'latent_dim': 586, 'batch_size': 336, 'transform_funcs': (1, 5, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 348.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 214.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 718.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.55 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 986.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 544.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 936.00 MiB memory in use. Process 115097 has 456.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.43 MiB is allocated by PyTorch, and 33.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dcebb3d1,"{'temperature_head': 0.2, 'latent_dim': 605, 'batch_size': 383, 'transform_funcs': (6, 9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 358.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 102.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 558.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 718.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.55 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 986.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 536.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 936.00 MiB memory in use. Process 115097 has 530.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.01 MiB is allocated by PyTorch, and 56.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
85f353cb,"{'temperature_head': 0.30000000000000004, 'latent_dim': 574, 'batch_size': 403, 'transform_funcs': (1, 5, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 82.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 718.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.55 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 988.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 522.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 936.00 MiB memory in use. Process 115097 has 560.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.33 MiB is allocated by PyTorch, and 43.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9b6f06b3,"{'temperature_head': 0.1, 'latent_dim': 535, 'batch_size': 167, 'transform_funcs': (0, 1, 2, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 318.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 148.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 718.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.55 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 920.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 568.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 940.00 MiB memory in use. Process 115097 has 560.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.95 MiB is allocated by PyTorch, and 33.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e2d3e7de,"{'temperature_head': 0.2, 'latent_dim': 669, 'batch_size': 439, 'transform_funcs': (1, 5, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 396.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 148.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 718.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.55 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 920.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 522.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 940.00 MiB memory in use. Process 115097 has 558.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.72 MiB is allocated by PyTorch, and 42.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a78f0e7a,"{'temperature_head': 0.1, 'latent_dim': 596, 'batch_size': 428, 'transform_funcs': (3, 7, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 354.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 204.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 718.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.55 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 920.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 566.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 838.00 MiB memory in use. Process 115097 has 560.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.48 MiB is allocated by PyTorch, and 359.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e0eacd95,"{'temperature_head': 0.1, 'latent_dim': 701, 'batch_size': 176, 'transform_funcs': (2, 4, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 416.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 100.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 516.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 718.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.55 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 920.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 670.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 560.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 140.32 MiB is allocated by PyTorch, and 35.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c7dc1a93,"{'temperature_head': 0.30000000000000004, 'latent_dim': 561, 'batch_size': 128, 'transform_funcs': (0, 3, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 332.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 108.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 556.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 718.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.55 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 966.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 670.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 836.00 MiB memory in use. Process 115097 has 512.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.24 MiB is allocated by PyTorch, and 357.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
13ab277f,"{'temperature_head': 0.30000000000000004, 'latent_dim': 112, 'batch_size': 351, 'transform_funcs': (4, 6, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 718.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.55 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 966.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 670.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 884.00 MiB memory in use. Process 115097 has 558.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.72 MiB is allocated by PyTorch, and 37.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
06a450fb,"{'temperature_head': 0.4, 'latent_dim': 609, 'batch_size': 419, 'transform_funcs': (0, 2, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 362.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 208.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 718.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 874.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.55 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 862.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 670.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 836.00 MiB memory in use. Process 115097 has 560.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.17 MiB is allocated by PyTorch, and 357.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
88ed51cc,"{'temperature_head': 0.7000000000000001, 'latent_dim': 539, 'batch_size': 380, 'transform_funcs': (4, 5, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 320.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 222.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 718.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 876.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 910.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 510.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 560.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.56 MiB is allocated by PyTorch, and 31.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1cfc5c50,"{'temperature_head': 0.2, 'latent_dim': 644, 'batch_size': 396, 'transform_funcs': (1, 2, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 114.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 514.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 826.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 876.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1000.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 910.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 560.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.95 MiB is allocated by PyTorch, and 35.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e6c7b611,"{'temperature_head': 0.2, 'latent_dim': 128, 'batch_size': 146, 'transform_funcs': (0, 6, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 826.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 956.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 700.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 766.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 886.00 MiB memory in use. Process 115097 has 638.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.84 MiB is allocated by PyTorch, and 37.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8d78d29f,"{'temperature_head': 0.4, 'latent_dim': 582, 'batch_size': 407, 'transform_funcs': (3, 4, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 346.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 146.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 514.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 826.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 508.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 766.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 886.00 MiB memory in use. Process 115097 has 708.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.95 MiB is allocated by PyTorch, and 35.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
da81b10a,"{'temperature_head': 0.2, 'latent_dim': 551, 'batch_size': 182, 'transform_funcs': (0, 1, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 326.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 300.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 522.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 826.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 886.00 MiB memory in use. Process 115097 has 754.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.63 MiB is allocated by PyTorch, and 33.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6e36d30e,"{'temperature_head': 0.1, 'latent_dim': 496, 'batch_size': 390, 'transform_funcs': (1, 4, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 278.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 558.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 826.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 544.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 838.00 MiB memory in use. Process 115097 has 754.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.22 MiB is allocated by PyTorch, and 360.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e66cfb35,"{'temperature_head': 0.2, 'latent_dim': 531, 'batch_size': 188, 'transform_funcs': (0, 3, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 254.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 514.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 826.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 562.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 844.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.98 MiB is allocated by PyTorch, and 35.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
16bd9971,"{'temperature_head': 0.1, 'latent_dim': 481, 'batch_size': 372, 'transform_funcs': (0, 2, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 286.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 258.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 558.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 826.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.50 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 844.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.61 MiB is allocated by PyTorch, and 36.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3c1d7076,"{'temperature_head': 0.1, 'latent_dim': 49, 'batch_size': 212, 'transform_funcs': (3, 4, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 718.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 826.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 474.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.51 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 890.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.23 MiB is allocated by PyTorch, and 37.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9797876f,"{'temperature_head': 0.2, 'latent_dim': 691, 'batch_size': 137, 'transform_funcs': (6, 7, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 410.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 702.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 678.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 524.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.51 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 884.00 MiB memory in use. Process 115097 has 918.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.68 MiB is allocated by PyTorch, and 44.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ee70174d,"{'temperature_head': 0.1, 'latent_dim': 599, 'batch_size': 398, 'transform_funcs': (1, 6, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 356.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 162.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 702.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 678.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 454.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.51 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 836.00 MiB memory in use. Process 115097 has 964.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.15 MiB is allocated by PyTorch, and 357.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e2310a08,"{'temperature_head': 0.30000000000000004, 'latent_dim': 541, 'batch_size': 169, 'transform_funcs': (1, 4, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 320.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 114.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 702.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 454.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.51 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 838.00 MiB memory in use. Process 115097 has 964.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.38 MiB is allocated by PyTorch, and 359.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9a344b5d,"{'temperature_head': 0.1, 'latent_dim': 109, 'batch_size': 197, 'transform_funcs': (0, 1, 2, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 748.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 558.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 426.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.51 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 884.00 MiB memory in use. Process 115097 has 964.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 46.22 MiB is allocated by PyTorch, and 39.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1480c7f4,"{'temperature_head': 0.30000000000000004, 'latent_dim': 620, 'batch_size': 381, 'transform_funcs': (0, 5, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 748.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 558.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 460.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.51 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 884.00 MiB memory in use. Process 115097 has 964.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 101.91 MiB is allocated by PyTorch, and 18.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
42c861b4,"{'temperature_head': 0.1, 'latent_dim': 559, 'batch_size': 425, 'transform_funcs': (2, 3, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 748.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 558.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 454.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.51 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 884.00 MiB memory in use. Process 115097 has 964.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 97.43 MiB is allocated by PyTorch, and 16.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
3991d6d5,"{'temperature_head': 0.2, 'latent_dim': 296, 'batch_size': 364, 'transform_funcs': (2, 6, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 32.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 726.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 466.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.51 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 884.00 MiB memory in use. Process 115097 has 964.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 310.65 MiB is allocated by PyTorch, and 75.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
bab4d54a,"{'temperature_head': 0.1, 'latent_dim': 583, 'batch_size': 160, 'transform_funcs': (1, 3, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 346.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 298.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 506.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 466.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.51 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 838.00 MiB memory in use. Process 115097 has 964.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.90 MiB is allocated by PyTorch, and 360.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b3891261,"{'temperature_head': 0.2, 'latent_dim': 35, 'batch_size': 333, 'transform_funcs': (0, 3, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 506.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 750.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 510.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.51 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 880.00 MiB memory in use. Process 115097 has 964.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.12 MiB is allocated by PyTorch, and 35.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e65bedcf,"{'temperature_head': 0.4, 'latent_dim': 484, 'batch_size': 144, 'transform_funcs': (0, 1, 2, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 514.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 750.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 500.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.51 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 880.00 MiB memory in use. Process 115097 has 966.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.63 MiB is allocated by PyTorch, and 36.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
816cbb24,"{'temperature_head': 0.2, 'latent_dim': 513, 'batch_size': 179, 'transform_funcs': (3, 5, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 510.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 750.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 880.00 MiB memory in use. Process 115097 has 988.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.47 MiB is allocated by PyTorch, and 33.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
562cb1b3,"{'temperature_head': 0.1, 'latent_dim': 462, 'batch_size': 433, 'transform_funcs': (2, 3, 4, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 510.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 730.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 988.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.46 MiB is allocated by PyTorch, and 36.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6e0a53db,"{'temperature_head': 0.1, 'latent_dim': 545, 'batch_size': 218, 'transform_funcs': (0, 5, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 672.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 532.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 988.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.11 MiB is allocated by PyTorch, and 33.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a8c34437,"{'temperature_head': 1.0, 'latent_dim': 719, 'batch_size': 129, 'transform_funcs': (4, 5, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 38.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 558.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 672.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 510.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 988.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.47 MiB is allocated by PyTorch, and 30.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e7c41613,"{'temperature_head': 0.2, 'latent_dim': 526, 'batch_size': 173, 'transform_funcs': (1, 2, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 312.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 90.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 514.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 674.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 454.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.48 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.95 MiB is allocated by PyTorch, and 35.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6db0a41c,"{'temperature_head': 0.1, 'latent_dim': 221, 'batch_size': 376, 'transform_funcs': (1, 2, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 454.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 672.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.53 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.57 MiB is allocated by PyTorch, and 36.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8f36b76f,"{'temperature_head': 0.30000000000000004, 'latent_dim': 592, 'batch_size': 148, 'transform_funcs': (1, 5, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 350.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 454.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 672.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 558.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.53 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 838.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.79 MiB is allocated by PyTorch, and 359.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3d588896,"{'temperature_head': 0.1, 'latent_dim': 77, 'batch_size': 358, 'transform_funcs': (1, 2, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 456.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 674.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.51 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 880.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.44 MiB is allocated by PyTorch, and 37.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9a7d4764,"{'temperature_head': 0.2, 'latent_dim': 572, 'batch_size': 138, 'transform_funcs': (0, 2, 3, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 466.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 674.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.51 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 880.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.32 MiB is allocated by PyTorch, and 33.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2e2643de,"{'temperature_head': 0.30000000000000004, 'latent_dim': 448, 'batch_size': 441, 'transform_funcs': (1, 7, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 162.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 514.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 562.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.51 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.35 MiB is allocated by PyTorch, and 36.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d8be164d,"{'temperature_head': 0.7000000000000001, 'latent_dim': 183, 'batch_size': 417, 'transform_funcs': (2, 3, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 622.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 562.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.51 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 243.46 MiB is allocated by PyTorch, and 38.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2865fb50,"{'temperature_head': 0.1, 'latent_dim': 489, 'batch_size': 344, 'transform_funcs': (1, 2, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 290.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 670.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 456.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.51 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.67 MiB is allocated by PyTorch, and 36.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
8e98d795,"{'temperature_head': 0.1, 'latent_dim': 525, 'batch_size': 238, 'transform_funcs': (0, 1, 3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 312.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 142.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 568.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 456.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 540.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.51 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.44 MiB is allocated by PyTorch, and 90.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7781229e,"{'temperature_head': 0.8, 'latent_dim': 554, 'batch_size': 202, 'transform_funcs': (1, 3, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 328.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 248.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.01 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.95 MiB is allocated by PyTorch, and 33.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
be8188e5,"{'temperature_head': 0.2, 'latent_dim': 677, 'batch_size': 157, 'transform_funcs': (3, 5, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 402.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 250.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 558.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.01 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.14 MiB is allocated by PyTorch, and 32.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7f7db40d,"{'temperature_head': 0.30000000000000004, 'latent_dim': 509, 'batch_size': 394, 'transform_funcs': (2, 3, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 302.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 160.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.01 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.82 MiB is allocated by PyTorch, and 36.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3a0dc6d3,"{'temperature_head': 0.1, 'latent_dim': 317, 'batch_size': 384, 'transform_funcs': (1, 7, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 702.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.01 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 324.32 MiB is allocated by PyTorch, and 37.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8f098e58,"{'temperature_head': 0.5, 'latent_dim': 567, 'batch_size': 410, 'transform_funcs': (5, 6, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 504.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.01 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 720.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 516.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.28 MiB is allocated by PyTorch, and 37.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2c12ca64,"{'temperature_head': 0.2, 'latent_dim': 535, 'batch_size': 297, 'transform_funcs': (3, 4, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 318.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 242.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 832.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 472.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 720.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 562.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 454.98 MiB is allocated by PyTorch, and 37.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
08970d7b,"{'temperature_head': 0.1, 'latent_dim': 499, 'batch_size': 351, 'transform_funcs': (1, 2, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 86.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.05 GiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 454.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 510.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 700.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 433.24 MiB is allocated by PyTorch, and 300.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
4ff7360b,"{'temperature_head': 0.1, 'latent_dim': 65, 'batch_size': 147, 'transform_funcs': (2, 7, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 416.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 560.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 1.26 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 994.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.87 MiB is allocated by PyTorch, and 30.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
86f79ca2,"{'temperature_head': 0.1, 'latent_dim': 549, 'batch_size': 210, 'transform_funcs': (0, 3, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 4.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 456.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 560.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 1.26 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 994.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 93.22 MiB is allocated by PyTorch, and 22.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
d2671988,"{'temperature_head': 0.2, 'latent_dim': 520, 'batch_size': 341, 'transform_funcs': (2, 4, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 40.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 508.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 556.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 1.26 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 994.00 MiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.91 MiB is allocated by PyTorch, and 30.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
76c46035,"{'temperature_head': 0.30000000000000004, 'latent_dim': 84, 'batch_size': 194, 'transform_funcs': (0, 3, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 510.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 554.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 454.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 1.26 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 884.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.50 MiB is allocated by PyTorch, and 35.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9d473eaf,"{'temperature_head': 0.30000000000000004, 'latent_dim': 477, 'batch_size': 128, 'transform_funcs': (2, 7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 140.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 796.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 922.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 528.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 434.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 884.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 419.58 MiB is allocated by PyTorch, and 36.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
30171921,"{'temperature_head': 0.1, 'latent_dim': 606, 'batch_size': 129, 'transform_funcs': (0, 1, 4, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 360.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 80.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 528.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 922.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 730.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 608.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 836.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.52 MiB is allocated by PyTorch, and 357.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b8aea5f1,"{'temperature_head': 0.1, 'latent_dim': 662, 'batch_size': 324, 'transform_funcs': (0, 3, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 96.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 514.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.11 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 608.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.02 MiB is allocated by PyTorch, and 34.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
bef4d372,"{'temperature_head': 0.30000000000000004, 'latent_dim': 275, 'batch_size': 446, 'transform_funcs': (1, 4, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 96.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.11 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 610.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.99 MiB is allocated by PyTorch, and 36.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d5a23618,"{'temperature_head': 0.1, 'latent_dim': 536, 'batch_size': 357, 'transform_funcs': (7, 8, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 318.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.11 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 500.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 624.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 836.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.16 MiB is allocated by PyTorch, and 357.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1c454d67,"{'temperature_head': 0.2, 'latent_dim': 236, 'batch_size': 391, 'transform_funcs': (2, 4, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 140.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 100.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.11 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 500.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 624.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 836.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.69 MiB is allocated by PyTorch, and 36.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
98ca9914,"{'temperature_head': 0.30000000000000004, 'latent_dim': 499, 'batch_size': 381, 'transform_funcs': (1, 3, 4, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 166.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 882.00 MiB memory in use. Process 113907 has 1.11 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 500.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 510.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 884.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.75 MiB is allocated by PyTorch, and 34.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7f85dfdb,"{'temperature_head': 0.1, 'latent_dim': 513, 'batch_size': 199, 'transform_funcs': (3, 6, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 304.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 558.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 882.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 518.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 884.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.92 MiB is allocated by PyTorch, and 40.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0eb6be86,"{'temperature_head': 0.2, 'latent_dim': 646, 'batch_size': 140, 'transform_funcs': (2, 6, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 108.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 558.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 882.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 754.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 564.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 836.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.39 MiB is allocated by PyTorch, and 357.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0e0a3286,"{'temperature_head': 0.1, 'latent_dim': 572, 'batch_size': 153, 'transform_funcs': (4, 6, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 514.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 882.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 810.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 564.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 884.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.95 MiB is allocated by PyTorch, and 35.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5aede59b,"{'temperature_head': 0.30000000000000004, 'latent_dim': 253, 'batch_size': 365, 'transform_funcs': (1, 5, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 882.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 454.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 896.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.55 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 836.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 284.89 MiB is allocated by PyTorch, and 211.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
a5bd57b1,"{'temperature_head': 0.4, 'latent_dim': 488, 'batch_size': 415, 'transform_funcs': (0, 3, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 290.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 514.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 882.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 456.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 896.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.56 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.01 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.66 MiB is allocated by PyTorch, and 36.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d52e0ef0,"{'temperature_head': 0.7000000000000001, 'latent_dim': 618, 'batch_size': 397, 'transform_funcs': (3, 7, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 102.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 558.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 468.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 896.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.56 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 1.17 GiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 504.71 MiB is allocated by PyTorch, and 357.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
568b54cc,"{'temperature_head': 0.1, 'latent_dim': 164, 'batch_size': 348, 'transform_funcs': (0, 3, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 612.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 456.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 456.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 896.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.56 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 1.22 GiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 232.08 MiB is allocated by PyTorch, and 39.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
92fdfcf2,"{'temperature_head': 0.30000000000000004, 'latent_dim': 425, 'batch_size': 407, 'transform_funcs': (3, 5, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 516.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 510.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 512.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 896.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.56 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 1.22 GiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.17 MiB is allocated by PyTorch, and 38.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8f5207df,"{'temperature_head': 0.2, 'latent_dim': 538, 'batch_size': 171, 'transform_funcs': (3, 4, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 320.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 612.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 424.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 896.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.58 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 1.17 GiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 455.93 MiB is allocated by PyTorch, and 406.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cde9eff2,"{'temperature_head': 0.2, 'latent_dim': 60, 'batch_size': 209, 'transform_funcs': (0, 2, 3, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 892.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.13 GiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 896.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 508.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 660.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.31 MiB is allocated by PyTorch, and 33.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
60e129a1,"{'temperature_head': 0.2, 'latent_dim': 104, 'batch_size': 369, 'transform_funcs': (1, 4, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 892.00 MiB memory in use. Process 110622 has 1.09 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.14 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.13 GiB memory in use. Process 114325 has 710.00 MiB memory in use. Process 114324 has 896.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 662.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.66 MiB is allocated by PyTorch, and 39.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e9d1d2f1,"{'temperature_head': 0.2, 'latent_dim': 523, 'batch_size': 192, 'transform_funcs': (0, 5, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 80.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1014.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 880.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 800.00 MiB memory in use. Process 114324 has 886.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 764.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 752.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 447.44 MiB is allocated by PyTorch, and 98.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
046d82a8,"{'temperature_head': 0.1, 'latent_dim': 552, 'batch_size': 204, 'transform_funcs': (0, 2, 3, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 328.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 254.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 764.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1004.00 MiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1006.00 MiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 800.00 MiB memory in use. Process 114324 has 932.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 928.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 540.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.66 MiB is allocated by PyTorch, and 62.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f71809fc,"{'temperature_head': 0.2, 'latent_dim': 510, 'batch_size': 188, 'transform_funcs': (2, 3, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 302.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 158.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 810.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.03 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 508.00 MiB memory in use. Process 114325 has 800.00 MiB memory in use. Process 114324 has 936.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 830.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 636.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 439.33 MiB is allocated by PyTorch, and 50.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c9e20aae,"{'temperature_head': 0.1, 'latent_dim': 546, 'batch_size': 196, 'transform_funcs': (1, 2, 3, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 162.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 812.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.08 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 454.00 MiB memory in use. Process 114325 has 800.00 MiB memory in use. Process 114324 has 1.15 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 760.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 456.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.60 MiB is allocated by PyTorch, and 281.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
01bac39b,"{'temperature_head': 0.2, 'latent_dim': 141, 'batch_size': 178, 'transform_funcs': (2, 6, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 812.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.08 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 454.00 MiB memory in use. Process 114325 has 800.00 MiB memory in use. Process 114324 has 1.15 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 804.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.95 MiB is allocated by PyTorch, and 37.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
f53f6756,"{'temperature_head': 0.1, 'latent_dim': 566, 'batch_size': 143, 'transform_funcs': (1, 2, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 336.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 918.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.08 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 800.00 MiB memory in use. Process 114324 has 1.15 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 806.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 434.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 472.39 MiB is allocated by PyTorch, and 105.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
03690e66,"{'temperature_head': 0.2, 'latent_dim': 503, 'batch_size': 225, 'transform_funcs': (1, 4, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 816.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 800.00 MiB memory in use. Process 114324 has 1.15 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 806.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 434.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 435.78 MiB is allocated by PyTorch, and 40.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
383a0c0d,"{'temperature_head': 0.2, 'latent_dim': 529, 'batch_size': 156, 'transform_funcs': (2, 4, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 116.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 816.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1002.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 800.00 MiB memory in use. Process 114324 has 1.15 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 758.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 434.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.48 MiB is allocated by PyTorch, and 280.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
4f3c600f,"{'temperature_head': 0.1, 'latent_dim': 18, 'batch_size': 170, 'transform_funcs': (0, 6, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 852.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1016.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 496.00 MiB memory in use. Process 114325 has 800.00 MiB memory in use. Process 114324 has 1.15 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 768.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 420.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.51 MiB is allocated by PyTorch, and 34.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c7536f54,"{'temperature_head': 0.1, 'latent_dim': 98, 'batch_size': 161, 'transform_funcs': (2, 6, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 860.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1016.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 496.00 MiB memory in use. Process 114325 has 800.00 MiB memory in use. Process 114324 has 1.15 GiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 802.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 422.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 54.18 MiB is allocated by PyTorch, and 27.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/dataset_simcrl.py"", line 42, in get_transformed_items
    transform_1 = torch.tensor(transform_1, dtype=torch.float32).to(self.device)
"
45289f89,"{'temperature_head': 0.1, 'latent_dim': 472, 'batch_size': 183, 'transform_funcs': (0, 8, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.01 GiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1016.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 964.00 MiB memory in use. Process 114325 has 798.00 MiB memory in use. Process 114324 has 498.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 804.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 454.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 417.03 MiB is allocated by PyTorch, and 276.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6ae5ee0a,"{'temperature_head': 0.2, 'latent_dim': 441, 'batch_size': 152, 'transform_funcs': (2, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 262.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 168.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 434.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1016.00 MiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 964.00 MiB memory in use. Process 114325 has 798.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 804.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.29 MiB is allocated by PyTorch, and 36.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9ce9b1c8,"{'temperature_head': 0.1, 'latent_dim': 57, 'batch_size': 133, 'transform_funcs': (3, 5, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 44.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 420.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 964.00 MiB memory in use. Process 114325 has 846.00 MiB memory in use. Process 114324 has 558.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 804.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.81 MiB is allocated by PyTorch, and 34.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
51df27a5,"{'temperature_head': 0.30000000000000004, 'latent_dim': 605, 'batch_size': 374, 'transform_funcs': (0, 1, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 460.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 964.00 MiB memory in use. Process 114325 has 846.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 804.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.58 MiB is allocated by PyTorch, and 35.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d136bb2e,"{'temperature_head': 0.2, 'latent_dim': 479, 'batch_size': 169, 'transform_funcs': (1, 2, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 516.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 964.00 MiB memory in use. Process 114325 has 846.00 MiB memory in use. Process 114324 has 456.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 804.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.59 MiB is allocated by PyTorch, and 38.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
51cd6cee,"{'temperature_head': 0.1, 'latent_dim': 576, 'batch_size': 128, 'transform_funcs': (1, 3, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 342.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 96.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 516.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 964.00 MiB memory in use. Process 114325 has 846.00 MiB memory in use. Process 114324 has 456.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 758.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.00 MiB is allocated by PyTorch, and 280.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
38773032,"{'temperature_head': 0.2, 'latent_dim': 537, 'batch_size': 189, 'transform_funcs': (6, 7, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 318.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 122.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 876.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 806.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.95 MiB is allocated by PyTorch, and 33.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
af5f3441,"{'temperature_head': 0.1, 'latent_dim': 556, 'batch_size': 388, 'transform_funcs': (2, 4, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 330.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 126.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 556.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 876.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 758.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.69 MiB is allocated by PyTorch, and 280.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9af45ddc,"{'temperature_head': 0.30000000000000004, 'latent_dim': 598, 'batch_size': 128, 'transform_funcs': (1, 5, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 354.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 124.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 510.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 876.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 806.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.13 MiB is allocated by PyTorch, and 30.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
659c1174,"{'temperature_head': 0.8, 'latent_dim': 492, 'batch_size': 420, 'transform_funcs': (1, 2, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 292.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 122.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 558.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 876.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 760.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.19 MiB is allocated by PyTorch, and 282.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c2a4db9d,"{'temperature_head': 0.1, 'latent_dim': 456, 'batch_size': 216, 'transform_funcs': (4, 6, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 270.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 124.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 876.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 804.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.41 MiB is allocated by PyTorch, and 34.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
dd3d1590,"{'temperature_head': 0.1, 'latent_dim': 513, 'batch_size': 161, 'transform_funcs': (4, 5, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 136.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 526.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 510.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 812.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 804.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 441.86 MiB is allocated by PyTorch, and 30.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
87bff697,"{'temperature_head': 0.5, 'latent_dim': 637, 'batch_size': 167, 'transform_funcs': (0, 5, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 378.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 858.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 804.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.83 MiB is allocated by PyTorch, and 33.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c4f62614,"{'temperature_head': 0.2, 'latent_dim': 530, 'batch_size': 407, 'transform_funcs': (0, 1, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 158.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 758.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 804.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.48 MiB is allocated by PyTorch, and 280.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e2abcb01,"{'temperature_head': 0.30000000000000004, 'latent_dim': 333, 'batch_size': 354, 'transform_funcs': (0, 2, 3, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 130.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 714.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 502.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 804.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 964.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 333.32 MiB is allocated by PyTorch, and 40.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d7caa60e,"{'temperature_head': 0.1, 'latent_dim': 477, 'batch_size': 143, 'transform_funcs': (3, 4, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 78.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 756.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 804.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 964.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.57 MiB is allocated by PyTorch, and 34.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a18238b1,"{'temperature_head': 0.4, 'latent_dim': 506, 'batch_size': 428, 'transform_funcs': (0, 2, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 172.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 772.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 554.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 806.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 810.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 437.80 MiB is allocated by PyTorch, and 32.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6ea2056c,"{'temperature_head': 0.1, 'latent_dim': 544, 'batch_size': 135, 'transform_funcs': (7, 8, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 322.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 144.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 802.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 554.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 758.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 856.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.59 MiB is allocated by PyTorch, and 280.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9f5c39e6,"{'temperature_head': 0.1, 'latent_dim': 563, 'batch_size': 396, 'transform_funcs': (2, 3, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 334.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 126.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 820.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 508.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 804.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 856.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.90 MiB is allocated by PyTorch, and 29.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
77d8df46,"{'temperature_head': 0.2, 'latent_dim': 445, 'batch_size': 172, 'transform_funcs': (0, 2, 3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 180.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 820.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 806.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 752.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.82 MiB is allocated by PyTorch, and 275.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7cb8e3fa,"{'temperature_head': 0.1, 'latent_dim': 467, 'batch_size': 156, 'transform_funcs': (2, 6, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 278.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 106.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 944.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 506.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 806.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 796.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.50 MiB is allocated by PyTorch, and 34.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
286e2c8d,"{'temperature_head': 0.1, 'latent_dim': 616, 'batch_size': 388, 'transform_funcs': (3, 9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 498.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 554.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 658.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.10 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 798.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 502.34 MiB is allocated by PyTorch, and 283.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8ef076d9,"{'temperature_head': 0.2, 'latent_dim': 589, 'batch_size': 162, 'transform_funcs': (5, 7, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 350.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 266.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 500.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 474.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 508.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.14 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 752.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.45 MiB is allocated by PyTorch, and 29.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
922ae67c,"{'temperature_head': 0.1, 'latent_dim': 493, 'batch_size': 128, 'transform_funcs': (0, 4, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 292.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 184.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 514.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 496.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 554.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.14 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 752.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.70 MiB is allocated by PyTorch, and 36.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a72d09c1,"{'temperature_head': 0.30000000000000004, 'latent_dim': 432, 'batch_size': 399, 'transform_funcs': (0, 2, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 832.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 604.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.10 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 494.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 392.12 MiB is allocated by PyTorch, and 391.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e7bb57a6,"{'temperature_head': 0.1, 'latent_dim': 564, 'batch_size': 339, 'transform_funcs': (2, 3, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 334.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 832.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 604.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.14 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 494.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.95 MiB is allocated by PyTorch, and 33.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3904bc1f,"{'temperature_head': 0.1, 'latent_dim': 407, 'batch_size': 369, 'transform_funcs': (1, 6, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 98.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 558.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 832.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 500.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.14 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.03 MiB is allocated by PyTorch, and 34.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d3ab6c8c,"{'temperature_head': 0.2, 'latent_dim': 463, 'batch_size': 224, 'transform_funcs': (3, 7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 620.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 878.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.14 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 472.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.46 MiB is allocated by PyTorch, and 34.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
170c9163,"{'temperature_head': 0.30000000000000004, 'latent_dim': 486, 'batch_size': 385, 'transform_funcs': (2, 4, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 620.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 878.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 454.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.14 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 518.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.64 MiB is allocated by PyTorch, and 40.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
01e8dff9,"{'temperature_head': 1.0, 'latent_dim': 509, 'batch_size': 197, 'transform_funcs': (0, 3, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 302.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 46.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 432.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 950.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 642.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.10 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 472.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 438.24 MiB is allocated by PyTorch, and 349.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
da7e7d7f,"{'temperature_head': 0.2, 'latent_dim': 3, 'batch_size': 351, 'transform_funcs': (4, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 418.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 950.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 642.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.14 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 472.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 45.39 MiB is allocated by PyTorch, and 32.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2f3fbb1a,"{'temperature_head': 0.30000000000000004, 'latent_dim': 175, 'batch_size': 326, 'transform_funcs': (0, 1, 3, 4)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 432.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 950.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 642.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.14 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 472.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 62.72 MiB is allocated by PyTorch, and 29.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 97, in fit
    batched_dataset = ds.get_transformed_items(self.batch_size, self.is_transform_function_vectorized)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/dataset_simcrl.py"", line 43, in get_transformed_items
    transform_2 = torch.tensor(transform_2, dtype=torch.float32).to(self.device)
"
e00b9e21,"{'temperature_head': 0.1, 'latent_dim': 304, 'batch_size': 419, 'transform_funcs': (1, 3, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 432.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 950.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 642.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.14 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 452.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 80.22 MiB is allocated by PyTorch, and 31.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
5186db4b,"{'temperature_head': 0.2, 'latent_dim': 604, 'batch_size': 143, 'transform_funcs': (4, 6, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 444.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 950.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 642.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.14 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 452.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 99.30 MiB is allocated by PyTorch, and 4.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
68961f01,"{'temperature_head': 0.1, 'latent_dim': 531, 'batch_size': 183, 'transform_funcs': (0, 4, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 186.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 464.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 950.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 510.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 1.10 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 434.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 451.42 MiB is allocated by PyTorch, and 334.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
514df6ee,"{'temperature_head': 0.2, 'latent_dim': 575, 'batch_size': 137, 'transform_funcs': (5, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.04 GiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 960.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 510.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 610.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 500.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.34 MiB is allocated by PyTorch, and 31.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3a176b32,"{'temperature_head': 0.1, 'latent_dim': 450, 'batch_size': 434, 'transform_funcs': (2, 3, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 30.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.04 GiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 960.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 610.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 440.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 48.89 MiB is allocated by PyTorch, and 51.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 24, in forward
    x = self.conv1(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6ec54117,"{'temperature_head': 0.1, 'latent_dim': 503, 'batch_size': 334, 'transform_funcs': (0, 1, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.04 GiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 960.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 610.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 468.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 93.19 MiB is allocated by PyTorch, and 34.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 24, in forward
    loss = self.calculate_loss(hidden_features_transform_1, hidden_features_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 48, in calculate_loss
    loss = entropy_function(logits, targets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py"", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
"
7f58dc01,"{'temperature_head': 0.5, 'latent_dim': 559, 'batch_size': 361, 'transform_funcs': (0, 3, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 332.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 118.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.04 GiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 960.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 508.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 454.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.22 MiB is allocated by PyTorch, and 29.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0dc49b84,"{'temperature_head': 0.2, 'latent_dim': 135, 'batch_size': 410, 'transform_funcs': (0, 2, 5, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 1.09 GiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 960.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 554.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 454.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.90 MiB is allocated by PyTorch, and 35.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9eb5df36,"{'temperature_head': 0.2, 'latent_dim': 633, 'batch_size': 128, 'transform_funcs': (1, 2, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 376.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 206.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 514.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1006.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 888.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 554.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 502.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 513.26 MiB is allocated by PyTorch, and 34.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
8dd1455d,"{'temperature_head': 0.1, 'latent_dim': 58, 'batch_size': 148, 'transform_funcs': (2, 3, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 514.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.06 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 936.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 564.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 568.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 168.59 MiB is allocated by PyTorch, and 55.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
0f555ada,"{'temperature_head': 0.1, 'latent_dim': 592, 'batch_size': 377, 'transform_funcs': (2, 3, 5, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 350.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 118.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 514.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.06 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 832.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 610.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 510.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.34 MiB is allocated by PyTorch, and 353.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1ecf7028,"{'temperature_head': 0.2, 'latent_dim': 521, 'batch_size': 168, 'transform_funcs': (5, 9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 74.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.06 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 878.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 610.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 510.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.93 MiB is allocated by PyTorch, and 34.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c4885f56,"{'temperature_head': 0.2, 'latent_dim': 547, 'batch_size': 194, 'transform_funcs': (0, 5, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 562.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.06 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 878.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 610.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 526.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.73 MiB is allocated by PyTorch, and 47.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fce3d603,"{'temperature_head': 0.1, 'latent_dim': 149, 'batch_size': 157, 'transform_funcs': (0, 1, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 562.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.06 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 878.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 600.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 526.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 223.10 MiB is allocated by PyTorch, and 36.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
00eac868,"{'temperature_head': 0.30000000000000004, 'latent_dim': 478, 'batch_size': 401, 'transform_funcs': (4, 5, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 152.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.06 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 878.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 472.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 570.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.58 MiB is allocated by PyTorch, and 34.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0fc88f32,"{'temperature_head': 0.2, 'latent_dim': 285, 'batch_size': 354, 'transform_funcs': (0, 7, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 880.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 510.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 566.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.07 MiB is allocated by PyTorch, and 33.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d73f0960,"{'temperature_head': 0.30000000000000004, 'latent_dim': 90, 'batch_size': 453, 'transform_funcs': (1, 3, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 24.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 880.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 456.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 614.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 78.55 MiB is allocated by PyTorch, and 37.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ba84ba6f,"{'temperature_head': 0.1, 'latent_dim': 536, 'batch_size': 230, 'transform_funcs': (2, 6, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 2.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 880.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 478.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 614.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 92.03 MiB is allocated by PyTorch, and 45.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 23, in forward
    hidden_features_transform_2 = model(samples_transform_2)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/simcrl_head.py"", line 20, in forward
    projection_1 = self.projection_1(base_model_output)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
"
919cbbff,"{'temperature_head': 0.2, 'latent_dim': 575, 'batch_size': 366, 'transform_funcs': (0, 7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 514.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 880.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 478.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 614.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.34 MiB is allocated by PyTorch, and 35.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b903fbd2,"{'temperature_head': 0.1, 'latent_dim': 651, 'batch_size': 343, 'transform_funcs': (2, 4, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 386.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 832.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 478.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 614.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.43 MiB is allocated by PyTorch, and 353.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d71bb86a,"{'temperature_head': 0.2, 'latent_dim': 121, 'batch_size': 133, 'transform_funcs': (4, 5, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 878.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 478.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 582.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 206.79 MiB is allocated by PyTorch, and 35.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
44fdc1dd,"{'temperature_head': 0.2, 'latent_dim': 496, 'batch_size': 147, 'transform_funcs': (2, 5, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 294.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 878.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 516.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 522.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.72 MiB is allocated by PyTorch, and 38.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5d4ee426,"{'temperature_head': 0.4, 'latent_dim': 625, 'batch_size': 187, 'transform_funcs': (0, 2, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 878.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 524.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.73 MiB is allocated by PyTorch, and 45.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
fc7e37a7,"{'temperature_head': 0.1, 'latent_dim': 434, 'batch_size': 165, 'transform_funcs': (6, 7, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 130.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 878.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 454.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.24 MiB is allocated by PyTorch, and 34.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
db25f086,"{'temperature_head': 0.2, 'latent_dim': 218, 'batch_size': 203, 'transform_funcs': (0, 2, 6, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 878.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.55 MiB is allocated by PyTorch, and 38.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
22a5007f,"{'temperature_head': 0.2, 'latent_dim': 352, 'batch_size': 158, 'transform_funcs': (2, 4, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 878.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 560.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.60 MiB is allocated by PyTorch, and 35.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0a0f8616,"{'temperature_head': 0.1, 'latent_dim': 669, 'batch_size': 173, 'transform_funcs': (0, 2, 3, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 396.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 116.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 878.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.08 MiB is allocated by PyTorch, and 34.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
15fb59fc,"{'temperature_head': 0.30000000000000004, 'latent_dim': 516, 'batch_size': 380, 'transform_funcs': (2, 4, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 306.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 128.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 510.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 880.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 454.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 562.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.88 MiB is allocated by PyTorch, and 32.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cd657219,"{'temperature_head': 0.2, 'latent_dim': 104, 'batch_size': 393, 'transform_funcs': (0, 7, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 12.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 510.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 880.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 570.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 562.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 196.66 MiB is allocated by PyTorch, and 33.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
80bacf61,"{'temperature_head': 0.1, 'latent_dim': 463, 'batch_size': 412, 'transform_funcs': (3, 4, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 86.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 530.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 880.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 524.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.46 MiB is allocated by PyTorch, and 36.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
284b4623,"{'temperature_head': 0.2, 'latent_dim': 482, 'batch_size': 369, 'transform_funcs': (1, 5, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 286.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 516.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 880.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 556.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.61 MiB is allocated by PyTorch, and 38.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cfcfaa35,"{'temperature_head': 0.1, 'latent_dim': 557, 'batch_size': 139, 'transform_funcs': (5, 6, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 330.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 76.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 558.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 832.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 556.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.69 MiB is allocated by PyTorch, and 354.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
86e9b114,"{'temperature_head': 0.1, 'latent_dim': 710, 'batch_size': 403, 'transform_funcs': (3, 6, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 558.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 878.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 514.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 556.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.40 MiB is allocated by PyTorch, and 34.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9c2697d0,"{'temperature_head': 0.9, 'latent_dim': 57, 'batch_size': 383, 'transform_funcs': (1, 2, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 568.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 878.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 504.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 556.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 167.99 MiB is allocated by PyTorch, and 60.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
2d1d3f71,"{'temperature_head': 0.30000000000000004, 'latent_dim': 541, 'batch_size': 359, 'transform_funcs': (3, 7, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 320.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 132.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 498.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 830.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 506.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 568.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.57 MiB is allocated by PyTorch, and 352.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e7971bc1,"{'temperature_head': 0.5, 'latent_dim': 402, 'batch_size': 174, 'transform_funcs': (1, 2, 4, 5)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 514.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 880.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 506.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 568.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.99 MiB is allocated by PyTorch, and 37.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
35f6b25d,"{'temperature_head': 0.30000000000000004, 'latent_dim': 450, 'batch_size': 260, 'transform_funcs': (3, 4, 6, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 124.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.11 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 880.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 506.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.36 MiB is allocated by PyTorch, and 34.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6d82fd94,"{'temperature_head': 0.1, 'latent_dim': 609, 'batch_size': 419, 'transform_funcs': (8, 9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 362.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 558.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.12 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 880.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 510.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.61 MiB is allocated by PyTorch, and 31.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
7c748367,"{'temperature_head': 0.2, 'latent_dim': 83, 'batch_size': 250, 'transform_funcs': (2, 3, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 564.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.12 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 880.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 556.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 183.56 MiB is allocated by PyTorch, and 40.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
1d57244c,"{'temperature_head': 0.1, 'latent_dim': 592, 'batch_size': 193, 'transform_funcs': (2, 6, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 350.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 112.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 454.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.12 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 882.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.47 MiB is allocated by PyTorch, and 35.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e7048717,"{'temperature_head': 0.2, 'latent_dim': 98, 'batch_size': 345, 'transform_funcs': (0, 2, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 510.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.12 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 882.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 558.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.61 MiB is allocated by PyTorch, and 35.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
caf44051,"{'temperature_head': 0.4, 'latent_dim': 572, 'batch_size': 147, 'transform_funcs': (1, 9, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 114.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 456.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.12 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 882.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 802.00 MiB memory in use. Process 114717 has 508.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.32 MiB is allocated by PyTorch, and 29.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
6a1ea990,"{'temperature_head': 0.1, 'latent_dim': 425, 'batch_size': 374, 'transform_funcs': (0, 6, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 66.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 456.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.17 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 882.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 792.00 MiB memory in use. Process 114717 has 566.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.17 MiB is allocated by PyTorch, and 36.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3ebcec11,"{'temperature_head': 0.2, 'latent_dim': 237, 'batch_size': 134, 'transform_funcs': (2, 3, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 10.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.17 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 882.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 792.00 MiB memory in use. Process 114717 has 566.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.70 MiB is allocated by PyTorch, and 36.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9b87a6d3,"{'temperature_head': 0.2, 'latent_dim': 43, 'batch_size': 305, 'transform_funcs': (1, 5, 6, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.17 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 882.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 792.00 MiB memory in use. Process 114717 has 500.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 506.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.18 MiB is allocated by PyTorch, and 31.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
10a6ffe3,"{'temperature_head': 0.1, 'latent_dim': 499, 'batch_size': 334, 'transform_funcs': (0, 1, 5, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 82.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 560.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.17 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 834.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 792.00 MiB memory in use. Process 114717 has 502.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 506.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.24 MiB is allocated by PyTorch, and 356.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
1f0127c3,"{'temperature_head': 0.30000000000000004, 'latent_dim': 513, 'batch_size': 160, 'transform_funcs': (0, 1, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 22.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 874.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.17 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 472.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.86 MiB is allocated by PyTorch, and 34.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
d42ab62b,"{'temperature_head': 0.2, 'latent_dim': 477, 'batch_size': 150, 'transform_funcs': (1, 3, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 118.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 874.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.12 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 472.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 508.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 510.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.57 MiB is allocated by PyTorch, and 32.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0e9ea75b,"{'temperature_head': 0.2, 'latent_dim': 558, 'batch_size': 179, 'transform_funcs': (4, 6, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 330.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 58.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 874.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.12 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 472.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 526.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 552.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.04 MiB is allocated by PyTorch, and 46.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3cd31b5c,"{'temperature_head': 0.1, 'latent_dim': 318, 'batch_size': 199, 'transform_funcs': (1, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 28.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 874.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.12 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 454.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 570.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 554.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 80.33 MiB is allocated by PyTorch, and 33.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 25, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
3bc0355c,"{'temperature_head': 0.4, 'latent_dim': 621, 'batch_size': 429, 'transform_funcs': (0, 3, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 874.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.12 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 464.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 570.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 554.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 102.54 MiB is allocated by PyTorch, and 21.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 48, in fit
    self.full_model.fit(X,y,X_val,y_val)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/simcrl_full_estimator.py"", line 55, in fit
    trained_simcrl_model,epoch_wise_loss = self.simcrl.fit(X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 103, in fit
    loss, gradients = nt_xent_loss(transform_1, transform_2, self.model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 25, in forward
    gradients = self.calculate_gradients(loss, model)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl.py"", line 53, in calculate_gradients
    gradients = torch.autograd.grad(loss, model.parameters())

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 394, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
ab89e6a7,"{'temperature_head': 0.2, 'latent_dim': 441, 'batch_size': 407, 'transform_funcs': (2, 3, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 512.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.12 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 568.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 674.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 706.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.29 MiB is allocated by PyTorch, and 34.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
ae42e64f,"{'temperature_head': 0.2, 'latent_dim': 583, 'batch_size': 129, 'transform_funcs': (3, 4, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 346.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 306.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 856.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 618.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 674.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 706.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 483.07 MiB is allocated by PyTorch, and 32.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
20300cdd,"{'temperature_head': 0.30000000000000004, 'latent_dim': 488, 'batch_size': 482, 'transform_funcs': (4, 7, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 290.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 224.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 906.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 764.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 752.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.66 MiB is allocated by PyTorch, and 36.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
c7846576,"{'temperature_head': 0.2, 'latent_dim': 531, 'batch_size': 172, 'transform_funcs': (2, 5, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 98.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 906.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 764.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 836.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 451.50 MiB is allocated by PyTorch, and 44.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
89bc2f2c,"{'temperature_head': 0.8, 'latent_dim': 3, 'batch_size': 364, 'transform_funcs': (0, 2, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 56.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 906.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 514.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 510.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 764.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 882.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 133.87 MiB is allocated by PyTorch, and 36.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
effb82b2,"{'temperature_head': 0.1, 'latent_dim': 642, 'batch_size': 158, 'transform_funcs': (0, 5, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 380.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 140.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 802.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 540.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 500.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 766.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 884.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.36 MiB is allocated by PyTorch, and 323.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2592de9d,"{'temperature_head': 0.1, 'latent_dim': 501, 'batch_size': 215, 'transform_funcs': (2, 4, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 848.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 516.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 766.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 884.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.76 MiB is allocated by PyTorch, and 38.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
77de560c,"{'temperature_head': 0.2, 'latent_dim': 542, 'batch_size': 348, 'transform_funcs': (4, 5, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 322.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 136.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 848.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 766.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 766.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.61 MiB is allocated by PyTorch, and 288.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
0059bb5a,"{'temperature_head': 0.30000000000000004, 'latent_dim': 336, 'batch_size': 128, 'transform_funcs': (2, 5, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 194.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 848.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 508.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 710.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 812.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 335.12 MiB is allocated by PyTorch, and 34.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c781c0d5,"{'temperature_head': 0.2, 'latent_dim': 561, 'batch_size': 144, 'transform_funcs': (2, 5, 6, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 332.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 142.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 848.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 760.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 766.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.46 MiB is allocated by PyTorch, and 287.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
631edeff,"{'temperature_head': 0.5, 'latent_dim': 602, 'batch_size': 437, 'transform_funcs': (4, 7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 356.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 202.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 848.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 556.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 560.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 656.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 810.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.01 MiB is allocated by PyTorch, and 176.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
3b5cc126,"{'temperature_head': 0.1, 'latent_dim': 523, 'batch_size': 329, 'transform_funcs': (2, 3, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 52.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 848.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.12 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 708.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 510.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 702.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 812.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.11 MiB is allocated by PyTorch, and 31.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
11460591,"{'temperature_head': 0.1, 'latent_dim': 80, 'batch_size': 503, 'transform_funcs': (1, 2, 5, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 802.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 698.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 798.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 812.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.47 MiB is allocated by PyTorch, and 37.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9b7f75bc,"{'temperature_head': 0.6000000000000001, 'latent_dim': 470, 'batch_size': 202, 'transform_funcs': (2, 8, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 278.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 62.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 802.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1008.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 476.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 770.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.01 MiB is allocated by PyTorch, and 292.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cddcd79a,"{'temperature_head': 0.1, 'latent_dim': 579, 'batch_size': 225, 'transform_funcs': (5, 6, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 320.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 498.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1008.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 476.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 816.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.56 MiB is allocated by PyTorch, and 33.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
a29b546f,"{'temperature_head': 0.2, 'latent_dim': 511, 'batch_size': 176, 'transform_funcs': (0, 4, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 18.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 498.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1008.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 558.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 476.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 1.05 GiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 439.44 MiB is allocated by PyTorch, and 292.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
cec876eb,"{'temperature_head': 0.1, 'latent_dim': 449, 'batch_size': 399, 'transform_funcs': (1, 3, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 152.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 780.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 662.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.00 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 540.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 403.36 MiB is allocated by PyTorch, and 36.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
c68de330,"{'temperature_head': 0.1, 'latent_dim': 543, 'batch_size': 292, 'transform_funcs': (3, 4, 5, 6)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 322.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 134.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 826.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 470.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 662.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.00 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.09 MiB is allocated by PyTorch, and 33.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
08b95ed3,"{'temperature_head': 0.2, 'latent_dim': 617, 'batch_size': 359, 'transform_funcs': (3, 5, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 366.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 172.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 896.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 420.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 512.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.04 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.67 MiB is allocated by PyTorch, and 33.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
e06541d0,"{'temperature_head': 0.1, 'latent_dim': 680, 'batch_size': 165, 'transform_funcs': (1, 4, 8, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 404.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 96.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 896.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 496.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 558.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.16 MiB is allocated by PyTorch, and 32.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
46280a24,"{'temperature_head': 0.30000000000000004, 'latent_dim': 134, 'batch_size': 278, 'transform_funcs': (0, 2, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 896.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 472.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 594.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.13 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 214.89 MiB is allocated by PyTorch, and 39.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
e72117ab,"{'temperature_head': 0.1, 'latent_dim': 362, 'batch_size': 208, 'transform_funcs': (0, 1, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 60.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 944.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 450.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 638.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.09 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.67 MiB is allocated by PyTorch, and 35.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
b28526d8,"{'temperature_head': 0.2, 'latent_dim': 85, 'batch_size': 146, 'transform_funcs': (5, 7, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 52.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 50.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 944.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 460.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 590.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.09 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 184.25 MiB is allocated by PyTorch, and 65.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
6b8425c8,"{'temperature_head': 0.1, 'latent_dim': 401, 'batch_size': 128, 'transform_funcs': (0, 8, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 170.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 898.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 478.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 498.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.09 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 373.55 MiB is allocated by PyTorch, and 184.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b9d24c56,"{'temperature_head': 0.30000000000000004, 'latent_dim': 521, 'batch_size': 386, 'transform_funcs': (4, 5, 10, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 148.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 942.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 502.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 498.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.09 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.97 MiB is allocated by PyTorch, and 36.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9d6be524,"{'temperature_head': 0.2, 'latent_dim': 433, 'batch_size': 404, 'transform_funcs': (2, 3, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 42.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 942.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 496.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 516.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.23 MiB is allocated by PyTorch, and 38.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
b813ab89,"{'temperature_head': 0.1, 'latent_dim': 569, 'batch_size': 154, 'transform_funcs': (0, 5, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 338.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 68.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 942.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 476.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 558.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.29 MiB is allocated by PyTorch, and 33.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
08bc201a,"{'temperature_head': 0.2, 'latent_dim': 591, 'batch_size': 170, 'transform_funcs': (0, 4, 7, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 350.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 346.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 632.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 460.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 558.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.96 MiB is allocated by PyTorch, and 154.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
ae3c5bf5,"{'temperature_head': 0.1, 'latent_dim': 660, 'batch_size': 368, 'transform_funcs': (2, 3, 4, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 144.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 676.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 560.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 664.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 512.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.01 MiB is allocated by PyTorch, and 32.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
cf3db9a7,"{'temperature_head': 0.1, 'latent_dim': 478, 'batch_size': 141, 'transform_funcs': (2, 5, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 284.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 244.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 676.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 560.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 516.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 560.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.58 MiB is allocated by PyTorch, and 38.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
422d651e,"{'temperature_head': 0.2, 'latent_dim': 459, 'batch_size': 270, 'transform_funcs': (1, 2, 6, 7)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 14.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 676.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 560.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 522.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 784.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 409.43 MiB is allocated by PyTorch, and 34.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
98b23b41,"{'temperature_head': 0.30000000000000004, 'latent_dim': 502, 'batch_size': 394, 'transform_funcs': (3, 5, 7, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 150.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 676.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 762.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 514.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 454.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 137.77 MiB is allocated by PyTorch, and 36.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
5d7f0b30,"{'temperature_head': 0.2, 'latent_dim': 209, 'batch_size': 427, 'transform_funcs': (2, 5, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 48.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 676.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 762.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.05 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 135.48 MiB is allocated by PyTorch, and 38.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f9f8baa6,"{'temperature_head': 0.4, 'latent_dim': 548, 'batch_size': 161, 'transform_funcs': (0, 2, 8, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 112.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 676.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 762.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 556.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1008.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 514.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 462.25 MiB is allocated by PyTorch, and 205.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
37015494,"{'temperature_head': 0.30000000000000004, 'latent_dim': 637, 'batch_size': 457, 'transform_funcs': (5, 6, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 378.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 678.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 756.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 558.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.03 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 510.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 139.00 MiB is allocated by PyTorch, and 31.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
aec2d4cb,"{'temperature_head': 0.2, 'latent_dim': 698, 'batch_size': 382, 'transform_funcs': (0, 3, 7, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 414.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 70.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 630.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 756.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 558.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.03 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.80 MiB is allocated by PyTorch, and 151.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
15ca6d7e,"{'temperature_head': 0.1, 'latent_dim': 600, 'batch_size': 193, 'transform_funcs': (0, 2, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 356.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 36.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 678.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 756.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 558.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 1.02 GiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 558.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 492.75 MiB is allocated by PyTorch, and 209.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
9b431d25,"{'temperature_head': 0.2, 'latent_dim': 531, 'batch_size': 169, 'transform_funcs': (0, 1, 5, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 286.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 628.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 806.00 MiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 746.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 500.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 662.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.44 MiB is allocated by PyTorch, and 149.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
9eb71b51,"{'temperature_head': 0.1, 'latent_dim': 485, 'batch_size': 128, 'transform_funcs': (1, 4, 7, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 54.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 676.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.01 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 746.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 458.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 662.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 81.64 MiB is allocated by PyTorch, and 36.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 27, in forward
    x = self.conv2(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
67a1e4e0,"{'temperature_head': 0.5, 'latent_dim': 571, 'batch_size': 372, 'transform_funcs': (2, 3, 4, 8)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 338.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 100.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 630.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.01 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 746.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 458.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 662.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.44 MiB is allocated by PyTorch, and 151.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
d96c6198,"{'temperature_head': 0.30000000000000004, 'latent_dim': 143, 'batch_size': 362, 'transform_funcs': (0, 1, 8, 9)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 72.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 680.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.01 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 746.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 500.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 598.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 219.50 MiB is allocated by PyTorch, and 38.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 31, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
f91adad7,"{'temperature_head': 0.2, 'latent_dim': 23, 'batch_size': 185, 'transform_funcs': (0, 2, 4, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 56.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 8.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 680.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.01 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 748.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 512.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 648.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 134.02 MiB is allocated by PyTorch, and 37.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 28, in forward
    x = self.relu(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 101, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1471, in relu
    result = torch.relu(input)
"
418dd551,"{'temperature_head': 0.2, 'latent_dim': 467, 'batch_size': 230, 'transform_funcs': (2, 8, 9, 11)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 278.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 126.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 680.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.01 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 748.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 498.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 544.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 136.99 MiB is allocated by PyTorch, and 67.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
2c54d984,"{'temperature_head': 0.30000000000000004, 'latent_dim': 583, 'batch_size': 178, 'transform_funcs': (1, 2, 9, 10)}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 346.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 318.25 MiB is free. Process 3320861 has 564.00 MiB memory in use. Process 110619 has 680.00 MiB memory in use. Process 110622 has 1.36 GiB memory in use. Process 110650 has 1.12 GiB memory in use. Process 110652 has 936.00 MiB memory in use. Process 110624 has 724.00 MiB memory in use. Process 113908 has 1.03 GiB memory in use. Process 113906 has 884.00 MiB memory in use. Process 113907 has 1.13 GiB memory in use. Process 113903 has 1.56 GiB memory in use. Process 113909 has 784.00 MiB memory in use. Process 114323 has 1.04 GiB memory in use. Process 114327 has 720.00 MiB memory in use. Process 114326 has 1.01 GiB memory in use. Process 114325 has 848.00 MiB memory in use. Process 114324 has 510.00 MiB memory in use. Process 114709 has 1.13 GiB memory in use. Process 114710 has 1004.00 MiB memory in use. Process 114711 has 838.00 MiB memory in use. Process 114717 has 498.00 MiB memory in use. Process 114714 has 794.00 MiB memory in use. Process 115104 has 590.00 MiB memory in use. Process 115097 has 1.02 GiB memory in use. Process 115103 has 940.00 MiB memory in use. Process 115098 has 1.14 GiB memory in use. Process 115139 has 720.00 MiB memory in use. Of the allocated memory 138.40 MiB is allocated by PyTorch, and 31.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/experiment_executor/ray_tune_search_/basic/do_reduce.py"", line 144, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/transforms/simcrl_full.py"", line 57, in transform
    embeddings = intermediate_model(test_data).cpu().detach().numpy()

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/librep/estimators/simcrl/torch/models/model_base.py"", line 30, in forward
    x = self.conv3(x)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1527, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)

  File ""/home/amparo/unicamp_hyper3/M4-Framework-Experiments/experiments/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py"", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
"
